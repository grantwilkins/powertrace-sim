{"date": "20251017-191435", "backend": "vllm", "model_id": "meta-llama/Llama-3.1-70B-Instruct", "tokenizer_id": "meta-llama/Llama-3.1-70B-Instruct", "num_prompts": 19, "tensor_parallel_size": 4, "request_rate": 0.0625, "burstiness": 1.0, "max_concurrency": null, "duration": 405.7910458460001, "completed": 18, "total_input_tokens": 116308, "total_output_tokens": 154, "request_throughput": 0.04435780479698189, "request_goodput:": null, "output_throughput": 0.3795056632630673, "total_token_throughput": 286.99992568145024, "input_lens": [13911, 3103, 5864, 16384, 15588, 681, 5682, 1691, 22106, 3138, 2341, 9894, 4615, 2284, 3255, 2884, 10337, 11837, 2819], "output_lens": [2, 6, 7, 13, 2, 71, 1, 1, 0, 1, 4, 10, 4, 2, 1, 17, 2, 3, 7], "ttfts": [0.06695064100040327, 0.24504348499976913, 0.45149682899955224, 1.3849508780003816, 1.277834053999868, 0.0822963950004123, 0.41801990699968883, 0.146388750999904, 0.0, 0.2501245640005436, 0.18420808500013663, 0.7846752499999639, 0.3627767550005956, 0.18379819900019356, 0.25919616800001677, 0.23052294100034487, 0.8852806979994057, 0.9116061330005323, 0.22692122799981007], "itls": [[0.015142108999498305], [0.015507051999520627, 0.015954176999912306, 0.016187990000616992, 0.015792700999554654, 0.016495054999722925], [0.015514642000198364, 0.01612751799984835, 0.01653487099974882, 0.01601881599981425, 0.016108233000522887, 0.016552313999454782], [0.01442616900021676, 0.016614610999567958, 0.01634359299987409, 0.01675166899985925, 0.016442807000203175, 0.016694375000042783, 0.016464557999825047, 0.016377855999962776, 0.01663617900067038, 0.01663630999973975, 0.016512199999851873, 0.01660094900034892], [0.014588571999411215], [0.015046192999761843, 0.01604214500002854, 0.015524879000622605, 0.015961104999405507, 0.015671996000492072, 0.015548942999885185, 0.016409073999966495, 0.015240615999573492, 0.016368949000025168, 0.015529958000115585, 0.015763946000333817, 0.01628717399944435, 0.015487882000343234, 0.01600553000025684, 0.015801827999894158, 0.015456838999853062, 0.01588789299967175, 0.015641003000382625, 0.01576427599957242, 0.015868101000705792, 0.015609914999913599, 0.015889149000031466, 0.0157937909998509, 0.015119804999812914, 0.016246158000285504, 0.015365098000074795, 0.01587667799958581, 0.015519990000029793, 0.015670278000470717, 0.01569450799979677, 0.01585597899975255, 0.01592869799969776, 0.01523326200003794, 0.016142518000378914, 0.015580080000290764, 0.015407203999529884, 0.015804243000275164, 0.015919720999590936, 0.015681095000218193, 0.015438022000125784, 0.016163321000021824, 0.01580647199989471, 0.01501650000045629, 0.016440694999801053, 0.01525311299974419, 0.016020363999814435, 0.015599850999933551, 0.01596915100071783, 0.015262499999153079, 0.016411907000474457, 0.015617791000295256, 0.015562724999654165, 0.01588607499979844, 0.01547860499977105, 0.015847536000364926, 0.015476010999918799, 0.01618443600000319, 0.015683996000007028, 0.01545624200025486, 0.016185679999580316, 0.015804788999957964, 0.015529421000792354, 0.015867579999394366, 0.015898079000180587, 0.015026815999590326, 0.016265304000626202, 0.015969297999617993, 0.015459573000043747, 0.015896312999757356, 0.015920495000500523], [], [], [], [], [0.015366665999863471, 0.01609531899975991, 0.016346436999810976], [0.01465917299992725, 0.016333123000549676, 0.016223711999373336, 0.016538794000553025, 0.01639859399983834, 0.016347984000276483, 0.01638529199954064, 0.01635766799972771, 0.016635607999887725], [0.015457753999726265, 0.01575307300026907, 0.01673632700021699], [0.015565879999485333], [], [0.01497544799985917, 0.5610269370008609, 0.22972703899995395, 0.01654108200000337, 0.01597045599919511, 0.01637336900057562, 0.016672249999828637, 0.016260778999821923, 0.015760451999994984, 0.01635452200025611, 0.015749152999887883, 0.01608743399992818, 0.015973859000041557, 0.015964295000230777, 0.015761814000143204, 0.016364031999728468], [0.01584767200074566], [0.01518297800066648, 0.017166603000077885], [0.015810674999556795, 0.01603096600047138, 0.016000997999981337, 0.016162533999704465, 0.015988625999852957, 0.01625971599969489]], "generated_texts": ["\ufffd.", "\ufffd_HOMESCREEN", "\ufffd_LIST\ufffd_LIST", "ventually\t\t\ufffd_HPPROPERTY\ufffd_HPP", "", "\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_", "\t", "", "", "", "\u0435\u0440\u0435\u043c\u0435\u043d", "stry\ufffd_id\ufffd_id\ufffd_id", "witcher\ufffd_", "<|", "", "es\t\t<|reserved_special_token_96|>I apologize, but it", "\ufffd_", "\ufffd.scal", "\ufffd_\ufffd_\ufffd_"], "errors": ["", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", ""], "request_timestamps": [1760728069.3149133, 1760728078.6265357, 1760728140.905769, 1760728148.062875, 1760728158.5632534, 1760728177.2130282, 1760728211.245533, 1760728251.3368423, 1760728268.594448, 1760728300.6773164, 1760728312.0902944, 1760728351.885119, 1760728392.563677, 1760728393.9558043, 1760728399.1667078, 1760728399.3374658, 1760728428.9271922, 1760728445.5892954], "mean_ttft_ms": 464.00505338897347, "median_ttft_ms": 254.6603660002802, "std_ttft_ms": 395.18074468382946, "p99_ttft_ms": 1366.741017920294, "mean_tpot_ms": 19.229064125052158, "median_tpot_ms": 15.984802366680622, "std_tpot_ms": 12.279277422988987, "p99_tpot_ms": 57.349977042692856, "mean_itl_ms": 21.487393970573976, "median_itl_ms": 15.908899999885762, "std_itl_ms": 49.902164254505436, "p99_itl_ms": 155.33088639999855}