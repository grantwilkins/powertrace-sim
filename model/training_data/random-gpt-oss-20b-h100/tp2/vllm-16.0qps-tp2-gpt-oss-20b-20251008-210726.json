{
  "date": "20251008-210726",
  "backend": "vllm",
  "model_id": "openai/gpt-oss-20b",
  "tokenizer_id": "openai/gpt-oss-20b",
  "num_prompts": 9600,
  "tensor_parallel_size": 2,
  "request_rate": 16.0,
  "burstiness": 1.0,
  "max_concurrency": null,
  "duration": 673.3476411760003,
  "completed": 8411,
  "total_input_tokens": 33037563,
  "total_output_tokens": 120937,
  "request_throughput": 12.491318726995473,
  "request_goodput:": null,
  "output_throughput": 179.60558945269904,
  "total_token_throughput": 49244.25062526209,
  "input_lens": [
    13911,
    3103,
    5864,
    16384,
    14946,
    681,
    5682,
    1691,
    1783,
    3138,
    2341,
    17622,
    15168,
    2284,
    3255,
    2884,
    10337,
    1594,
    2819,
    10438,
    120,
    4100,
    5171,
    883,
    16384,
    403,
    2101,
    1626,
    10786,
    10059,
    2369,
    3028,
    752,
    226,
    46575,
    2373,
    7733,
    7499,
    1304,
    1432,
    630,
    419,
    305,
    16384,
    1140,
    1234,
    503,
    4699,
    338,
    1581,
    746,
    3058,
    1139,
    545,
    20821,
    3200,
    2149,
    2786,
    994,
    1340,
    953,
    1345,
    816,
    299,
    2428,
    1284,
    332,
    3324,
    11222,
    2115,
    4455,
    2302,
    6997,
    513,
    3110,
    940,
    766,
    1057,
    1418,
    11855,
    554,
    5382,
    3335,
    368,
    10270,
    16082,
    23414,
    1639,
    615,
    6373,
    1282,
    7667,
    2512,
    5850,
    2957,
    4346,
    2021,
    14249,
    18247,
    3109,
    15858,
    453,
    493,
    5804,
    549,
    16384,
    1267,
    878,
    16384,
    10183,
    16858,
    5413,
    774,
    28158,
    1488,
    4830,
    5664,
    1684,
    11156,
    11226,
    3023,
    596,
    2774,
    8595,
    930,
    32759,
    1238,
    15278,
    4186,
    3128,
    856,
    3616,
    951,
    18361,
    992,
    4205,
    3767,
    1589,
    3089,
    600,
    387,
    3240,
    2400,
    4017,
    16384,
    5647,
    24658,
    6827,
    469,
    1202,
    1853,
    13156,
    880,
    805,
    1793,
    963,
    6900,
    609,
    565,
    1234,
    1155,
    16384,
    5678,
    2200,
    519,
    5058,
    664,
    365,
    7382,
    2831,
    5502,
    2837,
    5128,
    976,
    640,
    4229,
    825,
    11612,
    1210,
    2036,
    1353,
    440,
    984,
    173,
    3974,
    343,
    592,
    2116,
    885,
    10908,
    481,
    2680,
    10159,
    552,
    3553,
    1654,
    4670,
    4943,
    17704,
    8692,
    1331,
    1535,
    6698,
    4108,
    4040,
    337,
    28870,
    887,
    2718,
    10543,
    5438,
    2832,
    4745,
    1196,
    707,
    1272,
    1961,
    3032,
    16384,
    1907,
    698,
    1365,
    41865,
    3393,
    366,
    2142,
    2373,
    2579,
    1035,
    1538,
    417,
    1161,
    1099,
    3157,
    560,
    4718,
    10341,
    205,
    3193,
    4207,
    991,
    1290,
    13486,
    1440,
    1422,
    316,
    7097,
    6552,
    816,
    398,
    3544,
    1060,
    2335,
    1406,
    4275,
    4290,
    899,
    436,
    350,
    3910,
    18419,
    1144,
    1036,
    1885,
    237,
    2459,
    3555,
    2202,
    1419,
    2224,
    13716,
    94,
    16384,
    3068,
    974,
    1299,
    13929,
    1758,
    10986,
    16384,
    1769,
    6137,
    933,
    10829,
    2737,
    3903,
    632,
    7572,
    4267,
    8366,
    1001,
    1177,
    16384,
    622,
    1720,
    6978,
    2224,
    3794,
    12532,
    3002,
    16115,
    12381,
    1754,
    945,
    4158,
    1203,
    460,
    454,
    4286,
    1676,
    1724,
    6538,
    578,
    894,
    1308,
    2216,
    1907,
    1457,
    1867,
    1775,
    905,
    817,
    2702,
    749,
    13960,
    1417,
    1680,
    16384,
    920,
    5639,
    4545,
    540,
    4677,
    543,
    13093,
    31740,
    289,
    3281,
    941,
    12400,
    6472,
    10059,
    937,
    525,
    1230,
    1467,
    1337,
    2374,
    3775,
    2935,
    862,
    410,
    8964,
    17291,
    975,
    1126,
    263,
    1181,
    1178,
    3953,
    4308,
    2006,
    5569,
    2904,
    1964,
    2385,
    1620,
    1294,
    1488,
    577,
    2720,
    670,
    5043,
    1518,
    2110,
    3439,
    4054,
    355,
    1591,
    5261,
    308,
    3059,
    167,
    15854,
    22851,
    19312,
    675,
    395,
    12245,
    2393,
    3729,
    1564,
    1354,
    337,
    1449,
    864,
    5134,
    7010,
    10029,
    5104,
    1034,
    585,
    4643,
    2956,
    285,
    2954,
    4895,
    11724,
    1630,
    821,
    406,
    4819,
    1422,
    1545,
    13440,
    4242,
    3004,
    2336,
    10635,
    13247,
    5555,
    3791,
    199,
    2289,
    1731,
    2215,
    5638,
    98,
    1068,
    2688,
    11066,
    10247,
    5197,
    11902,
    686,
    2825,
    4933,
    2009,
    12961,
    2177,
    14121,
    558,
    17597,
    2474,
    5236,
    1760,
    3304,
    691,
    844,
    1769,
    626,
    13146,
    3325,
    2716,
    2900,
    16384,
    1193,
    177,
    2487,
    1890,
    1130,
    680,
    1232,
    2439,
    1149,
    16384,
    694,
    835,
    161,
    2634,
    217,
    1103,
    1475,
    915,
    13531,
    24533,
    8527,
    756,
    6915,
    3448,
    4668,
    16533,
    735,
    1252,
    5160,
    107,
    10558,
    3671,
    1900,
    2546,
    20111,
    1359,
    6703,
    8331,
    16384,
    1842,
    10552,
    1134,
    652,
    1834,
    24449,
    1924,
    6674,
    1544,
    1363,
    10739,
    331,
    356,
    546,
    8362,
    5349,
    9067,
    461,
    229,
    966,
    2424,
    3458,
    6328,
    2731,
    13587,
    1564,
    731,
    314,
    751,
    2607,
    751,
    5599,
    9448,
    12614,
    5169,
    170,
    3107,
    7687,
    2145,
    488,
    1049,
    1498,
    1635,
    1598,
    1770,
    2527,
    528,
    1531,
    10615,
    1308,
    1226,
    6542,
    119,
    19960,
    997,
    2393,
    2221,
    5634,
    1488,
    947,
    8330,
    148,
    2043,
    453,
    864,
    11868,
    1902,
    2476,
    281,
    896,
    2480,
    11183,
    3938,
    2017,
    3567,
    3291,
    267,
    2081,
    4650,
    3823,
    1339,
    823,
    583,
    1729,
    6949,
    233,
    966,
    570,
    4738,
    1086,
    1190,
    1573,
    3261,
    1297,
    70,
    3632,
    3238,
    1569,
    606,
    2942,
    3032,
    1191,
    1574,
    718,
    11064,
    363,
    3162,
    707,
    15298,
    425,
    1044,
    1769,
    321,
    2268,
    12270,
    293,
    476,
    3887,
    5351,
    1728,
    3118,
    2556,
    2871,
    8222,
    380,
    4205,
    1312,
    1561,
    1432,
    1322,
    518,
    2444,
    12557,
    1878,
    1995,
    938,
    1755,
    3336,
    1329,
    1212,
    3113,
    727,
    2637,
    4926,
    8919,
    1809,
    8994,
    6234,
    667,
    523,
    1428,
    6197,
    1845,
    1032,
    11020,
    2739,
    155,
    2832,
    3540,
    17251,
    15228,
    1855,
    10731,
    1329,
    706,
    716,
    498,
    3287,
    2225,
    1220,
    978,
    1947,
    6549,
    220,
    3024,
    1096,
    251,
    235,
    732,
    2543,
    3079,
    10663,
    6116,
    9559,
    3089,
    1042,
    6883,
    4586,
    5188,
    970,
    88,
    16384,
    339,
    1921,
    16384,
    2874,
    5676,
    382,
    282,
    1112,
    6633,
    13599,
    833,
    2484,
    6569,
    407,
    527,
    839,
    6661,
    2587,
    16384,
    5597,
    1922,
    8035,
    2521,
    920,
    4221,
    928,
    1451,
    8608,
    1787,
    825,
    1198,
    26668,
    1088,
    1305,
    1139,
    2446,
    1307,
    11549,
    753,
    716,
    7845,
    4885,
    3812,
    1146,
    814,
    1143,
    628,
    16384,
    169,
    3716,
    486,
    1781,
    673,
    547,
    570,
    13773,
    1726,
    860,
    3682,
    2021,
    4411,
    268,
    2790,
    4674,
    321,
    3271,
    12910,
    1965,
    4932,
    4178,
    917,
    2087,
    356,
    1216,
    2676,
    4426,
    2053,
    4411,
    593,
    1786,
    2041,
    11013,
    1578,
    1154,
    2045,
    727,
    2470,
    1337,
    10182,
    1873,
    1409,
    331,
    1855,
    10283,
    3545,
    10042,
    456,
    3376,
    2352,
    3575,
    3180,
    447,
    1909,
    868,
    1891,
    744,
    8465,
    776,
    743,
    12862,
    611,
    1252,
    801,
    9436,
    4742,
    1875,
    30008,
    5625,
    3120,
    3455,
    1941,
    311,
    1765,
    10997,
    4062,
    6081,
    968,
    25343,
    13486,
    958,
    12709,
    782,
    2049,
    1973,
    11866,
    795,
    1042,
    958,
    2863,
    2872,
    16384,
    9028,
    1140,
    2856,
    5983,
    2066,
    1850,
    2114,
    5187,
    785,
    1396,
    3352,
    2814,
    2600,
    12103,
    5824,
    16384,
    3124,
    1615,
    4588,
    1104,
    875,
    2071,
    116,
    25652,
    10317,
    450,
    641,
    1235,
    327,
    1278,
    1108,
    2054,
    7112,
    2415,
    2045,
    2229,
    2566,
    653,
    1761,
    2806,
    442,
    5178,
    6565,
    997,
    1532,
    760,
    4312,
    11848,
    1564,
    776,
    10090,
    277,
    8596,
    15035,
    2134,
    29750,
    864,
    752,
    5597,
    18938,
    12826,
    827,
    980,
    3359,
    5560,
    1647,
    418,
    16384,
    778,
    366,
    16384,
    1281,
    400,
    942,
    2993,
    10546,
    782,
    14838,
    1125,
    542,
    5748,
    8621,
    813,
    427,
    6207,
    210,
    11307,
    5791,
    24251,
    1494,
    2945,
    1689,
    478,
    8132,
    8582,
    2504,
    2099,
    16384,
    1474,
    10943,
    2983,
    18922,
    11522,
    1503,
    2805,
    438,
    12499,
    792,
    660,
    12704,
    835,
    1113,
    2988,
    8329,
    3392,
    16384,
    1840,
    2656,
    2705,
    9687,
    3491,
    1758,
    704,
    2614,
    9334,
    1272,
    3575,
    2619,
    5166,
    824,
    16384,
    489,
    1336,
    5607,
    2769,
    4979,
    1157,
    1840,
    2025,
    11228,
    4270,
    4799,
    969,
    5800,
    14209,
    9210,
    16384,
    1425,
    1278,
    772,
    34677,
    1312,
    2967,
    1704,
    1342,
    6444,
    712,
    3217,
    1278,
    4432,
    9170,
    1431,
    3245,
    2432,
    829,
    22275,
    2746,
    3146,
    1606,
    2216,
    565,
    1347,
    3683,
    16069,
    1255,
    2242,
    2567,
    2493,
    3622,
    25398,
    1892,
    2599,
    664,
    12599,
    2386,
    11156,
    837,
    736,
    2557,
    315,
    2531,
    2223,
    23294,
    10880,
    1262,
    15069,
    13141,
    836,
    632,
    605,
    6829,
    1129,
    872,
    2324,
    1591,
    947,
    4579,
    16386,
    5906,
    4645,
    3111,
    283,
    12533,
    2785,
    3900,
    6812,
    9669,
    3166,
    3226,
    1033,
    2072,
    780,
    905,
    747,
    1683,
    11926,
    16384,
    2461,
    453,
    8034,
    17817,
    966,
    2517,
    510,
    2552,
    1813,
    2226,
    3039,
    2152,
    2034,
    2731,
    3155,
    642,
    17658,
    1867,
    413,
    2200,
    18560,
    3896,
    630,
    775,
    2867,
    1285,
    1410,
    3852,
    14167,
    1285,
    828,
    634,
    778,
    19346,
    2115,
    759,
    1549,
    329,
    891,
    16384,
    1809,
    4468,
    1859,
    2930,
    4144,
    592,
    1931,
    11347,
    832,
    1071,
    1424,
    2686,
    3559,
    8055,
    3461,
    1866,
    7983,
    4335,
    385,
    16384,
    14001,
    1660,
    3028,
    8576,
    1653,
    4462,
    6734,
    654,
    1030,
    5505,
    3317,
    5520,
    1727,
    1454,
    221,
    566,
    2104,
    4949,
    3584,
    1735,
    1481,
    2537,
    2177,
    9367,
    2347,
    391,
    492,
    10621,
    550,
    11233,
    1487,
    1657,
    1724,
    7658,
    1616,
    1926,
    370,
    2508,
    3583,
    2599,
    9299,
    2123,
    2776,
    12250,
    363,
    14146,
    9592,
    5595,
    4214,
    4993,
    12308,
    12025,
    3027,
    2601,
    2379,
    2470,
    559,
    4664,
    1731,
    14825,
    1838,
    3174,
    2620,
    14776,
    5951,
    16245,
    1965,
    1435,
    1352,
    249,
    1643,
    2633,
    6375,
    5744,
    1263,
    1473,
    6879,
    1651,
    1140,
    9244,
    10428,
    2039,
    1039,
    218,
    11251,
    745,
    230,
    11422,
    4075,
    570,
    525,
    5208,
    18527,
    8314,
    3936,
    35351,
    3118,
    2466,
    5263,
    1212,
    2196,
    4569,
    3711,
    536,
    1152,
    2638,
    1275,
    14074,
    1296,
    1671,
    4658,
    2874,
    1703,
    869,
    21936,
    6266,
    3384,
    45106,
    13500,
    406,
    19817,
    5748,
    2561,
    1091,
    15060,
    16384,
    22500,
    3596,
    2834,
    33217,
    3619,
    4472,
    1322,
    1449,
    294,
    846,
    2692,
    6307,
    3862,
    1373,
    497,
    94,
    7093,
    1045,
    46983,
    2309,
    425,
    1359,
    16384,
    3483,
    2966,
    350,
    16384,
    417,
    16384,
    195,
    9375,
    11847,
    806,
    3180,
    3649,
    816,
    10879,
    468,
    3623,
    1819,
    1074,
    5787,
    3494,
    29555,
    533,
    3553,
    1106,
    2228,
    11315,
    3472,
    773,
    2384,
    700,
    11723,
    1077,
    2509,
    2803,
    2380,
    231,
    34251,
    1214,
    10221,
    1717,
    697,
    453,
    1284,
    1193,
    3512,
    11913,
    3877,
    1038,
    1507,
    1362,
    845,
    3974,
    816,
    1125,
    1843,
    479,
    1397,
    913,
    1303,
    1870,
    26139,
    1568,
    8429,
    1942,
    7042,
    2925,
    4682,
    852,
    2242,
    2315,
    1018,
    808,
    387,
    10360,
    685,
    8785,
    1194,
    773,
    3963,
    997,
    3734,
    1385,
    3389,
    688,
    4986,
    3417,
    726,
    16384,
    11770,
    16384,
    11617,
    1623,
    1269,
    1282,
    266,
    929,
    2621,
    10705,
    854,
    5272,
    503,
    1048,
    14986,
    3007,
    3304,
    5759,
    4665,
    2610,
    3069,
    11468,
    1139,
    4685,
    273,
    3141,
    1174,
    2003,
    6273,
    2394,
    5290,
    13175,
    3065,
    7245,
    16359,
    1980,
    1124,
    6293,
    3151,
    1143,
    2368,
    6283,
    1913,
    703,
    2310,
    226,
    4654,
    1257,
    1192,
    5235,
    445,
    13663,
    1178,
    1123,
    6144,
    4357,
    16384,
    1583,
    1750,
    392,
    1386,
    903,
    1219,
    293,
    12415,
    420,
    91,
    540,
    1028,
    564,
    6688,
    1717,
    2054,
    3910,
    2736,
    5863,
    589,
    1094,
    4157,
    122,
    18002,
    3467,
    1178,
    5595,
    4866,
    534,
    3125,
    7494,
    30313,
    681,
    5257,
    4019,
    3629,
    4391,
    74,
    5266,
    14602,
    3230,
    12316,
    36728,
    2898,
    48988,
    2001,
    859,
    661,
    666,
    441,
    18838,
    13868,
    4580,
    1004,
    10130,
    2261,
    971,
    10575,
    4700,
    1921,
    2891,
    5298,
    1481,
    19381,
    1421,
    1936,
    1397,
    1116,
    2418,
    3726,
    2347,
    3458,
    887,
    531,
    3161,
    4258,
    2110,
    8802,
    5423,
    16384,
    1602,
    665,
    885,
    17618,
    3373,
    13355,
    8521,
    1535,
    1523,
    12400,
    1762,
    2027,
    1747,
    2901,
    1044,
    11084,
    3652,
    2227,
    2482,
    6405,
    648,
    779,
    7966,
    391,
    473,
    4913,
    2596,
    2243,
    1806,
    2068,
    1805,
    8874,
    1289,
    1673,
    14384,
    2059,
    16384,
    1780,
    43048,
    323,
    2366,
    349,
    5058,
    526,
    2730,
    1464,
    558,
    14625,
    1138,
    13557,
    1446,
    5480,
    1876,
    5241,
    12275,
    1282,
    5677,
    1669,
    1816,
    1244,
    7074,
    2771,
    2097,
    4053,
    3816,
    2524,
    13192,
    1869,
    2713,
    985,
    2356,
    11459,
    46986,
    574,
    5981,
    1696,
    2220,
    1901,
    2179,
    5092,
    793,
    656,
    2193,
    341,
    441,
    15573,
    4597,
    1976,
    7799,
    636,
    1412,
    3967,
    5322,
    3512,
    122,
    688,
    3377,
    1350,
    16384,
    5537,
    3691,
    584,
    1922,
    2605,
    6908,
    5267,
    6224,
    723,
    9446,
    16525,
    1108,
    3209,
    1694,
    660,
    809,
    38779,
    3587,
    7995,
    1789,
    1286,
    395,
    5456,
    16384,
    276,
    620,
    946,
    1074,
    2565,
    11797,
    6059,
    3570,
    901,
    583,
    831,
    10969,
    1866,
    1222,
    1632,
    4949,
    471,
    18221,
    2373,
    1575,
    3252,
    15155,
    1368,
    1513,
    12258,
    4113,
    1112,
    13900,
    16203,
    8621,
    1894,
    1023,
    3115,
    16384,
    404,
    3042,
    2503,
    7170,
    5943,
    1627,
    313,
    21792,
    19459,
    705,
    7066,
    733,
    9349,
    10052,
    2838,
    2801,
    329,
    283,
    2532,
    3732,
    2188,
    809,
    2040,
    1825,
    697,
    6095,
    297,
    3818,
    3049,
    6067,
    10785,
    2233,
    16384,
    4139,
    2231,
    3615,
    2196,
    16384,
    5895,
    1818,
    14465,
    1300,
    7561,
    425,
    341,
    9942,
    16384,
    3344,
    13949,
    19196,
    980,
    2412,
    2085,
    3980,
    360,
    1143,
    5061,
    17572,
    670,
    16384,
    28010,
    1057,
    310,
    4457,
    4311,
    1438,
    594,
    1944,
    796,
    708,
    1783,
    628,
    2621,
    3900,
    793,
    10444,
    11130,
    710,
    966,
    2525,
    3863,
    1507,
    3317,
    1285,
    20953,
    9594,
    16384,
    12907,
    2335,
    15014,
    2955,
    1182,
    3337,
    1801,
    677,
    743,
    4828,
    262,
    3883,
    332,
    193,
    264,
    16384,
    1610,
    20531,
    9520,
    5583,
    432,
    5197,
    2446,
    1372,
    2052,
    35155,
    754,
    3105,
    1977,
    276,
    826,
    2471,
    8325,
    6011,
    3854,
    815,
    14491,
    2531,
    660,
    1634,
    5355,
    2015,
    5300,
    6728,
    10569,
    777,
    2319,
    2099,
    15448,
    333,
    1722,
    1050,
    2888,
    136,
    6811,
    2028,
    262,
    23108,
    3904,
    12639,
    2005,
    624,
    1084,
    2057,
    2444,
    1190,
    2697,
    4913,
    1470,
    9650,
    9980,
    1246,
    990,
    320,
    1738,
    1339,
    4707,
    379,
    1472,
    5800,
    894,
    863,
    406,
    16384,
    878,
    478,
    825,
    852,
    1485,
    13099,
    1439,
    724,
    404,
    35705,
    2093,
    10764,
    2212,
    1792,
    629,
    1427,
    23571,
    1329,
    695,
    3612,
    1708,
    1602,
    303,
    3439,
    3414,
    793,
    5938,
    445,
    12205,
    1482,
    469,
    2461,
    13001,
    17154,
    1200,
    3267,
    2244,
    2060,
    1251,
    9548,
    3301,
    1117,
    1774,
    884,
    1023,
    987,
    573,
    4698,
    1450,
    3675,
    956,
    10237,
    914,
    4410,
    1520,
    894,
    328,
    2706,
    916,
    1963,
    1163,
    5707,
    3635,
    3267,
    1014,
    3337,
    13178,
    799,
    2415,
    325,
    9306,
    1289,
    4726,
    300,
    14433,
    1349,
    3641,
    2358,
    1508,
    12763,
    326,
    2775,
    5440,
    1933,
    14970,
    1707,
    517,
    2083,
    3512,
    2154,
    1481,
    1165,
    1469,
    7970,
    12330,
    2088,
    1393,
    9910,
    2123,
    10233,
    193,
    3312,
    2719,
    10245,
    328,
    1684,
    2148,
    37650,
    7617,
    1376,
    16384,
    6371,
    5686,
    3696,
    620,
    18531,
    3751,
    4210,
    8416,
    1194,
    775,
    5141,
    820,
    11244,
    7477,
    3300,
    1348,
    2090,
    3838,
    2020,
    16384,
    672,
    663,
    682,
    1044,
    11950,
    999,
    973,
    2178,
    3163,
    510,
    5377,
    14508,
    1589,
    11291,
    2487,
    16384,
    6829,
    357,
    2039,
    6372,
    2066,
    1918,
    8076,
    13437,
    2037,
    2852,
    1384,
    1954,
    4686,
    3216,
    820,
    593,
    838,
    2000,
    1675,
    800,
    1034,
    375,
    3164,
    1912,
    499,
    2062,
    8750,
    885,
    8490,
    1399,
    2483,
    2225,
    12676,
    2378,
    569,
    472,
    370,
    303,
    2102,
    696,
    1828,
    921,
    855,
    1177,
    4332,
    5552,
    3005,
    672,
    4056,
    4263,
    2702,
    1028,
    4357,
    3181,
    64,
    4059,
    243,
    4146,
    1686,
    7427,
    1793,
    18169,
    1699,
    6411,
    2056,
    1762,
    4527,
    2518,
    1985,
    8979,
    24511,
    3923,
    1458,
    10369,
    7342,
    4406,
    524,
    2332,
    881,
    10431,
    2602,
    2230,
    1184,
    8105,
    309,
    18981,
    10259,
    3043,
    753,
    5250,
    2197,
    2624,
    651,
    972,
    2509,
    3796,
    16384,
    2553,
    5846,
    360,
    462,
    1351,
    11061,
    13155,
    1272,
    9139,
    10254,
    2094,
    10113,
    1878,
    3612,
    3400,
    1744,
    3482,
    13307,
    4377,
    2859,
    2292,
    655,
    645,
    2851,
    443,
    860,
    8181,
    16384,
    319,
    11959,
    1583,
    1965,
    1763,
    6559,
    340,
    3300,
    706,
    3743,
    10906,
    1997,
    3015,
    3135,
    829,
    16009,
    13057,
    4324,
    2165,
    10396,
    12817,
    35591,
    9469,
    11989,
    351,
    88,
    606,
    1730,
    9327,
    975,
    3481,
    8379,
    2301,
    14317,
    17850,
    532,
    3158,
    1601,
    2286,
    1896,
    4148,
    842,
    1381,
    16087,
    829,
    1465,
    1044,
    3259,
    6152,
    1155,
    1243,
    1470,
    19988,
    885,
    1321,
    147,
    437,
    1765,
    15334,
    2764,
    596,
    428,
    2421,
    324,
    6454,
    2143,
    341,
    690,
    900,
    853,
    388,
    763,
    941,
    913,
    6910,
    11440,
    15813,
    1382,
    759,
    1436,
    5234,
    2637,
    16384,
    3021,
    731,
    4869,
    6554,
    6658,
    14746,
    1698,
    6939,
    313,
    1153,
    13668,
    716,
    656,
    7907,
    1543,
    773,
    19550,
    2335,
    14634,
    8764,
    3463,
    413,
    1000,
    6483,
    1009,
    13467,
    596,
    3751,
    774,
    1140,
    6690,
    1737,
    4889,
    14509,
    4579,
    752,
    1565,
    3186,
    10447,
    11997,
    11950,
    1436,
    660,
    189,
    14423,
    1595,
    1220,
    1605,
    9526,
    691,
    4219,
    24809,
    1036,
    3728,
    5925,
    12392,
    857,
    552,
    6726,
    1061,
    261,
    9423,
    442,
    4709,
    2444,
    2742,
    17117,
    2987,
    319,
    3815,
    11077,
    12563,
    216,
    676,
    1625,
    3413,
    1777,
    1161,
    3846,
    7190,
    1547,
    4455,
    117,
    712,
    1403,
    1167,
    2881,
    14125,
    3488,
    1007,
    374,
    3687,
    264,
    4098,
    1624,
    548,
    13963,
    1991,
    1919,
    1821,
    3169,
    5524,
    3450,
    6083,
    1903,
    11852,
    3745,
    1098,
    599,
    2505,
    474,
    16591,
    2599,
    1023,
    715,
    1923,
    2164,
    1593,
    1319,
    5115,
    13085,
    1562,
    16384,
    2473,
    18832,
    1078,
    446,
    836,
    1488,
    1157,
    8690,
    1751,
    3319,
    1898,
    1240,
    2083,
    13166,
    858,
    4645,
    646,
    1205,
    2006,
    2861,
    22251,
    1891,
    789,
    4084,
    18759,
    2598,
    1758,
    235,
    3495,
    3796,
    5537,
    14479,
    536,
    3526,
    3134,
    1260,
    3092,
    3462,
    522,
    2619,
    727,
    975,
    283,
    1187,
    1597,
    3658,
    2000,
    366,
    11889,
    1753,
    3419,
    5782,
    9555,
    16384,
    1845,
    2813,
    610,
    13749,
    542,
    13516,
    4981,
    1125,
    4700,
    3130,
    35238,
    100,
    598,
    2034,
    521,
    974,
    401,
    2408,
    2208,
    1176,
    9290,
    10378,
    12550,
    275,
    592,
    3127,
    1000,
    1169,
    5371,
    3505,
    8480,
    13376,
    9070,
    1086,
    10398,
    2244,
    775,
    332,
    1434,
    1507,
    5132,
    1769,
    1241,
    6533,
    1560,
    1060,
    3759,
    1165,
    4124,
    1036,
    1563,
    24765,
    1324,
    1968,
    4900,
    11604,
    3391,
    993,
    5105,
    4173,
    6032,
    898,
    1652,
    4011,
    1022,
    1558,
    16384,
    16384,
    7816,
    5610,
    651,
    3511,
    1346,
    623,
    1141,
    2269,
    1094,
    1090,
    4775,
    2341,
    2583,
    2259,
    14191,
    442,
    2811,
    1143,
    218,
    1297,
    42061,
    4309,
    3546,
    3451,
    961,
    4468,
    2840,
    1273,
    1213,
    5334,
    1186,
    2790,
    6231,
    16322,
    12459,
    18756,
    381,
    936,
    1093,
    12313,
    925,
    3055,
    2232,
    714,
    3041,
    3096,
    502,
    21130,
    201,
    1043,
    5820,
    537,
    2937,
    480,
    1803,
    156,
    790,
    366,
    1284,
    1265,
    952,
    4806,
    753,
    4015,
    11994,
    2328,
    777,
    505,
    915,
    4337,
    2371,
    5599,
    4662,
    2332,
    3363,
    15379,
    9482,
    1432,
    5935,
    3806,
    6974,
    12120,
    684,
    336,
    3751,
    10041,
    851,
    1624,
    639,
    7299,
    10161,
    165,
    3018,
    1825,
    1178,
    1434,
    3607,
    1267,
    597,
    720,
    5309,
    1121,
    435,
    2235,
    3482,
    8620,
    2539,
    967,
    3365,
    4446,
    1914,
    1902,
    2660,
    1850,
    2631,
    649,
    563,
    796,
    4049,
    2656,
    6274,
    1627,
    567,
    7037,
    12500,
    8199,
    3857,
    16384,
    1569,
    14900,
    5326,
    12957,
    1652,
    400,
    363,
    2296,
    4780,
    4031,
    2904,
    5163,
    1044,
    1480,
    4497,
    3217,
    1585,
    8543,
    482,
    1129,
    1463,
    4905,
    2003,
    498,
    3517,
    6609,
    4506,
    12205,
    254,
    742,
    3395,
    1881,
    11970,
    496,
    11128,
    433,
    232,
    2766,
    5048,
    2618,
    1926,
    358,
    6043,
    1903,
    16384,
    5633,
    220,
    4585,
    16957,
    866,
    1516,
    1801,
    3094,
    648,
    563,
    3868,
    1969,
    13190,
    21085,
    1644,
    750,
    725,
    5508,
    598,
    600,
    1388,
    3279,
    755,
    7766,
    9846,
    757,
    1526,
    848,
    12544,
    26401,
    4478,
    18830,
    744,
    8689,
    8748,
    23970,
    3875,
    5221,
    16384,
    3379,
    1870,
    770,
    2795,
    6164,
    2615,
    847,
    2203,
    1733,
    2673,
    321,
    3662,
    3846,
    27986,
    1989,
    274,
    1956,
    6417,
    775,
    224,
    367,
    2822,
    3011,
    5297,
    1880,
    383,
    812,
    4918,
    2332,
    4083,
    3223,
    1594,
    1650,
    15410,
    11500,
    1734,
    3297,
    2553,
    186,
    4085,
    14809,
    846,
    9891,
    1506,
    2759,
    6485,
    905,
    7838,
    525,
    763,
    1040,
    4138,
    1373,
    375,
    1574,
    843,
    4466,
    1369,
    13875,
    1279,
    3220,
    1632,
    2857,
    115,
    2223,
    3150,
    1604,
    4172,
    4502,
    11720,
    2242,
    243,
    161,
    343,
    1916,
    1680,
    2707,
    1004,
    888,
    3679,
    4111,
    1506,
    1915,
    3117,
    20704,
    567,
    905,
    516,
    1144,
    11343,
    3644,
    597,
    3510,
    2196,
    1160,
    425,
    1648,
    4221,
    185,
    1292,
    16384,
    4187,
    2659,
    888,
    947,
    14145,
    11651,
    3334,
    765,
    7291,
    1448,
    12927,
    1071,
    662,
    2421,
    5887,
    6255,
    2380,
    673,
    1146,
    216,
    731,
    1642,
    3065,
    16773,
    1876,
    1292,
    4564,
    743,
    5020,
    16384,
    3361,
    1119,
    1107,
    7561,
    578,
    699,
    21359,
    489,
    633,
    4764,
    6717,
    928,
    2510,
    4605,
    11382,
    698,
    396,
    6072,
    3448,
    3769,
    590,
    2587,
    3991,
    2822,
    880,
    6084,
    372,
    5550,
    6562,
    11266,
    1370,
    665,
    4785,
    925,
    2097,
    1409,
    740,
    2844,
    17668,
    3833,
    689,
    297,
    1891,
    3212,
    3769,
    4915,
    150,
    661,
    2246,
    10624,
    4732,
    16179,
    1121,
    2702,
    595,
    1280,
    889,
    994,
    1296,
    2004,
    2047,
    3632,
    2330,
    1368,
    1124,
    1425,
    1219,
    3429,
    5177,
    11332,
    830,
    3348,
    430,
    3012,
    6574,
    1695,
    6502,
    571,
    751,
    1720,
    6151,
    1262,
    1213,
    671,
    2497,
    7874,
    12431,
    13569,
    1591,
    1075,
    20746,
    1929,
    1650,
    5367,
    1607,
    795,
    5432,
    2183,
    12635,
    587,
    2219,
    26320,
    12817,
    1380,
    10680,
    1876,
    406,
    354,
    7702,
    4158,
    4957,
    1875,
    898,
    13423,
    2320,
    794,
    3705,
    499,
    1385,
    1596,
    934,
    176,
    3270,
    870,
    8589,
    1371,
    1101,
    2209,
    6366,
    1075,
    14715,
    45073,
    5939,
    11957,
    8282,
    10576,
    11669,
    12551,
    1246,
    165,
    466,
    1220,
    1313,
    1689,
    664,
    345,
    1731,
    1622,
    821,
    883,
    710,
    1291,
    779,
    7989,
    2604,
    685,
    1467,
    545,
    6083,
    9160,
    7920,
    567,
    1807,
    1284,
    3707,
    659,
    950,
    1268,
    2365,
    4287,
    14935,
    4147,
    4935,
    1580,
    507,
    550,
    3831,
    1183,
    303,
    3921,
    2304,
    11175,
    13833,
    5015,
    2327,
    491,
    427,
    1425,
    303,
    3120,
    423,
    2395,
    1455,
    4371,
    712,
    2700,
    430,
    32529,
    1760,
    3447,
    467,
    3459,
    2798,
    2981,
    2818,
    1615,
    7827,
    1683,
    886,
    1873,
    702,
    1199,
    1644,
    18198,
    2488,
    16384,
    3744,
    6499,
    1148,
    1047,
    1318,
    5106,
    188,
    641,
    2236,
    1561,
    16384,
    3269,
    964,
    352,
    1373,
    476,
    3338,
    2385,
    2841,
    17276,
    736,
    37642,
    526,
    1828,
    11528,
    3735,
    10721,
    2635,
    527,
    1295,
    2194,
    25199,
    371,
    2865,
    2716,
    1319,
    2007,
    390,
    392,
    2317,
    958,
    1972,
    5031,
    1650,
    90,
    1693,
    1177,
    1543,
    5376,
    351,
    2613,
    11241,
    1003,
    3359,
    5784,
    2518,
    940,
    915,
    4528,
    3832,
    841,
    547,
    488,
    12429,
    1854,
    16384,
    10263,
    3240,
    2798,
    5997,
    690,
    16384,
    1789,
    921,
    2787,
    6644,
    659,
    3727,
    908,
    1144,
    11783,
    4628,
    589,
    2469,
    19097,
    786,
    525,
    532,
    331,
    5354,
    1531,
    2379,
    7302,
    522,
    709,
    2644,
    268,
    1057,
    722,
    2871,
    1250,
    16384,
    5606,
    781,
    1304,
    1363,
    16384,
    379,
    2499,
    201,
    1983,
    16331,
    1274,
    6734,
    1858,
    1255,
    1515,
    1047,
    1003,
    462,
    10482,
    1296,
    10888,
    17651,
    6827,
    1478,
    11684,
    267,
    3088,
    14656,
    768,
    1207,
    571,
    32299,
    2143,
    4339,
    3665,
    817,
    2559,
    1392,
    601,
    1737,
    16384,
    16384,
    2330,
    13531,
    1900,
    1884,
    234,
    694,
    843,
    2249,
    12999,
    1056,
    12711,
    1664,
    437,
    1018,
    1313,
    505,
    1389,
    797,
    7776,
    1528,
    1622,
    3199,
    3687,
    295,
    1320,
    735,
    1703,
    14074,
    2375,
    679,
    1070,
    1042,
    6573,
    2995,
    2998,
    1458,
    1308,
    3703,
    4699,
    2031,
    7015,
    8115,
    11979,
    3208,
    1906,
    3062,
    19075,
    725,
    336,
    6746,
    666,
    939,
    2502,
    939,
    346,
    2074,
    845,
    44395,
    1145,
    937,
    1586,
    6357,
    5424,
    600,
    16384,
    25849,
    562,
    5308,
    1342,
    16384,
    5075,
    1605,
    11303,
    5084,
    517,
    5309,
    1132,
    1823,
    2308,
    759,
    460,
    2994,
    433,
    117,
    796,
    2876,
    1484,
    8053,
    2445,
    860,
    1232,
    411,
    6597,
    437,
    726,
    29833,
    2003,
    382,
    737,
    2674,
    6923,
    2933,
    21365,
    358,
    1013,
    12922,
    6561,
    5315,
    2325,
    7518,
    16384,
    1039,
    863,
    10618,
    2588,
    2260,
    3076,
    972,
    640,
    16019,
    7867,
    411,
    3458,
    1081,
    1354,
    4524,
    5056,
    2913,
    254,
    11249,
    8444,
    2209,
    2020,
    14495,
    5664,
    1934,
    1448,
    1615,
    7295,
    6272,
    338,
    3331,
    5169,
    381,
    1991,
    282,
    2304,
    30370,
    943,
    1020,
    916,
    9864,
    3601,
    1287,
    715,
    11898,
    644,
    5827,
    16384,
    6364,
    2878,
    15115,
    1279,
    13627,
    1060,
    11127,
    575,
    1442,
    303,
    2380,
    497,
    12475,
    3144,
    3608,
    2726,
    600,
    2290,
    15074,
    16907,
    652,
    260,
    911,
    287,
    4981,
    4718,
    762,
    3926,
    1059,
    1900,
    3008,
    1226,
    3165,
    312,
    2273,
    1922,
    210,
    272,
    258,
    3151,
    2290,
    2700,
    464,
    6994,
    5890,
    859,
    7285,
    1516,
    283,
    331,
    4478,
    17539,
    5267,
    1813,
    2682,
    16384,
    27022,
    1241,
    3018,
    3442,
    4617,
    2160,
    1161,
    1990,
    1178,
    12729,
    7822,
    1597,
    3200,
    1665,
    7424,
    6334,
    3734,
    5210,
    4132,
    7269,
    3584,
    2361,
    1058,
    354,
    1937,
    884,
    2134,
    7006,
    2416,
    1265,
    781,
    414,
    8656,
    283,
    714,
    156,
    1411,
    1371,
    1280,
    25253,
    809,
    731,
    14759,
    1383,
    5423,
    795,
    11778,
    10568,
    2576,
    596,
    2198,
    2104,
    2600,
    681,
    374,
    2388,
    1975,
    2002,
    6182,
    394,
    6073,
    882,
    1293,
    805,
    2205,
    245,
    1069,
    1133,
    19302,
    2358,
    4294,
    2011,
    630,
    5420,
    788,
    1120,
    2441,
    5653,
    1601,
    10525,
    1065,
    4155,
    2006,
    10952,
    2529,
    11416,
    6615,
    1826,
    10977,
    7671,
    1387,
    3866,
    11684,
    796,
    14641,
    840,
    1050,
    305,
    12003,
    3095,
    2595,
    5840,
    463,
    1101,
    1806,
    363,
    8455,
    13908,
    1400,
    2591,
    873,
    2099,
    16384,
    3886,
    12520,
    1352,
    874,
    2809,
    456,
    157,
    34251,
    4045,
    5000,
    2061,
    16384,
    1815,
    1086,
    73,
    1897,
    4989,
    2013,
    6881,
    16384,
    1651,
    7741,
    349,
    6213,
    2142,
    1566,
    1669,
    1682,
    1422,
    2486,
    1649,
    560,
    3161,
    1023,
    6328,
    1925,
    2297,
    209,
    501,
    5617,
    891,
    1112,
    1471,
    8956,
    3015,
    8444,
    1488,
    2526,
    531,
    10858,
    2251,
    2097,
    2899,
    9813,
    1578,
    12448,
    783,
    3179,
    38531,
    1165,
    2616,
    5246,
    1716,
    383,
    625,
    3785,
    5327,
    4736,
    7052,
    2162,
    2512,
    14564,
    2832,
    3920,
    1052,
    4057,
    271,
    4565,
    2780,
    16384,
    9455,
    10484,
    4910,
    4069,
    544,
    1382,
    14904,
    402,
    1217,
    419,
    9858,
    1072,
    10926,
    1267,
    1147,
    8154,
    5612,
    100,
    3282,
    3866,
    2516,
    969,
    20860,
    1289,
    2521,
    1599,
    11488,
    2392,
    11363,
    2746,
    1086,
    2892,
    35330,
    15316,
    7542,
    3608,
    658,
    444,
    1599,
    424,
    842,
    1657,
    1173,
    1393,
    463,
    2577,
    5979,
    1093,
    4439,
    16384,
    1806,
    4090,
    2481,
    5805,
    301,
    29251,
    2339,
    5301,
    2306,
    320,
    807,
    833,
    3065,
    864,
    944,
    6589,
    8680,
    1268,
    3188,
    252,
    2485,
    7398,
    3566,
    28391,
    21218,
    980,
    19712,
    362,
    11748,
    3716,
    1785,
    1010,
    1849,
    4805,
    6078,
    739,
    684,
    16384,
    6976,
    4356,
    1715,
    5521,
    492,
    10774,
    1921,
    4769,
    4067,
    39029,
    1647,
    7659,
    6180,
    284,
    310,
    705,
    747,
    583,
    2695,
    1199,
    25463,
    9878,
    1936,
    12731,
    2052,
    1238,
    2145,
    5649,
    15017,
    1588,
    2771,
    2979,
    1332,
    3420,
    2755,
    1042,
    16384,
    3240,
    1388,
    1065,
    6200,
    2235,
    16384,
    1237,
    509,
    1938,
    2422,
    194,
    12497,
    1332,
    1331,
    998,
    455,
    4600,
    1051,
    648,
    866,
    1188,
    2251,
    4167,
    700,
    1179,
    454,
    64,
    13644,
    12859,
    3548,
    1143,
    2221,
    548,
    1746,
    1248,
    782,
    3121,
    14905,
    12781,
    1845,
    5284,
    5161,
    980,
    4057,
    409,
    824,
    2598,
    1266,
    11865,
    4075,
    1312,
    1190,
    2454,
    625,
    3847,
    440,
    3965,
    1667,
    3152,
    655,
    2616,
    16384,
    1208,
    2833,
    10468,
    4618,
    3213,
    655,
    490,
    2119,
    1200,
    10290,
    2505,
    949,
    3440,
    15435,
    658,
    1192,
    1892,
    7005,
    541,
    619,
    184,
    1231,
    4222,
    6449,
    2959,
    1031,
    4346,
    18664,
    241,
    517,
    10541,
    2848,
    440,
    4924,
    6422,
    1238,
    15313,
    64,
    5830,
    11162,
    579,
    2725,
    1377,
    1785,
    1252,
    461,
    15985,
    11016,
    2242,
    658,
    638,
    3145,
    3565,
    5248,
    6728,
    1585,
    1225,
    4543,
    991,
    5213,
    3016,
    7119,
    4177,
    626,
    771,
    4472,
    16281,
    466,
    2049,
    2723,
    373,
    3381,
    1803,
    199,
    11895,
    773,
    487,
    3172,
    3689,
    10553,
    1306,
    1974,
    894,
    472,
    6548,
    1784,
    1635,
    221,
    1642,
    790,
    1649,
    1570,
    11086,
    5612,
    3267,
    6904,
    465,
    978,
    1911,
    1277,
    1831,
    544,
    908,
    328,
    750,
    4288,
    1578,
    10470,
    1037,
    2277,
    526,
    16384,
    1641,
    4977,
    3148,
    1051,
    462,
    2372,
    1083,
    1684,
    4090,
    2177,
    3025,
    2356,
    397,
    9280,
    7284,
    572,
    3483,
    964,
    878,
    26350,
    13662,
    6398,
    3888,
    563,
    16384,
    5224,
    150,
    3100,
    1167,
    3136,
    3104,
    727,
    14890,
    2489,
    5627,
    8835,
    887,
    732,
    6864,
    9247,
    439,
    16384,
    1542,
    4276,
    11067,
    686,
    772,
    201,
    563,
    391,
    2088,
    9012,
    1939,
    2900,
    4702,
    4220,
    1307,
    399,
    1245,
    2141,
    766,
    2975,
    1448,
    3960,
    825,
    724,
    18308,
    2062,
    3671,
    596,
    1319,
    4231,
    11183,
    900,
    826,
    1948,
    373,
    1933,
    1860,
    4434,
    9471,
    3739,
    4517,
    2116,
    1345,
    222,
    753,
    2537,
    12191,
    2610,
    1285,
    649,
    1191,
    4454,
    5292,
    237,
    1695,
    5460,
    1504,
    2252,
    385,
    1178,
    14937,
    839,
    409,
    2355,
    4757,
    7429,
    1130,
    2552,
    3636,
    4081,
    1094,
    13147,
    14049,
    4353,
    1950,
    1047,
    985,
    1048,
    1222,
    13626,
    4303,
    921,
    1015,
    3420,
    1774,
    418,
    713,
    1609,
    1061,
    4562,
    15621,
    689,
    657,
    12662,
    3400,
    317,
    3961,
    5151,
    311,
    934,
    9621,
    6043,
    2053,
    3468,
    16384,
    3474,
    521,
    43079,
    766,
    5962,
    4112,
    5315,
    10883,
    16801,
    1850,
    16384,
    5848,
    2428,
    648,
    2247,
    732,
    397,
    3767,
    2147,
    853,
    3085,
    1147,
    14150,
    1932,
    16113,
    817,
    3923,
    15185,
    2692,
    6975,
    295,
    4349,
    19086,
    4635,
    5189,
    167,
    1226,
    956,
    2362,
    236,
    602,
    6015,
    2427,
    603,
    1512,
    6688,
    10725,
    12997,
    1552,
    2454,
    3477,
    16340,
    3674,
    1047,
    27243,
    777,
    3228,
    19039,
    6535,
    35775,
    171,
    13425,
    1047,
    8581,
    5037,
    13336,
    4788,
    977,
    4014,
    15602,
    313,
    2917,
    4349,
    7426,
    12748,
    6047,
    297,
    1325,
    1708,
    1390,
    1811,
    12638,
    4490,
    671,
    2293,
    2165,
    2340,
    704,
    9312,
    1558,
    410,
    4824,
    1990,
    1796,
    14417,
    3087,
    1884,
    853,
    419,
    2790,
    376,
    6847,
    699,
    15705,
    678,
    446,
    854,
    1462,
    154,
    135,
    909,
    5280,
    477,
    1837,
    9639,
    466,
    1233,
    882,
    5330,
    3328,
    3941,
    16384,
    11997,
    20532,
    1600,
    405,
    303,
    1892,
    478,
    3975,
    13872,
    1052,
    362,
    16384,
    4604,
    915,
    25538,
    8564,
    720,
    16272,
    642,
    1644,
    28267,
    122,
    25199,
    2195,
    296,
    328,
    7043,
    1693,
    11502,
    4024,
    1857,
    2070,
    1085,
    2225,
    1868,
    5020,
    1669,
    4943,
    10699,
    2437,
    471,
    1674,
    245,
    529,
    4462,
    3443,
    1991,
    10380,
    885,
    1136,
    5777,
    3375,
    442,
    2486,
    12405,
    12253,
    289,
    844,
    5831,
    13413,
    16384,
    546,
    2063,
    3697,
    5266,
    4388,
    1201,
    5456,
    871,
    1109,
    3302,
    10514,
    1554,
    13613,
    7560,
    497,
    15093,
    676,
    4044,
    5537,
    4738,
    2564,
    2110,
    324,
    846,
    4434,
    4145,
    637,
    2926,
    2636,
    13711,
    1261,
    1127,
    723,
    665,
    3018,
    920,
    6517,
    1002,
    10801,
    3163,
    2655,
    563,
    2869,
    2100,
    4004,
    10054,
    403,
    2704,
    2330,
    2613,
    6040,
    710,
    145,
    3369,
    3122,
    1182,
    2410,
    631,
    196,
    310,
    2093,
    11419,
    1301,
    4891,
    1039,
    1879,
    4799,
    2313,
    1101,
    771,
    1804,
    7334,
    355,
    5142,
    2729,
    10393,
    1958,
    1596,
    704,
    1103,
    13880,
    204,
    2359,
    6303,
    12048,
    588,
    16384,
    10710,
    9564,
    841,
    1076,
    23266,
    2465,
    18869,
    2387,
    797,
    28881,
    2914,
    567,
    1899,
    2732,
    33473,
    2220,
    710,
    1411,
    1930,
    1725,
    263,
    1387,
    932,
    1500,
    16384,
    799,
    9717,
    7162,
    4238,
    2005,
    4104,
    1218,
    1095,
    877,
    2700,
    1586,
    1535,
    9530,
    920,
    14318,
    1125,
    346,
    416,
    1163,
    3994,
    4047,
    1533,
    3945,
    2173,
    1498,
    5116,
    7381,
    6109,
    1425,
    3731,
    192,
    2476,
    2972,
    2361,
    1564,
    8393,
    1803,
    1713,
    1532,
    6232,
    1448,
    798,
    15728,
    13075,
    1435,
    3933,
    1471,
    1473,
    10066,
    524,
    1770,
    21605,
    11314,
    3248,
    813,
    4537,
    3292,
    9303,
    16384,
    11981,
    1297,
    1677,
    7141,
    1143,
    1712,
    4014,
    6487,
    2553,
    13934,
    2902,
    1417,
    682,
    2051,
    6853,
    576,
    11486,
    5864,
    5583,
    815,
    1515,
    1311,
    1998,
    1866,
    1409,
    17143,
    1583,
    2681,
    324,
    3412,
    12926,
    15127,
    705,
    6304,
    16384,
    1530,
    4416,
    16384,
    6206,
    11001,
    598,
    2589,
    19154,
    27011,
    4762,
    2372,
    45363,
    18333,
    3031,
    546,
    4604,
    3671,
    3607,
    1457,
    12062,
    3745,
    838,
    366,
    859,
    147,
    28176,
    2302,
    529,
    1096,
    11032,
    2248,
    10817,
    1630,
    1645,
    177,
    4456,
    6705,
    1371,
    1420,
    4887,
    888,
    845,
    2832,
    1025,
    3913,
    726,
    10513,
    4113,
    2148,
    764,
    624,
    744,
    413,
    8729,
    21079,
    6487,
    13534,
    8410,
    3276,
    1271,
    4556,
    2520,
    1500,
    1133,
    6549,
    10149,
    1476,
    1235,
    4306,
    993,
    3881,
    13502,
    1261,
    2052,
    16384,
    1325,
    2333,
    709,
    922,
    438,
    16384,
    3747,
    1899,
    624,
    268,
    2606,
    1703,
    3470,
    4279,
    6084,
    1907,
    3960,
    1276,
    783,
    1377,
    4655,
    3893,
    1970,
    2848,
    11710,
    275,
    502,
    1969,
    11851,
    1576,
    12446,
    73,
    153,
    1070,
    16384,
    1998,
    169,
    1344,
    3941,
    5758,
    3352,
    1541,
    4216,
    7108,
    1085,
    1744,
    1720,
    306,
    501,
    155,
    2192,
    1440,
    1376,
    1923,
    3537,
    953,
    7266,
    346,
    1968,
    1793,
    5089,
    1159,
    6474,
    1544,
    1786,
    1695,
    4306,
    5107,
    1027,
    424,
    679,
    2396,
    1961,
    2333,
    899,
    4794,
    1645,
    331,
    2370,
    3648,
    2340,
    2305,
    2565,
    626,
    12454,
    1395,
    10031,
    1086,
    5786,
    2602,
    2231,
    711,
    7528,
    3168,
    1809,
    7541,
    2202,
    16384,
    6114,
    1388,
    8903,
    2136,
    16384,
    2185,
    1831,
    2215,
    3100,
    10984,
    2757,
    1776,
    1161,
    4742,
    1085,
    552,
    708,
    1198,
    1742,
    6364,
    1058,
    7456,
    329,
    16384,
    348,
    2484,
    1572,
    842,
    4205,
    6392,
    1653,
    12251,
    2144,
    620,
    1831,
    1118,
    3315,
    11765,
    1841,
    605,
    6478,
    1351,
    616,
    16384,
    422,
    3491,
    184,
    2805,
    2457,
    1513,
    445,
    777,
    822,
    25425,
    704,
    9687,
    3072,
    8637,
    673,
    16671,
    295,
    539,
    1450,
    1258,
    14116,
    2250,
    1492,
    3312,
    2058,
    12926,
    1002,
    9310,
    8384,
    2651,
    6132,
    12174,
    1229,
    2447,
    2548,
    804,
    3265,
    567,
    2236,
    24530,
    3205,
    23480,
    1126,
    15858,
    1722,
    20875,
    956,
    2100,
    3034,
    1184,
    1518,
    1663,
    2766,
    6929,
    26679,
    4849,
    4841,
    2644,
    6567,
    2228,
    2249,
    1650,
    1484,
    1585,
    258,
    3867,
    1401,
    397,
    5810,
    683,
    5143,
    883,
    5737,
    16136,
    345,
    1509,
    5724,
    2718,
    2724,
    5470,
    839,
    487,
    911,
    8663,
    862,
    369,
    7132,
    1137,
    1219,
    431,
    3581,
    3732,
    1090,
    537,
    11825,
    3732,
    16384,
    3117,
    3901,
    2347,
    2935,
    1546,
    2761,
    827,
    510,
    2258,
    2226,
    21272,
    1089,
    1359,
    16746,
    2379,
    1661,
    346,
    2690,
    3576,
    16384,
    3264,
    5522,
    5580,
    272,
    1742,
    1658,
    12898,
    5126,
    11960,
    722,
    1683,
    10248,
    847,
    194,
    1577,
    593,
    236,
    5388,
    12076,
    3575,
    3157,
    3221,
    1834,
    3275,
    1729,
    874,
    8147,
    4553,
    16384,
    812,
    407,
    8742,
    12838,
    8888,
    16384,
    441,
    20585,
    314,
    1693,
    904,
    236,
    2230,
    8184,
    42852,
    7862,
    4300,
    1861,
    624,
    1192,
    16384,
    1302,
    3739,
    1477,
    596,
    4267,
    12260,
    11025,
    11730,
    2338,
    1992,
    3570,
    1564,
    12911,
    346,
    11204,
    2110,
    343,
    270,
    14028,
    6523,
    3046,
    397,
    1493,
    642,
    1338,
    1574,
    899,
    11825,
    4503,
    2628,
    3653,
    6963,
    6722,
    12450,
    5532,
    3311,
    1269,
    483,
    3824,
    1449,
    16384,
    1147,
    2719,
    2732,
    395,
    861,
    224,
    2702,
    2453,
    4528,
    899,
    622,
    1402,
    3148,
    607,
    3041,
    3426,
    4926,
    1348,
    13601,
    7718,
    925,
    1915,
    16384,
    2791,
    5639,
    11274,
    6048,
    3405,
    1569,
    1534,
    1554,
    4119,
    2052,
    1961,
    2183,
    2702,
    16191,
    721,
    6544,
    1250,
    10017,
    1697,
    450,
    10253,
    1720,
    1036,
    8323,
    807,
    1662,
    1028,
    11421,
    456,
    3155,
    7454,
    9400,
    2427,
    10986,
    701,
    1089,
    1104,
    13719,
    195,
    5672,
    7741,
    1455,
    7974,
    3756,
    682,
    934,
    1143,
    2868,
    5623,
    4184,
    1009,
    11911,
    1017,
    11390,
    1309,
    1855,
    1463,
    534,
    34868,
    4934,
    1656,
    325,
    1588,
    914,
    2116,
    5778,
    924,
    1684,
    2102,
    415,
    2946,
    1445,
    697,
    454,
    1906,
    4927,
    3429,
    546,
    1373,
    3309,
    7421,
    10492,
    2533,
    6527,
    428,
    3496,
    11518,
    1909,
    34732,
    8876,
    3975,
    12620,
    1452,
    1553,
    15544,
    3065,
    509,
    2058,
    16384,
    147,
    8556,
    1141,
    3573,
    4952,
    453,
    359,
    767,
    1794,
    313,
    4112,
    3833,
    2774,
    2558,
    468,
    1411,
    2091,
    4679,
    2307,
    12504,
    3971,
    2121,
    3286,
    11804,
    578,
    1344,
    11930,
    11638,
    697,
    3857,
    1208,
    3913,
    1204,
    498,
    7464,
    14447,
    2558,
    3552,
    13499,
    20693,
    7197,
    4378,
    8535,
    2813,
    2776,
    3903,
    452,
    764,
    8929,
    9534,
    3208,
    701,
    7502,
    2181,
    551,
    3950,
    5333,
    5238,
    1421,
    1128,
    474,
    10631,
    2525,
    11194,
    1502,
    13129,
    16343,
    2391,
    17933,
    1026,
    463,
    983,
    16313,
    1075,
    6572,
    233,
    16384,
    41039,
    5450,
    7813,
    1063,
    12157,
    1482,
    14750,
    368,
    1787,
    4542,
    5553,
    2571,
    3152,
    2809,
    887,
    368,
    1076,
    343,
    4948,
    16384,
    6081,
    1466,
    2035,
    18192,
    1031,
    16149,
    183,
    585,
    1068,
    4023,
    858,
    3945,
    2444,
    15448,
    612,
    216,
    136,
    1696,
    7088,
    12350,
    4122,
    1892,
    2594,
    378,
    16384,
    3397,
    469,
    230,
    3591,
    1771,
    1463,
    9673,
    1069,
    784,
    4433,
    3891,
    483,
    4761,
    16384,
    1381,
    1024,
    897,
    5097,
    5309,
    588,
    6985,
    8128,
    2762,
    180,
    4777,
    334,
    4508,
    6097,
    5733,
    112,
    897,
    4522,
    1825,
    373,
    1233,
    1986,
    303,
    13044,
    4877,
    2355,
    889,
    1416,
    973,
    671,
    2353,
    6725,
    12276,
    1269,
    2432,
    4721,
    1122,
    437,
    5653,
    446,
    3599,
    12640,
    745,
    9190,
    5985,
    18183,
    3242,
    3371,
    677,
    1076,
    328,
    2755,
    9666,
    1310,
    17886,
    1112,
    1189,
    1374,
    399,
    6991,
    1987,
    25148,
    2786,
    823,
    1410,
    348,
    4757,
    2323,
    842,
    380,
    1059,
    591,
    2318,
    627,
    16384,
    5906,
    1325,
    389,
    1767,
    12163,
    6417,
    4771,
    9833,
    1083,
    4847,
    9158,
    1237,
    891,
    8803,
    2344,
    3190,
    1813,
    506,
    6734,
    214,
    5989,
    1469,
    1625,
    1112,
    3567,
    3132,
    11762,
    1631,
    1635,
    11857,
    2240,
    1219,
    7120,
    9022,
    241,
    484,
    651,
    4137,
    749,
    3666,
    9031,
    4665,
    633,
    533,
    106,
    3425,
    502,
    2093,
    2575,
    473,
    5640,
    639,
    1039,
    22819,
    2108,
    961,
    16384,
    984,
    2452,
    1467,
    5299,
    2006,
    400,
    2486,
    3242,
    489,
    634,
    971,
    2651,
    1349,
    167,
    865,
    6965,
    4007,
    4102,
    1878,
    16384,
    1852,
    1549,
    1188,
    1288,
    19482,
    201,
    542,
    9328,
    851,
    578,
    1662,
    877,
    2757,
    535,
    10394,
    472,
    10770,
    2124,
    2620,
    1869,
    1985,
    1850,
    8402,
    11652,
    5767,
    892,
    1992,
    1731,
    33719,
    1048,
    14961,
    1682,
    1952,
    197,
    777,
    6776,
    1510,
    1531,
    3741,
    3621,
    13537,
    4001,
    1231,
    10012,
    17678,
    5755,
    740,
    4174,
    13958,
    1651,
    2023,
    721,
    621,
    2023,
    4754,
    1438,
    6742,
    5423,
    1335,
    4460,
    1733,
    2213,
    6510,
    16384,
    430,
    1389,
    7160,
    1527,
    1246,
    12512,
    1868,
    4750,
    1421,
    359,
    1138,
    4239,
    2470,
    830,
    16384,
    2274,
    668,
    8345,
    5476,
    1079,
    4103,
    4767,
    3322,
    2305,
    285,
    1400,
    1885,
    1051,
    1350,
    4322,
    1154,
    309,
    1003,
    1108,
    1672,
    36726,
    19209,
    39633,
    4710,
    1615,
    3649,
    2709,
    486,
    1907,
    11578,
    339,
    5668,
    2227,
    379,
    3754,
    6025,
    1868,
    12422,
    14833,
    1026,
    14925,
    12160,
    465,
    2289,
    2150,
    8289,
    7229,
    10521,
    10721,
    9089,
    3732,
    264,
    8470,
    591,
    4676,
    1048,
    1593,
    3255,
    1586,
    404,
    2797,
    562,
    3636,
    503,
    2329,
    2982,
    10751,
    237,
    2829,
    499,
    3382,
    1766,
    4656,
    9488,
    1378,
    1969,
    5402,
    1116,
    3113,
    5027,
    611,
    373,
    2424,
    23912,
    381,
    10679,
    1336,
    1654,
    26058,
    2332,
    780,
    1971,
    1545,
    1466,
    26847,
    972,
    10460,
    2631,
    4035,
    1724,
    515,
    2252,
    16384,
    3725,
    321,
    701,
    2214,
    3626,
    929,
    16384,
    3610,
    2881,
    7963,
    2618,
    229,
    1295,
    989,
    1378,
    2265,
    4280,
    853,
    861,
    1834,
    3763,
    3663,
    3867,
    6771,
    1343,
    6850,
    2887,
    2377,
    14495,
    1407,
    860,
    10013,
    1901,
    6740,
    3097,
    290,
    2722,
    3972,
    1844,
    3966,
    7415,
    10924,
    4775,
    789,
    2290,
    911,
    1204,
    12997,
    1884,
    2550,
    16384,
    2623,
    14200,
    10487,
    4650,
    1351,
    2079,
    908,
    4281,
    848,
    33537,
    2546,
    3224,
    3559,
    1186,
    447,
    166,
    747,
    970,
    932,
    15577,
    3316,
    1476,
    1718,
    841,
    12027,
    1474,
    150,
    849,
    463,
    427,
    3324,
    16384,
    528,
    1260,
    842,
    184,
    7037,
    702,
    4631,
    8530,
    1750,
    626,
    96,
    4128,
    16384,
    1216,
    3332,
    1304,
    1025,
    10831,
    10072,
    28002,
    2301,
    2289,
    14676,
    1657,
    13235,
    4792,
    1076,
    15121,
    7993,
    2880,
    16384,
    2888,
    2613,
    40448,
    317,
    6200,
    1293,
    861,
    3715,
    15390,
    4342,
    2604,
    1004,
    2652,
    393,
    3240,
    1135,
    1918,
    7765,
    2067,
    31615,
    5913,
    1900,
    7507,
    879,
    1439,
    678,
    466,
    2391,
    1004,
    14428,
    2321,
    623,
    1827,
    1122,
    15094,
    796,
    448,
    10607,
    2368,
    760,
    1085,
    491,
    786,
    2902,
    5300,
    3092,
    5763,
    13586,
    4061,
    3118,
    1951,
    136,
    1665,
    5511,
    823,
    14756,
    4960,
    10618,
    13902,
    198,
    5727,
    10494,
    7338,
    5862,
    1063,
    676,
    669,
    2407,
    717,
    699,
    1018,
    2861,
    827,
    6332,
    845,
    8993,
    649,
    1601,
    2236,
    692,
    890,
    2621,
    1196,
    1070,
    1263,
    2443,
    793,
    12453,
    251,
    11807,
    1696,
    1350,
    427,
    3951,
    317,
    3548,
    1784,
    1104,
    27729,
    903,
    150,
    3939,
    2325,
    3511,
    533,
    1036,
    3845,
    12170,
    6705,
    3188,
    10782,
    2328,
    13441,
    1180,
    982,
    2027,
    1917,
    1528,
    5257,
    3059,
    1147,
    18376,
    1068,
    3819,
    782,
    1102,
    1357,
    15446,
    2248,
    2457,
    12341,
    2567,
    643,
    28680,
    21105,
    1190,
    10559,
    8277,
    2449,
    2163,
    1637,
    2853,
    3351,
    1510,
    555,
    2650,
    2427,
    951,
    1882,
    813,
    3877,
    2375,
    2448,
    4434,
    16384,
    2086,
    3817,
    6600,
    1803,
    5362,
    7943,
    2025,
    16384,
    292,
    854,
    554,
    7071,
    2714,
    876,
    4810,
    1449,
    16384,
    1147,
    6620,
    660,
    3615,
    1218,
    477,
    209,
    1460,
    5884,
    2086,
    420,
    9430,
    3188,
    4724,
    3267,
    16384,
    2437,
    828,
    6553,
    181,
    2743,
    1317,
    22726,
    2102,
    870,
    2328,
    473,
    15247,
    1551,
    4263,
    1000,
    3240,
    1822,
    16384,
    395,
    1268,
    1141,
    515,
    1734,
    5110,
    897,
    11330,
    35310,
    3658,
    1130,
    10415,
    1222,
    16384,
    710,
    628,
    2500,
    2013,
    938,
    1964,
    13267,
    3010,
    3248,
    607,
    4295,
    12365,
    10828,
    6307,
    1938,
    1344,
    1496,
    3574,
    2443,
    4207,
    268,
    6928,
    1821,
    3678,
    9293,
    9016,
    441,
    6103,
    2673,
    6214,
    352,
    671,
    2650,
    742,
    1305,
    9421,
    17509,
    1622,
    5697,
    10402,
    16164,
    33246,
    511,
    8253,
    777,
    477,
    7465,
    1379,
    5044,
    27560,
    692,
    343,
    10775,
    4285,
    10016,
    1639,
    7848,
    13145,
    1519,
    1486,
    2213,
    1917,
    107,
    702,
    16024,
    2760,
    2650,
    1434,
    213,
    2287,
    2527,
    736,
    2945,
    2649,
    1102,
    1744,
    5017,
    2758,
    717,
    11202,
    44039,
    813,
    906,
    995,
    3805,
    4212,
    3819,
    4374,
    486,
    1078,
    23523,
    5022,
    6107,
    6666,
    1286,
    10444,
    3056,
    10597,
    243,
    4521,
    1377,
    11653,
    3997,
    21803,
    784,
    3548,
    3118,
    12274,
    2628,
    4734,
    29515,
    1211,
    685,
    1889,
    13071,
    299,
    1422,
    1900,
    1145,
    9190,
    17677,
    6085,
    10857,
    1779,
    3555,
    2338,
    811,
    16079,
    196,
    6503,
    17127,
    2966,
    5240,
    1937,
    638,
    8817,
    759,
    16384,
    1354,
    15237,
    2012,
    12745,
    1058,
    1392,
    12330,
    413,
    943,
    753,
    1777,
    2151,
    15274,
    2752,
    5703,
    4806,
    1657,
    16885,
    767,
    8556,
    2439,
    136,
    1363,
    736,
    5925,
    13173,
    948,
    1145,
    289,
    399,
    3588,
    828,
    7223,
    10916,
    2142,
    1381,
    565,
    2338,
    979,
    2014,
    3227,
    752,
    16384,
    1048,
    4751,
    1835,
    2207,
    2420,
    14122,
    19479,
    2051,
    2402,
    1312,
    1927,
    487,
    1452,
    1038,
    2095,
    3018,
    2025,
    13902,
    452,
    7383,
    3431,
    2000,
    249,
    18634,
    1326,
    2577,
    421,
    1051,
    1777,
    9079,
    1251,
    245,
    19356,
    10350,
    1440,
    879,
    2848,
    424,
    2346,
    1685,
    1504,
    1589,
    951,
    1132,
    882,
    2677,
    2157,
    1170,
    3557,
    3362,
    13885,
    5372,
    1958,
    629,
    2645,
    541,
    4126,
    1415,
    10449,
    604,
    1888,
    2506,
    1003,
    9240,
    16384,
    6228,
    820,
    602,
    1419,
    1669,
    1204,
    460,
    3522,
    1165,
    2789,
    16384,
    33192,
    1853,
    2128,
    2007,
    1859,
    2584,
    570,
    1975,
    1126,
    602,
    1365,
    262,
    114,
    13866,
    1173,
    2509,
    4584,
    8913,
    4297,
    4231,
    1973,
    8771,
    800,
    1275,
    462,
    2944,
    1105,
    3080,
    2738,
    16384,
    726,
    2266,
    1717,
    8973,
    1498,
    485,
    323,
    2081,
    8081,
    1706,
    4792,
    1845,
    883,
    7694,
    176,
    1114,
    2404,
    688,
    2809,
    5620,
    1669,
    1403,
    1282,
    962,
    1758,
    1263,
    1584,
    16384,
    813,
    2572,
    2318,
    16384,
    677,
    1912,
    915,
    2636,
    6069,
    878,
    11574,
    5047,
    1991,
    2128,
    836,
    10537,
    1246,
    1466,
    1438,
    5816,
    7204,
    1631,
    2012,
    3488,
    2478,
    4739,
    6695,
    990,
    1558,
    1887,
    1164,
    168,
    830,
    820,
    2603,
    3233,
    2786,
    2709,
    18521,
    399,
    4823,
    393,
    16384,
    2755,
    2267,
    3066,
    1202,
    4421,
    1725,
    794,
    3256,
    16384,
    585,
    1555,
    8646,
    1162,
    8910,
    6589,
    2032,
    1651,
    5621,
    849,
    4614,
    9338,
    7745,
    6010,
    681,
    4212,
    1851,
    624,
    1712,
    412,
    1640,
    1745,
    3611,
    6451,
    427,
    19193,
    10201,
    5026,
    938,
    11632,
    1903,
    1987,
    4241,
    185,
    1608,
    515,
    12849,
    3584,
    2942,
    16384,
    1701,
    5355,
    400,
    2493,
    16384,
    3455,
    873,
    683,
    353,
    3255,
    5152,
    2298,
    818,
    2607,
    938,
    7652,
    15994,
    756,
    1096,
    3057,
    516,
    4161,
    1482,
    2186,
    1732,
    16384,
    1658,
    5063,
    16384,
    3191,
    15250,
    2224,
    4800,
    1045,
    587,
    688,
    1945,
    2736,
    584,
    438,
    253,
    16384,
    19128,
    188,
    1978,
    1677,
    439,
    7152,
    1208,
    2091,
    1461,
    2102,
    6119,
    3890,
    1215,
    11305,
    10874,
    399,
    586,
    1020,
    10695,
    10678,
    1065,
    1924,
    1561,
    1683,
    616,
    835,
    1489,
    13025,
    8250,
    5471,
    2979,
    17453,
    14163,
    6835,
    1331,
    979,
    2452,
    2098,
    932,
    10335,
    972,
    2630,
    531,
    1508,
    6571,
    2093,
    1047,
    234,
    1373,
    1352,
    4476,
    8556,
    522,
    4826,
    22504,
    7074,
    1235,
    3688,
    10978,
    36403,
    2348,
    11329,
    4708,
    16384,
    27737,
    6592,
    4404,
    2112,
    656,
    2555,
    16384,
    7901,
    3419,
    1160,
    424,
    1605,
    735,
    1350,
    6720,
    7690,
    6607,
    3635,
    1115,
    3238,
    299,
    6730,
    596,
    8669,
    995,
    16384,
    1494,
    1759,
    4622,
    456,
    2541,
    661,
    4207,
    3462,
    2557,
    7783,
    29694,
    178,
    872,
    695,
    4145,
    12650,
    985,
    816,
    1372,
    3178,
    5315,
    2082,
    1227,
    2086,
    527,
    1207,
    9618,
    6499,
    16384,
    13209,
    16384,
    1144,
    974,
    2770,
    3430,
    20290,
    1834,
    16384,
    534,
    11458,
    2525,
    1795,
    2113,
    16384,
    12567,
    4054,
    860,
    2645,
    294,
    785,
    4558,
    710,
    1016,
    2557,
    78,
    2524,
    2821,
    3731,
    12719,
    1132,
    1593,
    841,
    1009,
    902,
    905,
    231,
    25127,
    4795,
    1374,
    1162,
    1238,
    2821,
    464,
    5440,
    202,
    6121,
    3194,
    207,
    2197,
    10435,
    537,
    1859,
    376,
    5190,
    4334,
    1967,
    120,
    1872,
    1642,
    953,
    402,
    791,
    1162,
    1779,
    4123,
    26986,
    2497,
    644,
    2489,
    4117,
    4270,
    5737,
    155,
    408,
    1296,
    4732,
    5051,
    1002,
    16384,
    257,
    1397,
    4277,
    1198,
    711,
    7582,
    1730,
    2523,
    7490,
    829,
    2497,
    1265,
    534,
    6470,
    3615,
    2732,
    2188,
    9384,
    16962,
    1455,
    403,
    2608,
    7678,
    783,
    10713,
    16511,
    4721,
    18460,
    3086,
    36901,
    900,
    1927,
    1189,
    48827,
    18106,
    2912,
    1794,
    1534,
    20212,
    178,
    4288,
    2063,
    16384,
    4405,
    2526,
    604,
    752,
    710,
    16384,
    804,
    374,
    5509,
    5220,
    1788,
    10009,
    2703,
    492,
    16384,
    174,
    1371,
    10031,
    16384,
    722,
    1984,
    673,
    10276,
    2720,
    1361,
    3676,
    366,
    501,
    2693,
    8260,
    1523,
    2912,
    18330,
    13924,
    5076,
    8674,
    12609,
    1539,
    1351,
    213,
    1227,
    4182,
    6586,
    2708,
    1759,
    11576,
    3141,
    18626,
    1701,
    2697,
    596,
    96,
    13540,
    677,
    5442,
    4131,
    1733,
    14925,
    25323,
    1356,
    11892,
    603,
    123,
    1349,
    5669,
    15982,
    1481,
    4312,
    849,
    541,
    1081,
    889,
    646,
    1668,
    7912,
    1409,
    22850,
    1105,
    1561,
    3688,
    4706,
    13949,
    1073,
    3491,
    1625,
    662,
    2002,
    175,
    1298,
    1811,
    36745,
    887,
    3381,
    1118,
    778,
    1973,
    1373,
    5509,
    3295,
    6778,
    24552,
    1110,
    1678,
    3030,
    11906,
    141,
    689,
    4343,
    2536,
    260,
    12669,
    39503,
    1106,
    1159,
    3911,
    10012,
    2728,
    19132,
    1204,
    917,
    1672,
    1328,
    7638,
    10185,
    604,
    206,
    732,
    224,
    5348,
    4875,
    46423,
    11304,
    4175,
    8442,
    2430,
    3095,
    11691,
    4519,
    141,
    4522,
    4681,
    14584,
    435,
    2457,
    1619,
    376,
    7853,
    3251,
    4552,
    265,
    598,
    1127,
    1181,
    193,
    836,
    1659,
    1301,
    2747,
    1357,
    453,
    1803,
    3000,
    12366,
    2359,
    16384,
    11988,
    1365,
    28720,
    2317,
    1711,
    1499,
    4908,
    2167,
    12177,
    2355,
    24845,
    338,
    10671,
    144,
    5477,
    36519,
    2445,
    15270,
    3099,
    5330,
    7743,
    1947,
    11747,
    2353,
    3235,
    3047,
    10982,
    898,
    5841,
    486,
    16384,
    2565,
    577,
    1466,
    17668,
    116,
    547,
    5815,
    36692,
    4215,
    4715,
    10576,
    2575,
    701,
    624,
    2020,
    8265,
    5053,
    642,
    437,
    1876,
    3136,
    4425,
    1672,
    19026,
    447,
    12907,
    1786,
    6596,
    1615,
    3513,
    2497,
    4722,
    1037,
    2473,
    1524,
    1444,
    6719,
    3248,
    546,
    11667,
    1321,
    2271,
    572,
    5822,
    2408,
    564,
    1081,
    16384,
    16384,
    2832,
    6287,
    9290,
    47790,
    4201,
    1588,
    2091,
    1337,
    45041,
    2071,
    19440,
    1019,
    7204,
    13791,
    1111,
    9020,
    1025,
    735,
    29362,
    4260,
    4140,
    5312,
    3636,
    898,
    938,
    2891,
    3419,
    12644,
    1771,
    15256,
    465,
    16384,
    9354,
    2862,
    2800,
    1525,
    813,
    1218,
    3124,
    16384,
    5292,
    409,
    666,
    5622,
    2059,
    643,
    695,
    539,
    13781,
    1900,
    33673,
    1371,
    1029,
    380,
    2831,
    8340,
    1369,
    2969,
    7059,
    4966,
    833,
    1402,
    2356,
    12844,
    7853,
    1767,
    250,
    1859,
    785,
    5471,
    758,
    11732,
    2162,
    1801,
    758,
    10565,
    619,
    68,
    300,
    2530,
    1837,
    324,
    258,
    11027,
    9777,
    3237,
    802,
    3262,
    802,
    161,
    22983,
    2597,
    5566,
    4501,
    1938,
    4634,
    800,
    423,
    24606,
    927,
    3895,
    5090,
    783,
    3236,
    3973,
    5225,
    3037,
    692,
    12862,
    629,
    523,
    10078,
    4162,
    2055,
    725,
    1106,
    12131,
    5387,
    3970,
    1987,
    5025,
    970,
    14935,
    3777,
    156,
    1048,
    1374,
    13270,
    1911,
    1996,
    5896,
    7240,
    208,
    3862,
    475,
    1783,
    10408,
    5401,
    16384,
    349,
    3452,
    8040,
    1635,
    990,
    18959,
    1354,
    1300,
    2186,
    1157,
    4040,
    561,
    904,
    1283,
    4522,
    4172,
    9684,
    1426,
    2995,
    8062,
    2147,
    5004,
    585,
    5076,
    31911,
    1199,
    566,
    26342,
    3614,
    2644,
    1806,
    6472,
    6592,
    793,
    1637,
    1297,
    2343,
    1873,
    32697,
    635,
    2768,
    15211,
    240,
    1706,
    541,
    2453,
    5741,
    2833,
    9884,
    3728,
    8438,
    2313,
    690,
    10505,
    12240,
    2509,
    5087,
    904,
    2277,
    871,
    5227,
    958,
    2899,
    540,
    1953,
    2969,
    6572,
    3238,
    4163,
    1616,
    1901,
    1207,
    11601,
    3624,
    3701,
    12206,
    8329,
    1549,
    13139,
    2626,
    886,
    2874,
    1875,
    1932,
    5627,
    1034,
    679,
    2509,
    972,
    2310,
    4764,
    443,
    5607,
    3405,
    2611,
    414,
    617,
    868,
    1184,
    14465,
    8310,
    3579,
    1252,
    1031,
    9087,
    43812,
    6189,
    806,
    2651,
    915,
    1690,
    1007,
    30933,
    1613,
    443,
    555,
    3209,
    2315,
    818,
    1117,
    3324,
    8472,
    18956,
    1600,
    2214,
    657,
    3161,
    3218,
    1603,
    1176,
    2117,
    3825,
    3169,
    9719,
    1587,
    2332,
    5064,
    1679,
    4772,
    3700,
    3963,
    978,
    11688,
    402,
    1677,
    5652,
    563,
    7367,
    723,
    389,
    8246,
    1147,
    718,
    9438,
    475,
    1120,
    2350,
    989,
    1212,
    11623,
    16427,
    8306,
    948,
    1924,
    2093,
    2133,
    2261,
    2414,
    2580,
    6050,
    7172,
    16384,
    22979,
    3779,
    371,
    709,
    10965,
    11431,
    18807,
    1674,
    3817,
    4559,
    607,
    2739,
    790,
    1222,
    908,
    10579,
    1340,
    480,
    2554,
    4326,
    8348,
    1571,
    1350,
    5572,
    549,
    5202,
    2941,
    3598,
    3800,
    16418,
    2502,
    576,
    18496,
    1053,
    7797,
    2747,
    661,
    32225,
    741,
    1134,
    21196,
    209,
    19300,
    1377,
    10448,
    1504,
    1685,
    12412,
    1802,
    14325,
    4702,
    16384,
    3813,
    594,
    4074,
    771,
    1406,
    2325,
    7879,
    2243,
    3860,
    2149,
    3945,
    1784,
    7715,
    412,
    864,
    587,
    13828,
    23504,
    3442,
    976,
    1919,
    1109,
    869,
    2231,
    473,
    603,
    320,
    924,
    1838,
    7157,
    796,
    11387,
    1737,
    3219,
    2407,
    21830,
    12570,
    9513,
    681,
    1259,
    3205,
    620,
    3072,
    1840,
    665,
    2918,
    5831,
    708,
    11647,
    2595,
    1735,
    3076,
    115,
    4688,
    2674,
    1209,
    2895,
    3119,
    622,
    2215,
    346,
    14693,
    10346,
    1428,
    426,
    1336,
    43769,
    2704,
    359,
    1331,
    4542,
    2866,
    2356,
    4181,
    1289,
    828,
    1086,
    4379,
    5322,
    2008,
    675,
    1642,
    5520,
    4385,
    649,
    2579,
    1685,
    1286,
    107,
    662,
    9211,
    1847,
    2328,
    1796,
    3113,
    3987,
    3732,
    7333,
    3309,
    13018,
    10526,
    2039,
    526,
    558,
    668,
    2441,
    500,
    1974,
    7649,
    3952,
    1597,
    1871,
    587,
    3001,
    2610,
    402,
    2502,
    2591,
    1588,
    812,
    1481,
    1096,
    482,
    7827,
    10351,
    1566,
    3497,
    364,
    14512,
    1866,
    728,
    47492,
    3914,
    2291,
    286,
    18891,
    1557,
    1528,
    696,
    1345,
    1641,
    259,
    3398,
    10811,
    1562,
    835,
    1978,
    1763,
    557,
    3691,
    535,
    8133,
    1099,
    24832,
    212,
    795,
    14595,
    4187,
    1266,
    2040,
    3975,
    1465,
    5231,
    1132,
    24587,
    2299,
    1713,
    360,
    3188,
    1674,
    8491,
    860,
    1709,
    567,
    3626,
    1869,
    2023,
    1250,
    767,
    2879,
    1563,
    2451,
    20615,
    3392,
    2183,
    1624,
    472,
    1812,
    10551,
    12401,
    1102,
    2233,
    5967,
    2039,
    21737,
    913,
    6729,
    4559,
    935,
    1014,
    762,
    9152,
    399,
    483,
    572,
    270,
    11583,
    352,
    1637,
    25793,
    764,
    3323,
    3747,
    1059,
    1318,
    1625,
    2480,
    2976,
    279,
    6874,
    16384,
    1502,
    3170,
    2984,
    1155,
    5108,
    4174,
    9929,
    2453,
    16384,
    2160,
    1576,
    2063,
    1811,
    2291,
    18772,
    1552,
    630,
    2407,
    1175,
    1463,
    506,
    10030,
    3270,
    927,
    2397,
    1380,
    1665,
    951,
    966,
    485,
    2546,
    405,
    1925,
    4921,
    849,
    17575,
    1115,
    1456,
    1817,
    2885,
    2780,
    5607,
    1195,
    16384,
    1422,
    12649,
    2574,
    2353,
    16384,
    1149,
    5599,
    3179,
    525,
    17633,
    653,
    4903,
    109,
    19946,
    941,
    438,
    1757,
    1151,
    8395,
    551,
    3197,
    1169,
    710,
    2472,
    1731,
    12089,
    506,
    3298,
    4751,
    6376,
    20532,
    1374,
    860,
    4770,
    1069,
    312,
    14394,
    1131,
    9171,
    1168,
    5705,
    1269,
    7942,
    5879,
    16384,
    3408,
    331,
    225,
    4409,
    2874,
    1304,
    11799,
    287,
    1437,
    1465,
    1163,
    10490,
    3913,
    3271,
    4876,
    1890,
    642,
    3791,
    12051,
    1308,
    450,
    3998,
    31213,
    2019,
    5128,
    14504,
    668,
    16384,
    1664,
    14105,
    1383,
    1554,
    1827,
    298,
    3254,
    920,
    10646,
    3310,
    3895,
    584,
    1258,
    1275,
    5472,
    2042,
    690,
    1991,
    589,
    7475,
    728,
    1397,
    971,
    38041,
    787,
    1954,
    6330,
    9166,
    2741,
    2950,
    3458,
    1529,
    1718,
    25659,
    496,
    3390,
    16384,
    1691,
    900,
    2085,
    1751,
    4929,
    659,
    10525,
    2107,
    2422,
    2512,
    242,
    15998,
    11784,
    3197,
    463,
    1699,
    449,
    1334,
    2467,
    9148,
    619,
    1483,
    16384,
    3868,
    8453,
    5850,
    1753,
    1224,
    597,
    1250,
    1478,
    11305,
    6615,
    75,
    561,
    1923,
    2675,
    1282,
    792,
    6210,
    3114,
    2394,
    1154,
    4962,
    16338,
    2702,
    4871,
    4600,
    906,
    437,
    12266,
    2191,
    754,
    3918,
    1670,
    2682,
    422,
    1225,
    498,
    10442,
    3913,
    1200,
    1498,
    15643,
    4204,
    1302,
    636,
    138,
    3296,
    13419,
    16384,
    4035,
    1413,
    1884,
    1774,
    747,
    1481,
    7272,
    11010,
    381,
    429,
    1888,
    1909,
    1542,
    491,
    2428,
    1605,
    5202,
    3154,
    12492,
    496,
    11443,
    2137,
    1644,
    1049,
    1233,
    2037,
    11959,
    11412,
    1399,
    16384,
    1017,
    5527,
    1562,
    5325,
    29693,
    2615,
    3027,
    16384,
    4006,
    2965,
    3276,
    1427,
    11848,
    3415,
    1430,
    402,
    11536,
    4234,
    1351,
    3077,
    1313,
    305,
    1675,
    16951,
    3935,
    16384,
    2826,
    7997,
    2875,
    478,
    3670,
    16096,
    342,
    2726,
    2458,
    592,
    1942,
    400,
    16384,
    2234,
    12923,
    1894,
    4612,
    4375,
    577,
    3064,
    1572,
    10317,
    1750,
    11229,
    1153,
    734,
    412,
    507,
    3427,
    1206,
    287,
    486,
    2454,
    12517,
    10242,
    473,
    1286,
    935,
    1460,
    3704,
    1564,
    2236,
    446,
    1090,
    5631,
    3160,
    11099,
    1201,
    1356,
    4279,
    454,
    429,
    503,
    7422,
    777,
    2619,
    7356,
    319,
    2847,
    2337,
    5305,
    9162,
    206,
    3165,
    315,
    16384,
    950,
    525,
    300,
    47884,
    486,
    4134,
    1759,
    2781,
    693,
    4216,
    3139,
    4656,
    258,
    1500,
    971,
    4898,
    592,
    1942,
    940,
    13557,
    2212,
    272,
    10003,
    16384,
    3506,
    5506,
    832,
    2371,
    11957,
    12738,
    1786,
    1939,
    1083,
    1382,
    3208,
    1413,
    3588,
    3391,
    4025,
    18356,
    7632,
    1815,
    2313,
    2118,
    11868,
    12567,
    6226,
    16038,
    583,
    5440,
    16384,
    8400,
    1142,
    4040,
    199,
    368,
    191,
    521,
    1888,
    1002,
    5428,
    14213,
    2298,
    14021,
    2543,
    1709,
    3355,
    18041,
    2587,
    2677,
    2285,
    1924,
    24132,
    2600,
    10186,
    2345,
    2431,
    759,
    2189,
    2551,
    1501,
    8323,
    325,
    3915,
    1397,
    2259,
    4549,
    3304,
    2232,
    9722,
    428,
    10629,
    867,
    2278,
    13898,
    960,
    1886,
    12289,
    533,
    1967,
    2415,
    6126,
    2977,
    1569,
    4246,
    6075,
    2162,
    1113,
    1500,
    48784,
    5911,
    2841,
    1913,
    10568,
    254,
    779,
    4506,
    5509,
    751,
    1095,
    3702,
    48144,
    1543,
    9692,
    1094,
    2292,
    1001,
    1515,
    2089,
    3450,
    4408,
    13801,
    2715,
    16384,
    13436,
    1721,
    5623,
    14134,
    16384,
    7277,
    2145,
    2887,
    1475,
    739,
    2167,
    13173,
    1987,
    1207,
    34312,
    358,
    7478,
    449,
    2530,
    3883,
    1175,
    3193,
    2962,
    16384,
    1469,
    335,
    1484,
    6020,
    4321,
    2415,
    21323,
    4707,
    5166,
    661,
    4006,
    862,
    2803,
    14518,
    3084,
    5251,
    1730,
    16384,
    421,
    2882,
    7094,
    1735,
    931,
    2266,
    1938,
    298,
    16384,
    12328,
    287,
    236,
    539,
    1987,
    3179,
    2074,
    10651,
    1645,
    2557,
    4451,
    2269,
    421,
    2830,
    5250,
    560,
    3688,
    10409,
    783,
    1039,
    537,
    4230,
    1930,
    10145,
    5312,
    6015,
    1708,
    2647,
    4636,
    2390,
    1518,
    13272,
    79,
    4133,
    2312,
    3839,
    2261,
    327,
    10802,
    16384,
    609,
    1455,
    160,
    806,
    3125,
    14667,
    1128,
    892,
    3318,
    1249,
    543,
    1771,
    553,
    8657,
    386,
    1537,
    493,
    616,
    4304,
    3077,
    7850,
    1349,
    8017,
    2226,
    1057,
    10474,
    4918,
    3331,
    7531,
    1838,
    2554,
    10904,
    1557,
    4820,
    2654,
    2027,
    697,
    3912,
    1392,
    1112,
    2962,
    12563,
    9560,
    11258,
    899,
    3713,
    1237,
    10011,
    155,
    1578,
    13769,
    1106,
    1315,
    2675,
    1702,
    3068,
    1707,
    1967,
    1101,
    5469,
    4651,
    2234,
    4867,
    1999,
    1557,
    8183,
    1843,
    6480,
    4775,
    2903,
    4011,
    1416,
    2987,
    2849,
    1724,
    2787,
    321,
    2439,
    1412,
    659,
    877,
    17757,
    1680,
    5156,
    668,
    558,
    8513,
    335,
    2435,
    4249,
    2135,
    1028,
    6334,
    166,
    1873,
    1762,
    2195,
    19798,
    502,
    387,
    2304,
    2212,
    1129,
    842,
    662,
    1848,
    368,
    758,
    739,
    4334,
    7472,
    15084,
    8599,
    1652,
    1741,
    372,
    272,
    3094,
    13689,
    13309,
    463,
    2464,
    780,
    2340,
    1388,
    2317,
    1034,
    739,
    5061,
    1034,
    1290,
    1607,
    501,
    1233,
    953,
    12622,
    2101,
    245,
    3310,
    1157,
    3590,
    2706,
    6459,
    1621,
    614,
    5597,
    6763,
    1343,
    1027,
    4464,
    1453,
    5506,
    7428,
    2336,
    5939,
    6169,
    4722,
    377,
    1750,
    32910,
    1180,
    500,
    752,
    5280,
    28964,
    1366,
    1773,
    5013,
    818,
    795,
    8491,
    1338,
    16384,
    11422,
    197,
    120,
    23288,
    2495,
    1428,
    536,
    352,
    5089,
    2865,
    1994,
    1921,
    1166,
    16384,
    1496,
    4956,
    984,
    802,
    1598,
    1504,
    2160,
    5988,
    21608,
    5527,
    10134,
    252,
    844,
    427,
    403,
    562,
    2222,
    2755,
    5299,
    2263,
    1934,
    2713,
    5810,
    413,
    427,
    1613,
    1108,
    3884,
    421,
    685,
    6213,
    9889,
    2583,
    8423,
    4619,
    3832,
    512,
    735,
    863,
    826,
    439,
    363,
    1663,
    4609,
    1456,
    1373,
    1234,
    2337,
    1437,
    198,
    16384,
    2898,
    2979,
    2820,
    3186,
    2443,
    3117,
    16384,
    1316,
    1695,
    797,
    852,
    7604,
    4613,
    2832,
    1662,
    12787,
    1110,
    1865,
    3461,
    10986,
    2567,
    497,
    610,
    2971,
    1505,
    4722,
    1183,
    11332,
    4241,
    3288,
    135,
    4022,
    1041,
    1711,
    583,
    1482,
    2889,
    5402,
    179,
    1300,
    524,
    397,
    1476,
    5232,
    659,
    1198,
    1627,
    200,
    1079,
    453,
    1338,
    7312,
    2489,
    12774,
    612,
    3786,
    2786,
    1038,
    9152,
    2860,
    10403,
    1019,
    2486,
    6661,
    5890,
    1854,
    12862,
    292,
    1037,
    1296,
    4722,
    2309,
    8692,
    7594,
    3217,
    4689,
    7506,
    1162,
    16384,
    3876,
    2567,
    3567,
    1691,
    1503,
    1122,
    2694,
    752,
    745,
    1609,
    2209,
    752,
    255,
    1837,
    846,
    3388,
    2069,
    918,
    1200,
    549,
    3637,
    477,
    3001,
    1819,
    901,
    879,
    2633,
    10258,
    12576,
    908,
    1109,
    2961,
    1535,
    17181,
    2484,
    399,
    1146,
    5174,
    474,
    15348,
    12984,
    10753,
    337,
    1049,
    2924,
    14353,
    770,
    2041,
    1522,
    677,
    507,
    427,
    152,
    838,
    1625,
    1945,
    512,
    3258,
    9809,
    1001,
    2150,
    4249,
    15336,
    11382,
    2216,
    959,
    4157,
    3587,
    10515,
    1116,
    226,
    1802,
    1086,
    2376,
    3006,
    3291,
    6973,
    3146,
    2169,
    10099,
    1886,
    1384,
    1560,
    1130,
    631,
    5903,
    1791,
    13575,
    6936,
    11151,
    622,
    12501,
    392,
    245,
    2953,
    880,
    2307,
    31949,
    1771,
    2962,
    2139,
    5583,
    13662,
    1623,
    3639,
    7435,
    2269,
    1964,
    47940,
    2818,
    10166,
    703,
    1151,
    2963,
    13488,
    4356,
    7576,
    14604,
    1785,
    1282,
    1834,
    1767,
    3687,
    4100,
    2273,
    518,
    2732,
    1383,
    739,
    3040,
    1886,
    8910,
    2602,
    1139,
    9361,
    6068,
    1193,
    1620,
    2566,
    2871,
    8478,
    2951,
    12622,
    1204,
    2222,
    5384,
    1018,
    3702,
    13804,
    4244,
    1626,
    1272,
    407,
    1886,
    16384,
    2435,
    4584,
    7362,
    2731,
    10274,
    3229,
    7982,
    1426,
    4338,
    3390,
    1652,
    625,
    6142,
    5538,
    2460,
    1312,
    391,
    7798,
    352,
    757,
    13301,
    1072,
    1858,
    552,
    963,
    4672,
    2661,
    11399,
    857,
    19742,
    1756,
    731,
    2862,
    1705,
    520,
    5280,
    968,
    1560,
    816,
    580,
    618,
    3321,
    875,
    13883,
    2676,
    10595,
    485,
    2837,
    779,
    31731,
    3932,
    4118,
    2434,
    163,
    428,
    4628,
    1030,
    6393,
    509,
    5058,
    3168,
    3622,
    2337,
    670,
    12527,
    3846,
    749,
    22586,
    6490,
    8999,
    4579,
    446,
    2531,
    4644,
    1064,
    716,
    454,
    623,
    16787,
    2296,
    10118,
    2042,
    1688,
    3630,
    11215,
    6503,
    12704,
    632,
    2601,
    1534,
    2494,
    6666,
    862,
    623,
    12298,
    99,
    2056,
    2067,
    1641,
    3169,
    768,
    17001,
    1155,
    1017,
    743,
    930,
    28939,
    16384,
    8240,
    8982,
    201,
    6374,
    968,
    4323,
    390,
    4324,
    888,
    573,
    4835,
    16384,
    2724,
    3936,
    12824,
    18645,
    1801,
    17408,
    1175,
    1466,
    16384,
    2432,
    14984,
    1184,
    1874,
    3910,
    1687,
    1425,
    12052,
    544,
    262,
    469,
    2351,
    973,
    1335,
    11286,
    1049,
    1448,
    261,
    1696,
    874,
    909,
    6539,
    3965,
    309,
    782,
    724,
    5517,
    28157,
    4363,
    1906,
    977,
    1407,
    254,
    2163,
    2752,
    1471,
    3887,
    4178,
    4452,
    8686,
    765,
    1635,
    1473,
    3613,
    509,
    978,
    747,
    11349,
    1886,
    1020,
    75,
    936,
    176,
    1241,
    948,
    2399,
    1717,
    850,
    3110,
    15997,
    891,
    218,
    768,
    10101,
    13354,
    14616,
    285,
    792,
    656,
    16218,
    486,
    1165,
    4600,
    7058,
    443,
    3900,
    1115,
    1022,
    13625,
    1911,
    1474,
    11331,
    2670,
    8052,
    7355,
    3868,
    4142,
    692,
    1859,
    3090,
    7686,
    345,
    729,
    11408,
    2436,
    1856,
    1936,
    3405,
    4910,
    5349,
    863,
    9714,
    7459,
    961,
    3429,
    18480,
    16384,
    7910,
    771,
    562,
    123,
    4206,
    807,
    1994,
    29428,
    303,
    2711,
    1193,
    649,
    2813,
    1085,
    1118,
    2214,
    2123,
    2446,
    6515,
    820,
    20210,
    625,
    2119,
    5330,
    1706,
    3630,
    16384,
    5430,
    956,
    2347,
    1262,
    1425,
    28771,
    2011,
    1909,
    7920,
    20231,
    2038,
    1303,
    6712,
    15933,
    977,
    9859,
    2491,
    2249,
    3140,
    2545,
    698,
    1844,
    1568,
    1611,
    1302,
    1695,
    2507,
    1164,
    8706,
    6227,
    13458,
    2707,
    1891,
    2713,
    1567,
    3128,
    312,
    575,
    1219,
    333,
    1840,
    672,
    1150,
    1961,
    4137,
    3547,
    2160,
    1783,
    1743,
    3482,
    13645,
    711,
    1594,
    409,
    16384,
    12341,
    6298,
    330,
    800,
    2084,
    413,
    12274,
    1798,
    16384,
    2803,
    299,
    16989,
    2713,
    13611,
    763,
    566,
    982,
    810,
    7030,
    9450,
    2720,
    314,
    1253,
    4132,
    1926,
    1915,
    818,
    2420,
    10153,
    1569,
    1077,
    756,
    514,
    6966,
    5110,
    4138,
    29794,
    7920,
    11030,
    388,
    1117,
    1077,
    3312,
    3319,
    791,
    34440,
    17367,
    176,
    914,
    939,
    3414,
    5810,
    2040,
    2066,
    16384,
    3043,
    2234,
    7849,
    2192,
    2056,
    1292,
    15451,
    1167,
    1757,
    719,
    12988,
    1525,
    1863,
    463,
    1496,
    10223,
    3804,
    946,
    18935,
    1370,
    1114,
    1513,
    7811,
    1014,
    763,
    569,
    1057,
    16384,
    8717,
    4356,
    6091,
    987,
    1184,
    7888,
    1909,
    1360,
    8230,
    464,
    6646,
    3046,
    934,
    1845,
    3361,
    1198,
    4898,
    11015,
    2964,
    466,
    17937,
    2124,
    1139,
    418,
    7205,
    4531,
    982,
    3363,
    640,
    14148,
    878,
    13952,
    6187,
    2116,
    227,
    12515,
    1398,
    1358,
    1328,
    246,
    16384,
    2405,
    2094,
    450,
    3569,
    25618,
    995,
    1959,
    10843,
    11412,
    380,
    2150,
    3028,
    5390,
    2037,
    1778,
    5680,
    7045,
    7286,
    795,
    1144,
    1152,
    2168,
    3628,
    4184,
    3087,
    2470,
    1908,
    3791,
    3128,
    5585,
    11816,
    1282,
    1101,
    3004,
    1266,
    7684,
    287,
    2047,
    2221,
    714,
    214,
    992,
    1259,
    4371,
    3911,
    1493,
    3175,
    588,
    977,
    1683,
    15252,
    402,
    3294,
    3603,
    266,
    2094,
    3729,
    1313,
    2379,
    882,
    159,
    72,
    1259,
    2993,
    1318,
    3000,
    4644,
    6943,
    2412,
    16384,
    6253,
    4802,
    369,
    1561,
    903,
    7808,
    1121,
    2992,
    1456,
    2251,
    1344,
    2161,
    5872,
    4140,
    281,
    605,
    3660,
    1263,
    11777,
    1594,
    17934,
    2922,
    10956,
    887,
    1260,
    5101,
    2724,
    5062,
    644,
    5843,
    1864,
    1013,
    432,
    7377,
    2322,
    3263,
    499,
    2084,
    691,
    3152,
    1647,
    117,
    323,
    1922,
    2099,
    1284,
    907,
    1831,
    651,
    2103,
    6251,
    1265,
    1007,
    2591,
    16384,
    470,
    9349,
    4471,
    7760,
    8977,
    1828,
    3591,
    1813,
    266,
    1099,
    3969,
    4950,
    1107,
    509,
    4528,
    6893,
    2387,
    2537,
    1800,
    856,
    1492,
    3090,
    647,
    10257,
    1676,
    124,
    5027,
    515,
    697,
    968,
    1594,
    2197,
    364,
    1961,
    2224,
    335,
    974,
    6777,
    2430,
    9450,
    4156,
    4723,
    206,
    5161,
    1304,
    1666,
    2029,
    2105,
    5265,
    2213,
    16384,
    2510,
    15099,
    14554,
    1114,
    543,
    16384,
    1330,
    1921,
    13264,
    1950,
    607,
    352,
    1711,
    8800,
    1687,
    549,
    910,
    1561,
    2949,
    1760,
    721,
    2405,
    979,
    1074,
    2242,
    1821,
    1145,
    512,
    516,
    1531,
    1896,
    2927,
    837,
    23219,
    691,
    746,
    4590,
    3439,
    1345,
    5531,
    7339,
    588,
    3926,
    9200,
    1514,
    869,
    714,
    5614,
    3643,
    5746,
    703,
    11033,
    1283,
    3832,
    19213,
    753,
    2109,
    10175,
    2719,
    686,
    9206,
    1024,
    1561,
    16384,
    749,
    2039,
    8364,
    16714,
    3650,
    629,
    183,
    8528,
    740,
    427,
    16384,
    215,
    1980,
    335,
    3252,
    10048,
    5458,
    1900,
    2062,
    1083,
    1675,
    13674,
    151,
    747,
    996,
    10261,
    889,
    2039,
    2752,
    14613,
    523,
    394,
    1118,
    16384,
    3306,
    2118,
    2457,
    817,
    608,
    4240,
    9497,
    3255,
    1835,
    601,
    1234,
    12599,
    80,
    12718,
    1699,
    1333,
    2324,
    1568,
    127,
    13963,
    4442,
    7531,
    638,
    1524,
    433,
    1832,
    5869,
    1591,
    1159,
    317,
    2531,
    953,
    15243,
    742,
    506,
    1644,
    967,
    7461,
    44541,
    835,
    1007,
    11320,
    18378,
    117,
    1004,
    2892,
    6509,
    390,
    1445,
    1418,
    8164,
    12694,
    735,
    763,
    982,
    118,
    2612,
    10376,
    6721,
    878,
    16384,
    455,
    479,
    7155,
    702,
    2001,
    2442,
    11333,
    25514,
    961,
    1725,
    87,
    3164,
    94,
    2676,
    2566,
    9332,
    11059,
    5050,
    5394,
    2845,
    1033,
    647,
    1014,
    12861,
    2685,
    1287,
    1435,
    2549,
    1567,
    4269,
    420,
    815,
    223,
    3250,
    4178,
    4404,
    1440,
    6781,
    812,
    1060,
    7461,
    110,
    11446,
    9487,
    4646,
    2398,
    4897,
    333,
    2780,
    8664,
    4975,
    35220,
    2387,
    1049,
    928,
    565,
    4409,
    710,
    506,
    5854,
    21303,
    726,
    2370,
    457,
    6391,
    1834,
    13019,
    1478,
    1420,
    289,
    3168,
    8191,
    1115,
    6200,
    2363,
    777,
    3336,
    2692,
    868,
    13087,
    2657,
    2697,
    2066,
    4104,
    16220,
    1480,
    7194,
    1623,
    4106,
    4552,
    11109,
    499,
    998,
    4005,
    2752,
    800,
    1587,
    919,
    360,
    13549,
    548,
    1326,
    1339,
    3407,
    319,
    1273,
    3415,
    1853,
    1543,
    13402,
    6172,
    1293,
    611,
    1213,
    1146,
    1164,
    1310,
    268,
    594,
    2959,
    1561,
    279,
    5886,
    10452,
    4931,
    3058,
    542,
    530,
    1688,
    14982,
    4899,
    21021,
    5025,
    198,
    2612,
    1922,
    4781,
    6782,
    16384,
    88,
    622,
    6404,
    5735,
    4950,
    124,
    11203,
    1598,
    16384,
    1862,
    3589,
    5776,
    1350,
    17713,
    3749,
    12099,
    4997,
    1732,
    2540,
    2977,
    1374,
    450,
    480,
    4673,
    1860,
    510,
    12721,
    7003,
    372,
    4902,
    536,
    362,
    1028,
    1023,
    614,
    1752,
    2029,
    667,
    1756,
    27621,
    308,
    1996,
    666,
    2967,
    922,
    1112,
    866,
    466,
    1110,
    11116,
    3125,
    328,
    1361,
    7165,
    2750,
    1699,
    369,
    2735,
    2027,
    182,
    6033,
    5229,
    6818,
    1808,
    10125,
    3489,
    11693,
    1348,
    1772,
    1207,
    12838,
    1357,
    1363,
    1994,
    11628,
    4883,
    2383,
    1344,
    1519,
    1058,
    11759,
    1166,
    905,
    1868,
    18592,
    357,
    1020,
    3529,
    10250,
    4033,
    2598,
    10712,
    3792,
    945,
    1109,
    1597,
    881,
    3153,
    2015,
    633,
    528,
    15013,
    765,
    13866,
    686,
    10812,
    2723,
    7799,
    3357,
    7218,
    488,
    352,
    3232,
    593,
    4073,
    3268,
    1700,
    4709,
    945,
    5758,
    776,
    7625,
    2748,
    114,
    366,
    2186,
    11453,
    890,
    4455,
    5539,
    4354,
    28608,
    7293,
    241,
    4338,
    600,
    1463,
    4262,
    7905,
    2448,
    3193,
    2038,
    351,
    1297,
    5248,
    1284,
    3347,
    383,
    3000,
    734,
    4461,
    846,
    3744,
    927,
    15601,
    30733,
    16384,
    5980,
    441,
    3571,
    345,
    3507,
    1977,
    244,
    3780,
    465,
    730,
    1051,
    1700,
    5452,
    1748,
    3997,
    1238,
    6294,
    1365,
    6501,
    5605,
    995,
    280,
    796,
    3325,
    440,
    1691,
    3310,
    47638,
    825,
    1639,
    1469,
    14609,
    5447,
    3988,
    1754,
    3551,
    822,
    408,
    1121,
    1189,
    1241,
    1865,
    2689,
    511,
    16384,
    3819,
    4354,
    2319,
    1239,
    5006,
    368,
    16384,
    482,
    12276,
    3231,
    933,
    266,
    1755,
    2040,
    1776,
    286,
    12646,
    799,
    2803,
    1096,
    3632,
    5638,
    2582,
    3312,
    3889,
    1122,
    4145,
    1135,
    3000,
    16384,
    260,
    9054,
    1440,
    300,
    2862,
    673,
    16384,
    21082,
    4054,
    2516,
    1414,
    2022,
    795,
    4012,
    11264,
    473,
    3690,
    826,
    1992,
    4412,
    7421,
    2565,
    1984,
    147,
    1534,
    1065,
    5004,
    2473,
    4231,
    1762,
    22162,
    4005,
    263,
    1522,
    5155,
    4025,
    4102,
    3676,
    1408,
    861,
    3824,
    4771,
    4598,
    4705,
    30051,
    963,
    10419,
    12287,
    4589,
    5363,
    684,
    1555,
    5985,
    1384,
    820,
    1357,
    16384,
    4247,
    2799,
    1232,
    16384,
    2597,
    716,
    1712,
    765,
    4352,
    1415,
    1803,
    4066,
    1208,
    13286,
    2626,
    1038,
    1064,
    481,
    2942,
    1473,
    2421,
    4669,
    1412,
    1031,
    1834,
    4106,
    372,
    767,
    1574,
    7067,
    3884,
    16385,
    1902,
    436,
    3854,
    532,
    1192,
    6698,
    3404,
    3077,
    3531,
    16384,
    14153,
    14509,
    3620,
    12260,
    533,
    571,
    11153,
    6350,
    1335,
    1857,
    303,
    1682,
    313,
    321,
    459,
    13986,
    8908,
    851,
    1035,
    378,
    3934,
    647,
    3242,
    1446,
    9142,
    5415,
    13607,
    826,
    4748,
    1999,
    3258,
    17623,
    1386,
    12828,
    818,
    13065,
    2967,
    1757,
    4068,
    16384,
    736,
    1643,
    178,
    221,
    14812,
    873,
    657,
    872,
    1503,
    512,
    1850,
    2548,
    3146,
    3638,
    1350,
    2487,
    923,
    948,
    1194,
    6120,
    708,
    399,
    6082,
    1105,
    16384,
    850,
    1519,
    296,
    1893,
    3042,
    10519,
    4693,
    1689,
    7890,
    2556
  ],
  "output_lens": [
    20,
    24,
    4,
    4,
    18,
    13,
    17,
    7,
    15,
    8,
    12,
    5,
    8,
    5,
    16,
    2,
    10,
    13,
    27,
    22,
    1,
    14,
    1,
    1,
    9,
    4,
    21,
    67,
    10,
    19,
    13,
    26,
    3,
    73,
    0,
    19,
    1,
    2,
    3,
    9,
    3,
    22,
    5,
    7,
    17,
    1,
    46,
    7,
    4,
    24,
    7,
    7,
    5,
    1,
    20,
    15,
    69,
    10,
    1,
    10,
    1,
    6,
    12,
    49,
    1,
    54,
    37,
    18,
    1,
    53,
    13,
    1,
    10,
    4,
    5,
    14,
    2,
    41,
    17,
    6,
    21,
    31,
    28,
    14,
    26,
    2,
    0,
    6,
    5,
    2,
    1,
    1,
    33,
    18,
    18,
    14,
    7,
    6,
    5,
    6,
    19,
    9,
    22,
    1,
    11,
    7,
    1,
    2,
    1,
    7,
    4,
    16,
    14,
    0,
    1,
    12,
    3,
    30,
    3,
    28,
    13,
    7,
    4,
    11,
    13,
    0,
    68,
    3,
    19,
    60,
    60,
    22,
    43,
    10,
    15,
    3,
    1,
    1,
    8,
    14,
    8,
    21,
    11,
    5,
    10,
    7,
    0,
    24,
    3,
    1,
    16,
    22,
    1,
    17,
    20,
    15,
    31,
    1,
    49,
    15,
    10,
    1,
    1,
    33,
    12,
    2,
    5,
    12,
    10,
    7,
    10,
    3,
    26,
    3,
    7,
    37,
    14,
    2,
    4,
    1,
    6,
    12,
    13,
    45,
    32,
    33,
    22,
    11,
    17,
    15,
    11,
    21,
    2,
    9,
    6,
    68,
    25,
    62,
    8,
    3,
    13,
    9,
    7,
    6,
    8,
    10,
    0,
    15,
    15,
    11,
    1,
    5,
    39,
    5,
    3,
    1,
    14,
    1,
    10,
    12,
    8,
    25,
    0,
    8,
    8,
    4,
    1,
    4,
    5,
    19,
    36,
    4,
    38,
    4,
    6,
    33,
    4,
    2,
    39,
    15,
    11,
    23,
    1,
    1,
    6,
    9,
    1,
    26,
    3,
    7,
    15,
    27,
    12,
    7,
    21,
    9,
    47,
    22,
    8,
    9,
    10,
    8,
    18,
    8,
    19,
    8,
    5,
    4,
    5,
    1,
    7,
    6,
    1,
    4,
    2,
    11,
    18,
    16,
    10,
    2,
    78,
    2,
    81,
    2,
    14,
    24,
    31,
    10,
    8,
    10,
    5,
    26,
    9,
    17,
    17,
    10,
    20,
    1,
    6,
    43,
    3,
    25,
    9,
    3,
    1,
    11,
    2,
    28,
    12,
    4,
    11,
    12,
    13,
    40,
    9,
    85,
    18,
    1,
    4,
    1,
    43,
    11,
    40,
    17,
    10,
    2,
    9,
    34,
    10,
    7,
    20,
    1,
    21,
    23,
    37,
    0,
    13,
    2,
    36,
    1,
    2,
    32,
    14,
    13,
    1,
    7,
    1,
    75,
    6,
    25,
    19,
    13,
    17,
    1,
    12,
    5,
    13,
    5,
    1,
    2,
    2,
    25,
    13,
    13,
    4,
    27,
    6,
    6,
    1,
    8,
    8,
    10,
    5,
    2,
    9,
    3,
    7,
    4,
    5,
    7,
    17,
    16,
    10,
    77,
    0,
    0,
    14,
    2,
    3,
    61,
    6,
    6,
    12,
    1,
    12,
    2,
    9,
    1,
    3,
    7,
    11,
    15,
    54,
    1,
    1,
    1,
    5,
    10,
    17,
    27,
    66,
    42,
    19,
    1,
    1,
    74,
    8,
    26,
    12,
    10,
    21,
    13,
    8,
    10,
    1,
    3,
    52,
    8,
    1,
    8,
    2,
    31,
    34,
    37,
    1,
    28,
    7,
    3,
    4,
    10,
    5,
    32,
    2,
    10,
    6,
    1,
    4,
    15,
    25,
    14,
    13,
    9,
    10,
    5,
    12,
    10,
    11,
    2,
    25,
    27,
    29,
    5,
    23,
    19,
    6,
    10,
    15,
    16,
    6,
    4,
    32,
    3,
    11,
    1,
    5,
    0,
    1,
    6,
    10,
    25,
    26,
    1,
    56,
    22,
    69,
    1,
    1,
    11,
    8,
    52,
    5,
    6,
    1,
    39,
    21,
    4,
    9,
    2,
    2,
    18,
    0,
    14,
    1,
    9,
    4,
    10,
    4,
    1,
    4,
    1,
    3,
    10,
    30,
    25,
    3,
    16,
    2,
    3,
    10,
    9,
    9,
    6,
    6,
    9,
    32,
    2,
    12,
    1,
    19,
    27,
    28,
    18,
    5,
    1,
    5,
    31,
    4,
    19,
    8,
    1,
    3,
    25,
    52,
    10,
    17,
    12,
    4,
    30,
    3,
    4,
    9,
    1,
    10,
    41,
    1,
    3,
    23,
    2,
    24,
    14,
    17,
    12,
    15,
    10,
    17,
    32,
    1,
    3,
    1,
    13,
    54,
    23,
    5,
    8,
    6,
    2,
    37,
    6,
    24,
    16,
    12,
    1,
    6,
    10,
    1,
    3,
    1,
    6,
    13,
    22,
    13,
    1,
    6,
    29,
    4,
    19,
    5,
    11,
    9,
    26,
    2,
    20,
    6,
    9,
    1,
    8,
    1,
    16,
    2,
    10,
    15,
    19,
    5,
    3,
    1,
    9,
    64,
    2,
    18,
    5,
    13,
    3,
    5,
    30,
    14,
    5,
    10,
    21,
    3,
    14,
    7,
    118,
    28,
    10,
    10,
    7,
    22,
    8,
    3,
    1,
    27,
    2,
    10,
    25,
    29,
    33,
    1,
    5,
    11,
    27,
    22,
    16,
    1,
    4,
    107,
    71,
    6,
    17,
    12,
    4,
    14,
    15,
    2,
    1,
    39,
    16,
    34,
    11,
    8,
    9,
    21,
    5,
    8,
    10,
    40,
    6,
    14,
    13,
    8,
    2,
    8,
    29,
    8,
    6,
    15,
    2,
    3,
    30,
    13,
    10,
    13,
    1,
    6,
    3,
    14,
    4,
    11,
    3,
    7,
    54,
    5,
    2,
    1,
    14,
    10,
    1,
    3,
    3,
    10,
    12,
    71,
    10,
    10,
    22,
    30,
    23,
    6,
    20,
    0,
    4,
    30,
    47,
    10,
    40,
    6,
    11,
    6,
    1,
    17,
    1,
    4,
    39,
    1,
    7,
    3,
    62,
    16,
    3,
    16,
    19,
    1,
    15,
    11,
    5,
    6,
    8,
    11,
    26,
    4,
    10,
    1,
    2,
    3,
    2,
    22,
    6,
    4,
    7,
    3,
    27,
    14,
    5,
    116,
    40,
    18,
    5,
    1,
    11,
    23,
    6,
    32,
    24,
    34,
    12,
    15,
    5,
    18,
    1,
    3,
    9,
    35,
    3,
    10,
    19,
    1,
    1,
    14,
    37,
    16,
    3,
    4,
    18,
    35,
    3,
    23,
    10,
    10,
    3,
    32,
    14,
    7,
    19,
    18,
    0,
    1,
    1,
    51,
    11,
    9,
    6,
    33,
    17,
    36,
    3,
    0,
    37,
    12,
    4,
    4,
    7,
    28,
    22,
    17,
    13,
    41,
    4,
    28,
    23,
    1,
    26,
    5,
    56,
    60,
    7,
    1,
    9,
    14,
    23,
    29,
    11,
    24,
    3,
    1,
    6,
    10,
    15,
    11,
    6,
    49,
    3,
    3,
    0,
    3,
    1,
    11,
    15,
    11,
    1,
    25,
    1,
    1,
    24,
    3,
    7,
    13,
    20,
    4,
    1,
    5,
    25,
    6,
    3,
    4,
    10,
    8,
    31,
    25,
    11,
    15,
    5,
    4,
    3,
    11,
    0,
    1,
    48,
    10,
    0,
    4,
    3,
    53,
    6,
    23,
    22,
    43,
    22,
    6,
    1,
    4,
    17,
    3,
    12,
    19,
    3,
    10,
    14,
    58,
    2,
    20,
    1,
    1,
    3,
    16,
    26,
    14,
    28,
    0,
    15,
    6,
    1,
    10,
    10,
    10,
    10,
    9,
    17,
    8,
    40,
    3,
    0,
    1,
    33,
    13,
    1,
    10,
    15,
    13,
    1,
    12,
    3,
    22,
    2,
    1,
    29,
    6,
    17,
    9,
    1,
    13,
    3,
    2,
    9,
    2,
    3,
    7,
    1,
    2,
    5,
    10,
    7,
    4,
    1,
    1,
    1,
    1,
    7,
    4,
    8,
    6,
    34,
    3,
    3,
    1,
    15,
    1,
    1,
    44,
    1,
    0,
    8,
    16,
    16,
    1,
    2,
    45,
    8,
    7,
    1,
    1,
    1,
    14,
    6,
    1,
    0,
    25,
    5,
    20,
    5,
    12,
    3,
    8,
    4,
    10,
    10,
    14,
    38,
    4,
    0,
    11,
    5,
    16,
    5,
    40,
    10,
    7,
    1,
    3,
    2,
    6,
    2,
    0,
    25,
    4,
    29,
    21,
    34,
    5,
    1,
    3,
    8,
    48,
    21,
    1,
    6,
    2,
    3,
    12,
    1,
    16,
    1,
    19,
    23,
    21,
    1,
    49,
    10,
    39,
    40,
    55,
    19,
    4,
    4,
    1,
    1,
    1,
    6,
    14,
    36,
    1,
    4,
    8,
    14,
    1,
    24,
    9,
    10,
    7,
    5,
    20,
    34,
    21,
    3,
    60,
    43,
    1,
    1,
    58,
    22,
    24,
    20,
    1,
    29,
    19,
    4,
    36,
    4,
    1,
    3,
    6,
    8,
    11,
    16,
    5,
    9,
    1,
    10,
    80,
    1,
    4,
    19,
    8,
    11,
    10,
    37,
    16,
    10,
    8,
    39,
    9,
    10,
    17,
    1,
    1,
    30,
    7,
    2,
    9,
    11,
    11,
    12,
    28,
    2,
    16,
    2,
    4,
    1,
    45,
    56,
    13,
    1,
    41,
    1,
    11,
    11,
    1,
    8,
    8,
    7,
    66,
    13,
    12,
    24,
    5,
    41,
    6,
    123,
    8,
    21,
    10,
    15,
    3,
    12,
    6,
    47,
    37,
    1,
    63,
    3,
    9,
    3,
    10,
    3,
    39,
    12,
    23,
    2,
    1,
    19,
    7,
    32,
    2,
    35,
    15,
    15,
    2,
    32,
    10,
    12,
    10,
    5,
    22,
    1,
    16,
    30,
    3,
    6,
    23,
    18,
    10,
    3,
    11,
    14,
    16,
    12,
    1,
    6,
    12,
    76,
    1,
    18,
    30,
    24,
    9,
    8,
    22,
    11,
    1,
    24,
    8,
    5,
    0,
    2,
    7,
    10,
    15,
    4,
    11,
    4,
    9,
    14,
    1,
    5,
    15,
    5,
    10,
    1,
    3,
    39,
    1,
    0,
    1,
    8,
    0,
    43,
    11,
    0,
    10,
    4,
    18,
    7,
    5,
    0,
    9,
    1,
    0,
    6,
    5,
    2,
    46,
    12,
    17,
    16,
    46,
    57,
    4,
    31,
    2,
    9,
    16,
    0,
    28,
    2,
    52,
    12,
    20,
    8,
    9,
    1,
    2,
    1,
    4,
    4,
    5,
    16,
    43,
    20,
    3,
    5,
    2,
    4,
    22,
    35,
    21,
    17,
    0,
    9,
    47,
    42,
    6,
    3,
    1,
    71,
    12,
    4,
    14,
    9,
    23,
    2,
    36,
    24,
    0,
    40,
    6,
    20,
    1,
    7,
    12,
    42,
    24,
    1,
    10,
    2,
    27,
    26,
    39,
    98,
    1,
    1,
    18,
    2,
    22,
    4,
    1,
    1,
    0,
    33,
    10,
    22,
    1,
    76,
    1,
    3,
    25,
    3,
    9,
    9,
    4,
    18,
    3,
    11,
    24,
    9,
    40,
    13,
    2,
    27,
    31,
    15,
    24,
    10,
    11,
    10,
    3,
    10,
    4,
    12,
    10,
    2,
    11,
    7,
    6,
    1,
    31,
    20,
    13,
    28,
    12,
    5,
    22,
    7,
    41,
    6,
    5,
    6,
    7,
    9,
    1,
    1,
    7,
    5,
    15,
    15,
    1,
    4,
    15,
    36,
    1,
    9,
    22,
    7,
    22,
    3,
    2,
    19,
    3,
    1,
    17,
    20,
    25,
    1,
    16,
    10,
    14,
    22,
    10,
    22,
    31,
    1,
    3,
    31,
    23,
    4,
    7,
    19,
    9,
    22,
    31,
    14,
    18,
    1,
    14,
    1,
    1,
    21,
    30,
    18,
    16,
    18,
    52,
    5,
    18,
    9,
    8,
    20,
    15,
    28,
    21,
    28,
    1,
    13,
    0,
    7,
    17,
    1,
    1,
    51,
    9,
    1,
    1,
    48,
    57,
    0,
    3,
    0,
    1,
    13,
    5,
    10,
    5,
    8,
    22,
    7,
    3,
    38,
    19,
    1,
    5,
    10,
    14,
    7,
    10,
    7,
    0,
    8,
    44,
    3,
    19,
    26,
    21,
    2,
    1,
    36,
    13,
    3,
    10,
    4,
    10,
    10,
    8,
    10,
    9,
    12,
    30,
    8,
    6,
    10,
    1,
    47,
    3,
    7,
    21,
    13,
    3,
    18,
    3,
    1,
    11,
    5,
    3,
    13,
    64,
    42,
    40,
    36,
    26,
    20,
    34,
    1,
    2,
    28,
    2,
    14,
    3,
    12,
    45,
    3,
    59,
    0,
    9,
    10,
    10,
    2,
    10,
    26,
    1,
    6,
    1,
    1,
    29,
    6,
    5,
    3,
    5,
    10,
    21,
    10,
    3,
    1,
    49,
    19,
    2,
    3,
    3,
    3,
    11,
    8,
    28,
    48,
    12,
    2,
    5,
    0,
    5,
    25,
    5,
    13,
    5,
    1,
    4,
    51,
    33,
    6,
    21,
    28,
    36,
    9,
    12,
    6,
    3,
    8,
    13,
    13,
    39,
    16,
    6,
    17,
    8,
    2,
    23,
    2,
    25,
    31,
    21,
    15,
    1,
    43,
    1,
    25,
    2,
    1,
    42,
    3,
    12,
    1,
    0,
    32,
    4,
    5,
    15,
    15,
    26,
    27,
    1,
    28,
    15,
    5,
    1,
    9,
    14,
    7,
    21,
    1,
    2,
    32,
    40,
    9,
    13,
    18,
    8,
    10,
    11,
    29,
    17,
    9,
    1,
    22,
    10,
    6,
    9,
    3,
    1,
    17,
    28,
    42,
    12,
    10,
    31,
    7,
    6,
    32,
    2,
    24,
    33,
    0,
    3,
    11,
    2,
    9,
    52,
    1,
    23,
    8,
    1,
    1,
    9,
    3,
    24,
    14,
    1,
    7,
    7,
    1,
    3,
    29,
    12,
    2,
    1,
    19,
    7,
    50,
    21,
    14,
    23,
    25,
    2,
    12,
    27,
    7,
    1,
    3,
    14,
    10,
    10,
    17,
    11,
    0,
    25,
    14,
    19,
    32,
    4,
    21,
    1,
    10,
    1,
    6,
    0,
    17,
    24,
    8,
    22,
    21,
    1,
    15,
    25,
    13,
    11,
    10,
    1,
    10,
    3,
    2,
    14,
    23,
    4,
    1,
    2,
    3,
    1,
    12,
    9,
    69,
    59,
    14,
    5,
    7,
    11,
    7,
    49,
    3,
    13,
    11,
    16,
    5,
    58,
    22,
    7,
    12,
    1,
    21,
    0,
    17,
    10,
    2,
    10,
    5,
    24,
    11,
    0,
    5,
    37,
    5,
    3,
    4,
    34,
    7,
    1,
    3,
    19,
    1,
    1,
    5,
    15,
    1,
    28,
    2,
    4,
    34,
    56,
    5,
    13,
    23,
    21,
    5,
    1,
    1,
    1,
    10,
    49,
    48,
    0,
    10,
    1,
    1,
    2,
    1,
    12,
    9,
    1,
    14,
    10,
    13,
    1,
    16,
    55,
    35,
    37,
    52,
    25,
    7,
    67,
    11,
    10,
    3,
    12,
    5,
    5,
    31,
    49,
    18,
    7,
    5,
    30,
    18,
    3,
    10,
    0,
    11,
    3,
    6,
    13,
    18,
    6,
    0,
    9,
    25,
    6,
    3,
    36,
    1,
    3,
    1,
    18,
    51,
    67,
    12,
    28,
    28,
    3,
    11,
    5,
    23,
    10,
    5,
    32,
    7,
    2,
    40,
    4,
    29,
    21,
    24,
    19,
    31,
    3,
    68,
    15,
    12,
    45,
    45,
    53,
    38,
    12,
    81,
    1,
    1,
    22,
    26,
    7,
    1,
    16,
    2,
    10,
    24,
    13,
    12,
    16,
    1,
    7,
    29,
    23,
    34,
    22,
    10,
    6,
    12,
    8,
    50,
    53,
    17,
    15,
    38,
    13,
    10,
    32,
    30,
    7,
    57,
    5,
    16,
    30,
    14,
    14,
    1,
    6,
    8,
    7,
    5,
    1,
    6,
    31,
    20,
    1,
    1,
    0,
    14,
    1,
    8,
    2,
    33,
    29,
    19,
    0,
    12,
    9,
    18,
    33,
    3,
    20,
    3,
    36,
    10,
    1,
    1,
    10,
    16,
    55,
    7,
    1,
    14,
    2,
    61,
    7,
    12,
    4,
    37,
    1,
    4,
    1,
    45,
    6,
    6,
    28,
    34,
    10,
    31,
    46,
    9,
    11,
    3,
    3,
    16,
    43,
    7,
    59,
    13,
    20,
    16,
    1,
    5,
    43,
    13,
    1,
    16,
    7,
    27,
    3,
    83,
    25,
    1,
    3,
    30,
    4,
    64,
    7,
    1,
    18,
    7,
    14,
    4,
    7,
    28,
    23,
    54,
    10,
    6,
    23,
    8,
    1,
    22,
    10,
    16,
    36,
    3,
    1,
    1,
    9,
    3,
    14,
    23,
    16,
    6,
    8,
    1,
    31,
    10,
    10,
    4,
    3,
    55,
    1,
    79,
    1,
    3,
    0,
    3,
    27,
    18,
    1,
    10,
    1,
    12,
    5,
    9,
    5,
    5,
    8,
    4,
    18,
    2,
    1,
    1,
    1,
    3,
    18,
    1,
    32,
    16,
    39,
    1,
    18,
    68,
    7,
    8,
    26,
    7,
    28,
    14,
    8,
    2,
    51,
    4,
    3,
    1,
    15,
    7,
    2,
    17,
    19,
    2,
    27,
    26,
    47,
    1,
    29,
    1,
    34,
    13,
    46,
    3,
    23,
    15,
    17,
    8,
    3,
    92,
    28,
    5,
    11,
    19,
    4,
    5,
    38,
    8,
    8,
    64,
    2,
    1,
    10,
    10,
    0,
    8,
    25,
    14,
    1,
    3,
    26,
    1,
    11,
    26,
    10,
    2,
    10,
    10,
    2,
    48,
    29,
    18,
    34,
    35,
    8,
    6,
    24,
    10,
    42,
    9,
    29,
    21,
    8,
    5,
    3,
    0,
    9,
    10,
    5,
    7,
    4,
    2,
    10,
    46,
    27,
    7,
    5,
    14,
    24,
    15,
    8,
    6,
    3,
    8,
    5,
    9,
    9,
    3,
    42,
    23,
    3,
    8,
    12,
    1,
    2,
    2,
    14,
    27,
    2,
    13,
    1,
    23,
    1,
    24,
    12,
    10,
    17,
    13,
    37,
    10,
    1,
    2,
    10,
    15,
    10,
    1,
    4,
    5,
    29,
    3,
    11,
    10,
    13,
    2,
    28,
    14,
    16,
    4,
    1,
    17,
    22,
    13,
    19,
    1,
    3,
    10,
    17,
    3,
    16,
    1,
    2,
    1,
    30,
    3,
    101,
    31,
    10,
    0,
    1,
    31,
    17,
    12,
    15,
    10,
    3,
    5,
    7,
    28,
    8,
    1,
    13,
    8,
    8,
    21,
    5,
    9,
    30,
    10,
    21,
    7,
    7,
    19,
    12,
    2,
    7,
    20,
    35,
    10,
    27,
    10,
    9,
    11,
    13,
    5,
    17,
    20,
    4,
    6,
    15,
    17,
    48,
    3,
    11,
    12,
    32,
    24,
    55,
    41,
    2,
    10,
    1,
    18,
    10,
    2,
    17,
    7,
    1,
    1,
    14,
    24,
    10,
    7,
    22,
    1,
    26,
    2,
    5,
    15,
    11,
    2,
    0,
    8,
    4,
    8,
    7,
    28,
    12,
    29,
    2,
    29,
    5,
    20,
    10,
    14,
    16,
    16,
    43,
    18,
    10,
    0,
    28,
    5,
    9,
    7,
    11,
    55,
    1,
    11,
    3,
    2,
    11,
    12,
    3,
    5,
    1,
    8,
    5,
    47,
    9,
    25,
    56,
    1,
    17,
    27,
    1,
    1,
    15,
    12,
    1,
    55,
    5,
    33,
    10,
    33,
    14,
    34,
    19,
    9,
    4,
    43,
    25,
    12,
    4,
    0,
    7,
    8,
    26,
    2,
    12,
    5,
    4,
    1,
    2,
    55,
    1,
    2,
    6,
    46,
    13,
    4,
    40,
    9,
    17,
    10,
    1,
    1,
    12,
    1,
    29,
    28,
    15,
    1,
    14,
    10,
    1,
    1,
    1,
    1,
    3,
    10,
    1,
    5,
    24,
    8,
    0,
    10,
    11,
    8,
    34,
    5,
    4,
    10,
    2,
    1,
    18,
    1,
    12,
    4,
    6,
    1,
    36,
    4,
    10,
    24,
    1,
    21,
    1,
    3,
    33,
    5,
    5,
    6,
    69,
    6,
    5,
    3,
    4,
    30,
    5,
    3,
    1,
    0,
    16,
    1,
    7,
    17,
    10,
    1,
    1,
    22,
    3,
    11,
    1,
    11,
    13,
    47,
    0,
    23,
    17,
    22,
    1,
    3,
    47,
    9,
    5,
    10,
    5,
    1,
    0,
    31,
    17,
    1,
    10,
    4,
    2,
    22,
    1,
    32,
    21,
    6,
    15,
    9,
    23,
    26,
    13,
    6,
    8,
    16,
    1,
    34,
    4,
    74,
    5,
    14,
    8,
    5,
    18,
    16,
    18,
    2,
    14,
    2,
    3,
    12,
    1,
    16,
    10,
    1,
    10,
    6,
    10,
    6,
    5,
    1,
    4,
    1,
    18,
    27,
    18,
    8,
    6,
    6,
    27,
    24,
    38,
    3,
    7,
    10,
    9,
    17,
    11,
    14,
    24,
    10,
    31,
    18,
    4,
    29,
    6,
    2,
    6,
    10,
    3,
    26,
    10,
    4,
    1,
    1,
    1,
    51,
    17,
    4,
    24,
    1,
    6,
    19,
    19,
    33,
    18,
    55,
    1,
    4,
    5,
    10,
    10,
    3,
    10,
    1,
    2,
    62,
    11,
    17,
    28,
    1,
    10,
    9,
    1,
    21,
    14,
    2,
    9,
    10,
    3,
    32,
    13,
    19,
    1,
    23,
    42,
    14,
    3,
    16,
    6,
    27,
    3,
    2,
    7,
    8,
    10,
    70,
    10,
    8,
    3,
    52,
    31,
    6,
    1,
    0,
    25,
    1,
    20,
    11,
    13,
    67,
    4,
    11,
    7,
    3,
    10,
    52,
    3,
    77,
    13,
    0,
    1,
    0,
    15,
    5,
    10,
    0,
    1,
    1,
    4,
    1,
    4,
    5,
    9,
    13,
    1,
    11,
    2,
    30,
    25,
    10,
    1,
    7,
    0,
    17,
    31,
    16,
    11,
    4,
    1,
    18,
    28,
    5,
    35,
    13,
    8,
    1,
    6,
    6,
    10,
    3,
    12,
    7,
    24,
    1,
    12,
    16,
    3,
    54,
    6,
    3,
    26,
    3,
    1,
    13,
    10,
    6,
    9,
    7,
    8,
    1,
    12,
    13,
    1,
    5,
    7,
    8,
    3,
    16,
    3,
    9,
    6,
    1,
    7,
    4,
    26,
    9,
    10,
    29,
    13,
    16,
    31,
    7,
    3,
    59,
    14,
    16,
    17,
    5,
    9,
    37,
    9,
    37,
    5,
    5,
    3,
    4,
    13,
    31,
    6,
    39,
    9,
    3,
    1,
    14,
    2,
    12,
    1,
    34,
    5,
    18,
    15,
    23,
    1,
    1,
    28,
    5,
    1,
    3,
    7,
    1,
    10,
    17,
    39,
    2,
    3,
    9,
    2,
    26,
    3,
    2,
    2,
    5,
    68,
    5,
    12,
    6,
    6,
    13,
    1,
    5,
    12,
    8,
    37,
    5,
    6,
    11,
    3,
    11,
    13,
    52,
    13,
    22,
    29,
    105,
    10,
    8,
    29,
    10,
    5,
    9,
    32,
    2,
    39,
    4,
    11,
    6,
    5,
    10,
    10,
    1,
    8,
    12,
    13,
    8,
    8,
    1,
    4,
    5,
    4,
    19,
    9,
    27,
    5,
    3,
    6,
    40,
    5,
    1,
    61,
    36,
    8,
    10,
    28,
    4,
    2,
    1,
    3,
    4,
    1,
    9,
    29,
    16,
    1,
    29,
    45,
    20,
    1,
    18,
    10,
    32,
    10,
    19,
    5,
    6,
    4,
    11,
    3,
    21,
    38,
    21,
    23,
    5,
    15,
    17,
    25,
    44,
    17,
    9,
    3,
    20,
    0,
    1,
    14,
    3,
    13,
    13,
    13,
    11,
    11,
    2,
    17,
    0,
    4,
    1,
    1,
    53,
    7,
    2,
    10,
    68,
    10,
    31,
    11,
    8,
    21,
    26,
    3,
    37,
    8,
    1,
    4,
    1,
    7,
    1,
    11,
    20,
    6,
    8,
    25,
    19,
    20,
    0,
    4,
    6,
    2,
    8,
    18,
    1,
    26,
    21,
    3,
    14,
    30,
    1,
    3,
    4,
    17,
    15,
    8,
    9,
    20,
    13,
    9,
    1,
    40,
    2,
    1,
    20,
    27,
    8,
    13,
    5,
    54,
    17,
    3,
    7,
    1,
    7,
    49,
    3,
    11,
    33,
    10,
    10,
    23,
    40,
    9,
    37,
    34,
    42,
    39,
    5,
    1,
    36,
    8,
    15,
    6,
    10,
    23,
    28,
    9,
    16,
    28,
    27,
    12,
    29,
    18,
    0,
    25,
    7,
    1,
    39,
    44,
    60,
    17,
    18,
    1,
    10,
    15,
    19,
    2,
    5,
    36,
    29,
    12,
    14,
    12,
    31,
    14,
    2,
    1,
    3,
    9,
    35,
    35,
    13,
    10,
    30,
    11,
    2,
    13,
    9,
    6,
    18,
    1,
    7,
    4,
    0,
    22,
    1,
    1,
    15,
    7,
    16,
    7,
    1,
    23,
    0,
    3,
    17,
    10,
    8,
    47,
    11,
    19,
    9,
    70,
    17,
    7,
    1,
    14,
    1,
    3,
    10,
    29,
    7,
    11,
    6,
    15,
    9,
    6,
    9,
    21,
    9,
    10,
    1,
    66,
    3,
    3,
    6,
    3,
    8,
    11,
    27,
    9,
    2,
    9,
    4,
    1,
    3,
    2,
    10,
    27,
    23,
    27,
    11,
    9,
    20,
    1,
    29,
    10,
    1,
    7,
    39,
    16,
    7,
    37,
    15,
    11,
    7,
    2,
    1,
    8,
    4,
    1,
    8,
    20,
    10,
    17,
    2,
    7,
    4,
    27,
    12,
    3,
    1,
    41,
    7,
    4,
    10,
    45,
    18,
    2,
    4,
    5,
    2,
    61,
    30,
    20,
    17,
    4,
    18,
    9,
    32,
    2,
    64,
    5,
    8,
    55,
    0,
    6,
    11,
    30,
    2,
    6,
    2,
    7,
    5,
    2,
    21,
    30,
    2,
    10,
    34,
    21,
    1,
    6,
    5,
    8,
    11,
    10,
    16,
    16,
    3,
    30,
    6,
    18,
    9,
    1,
    4,
    6,
    9,
    28,
    4,
    6,
    19,
    1,
    19,
    19,
    14,
    1,
    36,
    10,
    14,
    8,
    8,
    13,
    19,
    12,
    2,
    12,
    20,
    6,
    34,
    11,
    1,
    0,
    25,
    21,
    1,
    29,
    40,
    6,
    6,
    2,
    9,
    10,
    0,
    9,
    26,
    12,
    34,
    2,
    33,
    1,
    0,
    4,
    1,
    24,
    10,
    10,
    11,
    34,
    10,
    3,
    20,
    13,
    15,
    9,
    33,
    2,
    9,
    17,
    13,
    6,
    1,
    16,
    60,
    27,
    12,
    59,
    52,
    10,
    4,
    3,
    0,
    8,
    30,
    1,
    38,
    2,
    1,
    10,
    10,
    11,
    1,
    17,
    2,
    7,
    2,
    10,
    50,
    37,
    11,
    5,
    11,
    6,
    15,
    35,
    11,
    2,
    1,
    11,
    13,
    26,
    11,
    11,
    6,
    3,
    6,
    4,
    21,
    5,
    2,
    16,
    12,
    1,
    9,
    7,
    1,
    13,
    38,
    7,
    27,
    9,
    2,
    34,
    0,
    3,
    6,
    1,
    1,
    22,
    3,
    22,
    39,
    3,
    27,
    10,
    10,
    44,
    1,
    15,
    10,
    17,
    6,
    19,
    37,
    7,
    49,
    54,
    11,
    1,
    18,
    19,
    8,
    1,
    5,
    20,
    17,
    11,
    24,
    12,
    37,
    18,
    4,
    37,
    15,
    40,
    23,
    13,
    23,
    22,
    9,
    23,
    32,
    16,
    54,
    66,
    47,
    31,
    11,
    24,
    1,
    2,
    9,
    63,
    2,
    42,
    22,
    1,
    25,
    18,
    11,
    9,
    0,
    8,
    15,
    1,
    3,
    2,
    3,
    43,
    1,
    40,
    12,
    16,
    69,
    17,
    5,
    3,
    36,
    7,
    20,
    4,
    14,
    2,
    8,
    85,
    55,
    5,
    3,
    10,
    9,
    2,
    8,
    1,
    2,
    24,
    10,
    24,
    1,
    1,
    23,
    0,
    55,
    6,
    6,
    26,
    3,
    14,
    5,
    1,
    37,
    7,
    24,
    27,
    18,
    15,
    3,
    8,
    11,
    35,
    11,
    10,
    7,
    32,
    43,
    1,
    7,
    49,
    8,
    4,
    0,
    8,
    22,
    14,
    6,
    3,
    2,
    1,
    15,
    5,
    21,
    2,
    1,
    6,
    30,
    13,
    3,
    2,
    1,
    11,
    1,
    3,
    12,
    1,
    4,
    1,
    10,
    2,
    1,
    7,
    20,
    31,
    23,
    3,
    21,
    6,
    3,
    15,
    5,
    1,
    28,
    3,
    4,
    8,
    10,
    7,
    91,
    15,
    1,
    8,
    15,
    59,
    0,
    22,
    11,
    42,
    1,
    12,
    3,
    1,
    40,
    39,
    9,
    3,
    2,
    6,
    11,
    1,
    11,
    12,
    20,
    3,
    23,
    83,
    1,
    30,
    3,
    5,
    9,
    3,
    29,
    17,
    7,
    13,
    14,
    21,
    35,
    25,
    24,
    42,
    6,
    18,
    14,
    5,
    2,
    14,
    11,
    41,
    11,
    12,
    17,
    8,
    8,
    0,
    29,
    80,
    1,
    7,
    12,
    3,
    37,
    20,
    13,
    3,
    10,
    9,
    19,
    1,
    7,
    14,
    4,
    30,
    16,
    9,
    3,
    32,
    15,
    16,
    1,
    58,
    10,
    19,
    2,
    1,
    25,
    15,
    16,
    7,
    14,
    40,
    1,
    1,
    11,
    1,
    9,
    11,
    10,
    10,
    56,
    1,
    8,
    3,
    3,
    2,
    12,
    46,
    2,
    0,
    5,
    21,
    2,
    1,
    1,
    5,
    1,
    7,
    3,
    26,
    18,
    18,
    1,
    11,
    1,
    21,
    1,
    10,
    10,
    7,
    10,
    12,
    0,
    1,
    1,
    7,
    23,
    10,
    12,
    10,
    11,
    1,
    23,
    7,
    17,
    12,
    15,
    8,
    8,
    35,
    0,
    0,
    22,
    10,
    16,
    6,
    39,
    22,
    10,
    14,
    10,
    10,
    10,
    14,
    9,
    6,
    11,
    3,
    27,
    36,
    5,
    13,
    2,
    22,
    0,
    61,
    10,
    25,
    12,
    10,
    10,
    1,
    18,
    19,
    1,
    0,
    1,
    26,
    22,
    3,
    1,
    15,
    1,
    7,
    16,
    1,
    6,
    35,
    27,
    9,
    2,
    13,
    6,
    18,
    11,
    9,
    18,
    8,
    16,
    4,
    5,
    1,
    27,
    3,
    23,
    36,
    60,
    10,
    22,
    15,
    26,
    44,
    11,
    7,
    1,
    53,
    8,
    9,
    24,
    41,
    23,
    2,
    41,
    23,
    14,
    11,
    8,
    68,
    22,
    64,
    27,
    13,
    9,
    23,
    19,
    37,
    7,
    24,
    16,
    1,
    5,
    20,
    16,
    21,
    7,
    18,
    33,
    19,
    35,
    1,
    38,
    10,
    1,
    10,
    6,
    1,
    7,
    10,
    10,
    15,
    13,
    10,
    4,
    10,
    5,
    19,
    5,
    2,
    44,
    11,
    24,
    2,
    23,
    18,
    35,
    1,
    10,
    33,
    61,
    1,
    10,
    9,
    17,
    22,
    32,
    22,
    23,
    1,
    43,
    8,
    7,
    19,
    4,
    1,
    3,
    4,
    10,
    29,
    10,
    9,
    8,
    10,
    32,
    1,
    4,
    29,
    10,
    21,
    17,
    17,
    9,
    71,
    6,
    11,
    3,
    3,
    33,
    25,
    57,
    5,
    10,
    5,
    66,
    7,
    3,
    22,
    2,
    10,
    28,
    13,
    31,
    11,
    1,
    31,
    6,
    19,
    17,
    12,
    3,
    33,
    20,
    9,
    1,
    10,
    13,
    2,
    10,
    8,
    1,
    7,
    51,
    7,
    2,
    38,
    1,
    19,
    7,
    5,
    42,
    5,
    2,
    17,
    1,
    2,
    9,
    8,
    17,
    81,
    11,
    3,
    7,
    2,
    5,
    65,
    10,
    14,
    19,
    27,
    1,
    36,
    10,
    13,
    5,
    1,
    14,
    0,
    7,
    1,
    4,
    3,
    5,
    14,
    1,
    15,
    6,
    1,
    7,
    26,
    84,
    16,
    57,
    9,
    9,
    4,
    9,
    42,
    3,
    5,
    8,
    10,
    2,
    10,
    19,
    5,
    8,
    1,
    11,
    1,
    6,
    3,
    4,
    15,
    70,
    6,
    17,
    1,
    10,
    1,
    49,
    10,
    7,
    5,
    18,
    2,
    30,
    19,
    46,
    1,
    18,
    10,
    6,
    15,
    3,
    2,
    36,
    21,
    3,
    46,
    1,
    2,
    41,
    1,
    20,
    16,
    21,
    1,
    4,
    12,
    20,
    24,
    10,
    23,
    3,
    10,
    13,
    17,
    20,
    1,
    1,
    5,
    7,
    1,
    6,
    10,
    2,
    8,
    6,
    12,
    2,
    1,
    23,
    39,
    7,
    1,
    14,
    27,
    6,
    12,
    6,
    35,
    14,
    3,
    10,
    34,
    19,
    10,
    1,
    3,
    21,
    31,
    22,
    20,
    13,
    4,
    1,
    10,
    3,
    5,
    8,
    4,
    23,
    1,
    10,
    6,
    20,
    0,
    4,
    5,
    1,
    1,
    4,
    1,
    6,
    16,
    10,
    12,
    10,
    5,
    6,
    28,
    16,
    20,
    1,
    42,
    5,
    4,
    25,
    3,
    27,
    6,
    10,
    1,
    1,
    20,
    5,
    9,
    25,
    109,
    11,
    1,
    74,
    24,
    1,
    1,
    48,
    35,
    21,
    1,
    9,
    26,
    13,
    2,
    18,
    8,
    1,
    3,
    16,
    0,
    13,
    1,
    1,
    2,
    0,
    37,
    20,
    15,
    1,
    4,
    3,
    2,
    1,
    11,
    54,
    28,
    26,
    20,
    8,
    1,
    4,
    17,
    17,
    43,
    6,
    11,
    7,
    5,
    13,
    15,
    23,
    2,
    3,
    26,
    19,
    21,
    8,
    9,
    7,
    1,
    3,
    14,
    8,
    15,
    28,
    1,
    25,
    12,
    65,
    16,
    14,
    1,
    48,
    36,
    28,
    30,
    12,
    5,
    2,
    3,
    55,
    18,
    21,
    21,
    6,
    44,
    6,
    4,
    0,
    2,
    6,
    7,
    8,
    3,
    70,
    6,
    24,
    11,
    1,
    6,
    7,
    0,
    21,
    20,
    3,
    22,
    11,
    0,
    26,
    0,
    8,
    16,
    14,
    65,
    15,
    1,
    68,
    11,
    23,
    1,
    3,
    15,
    4,
    1,
    22,
    21,
    5,
    3,
    1,
    1,
    4,
    19,
    7,
    14,
    9,
    35,
    7,
    43,
    17,
    27,
    17,
    1,
    3,
    49,
    17,
    34,
    1,
    35,
    69,
    12,
    1,
    10,
    23,
    13,
    10,
    12,
    1,
    40,
    11,
    38,
    31,
    2,
    8,
    5,
    1,
    11,
    2,
    5,
    4,
    1,
    20,
    44,
    10,
    26,
    1,
    12,
    8,
    9,
    24,
    10,
    33,
    3,
    64,
    21,
    20,
    22,
    1,
    13,
    21,
    23,
    9,
    35,
    10,
    20,
    31,
    9,
    2,
    9,
    5,
    9,
    6,
    6,
    13,
    3,
    8,
    4,
    123,
    8,
    9,
    1,
    1,
    10,
    43,
    20,
    55,
    15,
    12,
    3,
    1,
    6,
    3,
    51,
    1,
    1,
    34,
    1,
    9,
    18,
    3,
    21,
    7,
    10,
    10,
    5,
    1,
    3,
    1,
    11,
    43,
    0,
    1,
    0,
    15,
    6,
    0,
    6,
    1,
    1,
    4,
    0,
    45,
    20,
    25,
    4,
    2,
    7,
    2,
    2,
    6,
    27,
    24,
    7,
    20,
    29,
    19,
    5,
    25,
    11,
    14,
    1,
    10,
    17,
    28,
    15,
    13,
    20,
    14,
    8,
    6,
    2,
    22,
    11,
    39,
    24,
    32,
    1,
    2,
    9,
    2,
    17,
    2,
    2,
    7,
    7,
    11,
    6,
    3,
    29,
    1,
    13,
    8,
    27,
    11,
    1,
    5,
    9,
    29,
    2,
    1,
    8,
    9,
    0,
    13,
    1,
    5,
    13,
    3,
    3,
    22,
    21,
    28,
    4,
    20,
    15,
    2,
    15,
    20,
    12,
    40,
    1,
    7,
    2,
    4,
    9,
    57,
    3,
    14,
    28,
    122,
    10,
    2,
    12,
    1,
    16,
    1,
    7,
    1,
    1,
    3,
    45,
    6,
    13,
    8,
    4,
    2,
    22,
    10,
    3,
    2,
    4,
    10,
    5,
    0,
    31,
    30,
    0,
    8,
    8,
    26,
    23,
    32,
    2,
    20,
    7,
    11,
    1,
    13,
    17,
    1,
    0,
    7,
    17,
    1,
    4,
    18,
    4,
    8,
    9,
    41,
    3,
    34,
    24,
    15,
    28,
    10,
    26,
    18,
    23,
    8,
    29,
    6,
    10,
    27,
    9,
    9,
    8,
    42,
    7,
    1,
    19,
    5,
    10,
    6,
    25,
    12,
    37,
    2,
    16,
    32,
    10,
    5,
    3,
    14,
    81,
    1,
    4,
    6,
    1,
    24,
    3,
    9,
    25,
    15,
    1,
    11,
    2,
    4,
    1,
    11,
    45,
    51,
    25,
    8,
    9,
    6,
    7,
    9,
    23,
    5,
    39,
    1,
    62,
    1,
    7,
    33,
    10,
    7,
    40,
    23,
    1,
    3,
    30,
    14,
    10,
    10,
    4,
    34,
    2,
    3,
    9,
    11,
    18,
    10,
    6,
    10,
    36,
    55,
    5,
    15,
    3,
    10,
    5,
    2,
    8,
    5,
    57,
    31,
    25,
    13,
    3,
    43,
    21,
    12,
    1,
    3,
    1,
    21,
    11,
    4,
    11,
    1,
    2,
    6,
    22,
    10,
    6,
    92,
    10,
    23,
    22,
    4,
    39,
    7,
    10,
    11,
    18,
    5,
    10,
    7,
    8,
    4,
    3,
    12,
    11,
    10,
    3,
    11,
    20,
    7,
    16,
    2,
    22,
    1,
    3,
    1,
    8,
    32,
    34,
    26,
    30,
    2,
    37,
    1,
    5,
    9,
    1,
    23,
    36,
    5,
    4,
    10,
    6,
    1,
    33,
    14,
    1,
    3,
    39,
    9,
    1,
    5,
    7,
    3,
    6,
    18,
    52,
    23,
    34,
    20,
    1,
    10,
    21,
    9,
    8,
    36,
    1,
    1,
    4,
    63,
    15,
    0,
    4,
    1,
    2,
    52,
    1,
    4,
    69,
    1,
    6,
    11,
    10,
    37,
    72,
    9,
    1,
    7,
    4,
    1,
    9,
    9,
    64,
    13,
    17,
    18,
    4,
    17,
    12,
    9,
    13,
    0,
    2,
    0,
    1,
    1,
    8,
    2,
    2,
    2,
    1,
    3,
    1,
    1,
    12,
    35,
    0,
    8,
    6,
    61,
    17,
    8,
    1,
    14,
    17,
    11,
    6,
    3,
    18,
    17,
    13,
    1,
    12,
    3,
    2,
    1,
    41,
    3,
    1,
    9,
    32,
    10,
    4,
    6,
    3,
    6,
    21,
    6,
    11,
    1,
    13,
    6,
    20,
    15,
    6,
    48,
    33,
    5,
    10,
    1,
    15,
    74,
    1,
    13,
    7,
    27,
    1,
    52,
    20,
    5,
    4,
    29,
    10,
    1,
    11,
    15,
    10,
    28,
    1,
    11,
    5,
    11,
    13,
    20,
    8,
    36,
    24,
    1,
    1,
    20,
    5,
    2,
    13,
    14,
    34,
    2,
    8,
    11,
    10,
    15,
    7,
    4,
    12,
    8,
    16,
    14,
    1,
    24,
    16,
    20,
    12,
    1,
    5,
    35,
    15,
    0,
    1,
    1,
    2,
    16,
    1,
    16,
    0,
    10,
    10,
    19,
    24,
    3,
    9,
    16,
    12,
    8,
    2,
    10,
    6,
    12,
    8,
    34,
    86,
    2,
    6,
    2,
    9,
    23,
    15,
    3,
    6,
    2,
    5,
    4,
    14,
    16,
    54,
    9,
    3,
    8,
    3,
    15,
    7,
    6,
    10,
    13,
    1,
    7,
    2,
    9,
    1,
    141,
    50,
    6,
    1,
    4,
    30,
    3,
    14,
    13,
    36,
    46,
    18,
    10,
    16,
    40,
    2,
    10,
    7,
    10,
    12,
    2,
    5,
    10,
    4,
    13,
    15,
    38,
    20,
    31,
    20,
    1,
    1,
    20,
    4,
    28,
    13,
    85,
    2,
    10,
    6,
    2,
    10,
    27,
    81,
    3,
    2,
    2,
    25,
    40,
    10,
    26,
    14,
    13,
    12,
    2,
    2,
    7,
    1,
    1,
    1,
    7,
    22,
    20,
    5,
    1,
    22,
    1,
    6,
    8,
    10,
    1,
    17,
    3,
    5,
    7,
    1,
    9,
    13,
    11,
    17,
    3,
    23,
    27,
    1,
    0,
    1,
    19,
    2,
    4,
    16,
    2,
    8,
    1,
    14,
    31,
    5,
    23,
    10,
    1,
    2,
    15,
    9,
    24,
    31,
    53,
    3,
    51,
    1,
    4,
    8,
    19,
    5,
    10,
    27,
    0,
    25,
    20,
    77,
    14,
    1,
    3,
    17,
    8,
    2,
    8,
    9,
    3,
    5,
    1,
    11,
    14,
    4,
    1,
    21,
    1,
    5,
    7,
    6,
    1,
    5,
    21,
    2,
    61,
    42,
    2,
    10,
    6,
    4,
    12,
    22,
    10,
    2,
    8,
    10,
    1,
    7,
    9,
    11,
    41,
    23,
    5,
    15,
    17,
    19,
    4,
    18,
    15,
    9,
    1,
    1,
    12,
    2,
    22,
    13,
    1,
    34,
    22,
    1,
    16,
    26,
    14,
    18,
    2,
    1,
    6,
    14,
    28,
    1,
    38,
    1,
    10,
    9,
    4,
    4,
    3,
    24,
    1,
    1,
    8,
    12,
    5,
    3,
    0,
    4,
    26,
    46,
    19,
    15,
    5,
    28,
    1,
    9,
    1,
    6,
    6,
    3,
    39,
    5,
    25,
    29,
    13,
    10,
    44,
    12,
    28,
    2,
    1,
    36,
    5,
    16,
    11,
    14,
    1,
    13,
    24,
    3,
    8,
    13,
    18,
    5,
    1,
    8,
    63,
    28,
    2,
    11,
    3,
    22,
    3,
    15,
    19,
    21,
    23,
    38,
    1,
    1,
    6,
    17,
    2,
    15,
    19,
    19,
    19,
    4,
    7,
    6,
    22,
    4,
    20,
    17,
    28,
    18,
    5,
    1,
    15,
    7,
    13,
    38,
    19,
    81,
    16,
    15,
    15,
    19,
    10,
    42,
    35,
    44,
    4,
    19,
    26,
    18,
    11,
    17,
    20,
    26,
    6,
    0,
    0,
    0,
    7,
    38,
    19,
    45,
    0,
    0,
    0,
    0,
    28,
    12,
    0,
    0,
    0,
    0,
    0,
    18,
    7,
    55,
    0,
    0,
    10,
    35,
    0,
    1,
    13,
    11,
    33,
    3,
    38,
    1,
    9,
    15,
    12,
    1,
    3,
    1,
    6,
    27,
    4,
    12,
    1,
    1,
    14,
    16,
    22,
    13,
    14,
    66,
    9,
    1,
    26,
    1,
    0,
    0,
    0,
    0,
    12,
    0,
    0,
    3,
    13,
    4,
    35,
    5,
    28,
    4,
    13,
    33,
    10,
    4,
    14,
    10,
    7,
    29,
    32,
    31,
    10,
    10,
    53,
    12,
    1,
    6,
    2,
    0,
    10,
    36,
    0,
    10,
    0,
    0,
    0,
    0,
    10,
    1,
    0,
    0,
    28,
    0,
    0,
    0,
    0,
    0,
    14,
    5,
    20,
    23,
    28,
    0,
    0,
    18,
    15,
    3,
    27,
    18,
    29,
    20,
    47,
    0,
    7,
    2,
    2,
    28,
    25,
    1,
    40,
    23,
    1,
    1,
    22,
    2,
    54,
    6,
    8,
    16,
    5,
    19,
    20,
    9,
    1,
    1,
    17,
    0,
    2,
    10,
    7,
    20,
    33,
    6,
    10,
    8,
    5,
    12,
    1,
    3,
    3,
    23,
    26,
    1,
    27,
    2,
    10,
    2,
    20,
    23,
    1,
    2,
    21,
    5,
    25,
    1,
    9,
    0,
    0,
    60,
    1,
    5,
    15,
    11,
    3,
    30,
    24,
    0,
    7,
    0,
    0,
    0,
    0,
    1,
    11,
    24,
    56,
    1,
    30,
    1,
    0,
    11,
    22,
    0,
    1,
    8,
    0,
    0,
    37,
    0,
    51,
    51,
    6,
    4,
    10,
    0,
    0,
    1,
    0,
    0,
    0,
    22,
    13,
    20,
    44,
    41,
    8,
    28,
    12,
    3,
    12,
    11,
    11,
    3,
    3,
    1,
    10,
    20,
    6,
    1,
    4,
    40,
    1,
    3,
    32,
    24,
    6,
    7,
    27,
    23,
    4,
    1,
    3,
    7,
    2,
    1,
    1,
    11,
    27,
    8,
    4,
    13,
    30,
    24,
    9,
    14,
    2,
    27,
    5,
    1,
    11,
    1,
    1,
    0,
    0,
    0,
    0,
    9,
    19,
    0,
    0,
    0,
    6,
    1,
    26,
    4,
    0,
    0,
    18,
    3,
    20,
    3,
    0,
    8,
    10,
    26,
    69,
    25,
    45,
    22,
    1,
    9,
    11,
    1,
    0,
    9,
    0,
    4,
    5,
    31,
    2,
    0,
    0,
    0,
    0,
    5,
    16,
    16,
    4,
    4,
    20,
    0,
    5,
    1,
    15,
    1,
    10,
    7,
    54,
    0,
    0,
    0,
    0,
    11,
    10,
    4,
    0,
    0,
    0,
    0,
    1,
    0,
    0,
    0,
    27,
    0,
    0,
    0,
    1,
    0,
    0,
    0,
    0,
    26,
    0,
    0,
    39,
    10,
    119,
    3,
    0,
    0,
    0,
    4,
    4,
    11,
    17,
    0,
    0,
    1,
    5,
    0,
    0,
    0,
    0,
    0,
    0,
    5,
    0,
    0,
    1,
    9,
    1,
    10,
    22,
    0,
    0,
    0,
    0,
    3,
    6,
    8,
    4,
    20,
    32,
    15,
    21,
    9,
    4,
    11,
    60,
    5,
    10,
    0,
    1,
    44,
    2,
    10,
    4,
    8,
    8,
    9,
    1,
    0,
    0,
    36,
    11,
    0,
    1,
    9,
    42,
    39,
    13,
    1,
    8,
    0,
    34,
    3,
    0,
    1,
    48,
    18,
    0,
    0,
    0,
    10,
    14,
    10,
    14,
    0,
    0,
    1,
    12,
    1,
    10,
    0,
    5,
    20,
    48,
    15,
    14,
    30,
    32,
    11,
    13,
    13,
    8,
    20,
    3,
    10,
    1,
    10,
    5,
    12,
    11,
    1,
    1,
    30,
    14,
    9,
    3,
    39,
    36,
    0,
    0,
    0,
    0,
    18,
    27,
    1,
    8,
    7,
    14,
    3,
    10,
    11,
    70,
    4,
    5,
    3,
    19,
    17,
    23,
    5,
    17,
    9,
    21,
    32,
    29,
    7,
    7,
    6,
    3,
    1,
    19,
    29,
    25,
    6,
    1,
    47,
    29,
    23,
    21,
    0,
    12,
    9,
    14,
    15,
    2,
    10,
    1,
    19,
    17,
    2,
    18,
    3,
    25,
    38,
    61,
    53,
    15,
    38,
    81,
    10,
    9,
    14,
    10,
    5,
    15,
    29,
    1,
    2,
    1,
    12,
    7,
    14,
    10,
    1,
    0,
    0,
    27,
    16,
    10,
    8,
    18,
    18,
    13,
    9,
    10,
    12,
    11,
    54,
    4,
    3,
    6,
    59,
    12,
    20,
    16,
    2,
    25,
    9,
    14,
    10,
    3,
    5,
    2,
    11,
    26,
    22,
    10,
    1,
    2,
    16,
    12,
    49,
    9,
    11,
    2,
    2,
    12,
    2,
    15,
    15,
    5,
    1,
    41,
    12,
    1,
    2,
    28,
    25,
    13,
    1,
    30,
    4,
    30,
    8,
    30,
    0,
    6,
    10,
    37,
    2,
    2,
    3,
    1,
    4,
    2,
    23,
    10,
    19,
    5,
    20,
    23,
    5,
    38,
    15,
    2,
    0,
    1,
    67,
    10,
    2,
    10,
    3,
    9,
    13,
    7,
    2,
    17,
    2,
    10,
    53,
    0,
    0,
    0,
    0,
    0,
    15,
    0,
    0,
    0,
    16,
    0,
    5,
    0,
    0,
    14,
    4,
    8,
    10,
    11,
    10,
    14,
    23,
    13,
    11,
    1,
    1,
    0,
    0,
    0,
    0,
    0,
    31,
    0,
    6,
    9,
    0,
    0,
    10,
    17,
    8,
    0,
    7,
    3,
    8,
    21,
    11,
    27,
    14,
    1,
    6,
    5,
    60,
    2,
    23,
    32,
    8,
    47,
    11,
    6,
    4,
    11,
    0,
    21,
    71,
    15,
    6,
    9,
    19,
    23,
    11,
    15,
    0,
    6,
    44,
    1,
    7,
    1,
    2,
    69,
    7,
    3,
    0,
    6,
    2,
    10,
    2,
    18,
    25,
    6,
    1,
    0,
    7,
    0,
    24,
    0,
    5,
    35,
    12,
    0,
    0,
    19,
    0,
    11,
    8,
    6,
    10,
    16,
    2,
    22,
    15,
    2,
    10,
    0,
    9,
    1,
    13,
    2,
    2,
    6,
    26,
    10,
    10,
    11,
    7,
    15,
    4,
    0,
    0,
    0,
    7,
    1,
    1,
    10,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    3,
    0,
    3,
    4,
    0,
    25,
    0,
    1,
    23,
    8,
    28,
    1,
    3,
    1,
    1,
    11,
    13,
    13,
    1,
    26,
    10,
    0,
    35,
    0,
    5,
    15,
    10,
    11,
    0,
    0,
    4,
    19,
    51,
    25,
    2,
    22,
    0,
    1,
    3,
    0,
    17,
    13,
    1,
    5,
    7,
    3,
    16,
    10,
    13,
    1,
    18,
    8,
    9,
    0,
    20,
    1,
    25,
    18,
    21,
    17,
    9,
    7,
    0,
    8,
    8,
    0,
    17,
    0,
    0,
    27,
    21,
    3,
    5,
    7,
    1,
    23,
    13,
    32,
    20,
    33,
    1,
    23,
    7,
    0,
    0,
    68,
    0,
    13,
    9,
    12,
    10,
    1,
    0,
    0,
    10,
    36,
    17,
    53,
    0,
    0,
    18,
    2,
    1,
    9,
    8,
    5,
    0,
    52,
    0,
    11,
    27,
    0,
    11,
    11,
    2,
    25,
    1,
    8,
    15,
    54,
    17,
    10,
    5,
    3,
    1,
    31,
    5,
    38,
    12,
    0,
    0,
    0,
    0,
    3,
    23,
    10,
    2,
    12,
    1,
    46,
    2,
    25,
    0,
    0,
    10,
    14,
    9,
    9,
    1,
    8,
    11,
    2,
    9,
    3,
    21,
    11,
    37,
    19,
    13,
    9,
    1,
    9,
    16,
    2,
    5,
    4,
    9,
    10,
    12,
    8,
    8,
    11,
    1,
    3,
    0,
    0,
    0,
    0,
    0,
    0,
    7,
    0,
    0,
    4,
    10,
    8,
    51,
    1,
    9,
    0,
    20,
    14,
    32,
    0,
    0,
    20,
    20,
    25,
    10,
    0,
    0,
    0,
    31,
    4,
    10,
    7,
    10,
    12,
    8,
    14,
    3,
    6,
    2,
    27,
    0,
    0,
    0,
    0,
    0,
    4,
    2,
    0,
    7,
    7,
    25,
    7,
    4,
    11,
    9,
    29,
    15,
    0,
    0,
    1,
    6,
    0,
    0,
    5,
    33,
    10,
    31,
    5,
    27,
    0,
    0,
    6,
    49,
    0,
    0,
    5,
    0,
    0,
    0,
    0,
    1,
    12,
    51,
    19,
    13,
    8,
    10,
    0,
    50,
    4,
    0,
    0,
    11,
    8,
    9,
    5,
    27,
    10,
    10,
    30,
    4,
    13,
    1,
    1,
    4,
    2,
    52,
    9,
    14,
    2,
    0,
    0,
    11,
    16,
    13,
    24,
    35,
    1,
    0,
    0,
    1,
    0,
    0,
    0,
    0,
    1,
    0,
    0,
    5,
    0,
    29,
    27,
    5,
    11,
    43,
    12,
    7,
    4,
    10,
    6,
    4,
    26,
    2,
    0,
    23,
    0,
    0,
    1,
    6,
    0,
    0,
    0,
    3,
    6,
    9,
    1,
    0,
    0,
    0,
    0,
    0,
    47,
    0,
    0,
    0,
    0,
    0,
    32,
    0,
    1,
    40,
    2,
    0,
    0,
    16,
    0,
    0,
    0,
    0,
    4,
    28,
    35,
    17,
    0,
    11,
    4,
    0,
    0,
    0,
    6,
    0,
    9,
    0,
    0,
    4,
    24,
    3,
    0,
    0,
    0,
    0,
    32,
    20,
    10,
    15,
    9,
    7,
    12,
    17,
    2,
    0,
    16,
    5,
    0,
    0,
    36,
    7,
    0,
    0,
    1,
    5,
    0,
    0,
    0,
    0,
    22,
    8,
    21,
    55,
    7,
    4,
    16,
    4,
    1,
    43,
    4,
    0,
    0,
    0,
    2,
    3,
    0,
    1,
    0,
    3,
    3,
    0,
    30,
    39,
    0,
    0,
    0,
    13,
    3,
    0,
    0,
    0,
    1,
    8,
    59,
    0,
    56,
    40,
    19,
    17,
    34,
    15,
    22,
    1,
    36,
    0,
    0,
    0,
    14,
    0,
    0,
    1,
    6,
    1,
    20,
    0,
    10,
    4,
    23,
    10,
    26,
    11,
    10,
    4,
    32,
    1,
    6,
    14,
    25,
    0,
    1,
    17,
    2,
    0,
    36,
    3,
    12,
    5,
    2,
    19,
    39,
    5,
    1,
    54,
    0,
    4,
    3,
    10,
    10,
    8,
    5,
    6,
    1,
    3,
    6,
    3,
    4,
    60,
    0,
    0,
    0,
    0,
    46,
    1,
    10,
    55,
    20,
    30,
    7,
    15,
    0,
    0,
    0,
    7,
    6,
    23,
    12,
    1,
    26,
    1,
    5,
    4,
    41,
    1,
    0,
    37,
    34,
    0,
    23,
    0,
    0,
    0,
    14,
    19,
    12,
    12,
    10,
    7,
    19,
    20,
    38,
    19,
    25,
    3,
    12,
    9,
    10,
    40,
    41,
    10,
    4,
    16,
    23,
    2,
    1,
    10,
    3,
    5,
    1,
    14,
    20,
    29,
    22,
    10,
    19,
    10,
    12,
    20,
    8,
    0,
    0,
    0,
    0,
    0,
    3,
    0,
    10,
    1,
    0,
    0,
    25,
    24,
    16,
    1,
    36,
    4,
    12,
    5,
    10,
    1,
    1,
    4,
    30,
    11,
    11,
    9,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    13,
    13,
    2,
    7,
    31,
    2,
    4,
    29,
    28,
    3,
    1,
    1,
    9,
    0,
    5,
    2,
    14,
    10,
    10,
    12,
    9,
    68,
    2,
    9,
    7,
    28,
    49,
    0,
    33,
    9,
    12,
    5,
    0,
    0,
    12,
    28,
    10,
    0,
    5,
    28,
    1,
    0,
    0,
    14,
    0,
    10,
    22,
    10,
    0,
    5,
    1,
    9,
    9,
    31,
    5,
    0,
    0,
    34,
    1,
    0,
    0,
    9,
    21,
    1,
    38,
    30,
    1,
    0,
    53,
    0,
    9,
    2,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    9,
    11,
    6,
    0,
    0,
    0,
    0,
    0,
    0,
    83,
    9,
    0,
    14,
    0,
    0,
    15,
    16,
    6,
    1,
    41,
    10,
    2,
    5,
    10,
    0,
    0,
    0,
    0,
    56,
    17,
    24,
    38,
    5,
    0,
    20,
    2,
    0,
    0,
    0,
    0,
    0,
    0,
    38,
    0,
    0,
    0,
    10,
    1,
    0,
    0,
    25,
    60,
    12,
    10,
    10,
    9,
    7,
    21,
    1,
    11,
    11,
    0,
    41,
    2,
    34,
    5,
    8,
    11,
    30,
    9,
    36,
    31,
    42,
    6,
    2,
    14,
    119,
    10,
    41,
    0,
    11,
    8,
    6,
    12,
    66,
    4,
    5,
    11,
    10,
    34,
    10,
    12,
    13,
    10,
    30,
    2,
    29,
    42,
    0,
    1,
    3,
    2,
    12,
    12,
    0,
    35,
    0,
    0,
    7,
    15,
    1,
    0,
    22,
    10,
    1,
    7,
    25,
    14,
    30,
    7,
    21,
    0,
    35,
    18,
    1,
    31,
    1,
    1,
    5,
    14,
    3,
    11,
    10,
    25,
    10,
    4,
    11,
    11,
    18,
    17,
    9,
    1,
    3,
    1,
    11,
    22,
    5,
    18,
    7,
    17,
    21,
    1,
    4,
    0,
    5,
    1,
    13,
    10,
    3,
    0,
    4,
    0,
    0,
    6,
    4,
    43,
    0,
    0,
    5,
    10,
    3,
    7,
    6,
    48,
    11,
    7,
    11,
    11,
    11,
    12,
    18,
    9,
    21,
    0,
    0,
    0,
    0,
    25,
    0,
    0,
    0,
    0,
    1,
    0,
    0,
    0,
    0,
    3,
    0,
    0,
    0,
    0,
    42,
    6,
    0,
    25,
    1,
    3,
    0,
    0,
    0,
    0,
    0,
    24,
    0,
    0,
    0,
    0,
    0,
    35,
    29,
    0,
    3,
    7,
    0,
    0,
    27,
    12,
    1,
    11,
    0,
    2,
    53,
    3,
    0,
    39,
    10,
    14,
    0,
    0,
    0,
    30,
    0,
    16,
    0,
    0,
    0,
    0,
    4,
    0,
    0,
    3,
    3,
    3,
    39,
    15,
    31,
    0,
    3,
    2,
    1,
    5,
    26,
    1,
    2,
    19,
    0,
    12,
    0,
    0,
    9,
    36,
    1,
    1,
    4,
    1,
    11,
    8,
    84,
    10,
    0,
    22,
    42,
    60,
    1,
    2,
    21,
    11,
    30,
    1,
    13,
    127,
    2,
    5,
    14,
    14,
    44,
    10,
    44,
    1,
    36,
    16,
    24,
    2,
    0,
    0,
    0,
    10,
    5,
    2,
    17,
    6,
    20,
    1,
    10,
    5,
    43,
    1,
    8,
    33,
    2,
    14,
    21,
    8,
    48,
    9,
    19,
    47,
    41,
    16,
    1,
    70,
    2,
    7,
    1,
    15,
    26,
    1,
    28,
    12,
    21,
    4,
    33,
    6,
    13,
    2,
    0,
    0,
    25,
    0,
    17,
    0,
    0,
    0,
    0,
    23,
    0,
    0,
    0,
    1,
    28,
    0,
    21,
    54,
    0,
    10,
    10,
    1,
    4,
    0,
    27,
    4,
    17,
    22,
    57,
    13,
    6,
    1,
    2,
    1,
    0,
    10,
    10,
    1,
    10,
    8,
    1,
    6,
    8,
    10,
    11,
    15,
    7,
    15,
    1,
    10,
    5,
    32,
    4,
    18,
    4,
    1,
    12,
    2,
    6,
    1,
    53,
    15,
    11,
    12,
    3,
    38,
    1,
    9,
    0,
    8,
    3,
    9,
    3,
    2,
    10,
    12,
    20,
    1,
    3,
    37,
    22,
    7,
    60,
    32,
    3,
    51,
    8,
    0,
    0,
    18,
    0,
    0,
    0,
    0,
    3,
    0,
    0,
    0,
    0,
    0,
    0,
    8,
    10,
    0,
    8,
    0,
    1,
    0,
    0,
    3,
    6,
    2,
    19,
    19,
    40,
    2,
    1,
    10,
    10,
    4,
    1,
    10,
    3,
    27,
    8,
    0,
    0,
    0,
    1,
    10,
    6,
    11,
    10,
    9,
    13,
    8,
    11,
    0,
    5,
    9,
    0,
    19,
    5,
    22,
    0,
    3,
    3,
    0,
    0,
    0,
    25,
    10,
    0,
    7,
    0,
    0,
    0,
    33,
    2,
    19,
    1,
    31,
    62,
    6,
    6,
    24,
    2,
    5,
    0,
    0,
    14,
    10,
    0,
    0,
    61,
    0,
    0,
    0,
    0,
    0,
    0,
    9,
    4,
    4,
    42,
    10,
    0,
    10,
    1,
    2,
    16,
    0,
    0,
    0,
    5,
    69,
    58,
    4,
    17,
    9,
    24,
    0,
    10,
    7,
    11,
    22,
    2,
    0,
    26,
    9,
    3,
    5,
    35,
    11,
    19,
    4,
    1,
    0,
    0,
    0,
    0,
    1,
    16,
    0,
    15,
    0,
    55,
    19,
    0,
    26,
    0,
    2,
    1,
    9,
    0,
    5,
    8,
    21,
    6,
    14,
    0,
    0,
    0,
    0,
    0,
    3,
    39,
    30,
    3,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    36,
    6,
    38,
    12,
    5,
    22,
    52,
    18,
    22,
    15,
    3,
    0,
    0,
    10,
    0,
    0,
    13,
    2,
    24,
    5,
    10,
    1,
    29,
    2,
    10,
    7,
    0,
    21,
    5,
    16,
    1,
    23,
    58,
    11,
    42,
    24,
    26,
    16,
    6,
    18,
    6,
    26,
    0,
    0,
    0,
    10,
    6,
    14,
    5,
    2,
    1,
    6,
    24,
    24,
    2,
    0,
    0,
    1,
    29,
    19,
    1,
    10,
    2,
    6,
    19,
    1,
    4,
    12,
    1,
    9,
    42,
    0,
    12,
    7,
    15,
    2,
    1,
    28,
    21,
    35,
    13,
    10,
    13,
    4,
    18,
    40,
    45,
    3,
    27,
    16,
    15,
    10,
    4,
    10,
    22,
    7,
    5,
    0,
    13,
    7,
    7,
    10,
    21,
    28,
    3,
    9,
    13,
    7,
    23,
    11,
    12,
    27,
    15,
    12,
    30,
    21,
    16,
    22,
    10,
    3,
    28,
    11,
    7,
    57,
    17,
    5,
    10,
    7,
    5,
    9,
    8,
    15,
    30,
    6,
    9,
    28,
    3,
    2,
    12,
    28,
    4,
    15,
    1,
    38,
    14,
    4,
    1,
    4,
    15,
    17,
    19,
    29,
    10,
    4,
    56,
    1,
    5,
    0,
    14,
    12,
    1,
    62,
    2,
    6,
    7,
    4,
    5,
    19,
    23,
    10,
    31,
    20,
    9,
    14,
    9,
    48,
    10,
    1,
    1,
    8,
    1,
    34,
    44,
    2,
    11,
    6,
    10,
    1,
    53,
    31,
    1,
    30,
    18,
    4,
    0,
    4,
    4,
    10,
    4,
    8,
    87,
    58,
    17,
    16,
    3,
    2,
    1,
    6,
    6,
    10,
    5,
    12,
    4,
    3,
    8,
    52,
    4,
    32,
    10,
    32,
    21,
    1,
    57,
    0,
    20,
    27,
    4,
    2,
    16,
    56,
    30,
    1,
    32,
    0,
    28,
    1,
    14,
    12,
    1,
    12,
    4,
    1,
    12,
    6,
    24,
    27,
    1,
    8,
    8,
    3,
    14,
    19,
    1,
    11,
    10,
    5,
    5,
    6,
    10,
    5,
    12,
    11,
    8,
    2,
    16,
    19,
    4,
    29,
    5,
    11,
    4,
    8,
    23,
    4,
    21,
    7,
    8,
    4,
    1,
    8,
    0,
    10,
    17,
    12,
    10,
    14,
    18,
    12,
    5,
    22,
    5,
    7,
    1,
    0,
    0,
    0,
    2,
    18,
    0,
    0,
    0,
    14,
    18,
    11,
    15,
    0,
    0,
    8,
    11,
    0,
    23,
    11,
    17,
    0,
    0,
    0,
    14,
    3,
    29,
    0,
    0,
    0,
    0,
    0,
    3,
    3,
    32,
    10,
    2,
    1,
    11,
    16,
    27,
    13,
    1,
    53,
    12,
    3,
    7,
    7,
    13,
    10,
    0,
    2,
    9,
    7,
    5,
    4,
    10,
    18,
    68,
    9,
    55,
    2,
    0,
    0,
    0,
    0,
    2,
    10,
    6,
    14,
    4,
    1,
    0,
    10,
    1,
    0,
    0,
    10,
    20,
    19,
    61,
    2,
    16,
    0,
    0,
    10,
    10,
    51,
    7,
    13,
    4,
    10,
    3,
    6,
    58,
    4,
    1,
    16,
    4,
    1,
    12,
    5,
    9,
    18,
    32,
    6,
    10,
    9,
    23,
    1,
    25,
    10,
    5,
    3,
    26,
    1,
    1,
    48,
    12,
    24,
    2,
    14,
    7,
    2,
    12,
    3,
    1,
    38,
    1,
    10,
    66,
    1,
    15,
    1,
    12,
    5,
    4,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    6,
    0,
    0,
    0,
    0,
    0,
    2,
    0,
    0,
    0,
    13,
    0,
    0,
    0,
    0,
    0,
    28,
    0,
    0,
    10,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    10,
    31,
    3,
    0,
    0,
    0,
    1,
    0,
    0,
    1,
    0,
    3,
    0,
    3,
    10,
    2,
    10,
    3,
    5,
    46,
    37,
    2,
    8,
    6,
    2,
    1,
    3,
    10,
    13,
    3,
    2,
    4,
    8,
    9,
    8,
    0,
    12,
    6,
    1,
    16,
    14,
    30,
    1,
    13,
    64,
    1,
    0,
    0,
    0,
    0,
    0,
    8,
    3,
    21,
    2,
    6,
    14,
    63,
    12,
    3,
    13,
    24,
    0,
    0,
    0,
    0,
    0,
    0,
    10,
    1,
    0,
    0,
    0,
    0,
    0,
    8,
    37,
    2,
    1,
    9,
    1,
    13,
    14,
    12,
    0,
    14,
    3,
    3,
    2,
    53,
    29,
    19,
    32,
    33,
    9,
    12,
    0,
    35,
    1,
    7,
    1,
    4,
    36,
    43,
    0,
    0,
    0,
    3,
    0,
    0,
    0,
    0,
    7,
    0,
    5,
    1,
    53,
    0,
    0,
    0,
    31,
    1,
    18,
    14,
    3,
    30,
    3,
    0,
    0,
    0,
    0,
    0,
    1,
    0,
    27,
    0,
    0,
    0,
    0,
    0,
    0,
    48,
    10,
    16,
    1,
    14,
    46,
    13,
    0,
    0,
    4,
    6,
    0,
    5,
    11,
    2,
    1,
    3,
    1,
    0,
    11,
    25,
    0,
    8,
    0,
    0,
    11,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    16,
    0,
    0,
    0,
    0,
    2,
    13,
    0,
    19,
    2,
    7,
    0,
    0,
    0,
    61,
    0,
    0,
    8,
    13,
    0,
    1,
    1,
    3,
    26,
    1,
    5,
    4,
    11,
    18,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    3,
    13,
    19,
    16,
    1,
    10,
    45,
    9,
    1,
    0,
    0,
    0,
    0,
    0,
    0,
    6,
    4,
    3,
    3,
    0,
    0,
    0,
    0,
    0,
    14,
    0,
    8,
    0,
    0,
    0,
    0,
    56,
    0,
    1,
    0,
    0,
    19,
    0,
    3,
    1,
    3,
    11,
    14,
    1,
    14,
    13,
    0,
    3,
    24,
    0,
    13,
    55,
    6,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    9,
    10,
    4,
    0,
    4,
    0,
    0,
    0,
    24,
    15,
    0,
    0,
    0,
    0,
    0,
    0,
    8,
    5,
    13,
    2,
    0,
    0,
    0,
    58,
    33,
    1,
    0,
    0,
    5,
    0,
    54,
    6,
    26,
    22,
    9,
    4,
    7,
    5,
    46,
    8,
    34,
    0,
    0,
    0,
    78,
    3,
    0,
    0,
    1,
    0,
    9,
    0,
    12,
    0,
    0,
    0,
    0,
    0,
    17,
    23,
    10,
    0,
    0,
    0,
    0,
    1,
    6,
    16,
    54,
    10,
    0,
    0,
    0,
    11,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    4,
    0,
    20,
    0,
    0,
    0,
    0,
    18,
    0,
    0,
    0,
    44,
    20,
    10,
    3,
    9,
    5,
    21,
    6,
    0,
    3,
    5,
    7,
    21,
    6,
    0,
    10,
    13,
    1,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    1,
    9,
    12,
    13,
    17,
    0,
    28,
    5,
    12,
    79,
    7,
    32,
    8,
    23,
    10,
    65,
    40,
    1,
    3,
    39,
    1,
    4,
    2,
    51,
    26,
    4,
    3,
    0,
    1,
    12,
    4,
    10,
    19,
    6,
    1,
    17,
    0,
    0,
    0,
    1,
    11,
    33,
    0,
    10,
    21,
    19,
    17,
    9,
    2,
    18,
    5,
    2,
    8,
    2,
    10,
    9,
    27,
    10,
    26,
    2,
    1,
    20,
    11,
    8,
    19,
    47,
    21,
    17,
    10,
    2,
    1,
    1,
    6,
    0,
    0,
    0,
    0,
    2,
    2,
    16,
    1,
    21,
    7,
    123,
    13,
    32,
    25,
    7,
    20,
    44,
    5,
    0,
    3,
    36,
    2,
    0,
    9,
    10,
    11,
    5,
    29,
    12,
    0,
    0,
    0,
    0,
    0,
    1,
    4,
    0,
    0,
    0,
    0,
    40,
    3,
    2,
    2,
    28,
    10,
    4,
    29,
    16,
    55,
    6,
    7,
    1,
    2,
    1,
    5,
    12,
    0,
    0,
    0,
    0,
    0,
    16,
    26,
    2,
    11,
    0,
    40,
    2,
    4,
    5,
    1,
    1,
    29,
    19,
    45,
    5,
    0,
    1,
    27,
    3,
    8,
    10,
    9,
    22,
    24,
    3,
    10,
    68,
    2,
    0,
    0,
    0,
    3,
    22,
    9,
    40,
    1,
    12,
    18,
    3,
    4,
    5,
    23,
    9,
    46,
    58,
    12,
    1,
    19,
    0,
    0,
    0,
    0,
    1,
    14,
    2,
    1,
    1,
    10,
    5,
    22,
    1,
    19,
    6,
    7,
    1,
    7,
    16,
    3,
    17,
    16,
    0,
    6,
    17,
    0,
    0,
    0,
    1,
    12,
    1,
    16,
    4,
    1,
    3,
    3,
    0,
    1,
    1,
    40,
    3,
    49,
    10,
    6,
    10,
    1,
    15,
    24,
    7,
    14,
    77,
    30,
    42,
    38,
    9,
    26,
    53,
    12,
    42,
    1,
    5,
    15,
    7,
    5,
    36,
    1,
    6,
    6,
    5,
    10,
    10,
    17,
    17,
    4,
    9,
    2,
    9,
    18,
    19,
    35,
    1,
    9,
    5,
    12,
    10,
    11,
    9,
    1,
    6,
    13,
    17,
    14,
    13,
    68,
    25,
    66,
    4,
    16,
    2,
    20,
    21,
    0,
    0,
    0,
    25,
    0,
    0,
    0,
    14,
    0,
    0,
    16,
    7,
    9,
    16,
    6,
    3,
    0,
    0,
    0,
    5,
    3,
    4,
    6,
    7,
    2,
    32,
    0,
    0,
    0,
    0,
    0,
    0,
    1,
    0,
    0,
    0,
    0,
    0,
    21,
    6,
    0,
    32,
    11,
    16,
    20,
    19,
    15,
    5,
    104,
    0,
    18,
    3,
    54,
    8,
    6,
    46,
    14,
    27,
    0,
    4,
    0,
    0,
    3,
    0,
    4,
    3,
    1,
    3,
    2,
    44,
    1,
    0,
    0,
    0,
    0,
    0,
    10,
    11,
    13,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    2,
    0,
    0,
    0,
    31,
    10,
    16,
    14,
    12,
    19,
    9,
    19,
    0,
    1,
    7,
    0,
    10,
    0,
    0,
    62,
    5,
    7,
    0,
    4,
    14,
    15,
    4,
    0,
    3,
    0,
    17,
    38,
    0,
    4,
    11,
    63,
    16,
    15,
    1,
    8,
    1,
    19,
    35,
    7,
    14,
    46,
    12,
    0,
    5,
    0,
    25,
    47,
    60,
    12,
    19,
    1,
    10,
    26,
    1,
    1,
    2,
    10,
    0,
    0,
    30,
    2,
    1,
    50,
    16,
    3,
    10,
    1,
    10,
    0,
    45,
    21,
    9,
    5,
    1,
    12,
    5,
    7,
    2,
    7,
    2,
    16,
    1,
    75,
    1,
    29,
    4,
    3,
    0,
    0,
    0,
    0,
    5,
    1,
    8,
    65,
    48,
    31,
    24,
    3,
    0,
    10,
    4,
    32,
    2,
    2,
    16,
    0,
    8,
    2,
    23,
    46,
    2,
    16,
    19,
    9,
    10,
    22,
    34,
    0,
    6,
    26,
    8,
    11,
    30,
    19,
    8,
    15,
    1,
    20,
    4,
    7,
    0,
    0,
    8,
    0,
    0,
    22,
    19,
    10,
    48,
    1,
    13,
    1,
    22,
    0,
    14,
    6,
    2,
    3,
    86,
    10,
    3,
    7,
    11,
    2,
    42,
    0,
    15,
    18,
    5,
    0,
    16,
    10,
    68,
    10,
    15,
    10,
    19,
    6,
    10,
    20,
    16,
    15,
    24,
    9,
    9,
    15,
    0,
    7,
    1,
    2,
    3,
    3,
    1,
    7,
    23,
    39,
    8,
    16,
    3,
    9,
    8,
    0,
    23,
    1,
    7,
    49,
    11,
    26,
    74,
    73,
    3,
    7,
    10,
    26,
    5,
    14,
    1,
    6,
    56,
    10,
    3,
    17,
    1,
    2,
    18,
    18,
    11,
    11,
    4,
    1,
    1,
    31,
    16,
    10,
    2,
    5,
    5,
    9,
    4,
    39,
    0,
    0,
    0,
    4,
    31,
    8,
    28,
    5,
    6,
    10,
    0,
    0,
    0,
    0,
    53,
    10,
    25,
    8,
    1,
    0,
    0,
    34,
    26,
    2,
    7,
    35,
    3,
    3,
    56,
    21,
    0,
    0,
    1,
    2,
    3,
    0,
    2,
    0,
    26,
    7,
    4,
    19,
    5,
    7,
    13,
    3,
    0,
    7,
    0,
    0,
    4,
    13,
    4,
    3,
    12,
    0,
    0,
    10,
    0,
    5,
    0,
    0,
    0,
    0,
    5,
    18,
    0,
    0,
    19,
    24,
    25,
    4,
    1,
    21,
    10,
    2,
    6,
    0,
    11,
    29,
    8,
    0,
    0,
    0,
    2,
    67,
    6,
    49,
    4,
    2,
    3,
    30,
    9,
    0,
    0,
    4,
    33,
    10,
    0,
    0,
    0,
    1,
    0,
    0,
    4,
    0,
    0,
    10,
    0,
    0,
    0,
    0,
    1,
    5,
    28,
    3,
    0,
    0,
    0,
    21,
    7,
    1,
    6,
    4,
    43,
    8,
    1,
    19,
    30,
    3,
    10,
    4,
    49,
    25,
    10,
    2,
    1,
    11,
    43,
    1,
    6,
    33,
    1,
    18,
    32,
    45,
    27,
    35,
    20,
    3,
    16,
    31,
    50,
    48,
    1,
    15,
    2,
    5,
    4,
    38,
    11,
    4,
    14,
    20,
    28,
    76,
    2,
    1,
    10,
    9,
    1,
    6,
    10,
    5,
    10,
    7,
    23,
    6,
    12,
    11,
    20,
    28,
    3,
    22,
    2,
    16,
    3,
    25,
    59,
    8,
    8,
    10,
    21,
    1,
    18,
    9,
    1,
    6,
    4,
    39,
    12,
    14,
    10,
    6,
    14,
    44,
    3,
    14,
    2,
    8,
    5,
    34,
    37,
    6,
    28,
    12,
    34,
    6,
    1,
    7,
    16,
    1,
    27,
    10,
    8,
    13,
    85,
    4,
    4,
    1,
    3,
    36,
    26,
    0,
    0,
    0,
    54,
    0,
    0,
    11,
    2,
    24,
    3,
    10,
    1,
    13,
    7,
    12,
    27,
    1,
    2,
    53,
    43,
    2,
    12,
    9,
    4,
    0,
    0,
    28,
    26,
    63,
    4,
    0,
    6,
    11,
    0,
    24,
    11,
    6,
    3,
    3,
    9,
    1,
    9,
    17,
    8,
    36,
    4,
    29,
    13,
    7,
    0,
    0,
    0,
    19,
    13,
    0,
    10,
    7,
    1,
    6,
    10,
    4,
    51,
    15,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    7,
    0,
    1,
    11,
    0,
    0,
    0,
    39,
    2,
    1,
    2,
    0,
    42,
    11,
    0,
    4,
    0,
    0,
    10,
    16,
    46,
    17,
    7,
    6,
    3,
    9,
    17,
    35,
    4,
    12,
    0,
    0,
    0,
    0,
    2,
    13,
    26,
    0,
    7,
    11,
    3,
    6,
    10,
    0,
    0,
    0,
    42,
    0,
    0,
    0,
    10,
    0,
    0,
    1,
    0,
    14,
    10,
    0,
    1,
    1,
    6,
    17,
    2,
    17,
    3,
    1,
    20,
    8,
    28,
    3,
    23,
    33,
    10,
    16,
    15,
    22,
    9,
    14,
    3,
    21,
    52,
    0,
    1,
    0,
    0,
    1,
    27,
    1,
    3,
    9,
    2,
    2,
    1,
    24,
    0,
    0,
    0,
    0,
    0,
    0,
    11,
    10,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    33,
    5,
    14,
    7,
    29,
    18,
    19,
    21,
    15,
    3,
    7,
    15,
    0,
    14,
    0,
    0,
    0,
    0,
    0,
    0,
    2,
    1,
    0,
    1,
    0,
    0,
    0,
    7,
    12,
    0,
    0,
    21,
    8,
    0,
    0,
    0,
    9,
    53,
    13,
    0,
    36,
    9,
    25,
    7,
    21,
    0,
    6,
    0,
    0,
    0,
    92,
    0,
    20,
    2,
    20,
    6,
    1,
    21,
    22,
    12,
    2,
    10,
    3,
    4,
    2,
    1,
    2,
    9,
    3,
    21,
    0,
    23,
    23,
    5,
    2,
    8,
    10,
    1,
    11,
    4,
    1,
    4,
    3,
    6,
    15,
    9,
    7,
    17,
    4,
    4,
    8,
    43,
    1,
    13,
    58,
    14,
    38,
    24,
    10,
    7,
    16,
    35,
    1,
    22,
    6,
    1,
    1,
    1,
    17,
    10,
    6,
    7,
    3,
    8,
    4,
    20,
    5,
    13,
    25,
    9,
    7,
    1,
    16,
    1,
    29,
    4,
    10,
    12,
    11,
    30,
    8,
    47,
    12,
    30,
    1,
    4,
    12,
    1,
    11,
    13,
    11,
    1,
    25,
    15,
    21,
    8,
    27,
    5,
    41,
    9,
    0,
    27,
    12,
    5,
    2,
    48,
    19,
    44,
    21,
    14,
    11,
    10,
    4,
    7,
    30,
    10,
    2,
    10,
    13,
    19,
    1,
    24,
    4,
    5,
    10,
    3,
    35,
    16,
    5,
    35,
    6,
    1,
    50,
    4,
    33,
    10,
    48,
    28,
    15,
    5,
    60,
    16,
    2,
    3,
    6,
    11,
    5,
    0,
    21,
    1,
    3,
    9,
    5,
    33,
    12,
    59,
    23,
    1,
    1,
    10,
    2,
    8,
    6,
    8,
    9,
    1,
    51,
    65,
    10,
    4,
    2,
    35,
    10,
    5,
    6,
    1,
    74,
    9,
    10,
    4,
    29,
    1,
    7,
    6,
    8,
    7,
    14,
    4,
    11,
    4,
    15,
    9,
    0,
    12,
    3,
    1,
    2,
    5,
    10,
    23,
    9,
    2,
    1,
    6,
    7,
    2,
    102,
    30,
    5,
    9,
    10,
    1,
    12,
    18,
    1,
    9,
    31,
    9,
    22,
    15,
    10,
    1,
    2,
    19,
    4,
    65,
    2,
    10,
    10,
    20,
    14,
    18,
    14,
    10,
    1,
    8,
    8,
    6,
    1,
    0,
    16,
    18,
    1,
    2,
    28,
    3,
    20,
    13,
    5,
    72,
    12,
    30,
    17,
    1,
    7,
    6,
    10,
    4,
    3,
    3,
    15,
    32,
    1,
    0,
    4,
    16,
    4,
    2,
    7,
    4,
    6,
    10,
    5,
    50,
    7,
    4,
    32,
    10,
    1,
    3,
    9,
    21,
    55,
    6,
    9,
    10,
    5,
    5,
    6,
    20,
    23,
    30,
    0,
    9,
    1,
    28,
    8,
    12,
    9,
    29,
    28,
    6,
    46,
    61,
    6,
    4,
    29,
    18,
    27,
    7,
    5,
    10,
    21,
    4,
    12,
    12,
    10,
    3,
    5,
    2,
    5,
    2,
    0,
    36,
    12,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    1,
    0,
    0,
    14,
    0,
    33,
    0,
    0,
    0,
    0,
    16,
    1,
    0,
    15,
    0,
    4,
    17,
    10,
    13,
    35,
    2,
    7,
    4,
    9,
    1,
    34,
    6,
    31,
    2,
    0,
    1,
    1,
    3,
    18,
    4,
    14,
    4,
    9,
    0,
    9,
    6,
    5,
    2,
    6,
    3,
    36,
    8,
    41,
    11,
    29,
    10,
    1,
    0,
    2,
    19,
    10,
    9,
    1,
    11,
    10,
    11,
    1,
    6,
    3,
    10,
    29,
    23,
    28,
    1,
    13,
    7,
    16,
    88,
    15,
    58,
    65,
    1,
    2,
    40,
    13,
    7,
    1,
    28,
    10,
    22,
    11,
    11,
    16,
    10,
    7,
    45,
    1,
    9,
    53,
    6,
    20,
    1,
    14,
    16,
    6,
    18,
    24,
    8,
    26,
    6,
    1,
    10,
    6,
    6,
    1,
    0,
    22,
    7,
    63,
    10,
    0,
    2,
    0,
    0,
    10,
    0,
    0,
    0,
    0,
    0,
    7,
    41,
    4,
    2,
    0,
    23,
    0,
    0,
    7,
    8,
    54,
    26,
    11,
    10,
    37,
    4,
    1,
    3,
    48,
    11,
    0,
    0,
    0,
    32,
    21,
    18,
    4,
    5,
    1,
    19,
    4,
    5,
    5,
    2,
    29,
    16,
    22,
    44,
    8,
    10,
    22,
    2,
    17,
    7,
    7,
    14,
    1,
    18,
    36,
    11,
    89,
    1,
    17,
    1,
    7,
    10,
    1
  ],
  "ttfts": [
    0.05146448000050441,
    0.07731265400070697,
    0.12434002100053476,
    0.4631483620014478,
    0.5939509820000239,
    0.5870342869984597,
    0.659110316000806,
    0.6542195199999696,
    0.6261880920010299,
    0.5597180029999436,
    0.41159857800084865,
    0.676825705999363,
    0.9209608290002507,
    1.0427856940004858,
    0.9911056450000615,
    0.9882882279998739,
    1.1925007849986287,
    1.1850181769987103,
    1.1217083039991849,
    1.3591795490010554,
    1.2791019649994269,
    1.268814813998688,
    1.138746753000305,
    1.0847877689993766,
    1.2346399180005392,
    1.205798650998986,
    1.127705127999434,
    1.0253323729994008,
    1.198696456000107,
    1.31539863999933,
    1.256239522001124,
    1.3586656709994713,
    1.3472777049992146,
    1.3456045929997345,
    0.0,
    2.1003372209997906,
    1.977915211000436,
    2.0421124969998345,
    2.038970209998297,
    2.0084744180003327,
    1.9693110059997707,
    1.8129158479987382,
    1.7904516109992983,
    2.1921296380005515,
    2.0845161669985828,
    1.9619614710009046,
    1.8119169660003536,
    1.7750258140004007,
    1.8556637299989234,
    1.5417445419989235,
    1.4866412160008622,
    1.1059165000006033,
    1.0851384469988261,
    1.0715877809998346,
    1.421897643000193,
    1.302025077999133,
    1.3148303110010602,
    1.2553077699994901,
    1.2173668129998987,
    1.1442930649991467,
    1.088199062000058,
    1.1960381820008479,
    1.1276372939992143,
    1.09280236000086,
    1.079428688999542,
    0.9806528459994297,
    0.9734531969988893,
    1.0073734329998842,
    1.115703855000902,
    1.1075127700005396,
    1.2090829490007309,
    1.1652290719994198,
    1.2386961809988861,
    1.1733375109997723,
    1.2767130609991,
    1.2607921680009895,
    1.1864572260001296,
    1.087044011999751,
    1.0376689509994321,
    1.1845515670011082,
    1.1822892549989774,
    1.1433051959993463,
    1.122731452998778,
    1.1081332100002328,
    1.2098024859988072,
    1.4557880259999365,
    0.0,
    1.405376279999473,
    1.8244605509989924,
    1.941815881000366,
    1.8760131810013263,
    1.9449443339999561,
    2.030560046998289,
    2.009394411001267,
    2.118816254998819,
    2.069036513001265,
    2.100930875998529,
    2.2218678509998426,
    2.574074545000258,
    2.5201036569997086,
    2.7000098929984233,
    2.6615313950005657,
    2.660524094999346,
    2.7771916420006164,
    2.6944857309990766,
    2.965959033999752,
    2.944146774001638,
    2.9087601139999606,
    3.012747311999192,
    3.2514054929997656,
    3.42438900200068,
    3.3134468240004935,
    3.3755664370000886,
    0.0,
    3.577939464999872,
    3.5463096650000807,
    3.620519742999022,
    3.5552237089996197,
    3.6165601140000945,
    3.857576448001055,
    3.8170527450001828,
    3.521875082000406,
    3.511490650000269,
    3.5541716889983945,
    3.681494009000744,
    0.0,
    4.263017454999499,
    4.482255441000234,
    4.437862376000339,
    4.411420340000404,
    4.384413861000212,
    4.338990709999052,
    4.310271549999015,
    4.658430464000048,
    4.601160526000967,
    4.599874392999482,
    4.571857315999296,
    4.542560641999444,
    4.367857635999826,
    4.482379908999064,
    4.315052142999775,
    4.280199089000234,
    4.221553605999361,
    4.326370455999495,
    4.5936013530008495,
    4.704695530999743,
    0.0,
    5.214137103999747,
    5.147259404000579,
    5.11889568100014,
    5.060471668999526,
    5.318417300000874,
    5.3005748559990025,
    5.093191256000864,
    5.083684805998928,
    5.037475658000403,
    5.099406263001583,
    5.039510455999334,
    5.022615858999416,
    4.974111165000068,
    4.910363970999242,
    5.300054781999279,
    5.213913246001539,
    5.237788575001105,
    5.213273011000638,
    5.178045927999847,
    5.108072864999485,
    5.0033341360012855,
    5.111675785999978,
    5.188816105001024,
    5.167233200998453,
    5.214302268999745,
    5.191510405000372,
    5.082930417000171,
    5.204372999000043,
    5.194065608000528,
    5.137395535999531,
    5.378387452999959,
    5.370283109999946,
    5.304357715998776,
    5.248610775999623,
    5.225552868001614,
    5.047346137000204,
    4.970696152000528,
    4.977797544999703,
    4.931760720999591,
    4.895568058000208,
    4.869845520001036,
    4.852995965000446,
    5.080817537000257,
    5.043177618001209,
    5.027375743000448,
    5.156186723999781,
    5.26536554499944,
    5.226235173999157,
    5.19897600799959,
    5.157064150000224,
    5.092144374999407,
    5.47689740900023,
    5.389132735999738,
    5.358426001001135,
    5.306643795000127,
    5.396805758999108,
    5.389367789000971,
    5.477708906999396,
    5.36805651800023,
    0.0,
    5.912438344999828,
    5.8954531339986715,
    6.022869587999594,
    6.12157125199883,
    6.11946177199934,
    6.092598643001111,
    5.897888927000167,
    5.786349920001157,
    5.8307259880002675,
    5.779777474001094,
    5.695607154000754,
    5.886171972999364,
    5.870244272999116,
    5.91352246599854,
    5.859779974000048,
    0.0,
    6.569068812999831,
    6.5593686509982945,
    6.682060892999289,
    6.607512713000688,
    6.598092442998677,
    6.528111842999351,
    6.598124063999421,
    6.58594665199962,
    6.559150479999516,
    6.504685419000452,
    6.496715903000222,
    6.434928253998805,
    6.5097367400012445,
    6.579873005999616,
    6.434474073999809,
    6.538256015001025,
    6.324610389001464,
    6.27358981100042,
    6.352818298999409,
    6.483466747999046,
    6.45501412700105,
    6.565643138001178,
    6.488568525001028,
    6.541787023999859,
    6.5038204889988265,
    6.581268429999909,
    6.552995526999439,
    6.546708451000086,
    6.524523243000658,
    6.495681095999316,
    6.6178093509988685,
    6.591456583999388,
    6.367544781000106,
    6.219483474998924,
    6.139729630000147,
    6.121749039999486,
    6.0775530060000165,
    6.4966991579985915,
    6.373824378999416,
    6.2811853749990405,
    6.217972836000627,
    6.212935083000048,
    6.150111482998909,
    6.093089198000598,
    6.087426632999268,
    6.000313288001053,
    5.908441916999436,
    6.155831199999739,
    6.1494451300004584,
    6.4148603650010045,
    6.283526683000673,
    6.274287534000905,
    6.235525198999312,
    6.432614940000349,
    6.424275814000794,
    6.665793875999952,
    6.91105069400146,
    6.5958579309990455,
    6.720009119999304,
    6.716053133999594,
    6.825561059000393,
    6.895147557999735,
    6.86604392299887,
    6.802729126000486,
    6.687045278998994,
    6.751451575000829,
    6.740325135000603,
    6.723601013000007,
    6.717517195000255,
    6.95449534600084,
    6.942078465999657,
    6.859314235000056,
    6.937009445999138,
    6.876387098000123,
    6.977189975999863,
    7.203498064000087,
    7.187560258000303,
    7.246344417999353,
    7.382228562000819,
    7.484335704000841,
    7.367662980001114,
    7.3652808029983134,
    7.328471433000232,
    7.417491649999647,
    7.377110245000949,
    7.351410011000553,
    7.325000462999014,
    7.3594218010002805,
    7.260544573999141,
    7.2211353040001995,
    7.1923302590003,
    7.171729015999517,
    7.14199945800101,
    7.126805032999982,
    7.112742123001226,
    7.22055853799975,
    7.208404623001115,
    7.161722285998621,
    6.969850460000089,
    6.958490851000533,
    7.0286692640002,
    7.09853429100076,
    7.211385045999123,
    7.128379650001079,
    7.322888560000138,
    7.202143264999904,
    7.274076648000118,
    7.243235190000632,
    7.172248880999177,
    7.249983321999025,
    7.227536706999672,
    7.410186326998883,
    0.0,
    7.830565379999825,
    7.7872352819995285,
    7.594974624000315,
    7.538461052999992,
    7.607945850999386,
    7.734325133000311,
    7.679625020999083,
    7.523491336998632,
    7.424390782998671,
    7.2692649319997145,
    7.0986151060005795,
    7.208045905999825,
    7.1397119570010545,
    7.177968469000916,
    7.1730649350010935,
    7.035733930999413,
    7.1510361500004365,
    7.42049103699901,
    7.333987586998774,
    7.3001351460006845,
    7.262813389001167,
    7.347618597999826,
    7.329217295999115,
    7.268238028998894,
    7.35506500199881,
    7.191998923000938,
    7.169000304000292,
    7.155008304000148,
    7.040626680000059,
    7.0376683400008915,
    7.0310798790014815,
    6.998641498001234,
    6.980650421000973,
    6.977955574000589,
    7.05083618000026,
    7.017021683999701,
    6.955721673999506,
    6.9343373800002155,
    7.041932453001209,
    6.989729069999157,
    7.0931700249984715,
    7.0800088879987015,
    7.034087164000084,
    7.046978956999737,
    6.935980033000305,
    6.933019463000164,
    6.8905742070001,
    7.142687577999823,
    0.0,
    0.0,
    7.752283765999891,
    7.736603624000054,
    8.005694820998542,
    7.964907534000304,
    7.766100786000607,
    7.722478964999027,
    7.3948997580009745,
    7.3553240279998136,
    7.246582155999931,
    7.191054319000614,
    7.2379335690002335,
    7.293565287998717,
    7.407173459998376,
    7.497017276999031,
    7.4582254759989155,
    7.450441702001626,
    7.562236507999842,
    7.532843318000232,
    7.527600527000686,
    7.486745291998886,
    7.551572272999692,
    7.761479524999231,
    7.755511755000043,
    7.753118330998404,
    7.6879368999998405,
    7.785187417999623,
    7.731900777000192,
    7.68564402300035,
    7.9081610280009045,
    7.771898584000155,
    7.798803542000314,
    7.729251115999432,
    7.861275721999846,
    8.12064547099908,
    8.212739358999897,
    8.169127334000223,
    8.141354450999643,
    8.122451969000394,
    8.1311888550008,
    8.087259904999883,
    8.181824206998499,
    8.161974511998778,
    8.082788953001,
    8.02614564400028,
    8.156217409001329,
    8.40439699200033,
    8.220199332001357,
    8.415973989000122,
    8.371018380999885,
    8.265252971999871,
    8.380971811999189,
    8.229706893000184,
    8.44668781099972,
    8.286312081998403,
    8.557303359999423,
    8.549945247999858,
    8.82178581900007,
    8.729718452999805,
    8.82456256000114,
    8.789272992000406,
    8.860041822999847,
    8.727274696999302,
    8.675360126999294,
    8.670073508999849,
    8.609035847000996,
    8.789364342999761,
    8.645423707999726,
    8.768906961999164,
    8.691100195999752,
    8.964102223999362,
    8.948299759998918,
    8.89117971899941,
    9.011461629999758,
    8.99744048499997,
    8.975712752999243,
    8.971424769000805,
    8.96727010199902,
    9.086284867000359,
    9.041690321000715,
    9.20057224500124,
    9.016931506999754,
    8.955460081000638,
    8.928784588999406,
    8.909240876000695,
    8.885242491000099,
    8.842570324999542,
    8.921758814998611,
    8.8729471129991,
    9.006033084000592,
    0.0,
    9.645715389000543,
    9.603110006999486,
    9.720297928000946,
    9.618338738999228,
    9.661282979999669,
    9.86308700399968,
    9.824522504000925,
    9.791740938000657,
    9.794938793000256,
    9.78240856299999,
    9.810195919999387,
    9.769700896998984,
    9.792868894999629,
    9.787893844999417,
    10.044762857000023,
    10.104759863999789,
    9.914745751999362,
    10.157871592999072,
    10.451575473000048,
    10.362476195999989,
    10.476521337001031,
    10.386816947000625,
    10.279507019999073,
    10.379319690000557,
    0.0,
    10.658701476000715,
    10.749076486001286,
    10.661699606000184,
    10.658043751998775,
    10.870490536000943,
    10.688110326000242,
    10.63501871399967,
    10.570895042999837,
    10.65440623900031,
    10.606221872998503,
    10.862686141999802,
    10.664823179999075,
    10.618286603999877,
    10.583634991999133,
    10.546742569000344,
    10.499362660999395,
    10.621368899001027,
    10.752306656000655,
    10.828664507000212,
    10.942754003001028,
    10.863293784999769,
    10.860484832999646,
    10.75104728200131,
    10.677340829999594,
    10.676104233001752,
    10.763654170001246,
    10.755880736000108,
    10.833267719001014,
    10.798273622000124,
    10.639564180999514,
    10.748749952999788,
    10.766871678000825,
    10.756426824998925,
    10.613225129998682,
    10.52484152100078,
    10.461137574000531,
    10.50352557899896,
    10.500068347999331,
    10.461907312999756,
    10.402931889999309,
    10.096619240999644,
    10.206443205999676,
    10.329500994999762,
    10.325633589000063,
    10.299956355000177,
    10.34527089599942,
    10.30209726799876,
    10.660398944000917,
    10.579133691999232,
    10.568853664999551,
    10.544751067000107,
    10.612830711001152,
    10.536202950999723,
    10.454864949999319,
    10.585270486999434,
    10.538451731999885,
    10.518356288999712,
    10.449362805000419,
    10.266669103000822,
    10.303962985000908,
    10.173506372000702,
    10.29085392900015,
    10.265636590998838,
    10.249317617000997,
    10.225067872999716,
    10.279103324999596,
    10.208144962000006,
    10.131367750000209,
    10.191832266000347,
    10.17634039800032,
    10.13882736800042,
    10.22358265299954,
    10.194180374999632,
    10.207948735000173,
    10.054767106999861,
    9.882503234999604,
    9.794227958000192,
    9.663188004000403,
    9.746763296001518,
    9.729090611001084,
    9.709807750999971,
    9.568556545998945,
    9.346648172000641,
    9.289949019999767,
    9.212341494001521,
    9.201857030999236,
    9.322820285999114,
    9.282021806999182,
    9.2495929050001,
    9.183232715999111,
    9.098907826999493,
    9.07655410100051,
    9.049395533998904,
    9.095586426999944,
    9.010524195000471,
    8.97489798999959,
    8.967097176000607,
    8.76426133699897,
    8.948857564000718,
    8.917655352999645,
    8.890607258999808,
    8.77985085599903,
    9.01290273000086,
    8.97859513900039,
    8.908877679001307,
    8.852370806998806,
    8.800895072999992,
    8.689093337001395,
    8.869766751000498,
    8.805169678000311,
    8.659818376001567,
    8.563217758999599,
    8.68058363399905,
    8.663214436999624,
    8.621887391998825,
    8.705998368999644,
    8.686472781000703,
    8.799872036999659,
    8.735974139999598,
    8.745526521999636,
    8.44116584999938,
    8.315937985000346,
    8.309085277000122,
    8.206478844998855,
    7.979716673999064,
    8.06992429499951,
    8.197843427000407,
    8.317585083999802,
    8.263534968000386,
    8.210957106999558,
    8.14769797200097,
    8.225248470000224,
    8.167305545999625,
    8.134361406000608,
    8.09926412599998,
    7.943587195999498,
    8.070108006000737,
    7.992862002000038,
    8.264868746000502,
    8.112016175999088,
    8.220160855998984,
    8.325382011000329,
    8.315820249999888,
    8.280918131000362,
    8.220184058000086,
    8.341325643001255,
    8.333745611998893,
    8.29821400399851,
    8.33341310799915,
    8.287171047999436,
    8.206545831000767,
    8.190069142001448,
    8.31440590100101,
    8.584864963000655,
    8.731164312001056,
    8.726393552000445,
    8.793632921999233,
    8.86027653400015,
    8.852291065000827,
    8.836398073000964,
    8.815130099999806,
    8.672398808001162,
    8.636628357000518,
    8.76163488199927,
    8.726503440999295,
    8.7028151049999,
    8.815915988001507,
    8.652728589000617,
    8.585224237000148,
    8.544924296000318,
    8.256986609001615,
    8.254901271000563,
    8.3339478350008,
    8.321844256000986,
    8.274651551000716,
    8.53940148899892,
    8.483529314000407,
    8.597132954000699,
    8.409337863999099,
    8.348438725999586,
    8.418015426001148,
    8.328199658000813,
    8.252681904999918,
    8.179814588000227,
    8.145936016999258,
    8.379708467000455,
    8.36101750799935,
    8.353472803999466,
    8.612213335998604,
    8.587808402000519,
    8.674536254000486,
    8.622725483999602,
    8.46107236699936,
    8.440029920999223,
    8.525679477999802,
    8.704934630000935,
    8.675048744000378,
    8.632296898000277,
    8.714986445998875,
    8.701598429999649,
    8.64300325899967,
    8.591857841000092,
    8.664437186998839,
    8.557740102000025,
    8.79362131400012,
    8.919615225000598,
    8.90866502300014,
    9.01930124700084,
    9.06990137700086,
    8.903669390001596,
    8.846707013999549,
    8.7602181630009,
    8.720869142000083,
    8.812040320999586,
    8.807075279000856,
    8.688187865000145,
    8.590918038999007,
    0.0,
    8.975707104000321,
    8.91347902799862,
    8.909575407000375,
    8.877471126999808,
    8.85887047200049,
    9.069660250001107,
    9.012543662998723,
    8.9859007440009,
    8.932838815999276,
    8.934321886999896,
    8.890887891000602,
    8.715901073999703,
    8.705668803000663,
    8.666518980000546,
    8.705884715000138,
    8.969241328999487,
    8.901357864999227,
    8.747755949998464,
    8.693516463001288,
    8.688870242000121,
    8.651921098999082,
    8.737473088000115,
    8.68070404699938,
    8.82497539600081,
    8.939471072999368,
    8.9339619329985,
    8.933731211000122,
    8.89572036500067,
    8.935686848999467,
    8.92876955599968,
    8.837917433000257,
    8.94993213500129,
    8.930897693000588,
    8.855378934000328,
    8.995867924000777,
    8.994414682001661,
    9.109496501001558,
    9.100973114998851,
    9.149535954000385,
    9.11547797700041,
    9.040609412000777,
    8.943183248000423,
    8.916757321001569,
    9.00381101899984,
    8.95462058799967,
    8.930747448999682,
    8.917159112999798,
    8.874471660999916,
    8.742542462001438,
    8.982915930999297,
    8.931315771998925,
    8.858673496999472,
    8.845110348000162,
    8.838684004000243,
    8.938574956000593,
    8.879316960999859,
    8.811920138999994,
    8.728329541001585,
    8.840304604000266,
    8.838734352999381,
    8.705317187999754,
    8.79171845699966,
    8.857979618000172,
    8.97102828199968,
    8.955086407000636,
    8.843683097999019,
    8.966815981000764,
    8.958640951999769,
    8.912544888000411,
    8.882708862998697,
    9.019836834000671,
    8.977848827000344,
    8.965659399998913,
    8.941226629000084,
    8.817328175999137,
    8.73435538600097,
    8.702722924001137,
    8.855721374000495,
    8.840667038999527,
    8.655287483001302,
    8.65399804200024,
    8.794192933000886,
    8.691610082998523,
    8.66933707499993,
    0.0,
    9.316287310000916,
    9.24614874999861,
    9.340574017000108,
    9.276519622000706,
    9.186191980999865,
    9.11772699300127,
    9.267011371999615,
    9.261791147999247,
    9.331591669999398,
    9.26987891799945,
    0.0,
    9.96411924899985,
    9.863923532999252,
    9.985526982998636,
    9.979400862999682,
    9.845479670000714,
    9.83031160199971,
    10.083517410999775,
    9.96253873599926,
    9.914072449000741,
    9.889735066000867,
    9.780848145999698,
    9.7651671299991,
    9.846564412999214,
    9.976283977001003,
    9.951522961999217,
    10.06926994800051,
    10.031995886000004,
    10.04360902100052,
    10.026806249999936,
    9.984087446000558,
    9.975868645000446,
    9.91999685600058,
    9.894442279999566,
    9.858164427998418,
    9.861412906000623,
    9.79617471200072,
    10.011609441999099,
    9.99318888400012,
    10.072782253999321,
    9.973941631000343,
    9.917609640999217,
    9.941308420000496,
    9.923602538001433,
    9.85730266200153,
    9.84713131799981,
    9.709610650001196,
    0.0,
    10.320768568999483,
    10.314344746000643,
    10.305716897999446,
    10.245904059998793,
    10.172439955998925,
    10.162255197001286,
    10.14625745199919,
    10.136110887999166,
    10.130750530999649,
    10.246417926000504,
    10.244719595999413,
    10.241955856001368,
    10.354130664998593,
    10.301151104000382,
    10.245062328000131,
    10.233585677999145,
    10.21501409800112,
    10.263871442000891,
    10.351161173999571,
    10.274329104000572,
    10.154442577000736,
    10.082576987999346,
    10.199854260001302,
    10.293813192000016,
    10.23677135700018,
    10.367548146001354,
    10.45584007099933,
    10.441008510999382,
    10.326017737999791,
    10.54900115000055,
    10.506719785000314,
    0.0,
    11.033069621000323,
    11.018313462000151,
    10.972185221999098,
    0.0,
    11.376092352998967,
    11.12502951100032,
    11.110512777999247,
    11.099294534000364,
    11.217359127000236,
    11.149085539000225,
    11.107184967999274,
    11.360780936998708,
    11.467856426999788,
    11.414807281998947,
    11.63393579500007,
    11.627744515999439,
    11.563677487998575,
    11.494183832001,
    11.340956326001105,
    11.506317104998743,
    11.376711257998977,
    11.634014229999593,
    11.566011056000207,
    11.457329989001664,
    11.582698895001158,
    11.669006140999045,
    11.621308198999031,
    11.569172012999843,
    11.463092837000659,
    11.32597711299968,
    11.413072602999819,
    11.539696338000795,
    0.0,
    11.801283176000652,
    11.69698481100022,
    11.626044713000738,
    11.609266471999945,
    11.578068115999486,
    11.701951502000156,
    11.672931334000168,
    11.593638648999331,
    11.750230360001297,
    11.865766209999492,
    11.882454342001438,
    11.779272328998559,
    0.0,
    12.459435454999038,
    12.372575285999119,
    12.327811598999688,
    12.179250941999271,
    12.157793358999697,
    12.092221418999543,
    12.161909571999786,
    12.294995034999374,
    12.290686713000468,
    12.270614418999685,
    12.198666594000315,
    12.287327452000682,
    12.259561050999764,
    12.507764809999571,
    12.606601704999775,
    12.583208903999548,
    12.545044160999169,
    12.554268075000437,
    12.592774953000117,
    12.467437768000309,
    12.441408128999683,
    12.239710792000551,
    12.496583377998832,
    12.443536019000021,
    12.346324907999588,
    12.464923249999629,
    12.407971585000269,
    12.358047335001174,
    12.630682576000254,
    12.604043552999428,
    12.396424067001135,
    12.368132135999986,
    12.396357445999456,
    12.382518861999415,
    12.174975904999883,
    12.274768692999714,
    12.268836373999875,
    12.389225820999854,
    12.485154289001002,
    12.586582084999463,
    12.368909389000692,
    12.281379182999444,
    12.52785598400078,
    12.65960395500042,
    12.914423661999535,
    12.962792349000665,
    12.941874901998744,
    12.896307924000212,
    0.0,
    13.363072042999192,
    13.33491565499935,
    13.164966636999452,
    13.155474170998787,
    13.27420424400043,
    13.076175820000572,
    13.044268838999415,
    13.141058400000475,
    13.038097913999081,
    13.052854391000437,
    13.040448316000038,
    13.162014235998868,
    13.156024112000523,
    13.039284534999751,
    0.0,
    13.34449045600013,
    13.468185108999023,
    13.347304009999789,
    13.32362029199976,
    13.26614589699966,
    13.276742383000965,
    13.257400172999041,
    13.522838586999569,
    13.505639520999466,
    13.417829019999772,
    13.489028214000427,
    13.48799432099986,
    13.610700576000454,
    0.0,
    13.720364946999325,
    13.639079758000662,
    13.621587843999805,
    13.734974223998506,
    13.717440830998385,
    13.886883741999554,
    13.639765367999644,
    13.635307512000509,
    13.613071438998304,
    13.410385842000323,
    13.48002020900094,
    13.447869231000368,
    0.0,
    13.821900331000506,
    13.818627221000497,
    14.045722032000413,
    14.297937535000528,
    14.17399102499985,
    14.119902510001339,
    14.116102773999955,
    14.218940578000911,
    14.206906763000006,
    14.196756024000933,
    14.310061312000471,
    14.28095494199988,
    14.206649486999595,
    14.176623420999022,
    14.56916923099925,
    14.539786540999557,
    14.553762141000334,
    14.539682934000666,
    14.466112830999919,
    14.695765858999948,
    14.668836541999553,
    14.702167378000013,
    14.735552493000796,
    14.85452204899957,
    14.751045950000844,
    14.825239036001221,
    14.789650669001276,
    14.787626983999871,
    14.66937005300133,
    14.565648664000037,
    14.464443609998852,
    14.435755476999475,
    14.655818852001175,
    14.873490698999376,
    14.794225936000657,
    14.785827507999784,
    14.905090221000137,
    15.039188188999105,
    14.94825388999925,
    14.902749791001042,
    14.842992697000227,
    14.828061476000585,
    14.925591732000612,
    14.800589825001225,
    14.762350855999102,
    14.885947086999295,
    14.879818503999559,
    14.840663684999527,
    14.958912014999441,
    14.85982524999963,
    15.060801345000073,
    15.04211336300068,
    14.9892148859999,
    15.080967661000614,
    15.359372322000127,
    15.330673598999056,
    15.18861310200009,
    15.312242624999271,
    15.227694512999733,
    15.226289570999143,
    15.214828726000633,
    15.220148366001013,
    15.316369309000947,
    15.427466736000497,
    15.272410159999708,
    15.269989942000393,
    15.183288434000133,
    15.224298457000259,
    15.314976597999703,
    15.288996586001304,
    15.252417018000415,
    15.208102933998816,
    15.180394333001459,
    15.44019216200104,
    15.417809403999854,
    15.50422969400097,
    15.458762105999995,
    15.587741726998502,
    15.339828015999956,
    15.198613163000118,
    15.179451534999316,
    15.37901308399887,
    15.309876928999074,
    15.250354671999958,
    15.244450809999762,
    15.353582861000177,
    15.342019005000111,
    15.46308159200089,
    15.401603275000525,
    15.520117037000091,
    15.517125070000475,
    15.467895371999475,
    15.356940145000408,
    15.566627173000597,
    15.812020346000281,
    15.786693657000797,
    15.91240432000086,
    16.008685178001542,
    16.00758781299919,
    16.072139552999943,
    16.00317612300023,
    16.0528476519994,
    15.982481319999351,
    15.926658180998857,
    16.034702451999692,
    16.01092419500128,
    16.101568873998986,
    16.0689803639998,
    15.973473141000795,
    15.837343343000612,
    15.649560783000197,
    15.678320266999435,
    15.659124957999666,
    15.5637871179988,
    15.530327053000292,
    15.481049156000154,
    15.446208465000382,
    15.553545106999081,
    15.678210763999232,
    15.655662487000882,
    15.634973656000511,
    15.725378126000578,
    15.562223306000305,
    15.810806831999798,
    15.753674523999507,
    15.726769275001061,
    15.649088629001199,
    15.694406024000273,
    15.810442821000834,
    15.74117768799988,
    15.651563683000859,
    15.46711636299915,
    15.584602644999904,
    15.405191376999937,
    15.464180387001761,
    15.416560016001313,
    15.551210334999269,
    15.65873340699909,
    15.652009761000954,
    15.836204917000941,
    15.854012562000207,
    15.727025586000309,
    15.795850866001274,
    15.695898283000133,
    15.956962730000669,
    16.080532108000625,
    16.184322524999516,
    16.080967900999894,
    16.06241209699874,
    16.18413715400129,
    16.16511953600093,
    16.101445238999077,
    15.99716301800072,
    16.079591604000598,
    16.1730825249997,
    16.110192799000288,
    16.051513607999368,
    16.296581997999965,
    16.41691014099888,
    16.68588011799875,
    16.579938523998862,
    16.36898375400051,
    16.419706135000524,
    16.281091135999304,
    16.173881177999647,
    16.066549386001498,
    16.124228210999718,
    16.233672076999937,
    16.222821360001035,
    16.144487006000418,
    16.271116833000633,
    16.2123405300008,
    16.071695257998726,
    16.162928896001176,
    16.329167957999744,
    16.263248498000394,
    16.25391439300074,
    16.226276858998972,
    16.475415466000413,
    16.46891682599926,
    16.44517938199897,
    16.57829451699945,
    16.691777977999664,
    16.61566566700094,
    16.59523589699893,
    16.586657769999874,
    16.898081478999302,
    16.992762145999222,
    16.958351547998973,
    0.0,
    17.228925749001064,
    17.154741020000074,
    17.22658267299994,
    17.215418376999878,
    17.3129126849999,
    17.286104153999986,
    17.333525831998486,
    17.328553797000495,
    17.314621800000168,
    17.204795503999776,
    17.057046600999456,
    17.29762391499935,
    17.132384328000626,
    17.043206385000303,
    17.06282303399894,
    17.03764200599835,
    17.163749527999244,
    17.142001194999466,
    0.0,
    17.384288948000176,
    17.457255568999244,
    0.0,
    18.524383922000197,
    18.4373624990003,
    0.0,
    18.761957336000705,
    18.849820561999877,
    18.809493868999198,
    18.935238477000894,
    19.15214499400099,
    0.0,
    19.65815494799972,
    19.60114828800033,
    0.0,
    20.086024346999693,
    20.182671560998642,
    20.157957030000034,
    20.087627932000032,
    20.004541754000456,
    20.00177331099985,
    19.871811909000826,
    19.959496785000738,
    20.06462196299981,
    20.02945066599932,
    19.891261164000753,
    19.84917023699927,
    19.96862372600117,
    19.904841457999282,
    0.0,
    20.8388232519992,
    20.827678702999037,
    20.795487371999116,
    20.85253707800075,
    20.942469754998456,
    20.92712802799906,
    20.889986723999755,
    21.097757127001387,
    20.92276537500038,
    21.146608454999296,
    20.98922870500064,
    21.2397202989996,
    21.24566756999957,
    21.143751737001367,
    21.0787338730006,
    21.01499978799984,
    21.009398247999343,
    21.21852981899974,
    21.216173779999735,
    21.134691756000393,
    21.13258644600137,
    21.128957830000218,
    21.121625821000634,
    21.10737035999955,
    0.0,
    21.450478075999854,
    21.542266202000974,
    21.537681375999455,
    21.423606907001158,
    21.67263679200005,
    21.61587442400014,
    21.475905368000895,
    21.201787812000475,
    21.278791724000257,
    21.206321128000127,
    21.178152263999436,
    21.101253529001042,
    21.171946906999437,
    21.098220333999052,
    21.081051619999926,
    0.0,
    21.621356591998847,
    21.718664714000624,
    21.679929996998908,
    21.58785684400027,
    21.440727863000575,
    21.415090180000334,
    21.488804533999428,
    21.41778727900055,
    21.226401934000023,
    21.30785020699841,
    21.272683831000904,
    21.125855594000313,
    21.097330773000067,
    21.200402657001177,
    21.15905877899968,
    21.153518678000182,
    21.13486796199868,
    21.257564006000393,
    21.22603510800036,
    21.209592342000178,
    21.06576670100003,
    21.053063094999743,
    20.997821016999296,
    0.0,
    21.561525150000307,
    21.593839548999313,
    21.573792977000267,
    21.697089108,
    21.6893780219998,
    21.77286948800065,
    21.74132244000066,
    21.672944343999916,
    21.749140912999792,
    21.744472609001605,
    21.74213448000046,
    21.697591611999087,
    21.68488981399969,
    21.66024708400073,
    21.735401300999,
    21.73280312300085,
    21.554110197001137,
    21.551586689000032,
    21.5363503510016,
    21.655378845000087,
    21.306779581998853,
    21.238982228000168,
    21.21278130599967,
    21.301610181999422,
    21.40929366799901,
    21.40244659599921,
    21.59745547899911,
    21.706471450999743,
    21.945610564998788,
    22.152885640998647,
    22.051458608000758,
    21.981509774999722,
    21.935843305000162,
    21.92454680499941,
    21.892462668998633,
    22.015003118000095,
    22.139922128999387,
    22.094236185999762,
    22.176934322000307,
    22.127875718000723,
    22.087833409999803,
    22.35226817900002,
    22.27092259100027,
    22.31979117499941,
    22.274476003000018,
    22.37826957499965,
    22.324696427000163,
    22.423872823999773,
    22.48452465599985,
    22.432622579999588,
    22.52354980400014,
    22.504512153000178,
    22.397235774000364,
    22.292778540000654,
    22.28123974099981,
    22.393609032000313,
    22.239431861000412,
    22.371566999001516,
    22.43357472200114,
    22.43688797300092,
    22.337105250000604,
    22.713445851999495,
    22.675374475000353,
    22.617694621001647,
    22.5754647069989,
    22.534428038999977,
    22.503471840000202,
    22.557146553001076,
    22.52578804299992,
    22.606649436000225,
    22.489977563998764,
    22.37418691200037,
    22.31674041000042,
    22.43808788000024,
    22.361054768998656,
    22.331094761000713,
    22.345393354000407,
    22.340304785000626,
    22.414556144000017,
    22.512533959999928,
    22.460567112999342,
    22.346044605001225,
    22.449553697999363,
    22.722913264000454,
    22.718026567999914,
    22.69149308299893,
    22.67235274900122,
    22.783186399999977,
    22.76795343000049,
    22.47660997299863,
    22.362944287000573,
    22.57304071100043,
    22.496647494999706,
    22.489084286000434,
    22.425250058999154,
    22.312434063000183,
    22.275802183999986,
    22.391657440999552,
    22.22074381300081,
    22.173461349999343,
    22.207967944999837,
    22.08915067000089,
    22.01362665600027,
    21.98886231799952,
    21.955460848999792,
    21.937798089000353,
    21.920962029000293,
    22.320170988999962,
    22.317421281999486,
    22.296882213000572,
    22.402271077000478,
    22.478090986000097,
    22.459475343999657,
    22.403900139999678,
    22.519664840001496,
    0.0,
    23.037996662000296,
    23.132776614998875,
    23.074948442999812,
    23.1404079060012,
    23.070048034000138,
    23.061864171999332,
    23.19843250300073,
    23.408216224999705,
    23.366969933998917,
    23.544893003998368,
    0.0,
    24.09706826799993,
    0.0,
    25.02226011699895,
    24.96994524600086,
    24.920574731999295,
    24.805648782999924,
    24.803905817998384,
    25.226805295000304,
    25.34443636300057,
    25.091252598998835,
    25.08718786999998,
    25.19632805800029,
    25.30424115599999,
    25.250887620000867,
    25.341794029000084,
    25.45448336699883,
    25.447294927998882,
    25.322512549999374,
    25.246336185000473,
    25.160447304000627,
    0.0,
    25.494376431999626,
    25.474211687000206,
    25.42896611800097,
    25.372851874000844,
    25.417694009000115,
    25.342030592999436,
    25.316215107999597,
    25.393614587999764,
    25.190427244000603,
    25.06263196999862,
    25.01553573899946,
    25.115649033999944,
    25.02974636199906,
    25.10379074299999,
    25.133372931999475,
    25.30105669799923,
    25.230161242998292,
    25.205413194000357,
    25.120846288000394,
    25.473485508000522,
    25.433059489998413,
    25.652375444000427,
    25.720832207000058,
    25.708863567999288,
    25.641023794998546,
    25.880980134999845,
    25.832508968000184,
    25.811181905999547,
    25.929329560000042,
    25.91655627399996,
    25.88073232900024,
    26.00553029799994,
    25.95196796699929,
    25.85937772500074,
    25.682971214000645,
    25.564207759000055,
    25.551711463000174,
    25.427259944999605,
    25.47310047800056,
    25.4984482939999,
    25.39783115499995,
    25.189079580000907,
    25.288219377000132,
    25.151527722999163,
    24.996873244999733,
    24.960924700999385,
    25.0289129540015,
    25.126058247999026,
    25.081927946999713,
    25.019568076000724,
    25.26746757500041,
    25.17727982699944,
    25.345744180998736,
    25.16237281999929,
    0.0,
    26.032993501999954,
    25.95509064199905,
    25.865315564999037,
    25.83919049999895,
    25.720992108001155,
    25.687310937000802,
    25.578924968000138,
    25.3593559810015,
    25.462268610999672,
    25.359103721000793,
    25.61428180099938,
    25.57944798399876,
    25.694809847000215,
    25.67985016900093,
    25.78086330699989,
    25.91971322900099,
    25.505565445000684,
    25.48057463400073,
    25.481359527000677,
    25.457571746999747,
    25.4239183410009,
    25.4891148709994,
    25.46843201899901,
    25.393435918998875,
    25.492622845998994,
    25.409273326999028,
    25.52897604699865,
    25.599791439999535,
    25.709374815000047,
    25.4868204530012,
    25.418174061000173,
    25.38068983500125,
    25.454856431000735,
    0.0,
    26.38947981899946,
    26.444250364000254,
    26.34211032100029,
    26.20569499799967,
    26.188941019001504,
    26.210804155000005,
    26.18637244799902,
    26.049375733999113,
    25.92955190199973,
    25.984398562000933,
    25.980048632000035,
    25.90968862400041,
    26.11844507999922,
    26.074202996000167,
    26.190738302999307,
    26.295160826999563,
    26.12738401000024,
    25.969618362998517,
    25.874530432998654,
    25.955559239999275,
    25.94081702999938,
    25.938381390998984,
    25.96151964300043,
    25.93567139699917,
    25.932361786999536,
    26.184692819999327,
    26.131493070999568,
    26.085760633000973,
    26.05082912800026,
    26.170150542000556,
    26.157945471999483,
    26.181776793999234,
    26.239208615999814,
    26.204306101999464,
    25.96579219100022,
    26.12101632700069,
    26.32700560000012,
    26.18308253899886,
    26.161277014000007,
    26.122555539999667,
    25.997781653000857,
    26.100573207000707,
    0.0,
    26.806808663000993,
    26.899448642001516,
    26.766759576999902,
    26.764337223999974,
    26.75538883000081,
    26.858834781998667,
    27.017264336000153,
    26.775170856999466,
    26.7438616670006,
    26.69085701699987,
    26.806688466000196,
    26.792498832999627,
    26.903462397000112,
    26.889502643000014,
    26.91356632300085,
    26.90786696699979,
    26.847341655999116,
    26.835594951999155,
    26.895534975999908,
    26.882508741000493,
    27.00625655099975,
    27.00519497500136,
    26.935732652998922,
    26.933692947000964,
    27.313781360000576,
    27.298802774999785,
    27.256560244000866,
    27.381657484000243,
    27.604597851999642,
    27.597022754000136,
    27.537307458000214,
    27.662653155000953,
    27.76550021500043,
    27.76354577100028,
    27.882617178000146,
    28.163106157000584,
    28.276276747999873,
    28.14356921199942,
    28.110914653998407,
    27.985982829999557,
    28.241118789999746,
    28.174707819000105,
    28.17206457700013,
    28.12730956499945,
    28.220436897998297,
    28.214670491001016,
    28.128575450000426,
    28.172996204999436,
    0.0,
    28.78687449499921,
    28.64998088900029,
    28.75613603200145,
    28.75148817599984,
    28.849658401000852,
    28.97492243600027,
    28.895573378000336,
    28.84167992699986,
    28.61517895399993,
    28.486784007000097,
    28.405199533000996,
    28.492714519999936,
    28.454484070000035,
    28.43815085499955,
    28.3800158009999,
    28.43631561499933,
    28.355412566999803,
    28.437699993000933,
    28.367951201000324,
    28.30574100100057,
    28.2380048670002,
    28.346970140999474,
    28.552575719000743,
    28.537523966000663,
    28.782029410998803,
    28.731460742001218,
    28.789182902000903,
    28.73569738900005,
    28.716970410001522,
    28.894996958000775,
    29.023448035999536,
    29.021410892999484,
    29.28143646799981,
    29.270197814999847,
    29.220172878000085,
    29.19570868000119,
    29.186488377999922,
    29.41088286500053,
    29.584532355998817,
    29.575640575998477,
    29.79295004800042,
    0.0,
    29.908057355998608,
    30.024370017001274,
    29.99361289099943,
    30.10212395599956,
    30.040797759998895,
    29.985379918000035,
    29.945122709001225,
    30.222232674001134,
    30.160010689000046,
    30.299947233999774,
    0.0,
    30.720957980000094,
    30.563027318001332,
    30.643972112000483,
    30.58685339600015,
    30.555962610998904,
    30.514468191999185,
    30.476436662000197,
    30.333331800999076,
    30.309898995001276,
    30.300045382999087,
    30.365404194000803,
    30.251765128999978,
    30.124981743998433,
    30.081607325000732,
    30.33710379600052,
    30.21897491799973,
    29.927178253999955,
    29.905239554000218,
    30.034430866999173,
    30.025559464000253,
    29.983452440999827,
    30.10038714899929,
    29.99262746900058,
    30.24812528199982,
    30.285675983001056,
    30.56031463600084,
    30.804375449999498,
    30.701605565000136,
    30.92270650699902,
    30.90783638299945,
    30.871854140999858,
    30.883152006999808,
    30.75702257699959,
    30.68198448500152,
    30.608305038000253,
    30.63466921899999,
    30.588484578000134,
    30.477539044000878,
    30.28636669699881,
    30.259512439999526,
    30.231006003001312,
    30.466590898000504,
    30.5643525079995,
    0.0,
    30.951151975999892,
    31.013821533000737,
    30.966905387000224,
    31.094799177999448,
    31.035820560000502,
    30.93253764200017,
    30.76075797699923,
    0.0,
    31.321582247999686,
    31.243551362998915,
    31.22938570000042,
    31.225929235000876,
    31.167355786999906,
    31.097054044999823,
    31.208832533999157,
    31.339012460999584,
    31.327604674999748,
    31.293489277000845,
    31.52054818400029,
    31.632193325000117,
    31.61049214600098,
    31.591842009000175,
    31.52680980600053,
    31.484291819000646,
    31.590753376000066,
    31.567709028000536,
    31.805352825000227,
    31.63547700900017,
    31.610251870000866,
    31.58876733299985,
    31.78529067800082,
    31.763047681999524,
    31.851431327000682,
    31.842463379000037,
    31.765059401001054,
    31.763202411000748,
    31.83071178099999,
    31.806922363999547,
    31.664571627999976,
    0.0,
    31.740732727999784,
    31.71581307500128,
    31.628491211999062,
    31.703059639999992,
    31.681139467998946,
    31.66278686000078,
    31.60383083799934,
    31.59374395300074,
    31.4938875200005,
    31.329162822999933,
    31.374643694000042,
    31.47654785099985,
    31.575739792000604,
    31.559446209999805,
    31.497997763999592,
    31.48353444500026,
    31.580600568999216,
    31.53657334899981,
    31.51688085999922,
    31.427921267000784,
    31.53313815799993,
    31.52968697600045,
    31.40825540500009,
    31.478178199999093,
    31.415250620000734,
    31.55081460800102,
    31.53377925699897,
    31.510617226998875,
    31.489427724998677,
    31.406565376999424,
    31.324562558998878,
    31.561079442000846,
    31.526112947,
    31.40604163700118,
    31.32922124600009,
    0.0,
    31.929843703001097,
    32.05217193399949,
    32.1713929689995,
    32.10225346700099,
    32.05522194399964,
    31.992385478999495,
    0.0,
    32.362377962999744,
    32.3320652329985,
    32.329616425000495,
    32.30610824099858,
    32.12039011700108,
    32.039847439998994,
    32.086399549001726,
    32.01082271999985,
    31.996116886999516,
    32.10205428699919,
    31.94757674900029,
    32.09961304799981,
    31.917320131999077,
    31.89073998800086,
    31.860527615999672,
    31.90140708800027,
    32.06360047999988,
    31.951815745000204,
    31.930995979000727,
    31.99500419099968,
    31.94661839299988,
    31.884746464000273,
    31.84992150799917,
    31.96245830100088,
    31.93922809200012,
    31.755545153999265,
    31.707333597998513,
    31.629910101999485,
    31.562161318999642,
    31.559002369000154,
    31.685735289998775,
    31.67670782300047,
    31.781520516000455,
    31.631226581999726,
    31.711144704999242,
    31.693385587999728,
    31.715394093000214,
    31.7053197740006,
    31.670906643999842,
    31.610475767000025,
    31.57755891299894,
    31.592778046000603,
    31.53541845000109,
    31.456257342000754,
    31.524494556999343,
    31.521099187999425,
    31.593001451999953,
    31.570181000000957,
    31.56326062199878,
    31.68441437599904,
    31.508495247999235,
    31.424133292999613,
    31.383522162999725,
    31.466334949000156,
    31.446962304000408,
    31.41706147900004,
    31.30197577400031,
    31.520421797999006,
    31.511304632000247,
    31.56024989800062,
    31.495635365999988,
    31.47509190799974,
    31.852241245998812,
    31.843004885999108,
    31.837417468999774,
    31.808982075999666,
    31.705664184999478,
    31.92201174100046,
    31.868484368998907,
    31.82738100900133,
    31.80659749000006,
    31.872672475999934,
    31.694163864000075,
    31.660892405001505,
    31.77150002899907,
    31.74500229899968,
    31.862827797000136,
    31.988905374999376,
    32.117768127998715,
    32.03840509899965,
    32.168481090999194,
    32.15806231299939,
    32.39291649500046,
    32.37399077899863,
    32.3376952969993,
    32.27340838899909,
    32.47421424799904,
    32.4353255799997,
    32.40013377899959,
    32.36642375599877,
    0.0,
    32.45093040100073,
    33.17897472699951,
    33.26605770400056,
    32.99538770399886,
    33.30287240799953,
    33.2789083330008,
    33.27227805700022,
    0.0,
    33.31541386999925,
    33.351246799000364,
    33.41068942200036,
    33.38146815399887,
    33.30080414499935,
    33.29557481499978,
    33.32108539299952,
    33.42544902100053,
    33.554694725000445,
    33.495592181001484,
    33.605719810000664,
    33.54581102099837,
    33.53163821999988,
    33.65649418300018,
    33.84218154700102,
    33.70967608299907,
    33.624251188000926,
    33.580479592999836,
    33.43444686099974,
    33.56512557899987,
    33.6428595870002,
    33.59085393799978,
    33.581196286000704,
    33.52327079399947,
    33.42378094199921,
    33.54629078000107,
    33.80234574399947,
    33.522824677000244,
    33.72951786699923,
    33.711656161000064,
    33.91693285400106,
    34.021528690000196,
    33.78766949300007,
    33.740354224999464,
    33.8422231200002,
    33.82622135599922,
    33.71858021099979,
    33.84187811599986,
    34.088510589999714,
    34.03372377499909,
    34.13176072999886,
    34.103771267999036,
    33.94261051600006,
    33.983469339000294,
    33.9461116450002,
    33.87528989599923,
    33.76919156599979,
    33.67671603499912,
    33.725500106000254,
    33.64868820799893,
    33.58093303699934,
    33.491100004001055,
    33.46761273800075,
    33.56026941699929,
    33.5412404180006,
    33.479576050000105,
    33.38852521800072,
    33.48931060799987,
    33.47340779799924,
    33.59678617300051,
    33.68956670800071,
    33.60092980399895,
    33.54226514699985,
    33.79379878600048,
    33.7061413729989,
    33.687606281000626,
    33.473815448000096,
    33.402278866000415,
    33.30028149199825,
    33.39295403599863,
    33.332288242001596,
    33.28926411700013,
    33.11384205300055,
    33.0517376429998,
    32.94202041999961,
    33.023187359000076,
    33.030825011999696,
    32.98683905100006,
    32.9696125290011,
    32.95919687700007,
    33.038868869,
    32.96945817999949,
    32.86329749300057,
    32.987271713000155,
    32.95701614999962,
    32.799861593999594,
    32.77843896300146,
    32.6096015589992,
    32.596453639000174,
    32.57095664000008,
    32.62647243699939,
    32.60726558799979,
    32.77875266299998,
    32.76762483499988,
    32.83000171200001,
    32.778871189999336,
    32.85643752299984,
    32.76662895200025,
    32.78174134700021,
    32.772845518000395,
    32.90073169800053,
    0.0,
    33.303537574000075,
    33.301657916001204,
    33.34478746499917,
    33.45726659200045,
    33.5623720450003,
    33.3400464690003,
    33.28490495400001,
    33.211919968000075,
    33.3180559930006,
    33.380450311999084,
    33.353475817999424,
    33.231075099998634,
    33.317926052000985,
    33.292645953999454,
    33.70845643600114,
    33.721557875000144,
    33.56206908599961,
    33.5518841789999,
    33.58750047600006,
    33.57973163300085,
    33.58325239199985,
    33.532085230999655,
    33.53176250400065,
    33.52045218999956,
    33.55729036699995,
    33.823819664999974,
    33.80631030299992,
    33.902335730999766,
    33.88632974400025,
    33.8649923590001,
    33.836488040000404,
    33.96169721700062,
    34.23113584699968,
    34.16493334500046,
    34.17884038199918,
    34.43232190100025,
    34.36645768699964,
    34.49571913900036,
    34.32247162400017,
    34.456041179999374,
    34.45069578199946,
    34.54503132900027,
    34.46025556400127,
    34.68118306600081,
    34.61432924200017,
    34.72493426300025,
    34.685180157001014,
    34.65414430799865,
    34.551200481000706,
    34.47370058400156,
    34.322468645999834,
    34.387050287999955,
    34.359439892999944,
    34.55267459300012,
    34.549189348001164,
    34.59187603600003,
    34.50996292200034,
    34.55019726200044,
    34.54148824999902,
    34.602979848999894,
    34.53894116599986,
    34.52037009599917,
    34.487937506999515,
    34.543309362999935,
    34.56832246600061,
    34.5330133009993,
    34.601676173999294,
    34.59596405499906,
    34.56578829499995,
    34.84250521799913,
    35.0605421399996,
    35.059033426001406,
    35.12472641900058,
    35.169160773999465,
    35.42291206399932,
    0.0,
    36.120951906999835,
    36.38097833400025,
    36.30848463899929,
    36.21157681799923,
    36.19356915299977,
    36.0585194209998,
    36.176234777998616,
    36.053988117999324,
    36.177766116001294,
    36.24189041700083,
    36.20636229199954,
    36.48063638400163,
    36.58560084899909,
    36.57019871000011,
    36.5886793819991,
    36.495528976998685,
    36.35607605399855,
    36.290508697000405,
    36.27473636800096,
    36.21020815600059,
    36.18440833400018,
    36.373694129000796,
    36.36368133799988,
    36.46646517100089,
    36.45402073599871,
    36.29258601499896,
    36.41579595999974,
    36.396612749998894,
    36.38886859100057,
    36.37446923099924,
    0.0,
    36.73425167200003,
    36.71110563899856,
    36.70496248600102,
    36.67071429999851,
    36.665029503999904,
    36.65485918700142,
    36.77102756600107,
    36.72732739800085,
    36.64185404199998,
    36.597984525000356,
    36.58502018299987,
    36.43522670799939,
    36.358018164000896,
    36.15956486200048,
    36.20744884300075,
    36.145488774000114,
    36.07752689600056,
    35.996916131000035,
    35.91104269399875,
    35.88837233000049,
    35.85077301700039,
    35.87306851699941,
    35.79008357599923,
    35.989714493000065,
    36.01977147400066,
    35.84270236100019,
    35.77122452200092,
    35.775794847000725,
    35.75179021400072,
    36.01911116500014,
    35.93062937000104,
    35.91086828299922,
    35.98753123300048,
    36.03288358899954,
    36.096778993000044,
    36.329970379998485,
    36.318619526000475,
    36.383724295999855,
    36.34768668000106,
    36.34246790200086,
    36.45860588800133,
    36.44142870000178,
    36.43969921700045,
    36.41330151699913,
    36.39864992799994,
    36.39030793600068,
    36.76600483599941,
    36.76485873300044,
    36.914417313999365,
    36.99381455600087,
    36.864039056001275,
    36.78514228499989,
    36.75247412700082,
    36.82604446000005,
    36.76994865300003,
    37.02219799199884,
    36.98998106699946,
    37.03100702699885,
    36.98355280200121,
    36.93543444700117,
    37.05225667900049,
    37.01188620699941,
    37.10123827800089,
    37.09584177299985,
    37.19862608400035,
    37.073244306999186,
    37.068466519998765,
    37.14820006800073,
    37.2473768990003,
    37.289871110000604,
    37.25012205999883,
    37.24584448300084,
    37.23534553099853,
    37.23171078800078,
    37.45669748,
    37.27391652900042,
    37.20592855900031,
    37.29259116000139,
    37.38766378100081,
    37.320343529998354,
    37.242204644000594,
    0.0,
    37.56164167600036,
    37.49683095299952,
    37.627035131999946,
    37.7665289760007,
    37.83850602600069,
    37.83233188799932,
    37.817845798001144,
    37.936115018001146,
    37.885489749000044,
    37.97328026300056,
    37.967605670999546,
    37.90461920500093,
    37.90650486599952,
    37.8618282970001,
    38.104908884000906,
    38.18127165000078,
    38.145739651999975,
    38.13366087099894,
    38.35786236700005,
    38.33783871800006,
    38.224471065001126,
    38.21716122900034,
    38.1594037019986,
    38.146608877999824,
    38.12309791000007,
    38.07250647899855,
    38.098573860001125,
    38.22779151299983,
    37.91314420699928,
    37.90419112500058,
    37.63771942400126,
    37.746169685000496,
    37.72385023899915,
    37.698036126999796,
    37.6587960880006,
    37.88524040000084,
    37.831115136001245,
    37.94586030000028,
    37.92093069399925,
    37.87577925599908,
    37.87265775099877,
    37.83991529500054,
    37.83859709799981,
    37.80894006000017,
    38.0014307750007,
    37.97048833699955,
    37.96332467799948,
    37.8922835100002,
    37.886418058000345,
    38.22723444499934,
    38.22625025399975,
    38.14269875100035,
    38.12319017799928,
    38.17528435299937,
    38.14615865699852,
    38.06555694300005,
    38.00946697499967,
    37.99702413200066,
    38.01607922100084,
    38.22164281299956,
    38.20411834600054,
    38.047803620000195,
    37.77861967900026,
    37.777939825999056,
    37.86525984999935,
    37.84360431099958,
    37.76105782600098,
    37.88504926499991,
    37.97198423500049,
    38.040283899001224,
    38.225075944999844,
    38.208953459999975,
    0.0,
    38.45354774800035,
    38.41477152600055,
    38.415549245000875,
    38.27602606800065,
    38.26547467400087,
    38.228226150999035,
    38.21603927199976,
    38.289045916999385,
    38.16306078299931,
    38.08647890499924,
    38.065746659998695,
    38.328941875000965,
    38.29800747599984,
    38.367571439999665,
    38.198601977999715,
    38.1772289440014,
    38.16332067300027,
    38.23990015900017,
    0.0,
    38.48549877700134,
    38.45791394400112,
    38.454884033999406,
    38.61230597499889,
    38.52221479599939,
    38.515761254999234,
    38.484412098001485,
    38.44660562700119,
    38.205181311999695,
    38.251277421999475,
    38.451446529999885,
    38.431025015999694,
    38.41504967800029,
    38.39867662500001,
    38.509607543999664,
    38.49152700800005,
    38.399106917999234,
    38.515230848999636,
    38.434833650000655,
    38.42636333200062,
    38.30243784400045,
    38.29057990599904,
    38.21895190400028,
    38.20862492100059,
    38.27943876900099,
    38.269660739000756,
    38.19419036100044,
    38.44150173299931,
    38.3921792989986,
    38.27587993399902,
    38.344380775999525,
    38.45282242900066,
    38.69277534199864,
    38.68969900100092,
    38.668339263000234,
    38.46974079100073,
    38.63456361799945,
    38.60623493099956,
    38.68560063699988,
    38.70024987100078,
    38.65851564699915,
    38.758181137000065,
    38.74147987299875,
    0.0,
    39.42502049399991,
    39.38767160799944,
    39.24436161199992,
    39.097085325998705,
    38.97880637799972,
    38.97422937900046,
    39.09281125400048,
    39.08029413999975,
    39.07304651599952,
    39.1553070760001,
    39.270547797999825,
    39.461826699000085,
    39.453400341000815,
    39.398692988999755,
    39.47420938999858,
    39.41500035700119,
    39.14877504799915,
    39.25118682399989,
    39.211643085000105,
    39.33980580000025,
    39.548085888998685,
    39.643952624999656,
    39.630897396000364,
    39.75108689300032,
    39.74793383299948,
    39.56170985499921,
    39.3932134300012,
    39.18673482899976,
    39.17977039700054,
    39.264797146001,
    39.130473327999425,
    39.0079649700001,
    39.136904840999705,
    39.02039421600057,
    38.86446788499961,
    38.97065196299991,
    38.95517209500031,
    38.8931331900003,
    39.007993574001375,
    38.98177324799872,
    0.0,
    39.33104794300016,
    39.27392797500033,
    39.28137283800061,
    39.29886755900043,
    39.426509794000594,
    39.383284841000204,
    39.49454123800024,
    39.494098536999445,
    39.50359358800051,
    39.46867587899942,
    39.37477196299915,
    39.44312708100006,
    39.427340490999995,
    39.41099693000069,
    39.5840395439991,
    39.83086942299997,
    39.95621961699908,
    40.08295780000117,
    40.060153251000884,
    40.01400573200044,
    40.02062701599971,
    40.02122075200168,
    39.97002045299996,
    39.96869192899976,
    39.899666544000866,
    39.87866381499953,
    39.986631959998704,
    39.88364307400116,
    39.97397468499912,
    39.950280308999936,
    40.1356541210007,
    40.10440976700011,
    39.97760865100099,
    39.97490599299999,
    39.954033877000256,
    39.80130981699949,
    0.0,
    40.724984516000404,
    40.8316669679989,
    40.72985762600001,
    40.6721530750001,
    40.65283577599985,
    40.651032969999505,
    40.64643669399993,
    40.609626051000305,
    40.54211090300123,
    40.54017889900024,
    40.64410070199847,
    40.627017233000515,
    40.796128572999805,
    41.000502452001456,
    0.0,
    41.19505365199984,
    41.309030471998994,
    41.251564757998494,
    41.36707110600037,
    41.2464993020003,
    41.282059451999885,
    41.25381160899997,
    41.24439590499969,
    41.363321178998376,
    41.35369735700078,
    41.32372892300009,
    0.0,
    41.387801730999854,
    41.3482493169995,
    41.461291067000275,
    41.29533861600066,
    41.195810772000186,
    41.194110393998926,
    41.18076694999945,
    41.00650188600048,
    40.977545794001344,
    40.96109513800002,
    41.08828336099941,
    41.04385630700017,
    40.91961650200028,
    40.858811411000715,
    40.97649096299938,
    40.92379073400116,
    41.05550425900037,
    40.9899829269998,
    40.915280507000716,
    40.854354993000015,
    40.82372799000041,
    40.86878777499987,
    40.8312621189998,
    40.860770171000695,
    40.6903598429999,
    40.71095785699981,
    40.654158213999835,
    40.93151184399903,
    40.8419934880003,
    40.773976331000085,
    40.87687848600035,
    40.9124877610011,
    40.84333426000012,
    41.10277196700008,
    41.016846450998855,
    40.94345697300014,
    40.773894812000435,
    40.88885999700142,
    40.81813083099951,
    40.73928288100069,
    40.662444096999025,
    40.780753076998735,
    40.88262241600023,
    40.858254955999655,
    40.93904957800078,
    40.92207984900051,
    40.87795250099953,
    40.64766997900006,
    40.680212739000126,
    40.58021580900095,
    40.48941772999933,
    40.34392904500055,
    40.36527211499924,
    40.272956524999245,
    40.19745989600051,
    40.10994855200079,
    40.24515357499877,
    40.29939530299998,
    40.22865009000088,
    40.149950607999926,
    40.19243511199966,
    40.03085629199995,
    39.962407386999985,
    40.05392216300061,
    40.04808965600023,
    39.89467918099945,
    40.00631840499955,
    39.99512270200103,
    39.959464842999296,
    39.75233308600036,
    39.66617033500006,
    39.71475683299832,
    39.78569385699848,
    39.74347350500102,
    39.72296729700065,
    39.78859473599914,
    39.848655662000965,
    39.97179163800138,
    39.99988138200024,
    40.21828189699954,
    40.200810910000655,
    40.35224089199983,
    40.42498907300069,
    40.56018475900055,
    40.495533605000674,
    40.55886034499963,
    40.47607071999846,
    40.40968837000037,
    40.405731040998944,
    40.37921036800071,
    40.37532319999991,
    40.46721057200011,
    40.44482056199922,
    40.38489116299934,
    40.51174836399878,
    40.415374991000135,
    40.40413636899939,
    40.631575529001566,
    40.610206550998555,
    40.556346004999796,
    40.30930693499977,
    40.34607031500127,
    40.21311906000119,
    40.08109060000061,
    39.843637146999754,
    39.90702540299935,
    39.990343748999294,
    40.11942453299889,
    40.04017498800022,
    40.002655801999936,
    40.120204208998985,
    40.07463195899982,
    40.273290597000596,
    40.15914105000047,
    40.262771211000654,
    40.255157764000614,
    40.22522735699931,
    40.18163622400061,
    40.157079286000226,
    40.15124653000021,
    40.26897466199989,
    40.131969198999286,
    40.08497972499936,
    40.20574473899978,
    40.449310144000265,
    40.426070681000056,
    40.390903853000054,
    40.476805033000346,
    40.68007058600051,
    40.638284530999954,
    40.75593729299908,
    40.68862969300062,
    40.670742319000055,
    40.56747965300019,
    40.54455827400125,
    40.66311858900008,
    40.458747396000035,
    40.718798908999815,
    0.0,
    41.07978310500039,
    40.99716692399852,
    40.94130868600041,
    40.81306320499971,
    40.88724270199964,
    40.88462435099973,
    40.87329585400039,
    40.84504357500009,
    40.72402914200029,
    40.827020663999065,
    40.9370169470003,
    41.03497546200015,
    40.978702893000445,
    40.95455850700091,
    41.09285226399879,
    0.0,
    41.59820514600142,
    0.0,
    41.9620420579995,
    42.074852011000985,
    42.09511424899938,
    0.0,
    42.43713481300074,
    42.46484348299964,
    42.68181236300006,
    42.803345651998825,
    42.758185955000954,
    42.67696084199997,
    42.608879436998905,
    42.73107302400058,
    42.71301323999978,
    42.77967923700089,
    42.77194706799855,
    42.734747466000044,
    42.693626948999736,
    42.6779839439987,
    42.79777080599888,
    42.64099743099905,
    0.0,
    43.13846747199932,
    43.135869461000766,
    43.10635080999964,
    43.185180190999745,
    43.144699321999724,
    43.07297973200002,
    43.03710139299983,
    43.02981211900078,
    43.004881165999905,
    43.11216065999906,
    43.08876322300057,
    43.06935427600001,
    42.94898770800137,
    42.87419826199948,
    42.83691861900115,
    42.86171252399981,
    42.84853300899886,
    42.81550341900038,
    42.643326866998905,
    42.831580382999164,
    43.079338977999214,
    43.02147802199943,
    42.92619343000115,
    43.038616203000856,
    43.030770157000006,
    43.02611158199943,
    43.21788469199964,
    43.20684180900025,
    43.323001171000215,
    43.43312968399914,
    43.35377093900024,
    43.490859532001195,
    43.49071183200067,
    43.59376130800047,
    43.5880202139997,
    43.580304713999794,
    43.51740351999979,
    43.7904732879997,
    43.68986761999986,
    43.61262017599984,
    43.41442185500091,
    43.39334155999859,
    43.34061503900011,
    43.15929382200011,
    43.220471404998534,
    43.16134692699961,
    43.07444017099988,
    43.01819502699982,
    43.05379764999998,
    43.025827859000856,
    43.001161875001344,
    43.08227210900077,
    42.98861346600097,
    42.97945261700079,
    43.039764195000316,
    43.13590022199969,
    43.246538435998445,
    43.22570616300072,
    42.79445516600026,
    42.68387142600113,
    42.57187261800027,
    42.53269296899998,
    42.49126452999917,
    42.61243084899979,
    42.56373522300055,
    42.39732198399906,
    42.5030193019993,
    42.48917494000125,
    42.34672436400069,
    42.460051510000994,
    42.62588053200125,
    42.595070269000644,
    42.571504688999994,
    42.530076684999585,
    42.60631207999904,
    42.603287351999825,
    42.579094822000116,
    42.51341875399885,
    42.59873395700015,
    42.50550417700106,
    42.47184883099908,
    42.38858841799993,
    42.50131055399834,
    42.43066369799999,
    42.36579616100062,
    42.30970040799912,
    42.55366964099994,
    42.610849790999055,
    42.56585453200023,
    42.55112207699858,
    42.65441990599902,
    42.78878445800001,
    42.992190217000825,
    42.93531436500052,
    42.89962490899961,
    42.98977527399984,
    42.93974306900054,
    43.15577543799918,
    43.12387629099976,
    43.080849144998865,
    43.098738120001144,
    43.050433727999916,
    43.12114675399971,
    43.025349223000376,
    43.0061719080004,
    43.07464274599988,
    43.02613308800028,
    42.981999220000944,
    42.950032407001345,
    42.71536604500034,
    42.966190036000626,
    42.970559554998545,
    42.94622202900064,
    42.91969721199894,
    42.89696812500006,
    42.83782531399993,
    43.03701648599963,
    43.10062392399959,
    43.06676365000021,
    42.89624307400118,
    42.97894597800041,
    42.93760036000094,
    42.83169577499939,
    43.24866440999904,
    43.24049130200001,
    43.23521730700122,
    43.17474179199962,
    43.07930754900008,
    43.0486155210001,
    43.13669879599911,
    42.98817695700018,
    43.22385245999976,
    43.192682375000004,
    43.054505641001015,
    43.173297827999704,
    43.00248520999958,
    43.10426223899958,
    43.050139827999374,
    42.96736518999933,
    42.947230936999404,
    42.90899465700022,
    42.85808091599938,
    42.962501668000186,
    42.820754959000624,
    42.75400742700003,
    42.87514077800006,
    42.834319120000146,
    42.766324279999026,
    42.74467910799831,
    42.857561119999446,
    42.79761023800165,
    42.69281344599949,
    42.668665887000316,
    42.64491332000034,
    42.68268318599985,
    42.91355626999939,
    42.80462927899862,
    42.77997860400137,
    42.7538719639997,
    42.760586364998744,
    42.72810595400006,
    42.705453783999474,
    42.822986977000255,
    42.786037370000486,
    42.76849027000026,
    42.72525831200073,
    42.977412293999805,
    42.79168812199896,
    42.94661808000092,
    42.98116493899943,
    42.85198057600064,
    42.685865147001095,
    42.66861899700052,
    42.629569514998366,
    42.504459731999304,
    42.61031619200003,
    42.52899342099954,
    42.51878285299972,
    42.61991470999965,
    42.584879140998964,
    42.53846782899927,
    42.452199569001095,
    42.40220427799977,
    42.36252275100014,
    42.46246278200124,
    42.561305851000725,
    42.65698939900176,
    42.649497201000486,
    42.75043283699961,
    42.72471889899862,
    42.179140367999935,
    42.23680031600088,
    42.21128926499841,
    42.173811971999385,
    42.107977248999305,
    41.99982164799985,
    41.87379049499941,
    41.94244389400046,
    41.88787804899948,
    41.82390867600043,
    41.38845644799949,
    41.292708349999884,
    41.42015570999865,
    41.49615844300024,
    41.72102394299873,
    41.68275040899971,
    41.67854427199927,
    0.0,
    42.03846613299902,
    42.01620044400079,
    42.03235807099918,
    41.963930353998876,
    41.95325348199913,
    42.03295197300031,
    41.893976108998686,
    42.147011166000084,
    41.98988234799981,
    41.805014447998474,
    0.0,
    42.44212087500091,
    42.327084683000066,
    42.4956205590006,
    42.49252631099989,
    42.45282769900041,
    42.443734668000616,
    42.55970901099863,
    42.63624064999931,
    42.630539579999095,
    42.59890611599985,
    42.7122662769998,
    42.838031299999784,
    42.80053095599942,
    42.90777854699991,
    42.74864393700045,
    42.62864662300126,
    42.59822663600062,
    42.572371152000414,
    42.57093402399914,
    42.53895958800058,
    42.51181918200018,
    42.42634707999969,
    42.4956550220013,
    42.489329635000104,
    42.6094073029999,
    42.526756854998894,
    42.645473616001254,
    42.64337978799995,
    42.89338049899925,
    0.0,
    43.72420378100105,
    43.969788492999214,
    44.0783812009995,
    44.17577730500125,
    44.3030000990002,
    44.56317158899947,
    44.55775467000058,
    44.44512275499983,
    44.400823466001384,
    44.380130808000104,
    44.46805863500049,
    44.46298188699984,
    44.355660851999346,
    44.27614517500115,
    44.26649580599951,
    44.20343583200156,
    44.19911714999944,
    44.2909011390002,
    44.12955206100014,
    44.11199287199997,
    44.097609972999635,
    44.228797746000055,
    44.167835157999434,
    44.15280470499965,
    44.12533786699896,
    44.21887473500101,
    44.21107515699987,
    44.26934537799934,
    44.36115293999865,
    44.30266340799972,
    44.24850891499955,
    44.24406976799946,
    44.15889127400078,
    44.211686884998926,
    44.19393656700049,
    44.1831302999999,
    44.17533182099942,
    44.21023532900108,
    44.302315007998914,
    44.42133266899873,
    44.51866475599854,
    44.495885594000356,
    44.46932271600053,
    44.35630658500122,
    44.32339336299992,
    44.44421470499947,
    44.30629350599884,
    44.190414177001,
    44.09346301400001,
    44.27253409199875,
    44.53156046500044,
    44.50041296300151,
    44.58450315599839,
    44.50950274200113,
    44.484504207999635,
    44.184061701000246,
    44.07891213900075,
    44.071728804001395,
    44.010543259999395,
    43.965838191999865,
    43.88813455300078,
    43.777154544999576,
    43.62221156399937,
    43.683245980999345,
    43.67851839099967,
    0.0,
    44.153330769000604,
    44.24941926300016,
    44.050963571000466,
    43.97831971499909,
    43.97557484700155,
    43.944155117000264,
    43.866111102001014,
    43.81289283499973,
    43.93515974699949,
    44.012899858998935,
    44.00800736900055,
    43.91912279600001,
    43.897850129998915,
    43.7846516059999,
    43.714367229000345,
    43.82519170600062,
    43.78430995099916,
    43.92141406799965,
    43.917978753999705,
    43.936150546000135,
    43.87707626700103,
    43.81527644600101,
    43.933564539000145,
    43.863318630999856,
    43.85942504599916,
    43.84598308599925,
    43.88310747200012,
    43.81354121299955,
    44.034260583001014,
    43.972281735999786,
    43.86895682700015,
    43.77421935299935,
    43.62459895699976,
    43.61388217900094,
    43.456334147000234,
    43.45474290899983,
    43.57278105899968,
    43.84360765100064,
    43.739610174998234,
    0.0,
    44.49155605699889,
    44.41022967700155,
    44.655439075000686,
    44.65290828700017,
    44.68611624799996,
    44.776145509000344,
    44.7520573949987,
    44.68067274799978,
    44.56907167499958,
    0.0,
    44.922665907999544,
    44.81734316999973,
    44.79909728400162,
    44.41946339400056,
    44.534981167000296,
    44.523026999999274,
    44.29440051799975,
    44.28554301299846,
    44.209273147000204,
    44.08522452899888,
    44.17163613900084,
    44.16076549200079,
    44.155439688000115,
    44.135280403999786,
    44.237395455000296,
    44.19643692000136,
    44.135995520000506,
    44.09984592100045,
    44.19585909000125,
    44.250478240999655,
    44.110639397998966,
    44.2291750910008,
    44.22775725700012,
    44.307001416000276,
    44.277877918999366,
    44.13720670300063,
    44.25194746900161,
    44.22643723299916,
    44.13436926099894,
    44.12197575800019,
    44.03678595200108,
    44.284094863000064,
    44.17444463500033,
    44.33395585700055,
    44.47724807399936,
    44.43475923799997,
    44.36125344900029,
    44.45174283800043,
    44.39296676499907,
    44.636116736000986,
    44.59791263700026,
    44.69700449599986,
    44.58242264799992,
    44.68064214600054,
    44.57170530999974,
    44.53068265300135,
    44.44782041200051,
    44.42499810299887,
    44.46137074999933,
    44.507745345999865,
    44.471974120000596,
    44.32974554700013,
    44.58516221999889,
    44.50123747100042,
    44.61467958799949,
    44.51738136199856,
    44.42959415899895,
    44.247959886999524,
    44.2808422629987,
    44.21940159299993,
    44.30030419000104,
    44.29673403099878,
    44.261162111000885,
    44.21977090799919,
    44.14038883699868,
    44.122911698999815,
    44.056329806000576,
    44.18057946299996,
    44.15212244199938,
    44.41176479299975,
    44.49609201800013,
    44.4388458680005,
    44.296804458001134,
    44.10100674499881,
    44.36609478900027,
    44.27543265900022,
    44.39420563299973,
    44.39067390599848,
    44.28660479399878,
    44.45157230099903,
    44.371838188000766,
    44.49612834300024,
    44.30365647299914,
    44.29767994900067,
    44.29234450900003,
    44.25292360200001,
    44.01054045199999,
    43.97950703599963,
    43.79703449199951,
    43.756134254001154,
    44.01829507200091,
    44.2402524980007,
    44.204876113000864,
    44.17288194299908,
    44.265013184000054,
    44.21245189699948,
    43.96257545200024,
    44.11471123499905,
    44.07074837899927,
    44.0184755930004,
    43.89339416000075,
    0.0,
    44.36422339099954,
    44.4753134929997,
    44.266907753999476,
    44.39341324799898,
    44.31124901600015,
    44.3059332440007,
    44.27693636299955,
    44.16505826899993,
    44.409074682998835,
    44.64625975900162,
    44.732231533998856,
    44.818670533999466,
    44.90032005399917,
    44.7785673620001,
    44.71401264999986,
    44.612963456000216,
    44.53735441999925,
    44.51894344399989,
    44.66567209999994,
    44.592858041998625,
    44.800806188000934,
    44.73085303799962,
    44.65976099300133,
    44.65616280999893,
    44.48608680799953,
    44.48120932100028,
    44.60174620599901,
    44.55459489600071,
    44.57093150900073,
    44.548751577000075,
    44.4927156699996,
    44.54788442499921,
    44.52454915400085,
    44.4747349950012,
    44.44037837400174,
    44.379572963998726,
    44.265173073999904,
    44.44827176400031,
    44.296418537000136,
    44.27209283100092,
    44.10310870499961,
    44.00539392599967,
    44.11583851599971,
    44.09289394600091,
    44.04714614899967,
    44.134272063000026,
    44.10885445199892,
    44.09881574300016,
    44.22262213000067,
    44.12461152099968,
    44.23798905399963,
    44.33871442599957,
    44.466096666999874,
    44.461199880001004,
    44.299613525001405,
    44.22009493100086,
    0.0,
    44.34989746899919,
    44.329647701000795,
    44.158141586000056,
    44.1430999990007,
    44.056972334999955,
    44.05969775499943,
    44.015763211000376,
    43.91949204299999,
    43.91762225400089,
    43.91253749699899,
    0.0,
    43.82874662299946,
    44.74426003000008,
    44.71102441800031,
    44.7869593989999,
    44.88435529799972,
    44.80466857200008,
    44.99033235800016,
    0.0,
    45.32101397200131,
    45.40180374500051,
    45.3510096659993,
    45.593479742001364,
    45.6142444649995,
    45.554831613000715,
    45.380829077999806,
    45.47457009699974,
    45.45670697099922,
    45.46643798699915,
    45.42880272200091,
    45.262842501000705,
    45.2267344690008,
    45.20687094400091,
    45.18418527799986,
    45.303427359000125,
    45.2825631300002,
    45.26997508000022,
    45.16596011100046,
    45.02194902500014,
    44.97443958999975,
    45.193705215999216,
    45.176939906999905,
    45.153544297001645,
    45.1487592630001,
    44.89718581099987,
    44.95396471299864,
    44.902879105000466,
    44.88547310799913,
    0.0,
    45.1359047370006,
    45.132897520999904,
    45.070304181999745,
    45.178023496000606,
    45.126994182001,
    45.08106455300003,
    45.442164170999604,
    45.33275214999958,
    45.1278906360003,
    45.217415537001216,
    45.19712977200106,
    45.29025711600116,
    45.2645265200008,
    45.32995033400039,
    45.55836662100046,
    45.54594008500135,
    45.521081992999825,
    45.76434627500021,
    45.654630384000484,
    45.578093637001075,
    45.51851993799937,
    45.4519213450003,
    45.44015097499869,
    45.70192072699865,
    45.78424489200006,
    45.77125037599944,
    45.71566782500122,
    45.82156196299911,
    45.78141805499945,
    45.68103310100014,
    45.714609052000014,
    45.66582717200072,
    45.62978376799947,
    45.876799419000236,
    45.90654047299904,
    45.785356488000616,
    45.756919583000126,
    45.978027241000746,
    46.062693541000044,
    46.04131207300088,
    46.00734521399863,
    46.119544245000725,
    46.109452001001046,
    46.087647409000056,
    45.98813352599973,
    45.96313337299944,
    46.07451449799919,
    46.04549205100011,
    46.01232763999906,
    46.002069108000796,
    46.11757254800068,
    0.0,
    46.67915136599913,
    46.65179338799862,
    46.61762309400001,
    46.72564678599883,
    46.85093761999997,
    46.74158814600014,
    46.69301641200036,
    46.764046453001356,
    46.69189134500084,
    46.74334902999908,
    46.922510758999124,
    47.01474049299941,
    47.00094872199952,
    47.26714954199997,
    47.21546974700141,
    47.43433925000136,
    47.43221005000123,
    47.68598711999948,
    47.675044007000906,
    47.64972480200049,
    47.59749847300009,
    47.43621428699953,
    47.40129581600013,
    47.65563264699995,
    47.596959083999536,
    47.6365932159988,
    47.57691500799956,
    47.52264550200016,
    47.510189631000685,
    47.77963829100008,
    47.93418829899929,
    47.93281329899946,
    47.92378745299902,
    47.907763764000265,
    47.77023064799869,
    47.55491029899895,
    47.526587902000756,
    47.523659976999625,
    47.60943067500011,
    47.58538417700038,
    47.53582720200029,
    47.52849404299923,
    47.346134082999924,
    47.24707056200168,
    47.214728427999944,
    47.212170856999364,
    47.2118174419993,
    47.20908346500073,
    47.24116867799967,
    47.1735166769995,
    47.1193002050004,
    47.11046275899935,
    47.246256659998835,
    47.23377493299995,
    47.330760699000166,
    47.32199120699988,
    47.27720135399977,
    47.342212858000494,
    47.30550877600035,
    47.190096639998956,
    47.222091818999615,
    47.18737742600024,
    47.46704173599937,
    47.58501527000044,
    47.528604044999156,
    47.634878643000775,
    47.82398939799896,
    0.0,
    48.15787088399884,
    48.222182810999584,
    48.22061838399895,
    48.30605132999881,
    48.265588664999086,
    48.26221773499856,
    48.163093974999356,
    48.01936057199964,
    48.28614887600088,
    48.415997395000886,
    48.41205307400014,
    48.53329804399982,
    48.476239372001146,
    48.48603817499861,
    48.57265698000083,
    48.52559645399924,
    48.64846081900032,
    48.55355478799902,
    48.63050350599951,
    48.689292828999896,
    48.65996134299894,
    48.37267318100021,
    48.36584734899952,
    48.206366230999265,
    48.18386181999995,
    48.29821266499857,
    48.40639736400044,
    48.27295944100115,
    48.22871283200038,
    48.20464387900029,
    48.14047545500034,
    48.25208962299985,
    48.14531550600077,
    48.142906455999764,
    48.06869590900169,
    48.17596913499983,
    48.14495962199908,
    47.94909165200079,
    0.0,
    48.20635708200098,
    48.18517024200082,
    48.41752520200134,
    48.41125797300083,
    48.48230062100083,
    48.422975020001104,
    48.519735040999876,
    48.55998422999983,
    48.52247885699944,
    48.521186152000155,
    48.42398755800059,
    48.40504128400062,
    48.36878407600125,
    48.33117378099996,
    48.32714350899914,
    48.29864103299951,
    48.29239135900025,
    48.27171555099994,
    48.298663280000255,
    48.26366865499949,
    48.255962176999674,
    48.186957763000464,
    48.155128536998745,
    48.152112930998555,
    48.122218489999796,
    48.10033782000028,
    48.055642732000706,
    48.12954707300014,
    0.0,
    48.357986228998925,
    48.464064489999146,
    48.4543420580012,
    48.41350052300004,
    48.459983082999315,
    48.31056282899954,
    48.299467004999315,
    48.28188654299993,
    48.375072898001235,
    48.35000115399998,
    48.3354734429995,
    48.3189173869996,
    48.252778608999506,
    48.293924610999966,
    48.42308324299847,
    48.33769304699854,
    48.52056280099896,
    48.56762325500131,
    48.50998853700003,
    48.59817206799926,
    48.6534324889999,
    48.64604402400073,
    48.59998418500072,
    48.65128069599996,
    48.552105587999904,
    48.688469443999566,
    48.60131494399866,
    48.71579584100073,
    48.714487131999704,
    48.77479171699997,
    48.76873685699866,
    48.88761074499962,
    48.9878152780002,
    48.98045567000008,
    48.932647255998745,
    48.910358831999474,
    48.85863697900095,
    48.98864291300015,
    49.171454082999844,
    49.17073127100048,
    49.15343835099884,
    49.145288211999286,
    49.25324309700045,
    49.50559255199914,
    49.36417284900017,
    49.6277315719999,
    49.53344477399878,
    49.51995571500083,
    49.432828019000226,
    49.47717671600003,
    49.46013041100014,
    0.0,
    49.81313822099946,
    49.939381583000795,
    49.93805612600045,
    50.20292659700135,
    50.538067601000876,
    50.5130829589998,
    50.49466644400127,
    50.47837965299914,
    50.44153617700067,
    50.34111865400155,
    50.45413800800088,
    50.55367057600051,
    50.525370834999194,
    50.603548982000575,
    50.48115234400029,
    50.596414816000106,
    50.548244976000205,
    50.480062807999275,
    50.475537730000724,
    50.47394006099967,
    50.44173696600046,
    50.310525180000695,
    50.28406710700074,
    50.256727390999,
    50.35136179199981,
    50.34221720499954,
    50.47078512200096,
    50.458502892999604,
    50.43434641500062,
    50.411803584000154,
    50.37575318600102,
    50.4837502270002,
    50.482726902999275,
    50.406973295999705,
    50.48657935099982,
    50.490013363998514,
    50.485436218999894,
    50.600518798999474,
    50.563658916998975,
    50.68122764899999,
    50.5960437929989,
    50.58090432800054,
    50.549852240999826,
    50.6072789610007,
    50.46292903500034,
    50.5910358229994,
    50.52635283999916,
    50.78272813200056,
    50.74895012199886,
    50.72330339099972,
    0.0,
    51.5721050989996,
    51.50199738799893,
    51.48940021800081,
    51.515946061999784,
    51.430391647998476,
    51.38339595399884,
    51.25928766499965,
    51.383702911,
    51.512286029999814,
    51.49132740099958,
    51.442555075998825,
    51.26428166699952,
    51.48774391400002,
    51.448618735999844,
    51.567780329000016,
    51.527490006001244,
    51.52069978399959,
    51.50380778900035,
    51.61649775499973,
    51.54710881900064,
    51.81497283899989,
    52.05793286900007,
    52.14661084100044,
    52.25892005600144,
    52.17894984200029,
    52.13466888400035,
    52.12254623800072,
    52.36541226099871,
    52.33002040700012,
    52.20298914900013,
    52.098894318998646,
    52.34593450099965,
    52.24626196600002,
    51.76326404499923,
    51.66086857099981,
    51.73646105900116,
    51.81294484400132,
    51.79419794000023,
    51.79459594599939,
    51.84155997800008,
    51.84022944199933,
    51.75348325700179,
    51.770264274999136,
    51.8367757470005,
    51.57713768299982,
    51.680954817000384,
    51.674313288998746,
    51.62576225799967,
    51.74655358599921,
    51.829907336999895,
    51.783082787998865,
    51.870041094000044,
    51.86671107999973,
    0.0,
    52.61832448399946,
    52.736517843999536,
    52.8640866679998,
    52.861424198999885,
    52.86116879899964,
    52.84810994899999,
    52.738489405999644,
    52.72565596000095,
    52.60978133400022,
    52.675422856000296,
    52.66896742099925,
    52.63709860199924,
    52.63579433900122,
    52.74488534000011,
    52.68833593399904,
    52.6245635159994,
    52.704535183998814,
    52.608871854001336,
    52.572849891999795,
    52.64941840100073,
    52.604528200999994,
    52.53622636699947,
    0.0,
    53.061932549999256,
    53.08922801299923,
    53.04333298399979,
    53.03492861199993,
    53.055395338999006,
    53.02896392299954,
    53.02735657300036,
    53.02327631600019,
    52.95953466500032,
    53.07052002400087,
    53.15694547500061,
    53.08202166599949,
    53.18573614399975,
    53.15274422699986,
    53.047586290000254,
    53.01313744300023,
    52.99472912000056,
    0.0,
    0.0,
    53.82861590899847,
    54.07119053399947,
    54.032132866999746,
    54.29419141300059,
    54.246132080999814,
    54.22940329700032,
    54.132577128000776,
    54.11115434199928,
    54.196865565001644,
    54.19414250800037,
    54.193267721000666,
    54.14468110100097,
    54.49281826300103,
    54.448057977000644,
    54.55112350499985,
    54.55029228500098,
    54.587702171000274,
    54.46376955699998,
    54.59824658999969,
    54.49832784499995,
    54.44898545099932,
    54.550051396001436,
    0.0,
    55.15580417300043,
    55.24859315499998,
    55.12151658000039,
    55.17360691799877,
    55.136372770999515,
    55.08043613500013,
    55.07450027699997,
    55.020159924000836,
    55.01701241200135,
    54.96500885700152,
    0.0,
    55.6208320780006,
    55.61353312199935,
    55.60323394400075,
    55.600343010999495,
    55.58541102400159,
    55.459920446999604,
    55.44291723099923,
    55.671687708998434,
    55.66720386700035,
    55.62509463200149,
    55.64756313900034,
    55.61522129500008,
    55.59049817400046,
    55.61235103299987,
    55.55793278400051,
    55.77512277700043,
    55.76610436899864,
    55.850566147999416,
    55.848493630999656,
    55.84803393600123,
    55.9316294729997,
    56.169298323000476,
    56.1235508080008,
    56.118095861000256,
    56.09051340299993,
    56.20703847100049,
    56.17235618599989,
    56.23062496000057,
    56.17812667100043,
    56.15707415199904,
    56.06442587799938,
    55.91968993699993,
    55.84046828300052,
    55.7722295270014,
    55.70023174900052,
    55.685662029000014,
    55.614566877999096,
    55.61154792999878,
    55.71681561500009,
    55.50440265799989,
    55.42884749999939,
    55.41320316299971,
    55.38307708100001,
    55.5830529520008,
    55.60598199299966,
    55.72352481300004,
    55.678274142999726,
    55.36263044000043,
    55.36057058900042,
    55.35387471500144,
    55.44292198900075,
    55.301304218999576,
    55.290983361001054,
    55.40183754499958,
    55.618302406999646,
    55.598100711998995,
    55.486908279999625,
    55.588825044998885,
    55.524049558000115,
    55.61736429099983,
    55.50624380100089,
    55.49444941699949,
    55.314621340001395,
    55.29295542900036,
    55.557141162000335,
    55.507314466000025,
    55.53590342999996,
    55.50551678699958,
    55.45314966600017,
    55.38765034300013,
    55.51025071799995,
    55.42479920099868,
    55.32785320500079,
    55.25916569199944,
    55.32523469099942,
    55.285878197000784,
    55.26574759400137,
    55.406551449999824,
    55.38996641000085,
    55.51461127000039,
    55.64367826399939,
    55.71550202800063,
    55.713665228000536,
    55.70322985100029,
    55.695839416001036,
    55.661301258000094,
    55.77975306100052,
    55.768128906998754,
    55.758198600999094,
    55.759306179001214,
    55.8019691770005,
    56.02217124100025,
    55.91862566800046,
    55.850606148000224,
    55.80376625600002,
    55.88237485600075,
    55.81987349500014,
    55.818653925000035,
    55.81276501299908,
    55.78838197499863,
    55.894826280000416,
    55.917776795000464,
    55.73473401699994,
    55.730962388999615,
    55.7702376899997,
    55.95361076699919,
    55.93864250400111,
    55.663278526000795,
    55.917662537998694,
    55.802431926998906,
    55.78563987399866,
    55.87548698399951,
    55.845539853000446,
    55.91758113099968,
    55.83350243800123,
    55.78872515200055,
    55.862746910999704,
    56.183140704000834,
    56.07873452700005,
    55.89033120299973,
    55.81488258100035,
    55.61382001699894,
    55.603107400000226,
    55.58767035500023,
    55.71928227799981,
    55.77347287200064,
    55.69796415400015,
    55.62045217099876,
    55.576625658999546,
    55.69212897699981,
    55.555910068998855,
    55.578853283999706,
    55.673462965,
    55.56201269899975,
    55.329372659998626,
    55.450539284000115,
    55.371061413999996,
    55.361887088,
    55.24959697200029,
    55.29233978500088,
    55.28657478799869,
    55.24876714200036,
    55.37617885600048,
    55.32850039600089,
    55.62112607000017,
    55.561596479999935,
    55.556870204000006,
    55.67432584800008,
    55.67285605000143,
    55.626245782001206,
    55.755744823001805,
    55.66507009400084,
    55.788257382000666,
    55.72375716500028,
    55.678353761000835,
    55.72399087799931,
    55.66784477299916,
    55.739420638999945,
    55.87713966100091,
    55.84970345699912,
    55.748650161000114,
    55.546733199998926,
    55.660951963000116,
    55.57249705200047,
    55.544899525999426,
    55.54029183300008,
    55.495172820001244,
    55.51254108900139,
    55.45101111000076,
    55.39347237099901,
    55.49935002099846,
    55.59033734699915,
    55.72208583900101,
    55.69394722300058,
    55.61581822699918,
    55.59004928700051,
    55.50188786900071,
    55.46603076400061,
    55.41291047099912,
    55.38993694400051,
    55.31744999500006,
    55.30066185400028,
    55.351911974999894,
    55.31585166599871,
    55.293295555999066,
    55.54326959100035,
    55.48928101599995,
    55.46508844300115,
    55.44570333699994,
    55.65026520799984,
    55.58524428900091,
    55.56461652699909,
    55.413167803999386,
    55.45408682000016,
    55.453417864000585,
    55.416980363999755,
    55.18983678699988,
    55.09374532000038,
    55.217466367999805,
    55.2116584589985,
    55.06987598399974,
    55.10094594899965,
    54.97812194299877,
    55.09880836100092,
    55.227973276998455,
    55.218212873000084,
    55.15171723600179,
    55.15095831200051,
    55.24706124600016,
    0.0,
    56.18652909500088,
    56.17040268800156,
    56.16251438799918,
    56.08504474500114,
    56.253160848000334,
    56.31426436299989,
    56.202181970998936,
    56.16796829800114,
    56.09308059599971,
    56.16372705100002,
    56.08131346400114,
    56.00246244400114,
    56.1610565230003,
    56.139638324999396,
    56.22497189400019,
    56.35454238300008,
    56.331698878999305,
    56.286037898998984,
    56.392158297001515,
    56.52586481000071,
    56.31089948999943,
    56.58448665799915,
    56.55936381100037,
    56.55225319700003,
    56.7837965639992,
    56.77812873699986,
    56.75249284899837,
    56.6662544310002,
    56.64367251499971,
    56.57228654600112,
    56.496259677000126,
    56.63147563599887,
    56.72703411800103,
    56.702903170000354,
    56.81745807699917,
    56.80945350100046,
    56.76970030400116,
    56.65993427399917,
    56.59161099300036,
    56.68094176200066,
    56.60812863300089,
    56.53544862700073,
    56.48168379600065,
    56.59048939099921,
    56.571366029000274,
    56.56574054199882,
    56.778862719000244,
    56.67301644500003,
    56.65701666700079,
    56.6483087659999,
    56.6310821140014,
    56.75084401700042,
    56.72075791700081,
    56.696427273000154,
    56.79909650300033,
    56.767288909000854,
    56.629632721000235,
    56.32797624500017,
    56.269180855999366,
    56.308042427001055,
    56.439275163000275,
    56.46663802999865,
    56.44949766300124,
    56.425760391999574,
    56.45411912899908,
    56.450757726999655,
    56.38961138600098,
    56.3670782470017,
    56.481513348999215,
    56.45915102800063,
    56.441891571999804,
    56.412728720000814,
    56.35924451500068,
    56.42434201600008,
    56.41774401300063,
    56.45686279899928,
    56.41810725399955,
    56.406035128999065,
    56.489381912999306,
    56.43786679599907,
    56.37091535599939,
    56.310140710998894,
    56.54695125000035,
    56.52870391800025,
    56.50809683800071,
    56.499682662999476,
    56.49274045099992,
    56.51734216300065,
    56.47346923900113,
    56.45824998399985,
    56.50075685899901,
    56.49548055000014,
    56.427584532000765,
    56.56452991400147,
    56.723503044999234,
    56.81558327099992,
    56.74567620699963,
    56.67419681299907,
    56.43514221700025,
    56.425510602999566,
    56.38645817500037,
    56.5768269880009,
    56.691891331998704,
    56.51355694799895,
    56.505004667998946,
    56.34219782800028,
    56.29647483100052,
    56.37771646800138,
    56.21513837099883,
    56.21387708200018,
    56.18244647599931,
    56.30581030599933,
    56.48792639000021,
    56.47437271099989,
    56.44281854399924,
    56.577361797000776,
    56.67806636299974,
    56.66492198999913,
    56.43446365100135,
    56.53709219300072,
    56.53294950000054,
    56.52261629900022,
    56.6654843719989,
    56.732789970999875,
    56.696571943999515,
    56.79229941500125,
    57.05188742199971,
    57.02012583400028,
    56.97018910299994,
    0.0,
    57.87282967699866,
    57.96861963599986,
    57.923038476999864,
    58.02146377899953,
    58.105965827000546,
    58.25393136499952,
    58.160511598000085,
    58.5213031509993,
    58.36231606799993,
    58.48885035700005,
    58.24179893300061,
    58.19496091399924,
    58.18403788000069,
    58.13209560900032,
    58.03208915799951,
    57.96499271399989,
    57.9064405479985,
    57.90336615399974,
    57.99512134100041,
    58.090767649000554,
    58.21450207599992,
    58.497173690000636,
    58.4940324399995,
    58.40635030900012,
    58.60876983399976,
    58.57575072899999,
    58.6634559260001,
    58.620407655000236,
    58.605339695999646,
    58.87780584099892,
    58.98286828699929,
    58.98188737000055,
    58.93959127800008,
    58.85634845899949,
    58.78637774299932,
    58.78493032299957,
    58.657245259000774,
    58.592145582999365,
    58.71693549000156,
    58.70530745799988,
    58.63360581099914,
    58.730077197000355,
    58.70929094499843,
    58.87864362900109,
    58.92421216299954,
    59.01895522700033,
    58.92554787100016,
    58.92410993500016,
    59.095633966000605,
    59.182536440999684,
    59.17969546299901,
    0.0,
    59.66750322700136,
    59.413229076999414,
    59.52711993199955,
    59.55131528899983,
    0.0,
    60.14039043699995,
    60.11888129199906,
    60.10504542200033,
    60.319442390000404,
    60.315223135999986,
    60.58427253799891,
    60.55225574399992,
    60.658318492000035,
    60.6368403230008,
    60.872701735999726,
    60.594286880001164,
    60.77752000300097,
    60.851092326998696,
    60.97627228499914,
    61.154289282998434,
    61.06504089400005,
    61.02897372600091,
    61.140266054000676,
    61.12720491099935,
    61.1076076850004,
    61.07240210800046,
    61.246297802999834,
    61.24426832300014,
    60.97994677799943,
    61.08649805099958,
    60.99674809499993,
    60.970554135001294,
    60.90370570899904,
    61.16962794799838,
    61.13571705300092,
    61.01112644800014,
    61.00266987299983,
    61.075271757001246,
    60.9894227929999,
    61.19187975800014,
    60.863862738000535,
    60.82865980599854,
    60.758260444999905,
    60.71223226100119,
    60.477463894998436,
    60.47638497799926,
    60.54911087099936,
    60.47819099300068,
    60.678986394001186,
    60.40208794400132,
    60.62988491999931,
    60.60918303100152,
    60.481207210999855,
    60.44936076999875,
    60.43635618400003,
    60.38304620700001,
    60.34290259200134,
    60.29302792599992,
    60.196533055001055,
    60.45477294000011,
    60.414438421999876,
    60.353644083999825,
    60.32715289999942,
    60.43674589400143,
    60.39341700700061,
    60.3535251609992,
    60.62803444000019,
    60.7473177740012,
    0.0,
    60.98480264799946,
    60.94904447399858,
    60.89933853399998,
    60.878849504000755,
    60.874890799999775,
    60.98448847799955,
    61.114022694000596,
    61.15052155400008,
    61.11360995399991,
    61.268922483001006,
    61.13706977400034,
    61.128362961000676,
    0.0,
    61.81220578200009,
    61.760919422998995,
    62.00919683400025,
    62.00183488000039,
    61.982049494999956,
    0.0,
    62.46081015599884,
    0.0,
    62.819603156000085,
    62.796728090001125,
    62.77647910400083,
    62.76494382000055,
    62.72981512299884,
    62.97345062599925,
    62.82770130800054,
    63.00061220099997,
    62.978355734001525,
    62.89684708999994,
    62.86598379000134,
    62.8101160719998,
    62.87320407200059,
    62.80688953000026,
    62.92949202699856,
    63.027424321999206,
    62.96431680299975,
    62.95003185299902,
    62.946024253998985,
    62.915684502999284,
    62.90864229499857,
    63.01459959599924,
    62.91469143900031,
    62.90276951699889,
    63.07216703300037,
    63.07131720400139,
    62.85327208200033,
    62.96853208399989,
    62.87335706699923,
    62.691776994000975,
    62.623355517000164,
    62.738915718999124,
    62.98835636900003,
    62.98520785499932,
    62.87807205399986,
    62.9338018920007,
    63.19591033999859,
    63.4697806510012,
    63.43705088999923,
    63.32308531400122,
    63.240031900999384,
    63.36671717700119,
    63.464063285999146,
    63.42176095499963,
    63.37237015299979,
    63.42566958499992,
    63.37908636099928,
    63.36103713600096,
    63.46811109199916,
    63.48800032300096,
    63.618430680999154,
    63.677723023,
    63.64060829999835,
    63.89256671200019,
    63.83348324700091,
    63.93464790899998,
    63.988009492000856,
    63.984723613000824,
    63.98031219299992,
    64.10214104199986,
    64.06306274900089,
    64.04113980400143,
    64.00593006300005,
    64.12051066099957,
    63.96923765000065,
    63.925606111999514,
    64.03758359200037,
    64.12503185300011,
    64.1566589719987,
    64.15026142100032,
    64.12935080200077,
    64.01394920599887,
    63.94897674399908,
    63.91548768699977,
    63.96772124800009,
    63.89346473200021,
    64.16033607099962,
    64.15359965600146,
    64.07785330600018,
    64.01834183599931,
    63.88497934299994,
    63.819757092000145,
    63.905165672000294,
    64.01333379700009,
    63.98516417300016,
    63.975640848000694,
    64.01283546400009,
    64.01101243599987,
    64.35694008499922,
    64.3162006019993,
    64.15038339600142,
    63.97483175900015,
    63.88401394600078,
    63.83085286700043,
    63.68418442499933,
    63.66670643700127,
    63.6403974950008,
    63.55865871700007,
    63.65140596099991,
    63.782048475999545,
    63.76667905400063,
    63.82106505699994,
    63.81129170299937,
    63.60734828499881,
    63.66958959400108,
    63.668852540000444,
    63.649258142999315,
    63.60219817400139,
    63.735943988000145,
    63.59417580199988,
    63.65341294499922,
    63.59018463100074,
    63.60989367300135,
    63.73943237399908,
    63.73234745099944,
    63.64661978600088,
    63.48779735100106,
    63.44536229699952,
    63.52941259799991,
    63.490769371999704,
    63.61404890399899,
    63.59100226100054,
    63.60543063099976,
    63.58404570699895,
    63.804791243999716,
    63.83672323399878,
    64.04248781899878,
    63.964193088000684,
    63.85073940800066,
    0.0,
    64.03021824200005,
    0.0,
    64.41751399500026,
    64.3970521329993,
    0.0,
    64.93239718599943,
    64.83706700499897,
    64.74453744499988,
    64.74384186399948,
    0.0,
    65.20727769399855,
    65.1508092439999,
    64.90399283099941,
    64.91218914100136,
    64.90310799799954,
    64.87973097599934,
    64.82041773700075,
    64.78232084299998,
    64.74148713400064,
    64.97831855000004,
    64.90467926499878,
    65.15408628600017,
    65.23067805400024,
    65.19587050399969,
    65.1873808629989,
    65.25238862700098,
    65.1869299910013,
    65.16175560699958,
    65.14554971300095,
    65.13861367200116,
    65.06415555899912,
    65.02707855600056,
    65.1051621459992,
    65.04787738099913,
    65.21530238899868,
    65.16734405699935,
    65.06175993800025,
    65.0584505579991,
    65.0392351570008,
    65.13331662699966,
    65.12671705799949,
    65.24382807000075,
    65.03347261199997,
    64.96544851500039,
    65.06249432199911,
    65.01693881000028,
    65.13457112000106,
    65.23307374999968,
    65.21069466799963,
    65.24524145600117,
    65.22028509399934,
    65.18947866100098,
    65.1566122510012,
    65.28439432599953,
    65.05455560600058,
    65.16863671400097,
    65.15631587799908,
    64.97628964599971,
    65.05929652099985,
    64.97241893400133,
    65.09557787599988,
    65.08319762899919,
    65.32214198399924,
    65.45642690299974,
    65.3588524780007,
    65.33192916399821,
    65.29144920499857,
    65.13359285899969,
    65.23345214300025,
    65.08333805799884,
    65.00646872400102,
    0.0,
    65.32629538299989,
    65.32177589999992,
    65.44125454300047,
    65.38985964600033,
    65.51097051299985,
    65.3473602110007,
    65.53379635799865,
    65.6543882320002,
    65.52482237000004,
    65.6106649100002,
    65.737820508999,
    65.72653156900014,
    65.59007149799982,
    65.48915882100118,
    65.56298070999947,
    65.60565127500013,
    65.70312233299956,
    65.77277344600043,
    65.72747375200015,
    65.6692894150001,
    65.66125559800093,
    65.70875813899875,
    65.54902833900087,
    65.75067679699896,
    65.6704045259994,
    65.7317948130003,
    65.69411391300127,
    65.64565031799975,
    65.76170026799991,
    65.69247915199958,
    65.66345884699876,
    65.62918511099997,
    65.75652394000099,
    65.84086847300023,
    65.78991568399942,
    65.65857588200015,
    65.65767933100142,
    65.92413046900037,
    66.17033027099933,
    66.12353671499841,
    66.21188504200109,
    66.44160259399905,
    66.36138068100081,
    66.29576502500095,
    66.5085124849993,
    66.40417838199937,
    66.4304417129988,
    66.24444459799997,
    66.0625241960006,
    66.27227379299984,
    0.0,
    66.8276642439996,
    66.77010696700017,
    0.0,
    67.95975578300022,
    67.89403151700026,
    67.80121574899931,
    67.84679467000024,
    67.80968956800098,
    67.8876996479994,
    67.8785886429996,
    68.11485440799879,
    68.07142287300121,
    68.02994733100059,
    67.84604645800027,
    67.83692762200008,
    67.8149545239994,
    0.0,
    68.01968172600027,
    67.99164246400142,
    67.95802732500124,
    68.20024423900031,
    68.15441403899968,
    68.27385160099948,
    68.34404511600042,
    68.32323646499935,
    68.31395598900053,
    68.28775999699974,
    68.4126418349988,
    68.36094914299974,
    68.46492493999904,
    68.4577335899994,
    68.39639003800039,
    68.34904924700095,
    68.3473309710007,
    68.21062249500028,
    68.09834573599983,
    67.9693644070012,
    68.19028799800071,
    68.16395785799978,
    68.28895813200143,
    68.2020796880006,
    68.05101833499975,
    68.04579619400101,
    68.01773765299913,
    68.0375018270006,
    68.45339929799957,
    68.55289244800042,
    68.64360904499881,
    68.76316530999975,
    68.88576777300113,
    68.62583000400082,
    68.60881089199938,
    68.64251101400077,
    68.62601641800029,
    68.59982533999937,
    68.6609602690005,
    68.73270688500088,
    68.68133669099916,
    68.80695924300016,
    68.66266844399979,
    68.5973114619992,
    68.57785298599993,
    68.61340019300042,
    68.7365938790008,
    68.42278164699928,
    68.68294106299982,
    68.64882054699956,
    68.53274057400085,
    68.51509897100004,
    68.44909506499971,
    68.38365651499953,
    68.48674582000058,
    68.47452562299986,
    68.41094139699999,
    68.40272356499918,
    68.38540006499898,
    68.41166814700046,
    68.19646375900084,
    68.18584152499898,
    68.26980689000084,
    68.3978132760003,
    68.35494540299987,
    68.33153102100005,
    68.38816932000009,
    68.37150843699965,
    68.28012930099976,
    68.29001662799965,
    68.247113034,
    68.08574634999968,
    68.07650030100012,
    68.14779483199891,
    68.07921383299981,
    68.05857599199953,
    67.98056243500105,
    68.24466234700049,
    68.09545978699862,
    68.23201894600061,
    68.22834310899998,
    68.15265096200164,
    68.02150336100021,
    68.24344019599994,
    68.13679579600102,
    68.05264624600022,
    68.00064010999995,
    68.11713555299866,
    68.21917690400005,
    68.20961056499982,
    68.19792970299932,
    68.20813405199988,
    68.25089896999998,
    68.16596584000035,
    68.07756656399943,
    68.06875700800083,
    67.96593527799996,
    67.92202270399866,
    67.84219722600028,
    67.9056262260001,
    67.87952601699908,
    67.87547008699948,
    67.84265543699985,
    67.93139035899912,
    67.91584376599894,
    68.01499762300045,
    67.99505441400106,
    67.91748946600092,
    67.86557657400044,
    67.95720290800091,
    67.93217177900078,
    68.04200211500029,
    68.00337902200044,
    67.91738627199993,
    67.77833942799953,
    67.9044892740003,
    68.00570611400144,
    67.98389479700018,
    67.50466312099888,
    67.49936850199992,
    67.4919991029983,
    67.34771012300007,
    67.35073847899912,
    66.93571152100048,
    66.79703192000125,
    66.81501198300066,
    66.62066935199982,
    66.53148677599893,
    66.52340849400025,
    66.61053674200048,
    66.55658167000001,
    66.54622377399937,
    66.54139152399875,
    66.76557583200156,
    66.67189792300087,
    66.9108008330004,
    66.63692056900072,
    66.8434059049996,
    66.71451704799983,
    66.71272224099994,
    66.70448542299891,
    66.81251411700032,
    66.76185470100063,
    66.61349742200036,
    66.66789933499967,
    66.48934705299871,
    66.75814879899917,
    66.86329508500057,
    66.85733955499927,
    66.97864632900018,
    66.90875575099926,
    66.92583295499935,
    67.02830932500001,
    67.02853056200001,
    66.95722894100072,
    66.91426001299988,
    66.99259177699969,
    66.92118653999933,
    66.85542343099951,
    66.96099261000018,
    66.85755627300023,
    66.84021450799992,
    66.58917342600034,
    66.43332832899978,
    66.50245070999881,
    66.49859354799992,
    66.59406928499993,
    66.51493329300138,
    66.53880529200069,
    66.53579911799898,
    66.7950088409998,
    66.73063925899987,
    66.71737928000039,
    66.59917111499999,
    66.71824197499882,
    66.70930310100084,
    66.76696635799999,
    66.74098769100056,
    67.00686647300063,
    66.96588214300027,
    66.9334851879994,
    66.78763957000047,
    66.72219952100022,
    66.83934587600015,
    66.95200978499997,
    66.90470398100115,
    66.87123054699987,
    66.99593468399871,
    66.9901674949997,
    67.0469663290005,
    67.30097529400155,
    67.25249604599958,
    67.2442890880011,
    67.19842682299895,
    67.17088191000039,
    67.28813091800112,
    67.28508465699997,
    67.1904502920006,
    66.98159693900016,
    66.9519552310012,
    0.0,
    67.48073114100043,
    67.5316465699998,
    67.50133434199961,
    67.61176146199978,
    67.57880516299883,
    67.6932959170008,
    67.66704999400099,
    67.65046161300052,
    67.65677195899843,
    67.59770147000017,
    67.78840615700028,
    67.78290653099975,
    67.62941672800116,
    67.75279500000033,
    67.7170110169991,
    67.80627269100114,
    67.92349458900026,
    68.05501418099993,
    68.14998190400001,
    68.14298059500106,
    68.25918333499976,
    68.36738412400155,
    68.44982756100035,
    68.43615163100003,
    68.40792724200037,
    68.40212112500012,
    68.45292519500072,
    68.32474942800036,
    68.30662056799883,
    0.0,
    68.54832377899947,
    0.0,
    68.9651272379997,
    69.10931694499959,
    69.0938846229983,
    69.31215006400089,
    69.41535504300009,
    69.37288608899871,
    69.29941291099931,
    69.2166182410001,
    69.21803078499943,
    69.20628823399966,
    69.19919391499934,
    69.2401964290002,
    0.0,
    69.66369879999911,
    69.77170697200017,
    69.69013033800002,
    69.75927801599937,
    69.66119186200012,
    69.62264367500029,
    69.51322034900113,
    69.45353009099927,
    69.45232178900005,
    69.44048588999976,
    69.32961768700079,
    69.3329102179996,
    69.21190648099946,
    69.15823766199901,
    69.12871226199968,
    69.19561206399885,
    69.12918749900018,
    69.12412493100055,
    69.19045278699923,
    69.18552681300025,
    68.97474357099964,
    69.03881368899965,
    68.9617379930005,
    69.08039354100038,
    69.07222298799934,
    69.05379354800061,
    69.09490612600166,
    69.06900094699995,
    69.19113380199997,
    69.12335151999832,
    68.9620279130013,
    69.08288625299974,
    69.02217013600057,
    68.8908720569998,
    68.72764607400131,
    68.81948685300085,
    68.8033892200001,
    68.78186191900022,
    68.65938038599961,
    68.77298573900043,
    68.7435871939997,
    68.9661178339993,
    69.08430873700127,
    69.04875758299931,
    69.0224290469996,
    69.13626455600024,
    69.13465043500037,
    69.04470920399945,
    69.02366980700026,
    69.13958441100112,
    69.08523913099998,
    68.98180099799902,
    69.35779131100026,
    69.26197416499963,
    69.21286410200082,
    69.41233211700091,
    69.44388850399991,
    69.39816252399942,
    69.2999852390003,
    69.18942100299864,
    69.2939347270003,
    69.48916214000019,
    69.48028495499966,
    69.51222538500042,
    69.44385983999928,
    69.43608897000013,
    69.56534844599992,
    69.55529682300039,
    69.80645944999924,
    69.77293916999952,
    69.9726935280014,
    69.95169152200106,
    69.9298732240004,
    69.851158812,
    69.84849259899966,
    69.84119870900031,
    69.95768538199991,
    69.93391616100052,
    69.90575325499958,
    69.69165280200104,
    69.92385420199935,
    69.91095946200039,
    70.04111638699942,
    69.93606065699896,
    69.92423572199914,
    70.02617546199872,
    70.0222458850003,
    69.98001884899895,
    70.04592486699948,
    70.150725169,
    70.40912502199899,
    70.34118204200058,
    70.31682157999967,
    70.30346118600028,
    70.37031055400075,
    70.45236806799949,
    70.51230997300081,
    70.33446775499942,
    0.0,
    70.5679569189997,
    70.52945908100082,
    70.42609205000008,
    70.41927774200121,
    70.36808885000028,
    70.49532828700103,
    0.0,
    71.54229939200013,
    71.53596467199895,
    71.50453454099988,
    71.47830718200021,
    71.57807094300006,
    71.84412399200119,
    71.73077971299972,
    71.71977776199856,
    71.56013527899995,
    71.6787319670002,
    71.64972027399926,
    71.7964245710009,
    71.91022143100054,
    72.16197060100058,
    72.15521569599878,
    72.14854406000086,
    72.25854929600064,
    72.24016695700084,
    72.30426685699967,
    72.22855779600104,
    72.42363895299968,
    72.37661166699945,
    72.35067391600023,
    72.30679641399911,
    72.5641807209995,
    72.61308700399968,
    72.55942654699902,
    72.51735991900023,
    72.41228012400097,
    72.27090635700006,
    72.36798749300033,
    72.2975995680008,
    72.27129922199856,
    72.31044084600035,
    72.04193248199954,
    72.2677575380003,
    72.3916056729995,
    72.50433370700011,
    72.30931383200004,
    72.45250243900045,
    72.57843632800177,
    72.52877391200127,
    72.4696481129995,
    72.44187690299987,
    72.52444169000046,
    72.51479725900026,
    72.70810599299875,
    72.69672744000127,
    72.81150641299973,
    72.74921832200016,
    72.69339891500022,
    72.5147673320007,
    72.41238428700126,
    72.33176600600018,
    72.30377686199972,
    72.2907830840013,
    72.28934987199864,
    72.40093842900023,
    72.38997488399946,
    72.16878256999917,
    72.002128215001,
    72.1022955110002,
    72.06134152400045,
    72.14683948799939,
    72.08861758100102,
    72.32146597500105,
    72.03389238399905,
    72.13455012200029,
    72.11427406999974,
    72.30083949999971,
    72.1896668190002,
    72.29982709700016,
    72.42694085399853,
    72.49946595499932,
    72.44754894100151,
    72.3990868109995,
    72.3388942720012,
    72.33852090899927,
    72.44903734000036,
    72.21377467999991,
    72.19903443099975,
    72.05527930199969,
    72.06300531600027,
    72.28426972300076,
    72.25888672200017,
    72.34077587799948,
    72.18566583400025,
    72.2955145750002,
    72.28826735800067,
    72.13554066899997,
    72.37771242599956,
    72.12644358599937,
    72.0356043740012,
    72.06694736299869,
    72.03272430000106,
    71.92294107199996,
    72.03829238199978,
    72.14690893000079,
    72.01413112500086,
    72.00797943600082,
    72.13625500799935,
    72.38509958500072,
    72.35577092200037,
    72.43994657900112,
    72.40949849000026,
    72.40397270600079,
    72.37977293999938,
    72.10263888500049,
    72.09137837200069,
    72.03401638399919,
    72.06344007299958,
    71.8750029640014,
    71.94965192100062,
    72.06661493499996,
    72.06630522799969,
    71.94308992900005,
    71.93320641299943,
    71.8892303520006,
    71.88414040600037,
    71.98209500899975,
    71.9370104589998,
    72.05016514900126,
    72.0948975880001,
    72.1481213140014,
    72.1184155330011,
    72.11507610499939,
    72.17507027900137,
    72.14123826299874,
    0.0,
    72.81295848500122,
    72.7174938219996,
    72.6749413790003,
    72.61986668899954,
    72.61222395500045,
    72.56015758899957,
    72.6828723689996,
    72.67996703400058,
    72.74700325100093,
    72.71785476700097,
    72.71611922500051,
    72.63055515100132,
    72.61419412199939,
    72.60369264199835,
    72.71956557500016,
    72.41883998499907,
    72.22713313300119,
    72.33900631999859,
    72.28532378900127,
    72.20931443399968,
    72.20203176700124,
    72.25885050000034,
    72.52285320700139,
    72.48146641699896,
    72.36687056200026,
    72.11767395599963,
    71.91272240299986,
    72.20039767599883,
    72.10798958099986,
    0.0,
    72.91187993800122,
    72.89960101399993,
    73.04765974300062,
    72.85666833100004,
    72.82101373899968,
    72.97201999700155,
    72.885333446,
    72.7759308629993,
    72.8974217670002,
    73.13982751899857,
    73.10349619699991,
    73.20125126700077,
    73.19916921599906,
    73.18974999000056,
    73.23684219400093,
    73.19908206800028,
    73.1719720630008,
    73.13476594300118,
    73.2464174050001,
    73.11712902799991,
    73.10670428400044,
    73.12408614699962,
    73.09522106800068,
    73.07403000100021,
    72.9739554429998,
    72.87623688399981,
    72.95309487799932,
    72.83529443599946,
    72.95057809999889,
    73.06336239599841,
    73.03804841499914,
    72.99903375800022,
    72.95534355899872,
    72.99171506700077,
    72.9806163230005,
    72.92433194200021,
    73.03376693800055,
    73.16681651800172,
    72.83592375400076,
    72.9597793819994,
    72.89568387200052,
    72.86853391299883,
    72.83858661100021,
    72.93572269200013,
    72.89770873199996,
    73.09595529799844,
    73.1802102169986,
    73.14040370799921,
    73.60773979999976,
    73.67565065099916,
    73.62669169400033,
    73.73791072499989,
    73.85942391900062,
    73.79739684800006,
    73.87903068100059,
    73.84307795599852,
    73.79638201799935,
    73.77476041299997,
    73.76172045299973,
    73.98989383099979,
    73.95539371700033,
    73.95079138800065,
    74.0304279840002,
    74.02617914700022,
    73.985131206,
    73.99151539400009,
    73.7934879350014,
    73.9038536479984,
    73.89032156900066,
    73.88628690899895,
    74.00023951300136,
    74.00985673099967,
    73.98475030099871,
    74.21026335900024,
    74.18213606000063,
    74.25071738299994,
    74.59547689099963,
    74.58306097700006,
    74.84073247499873,
    74.81766330499886,
    74.80415055699996,
    74.77667058100087,
    74.88290653299919,
    75.00755813599972,
    74.94239039899912,
    74.93644192200009,
    75.1759925410006,
    0.0,
    75.6613145579995,
    75.74102596800003,
    75.69275315300001,
    75.8392961669997,
    75.81900722699902,
    76.02578686700144,
    75.9747580960011,
    75.88648765899961,
    75.92863995500011,
    75.86971767500108,
    75.81617398900016,
    75.8085663339989,
    75.91097717999946,
    75.87874130000091,
    75.85086019899973,
    75.73936468200009,
    75.71514553599991,
    75.8449379600006,
    75.99271625500114,
    75.78011043699917,
    75.84058220499901,
    75.79895628100167,
    76.04024274599942,
    75.96346878499935,
    76.2332329460005,
    76.01643339300063,
    75.9809799600007,
    76.06282886100053,
    76.06076664600005,
    75.95523690400114,
    75.98346723500072,
    75.97652400699917,
    75.9759442100003,
    75.9516024709992,
    75.86101459900055,
    75.81248351199974,
    75.77905556599944,
    75.89447432199995,
    76.11062162000053,
    76.06389218000004,
    76.0577493740002,
    76.18047437400128,
    76.17855986700124,
    76.34892371499882,
    76.3282551430002,
    76.32557422299942,
    76.27538645900131,
    76.20870431000003,
    76.16537831599999,
    76.00256412899944,
    76.13304355400032,
    76.10227019200101,
    76.08007700300004,
    75.98398687400004,
    75.93525855500047,
    75.81046249999963,
    75.8001717269999,
    76.15958377400057,
    76.14777946700087,
    76.02793584900064,
    75.99870395300059,
    76.11526201299966,
    76.07361815500008,
    75.95202786499976,
    75.854534099999,
    75.90177592299915,
    76.02587819899964,
    76.01923013400119,
    75.9641552739995,
    75.90828782200151,
    76.0272815240005,
    76.10588012799963,
    76.05261939200136,
    75.84467333700013,
    75.74800843500088,
    75.79131081500054,
    75.78931542399914,
    75.78168387200094,
    75.69623184600096,
    75.76982410399978,
    75.75575306700011,
    75.83815075500024,
    75.95832949099895,
    75.85737632200107,
    75.7863492689994,
    75.82707232400026,
    75.8160848940006,
    75.79029111099953,
    75.69488593499955,
    75.81475579800099,
    75.94879251900056,
    76.03362109699992,
    76.02778870399925,
    76.09325960599926,
    0.0,
    0.0,
    0.0,
    75.8337858850009,
    75.74513501100046,
    75.97326967200024,
    75.81079184400005,
    0.0,
    0.0,
    0.0,
    0.0,
    75.62218319400017,
    75.48420553600045,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    75.44123694100017,
    75.55535945400152,
    75.53482657600034,
    0.0,
    0.0,
    75.56379140200079,
    75.46792781300064,
    0.0,
    75.73658835699825,
    75.72918837500038,
    75.68412136400002,
    75.5607183079992,
    75.40244321099999,
    75.48652368900002,
    75.42977901400081,
    75.40680661199985,
    75.36260815300011,
    75.35903118499846,
    75.23374300900105,
    75.08407319300022,
    75.10699303100046,
    75.10676080400117,
    74.90446373399936,
    74.89612298199972,
    74.99950927699865,
    75.12079018899931,
    75.20454536299985,
    75.18999925999924,
    75.22721465699942,
    75.177924996,
    75.30068986200058,
    75.42758140700062,
    75.32685608700012,
    75.28087939200122,
    75.40289473399935,
    75.33233680299963,
    75.42190797299918,
    0.0,
    0.0,
    0.0,
    0.0,
    75.12531832000059,
    0.0,
    0.0,
    74.9022426470001,
    74.82096094799999,
    74.8683415129999,
    74.96510024700001,
    74.92203627299932,
    74.81902340700071,
    75.03530682500059,
    75.02094803100044,
    75.01665555900036,
    75.10181201500018,
    75.18491664400062,
    75.17186534199936,
    75.02103564099889,
    75.15071453699966,
    75.09264497500044,
    74.97150217499984,
    74.98276829799943,
    75.09060799299914,
    75.08600410599865,
    75.01491112300027,
    75.00857170500058,
    74.99861101799979,
    75.02418546300032,
    74.99659690999943,
    0.0,
    74.82247759700113,
    74.80920410500039,
    0.0,
    74.69309841500035,
    0.0,
    0.0,
    0.0,
    0.0,
    75.16631951699856,
    75.26008951599943,
    0.0,
    0.0,
    75.08263091899971,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    74.70612635100042,
    74.70355636800014,
    74.77106672099944,
    74.68727255599879,
    74.68538006199924,
    0.0,
    0.0,
    74.53091792300074,
    74.64790931799871,
    74.50893364200056,
    74.70415719199991,
    74.69262574999993,
    74.75130327000079,
    74.72429371699945,
    74.56518359999973,
    0.0,
    74.80664603100013,
    74.73174120600015,
    74.73603179100064,
    74.72559505100071,
    74.7216813039995,
    74.69961050500024,
    74.57189910899979,
    74.68184237899914,
    74.60537485799978,
    74.70274128099845,
    74.58040846800031,
    74.69950659000096,
    74.8081397850001,
    74.74468865900053,
    74.74253179900006,
    74.72500767899874,
    74.82891781299986,
    74.92513594299999,
    75.00830809000036,
    74.82566221200068,
    74.76015138899857,
    74.75093653000113,
    74.75895812800081,
    0.0,
    75.14309572800084,
    75.2998093770002,
    75.23516250600005,
    75.22831033300099,
    75.20371204200092,
    75.17900387900045,
    75.2727979020001,
    75.25844966799923,
    75.36682369399932,
    75.21341148299871,
    75.2406186219996,
    75.37391113000012,
    75.47688147599911,
    75.42555291900135,
    75.5560440950012,
    75.76673530599874,
    75.85503524399974,
    75.84318720299962,
    75.91097808800077,
    76.16365698299887,
    76.14519343699976,
    76.1344783830009,
    76.09227936299976,
    76.05845833500098,
    75.98830820799958,
    76.09045882600003,
    76.01888402400073,
    76.12613517200043,
    76.23801465299948,
    0.0,
    0.0,
    76.13362668199989,
    76.1064664810001,
    76.17476968699884,
    76.23056521000035,
    76.06439610200141,
    76.06215484599852,
    76.18896430199857,
    76.18787369599886,
    0.0,
    76.31256048000068,
    0.0,
    0.0,
    0.0,
    0.0,
    76.08868111299853,
    76.1858456129994,
    76.05626880300042,
    75.74479024800166,
    75.9730321370007,
    75.92301559599946,
    75.9119520889999,
    0.0,
    75.82196299200041,
    75.80770610099898,
    0.0,
    75.72263346100044,
    75.6813269660015,
    0.0,
    0.0,
    75.67231241500122,
    0.0,
    75.50484518599842,
    75.4553466489997,
    75.40319920399997,
    75.07310498800143,
    75.12602789099947,
    0.0,
    0.0,
    75.01840960300069,
    0.0,
    0.0,
    0.0,
    76.30043450999983,
    76.17807847299991,
    76.2771285710005,
    76.26148011999976,
    76.21548877100031,
    76.14297763600007,
    76.21857532499962,
    76.14929059400129,
    76.25077955600136,
    76.23232754699893,
    76.18810346600003,
    76.09443355900112,
    76.21788329399897,
    76.13650746799976,
    76.2561832980009,
    76.49914034299945,
    76.48121811300007,
    76.75395116499931,
    76.8840042819993,
    76.81495725599962,
    76.93014229300024,
    76.87815800099997,
    76.9293710359998,
    77.0314594219999,
    77.16623737699956,
    77.61338011299995,
    77.5720458300002,
    77.48422659400057,
    77.39093396099997,
    77.39390850200107,
    77.35851341800117,
    77.37378218899903,
    77.28777252100008,
    77.19009850700058,
    77.31502763400022,
    77.26043582099919,
    77.15513578399987,
    77.08506373800083,
    77.0038667630015,
    77.07560509699942,
    76.91604129199914,
    76.88116028399963,
    76.99760960599997,
    77.09269558000051,
    76.99298150400136,
    76.96686570899874,
    76.92808982399947,
    76.99382089199935,
    76.96977210899968,
    77.06900377300008,
    77.06100280300052,
    77.04586687200026,
    0.0,
    0.0,
    0.0,
    0.0,
    76.93040672999996,
    76.91591235300075,
    0.0,
    0.0,
    0.0,
    76.77943679200143,
    76.8699438420008,
    76.74815229100022,
    76.65881415799959,
    0.0,
    0.0,
    76.9982660530004,
    76.85004707199914,
    76.57940529799998,
    76.49719281100079,
    0.0,
    76.9247484309999,
    77.03121680299955,
    77.1480407729996,
    77.12389349500154,
    77.0715745310008,
    77.06346730199948,
    77.13192135800091,
    77.33290692699848,
    77.05283599799986,
    77.25313844300035,
    77.22551774899875,
    0.0,
    77.2087975100003,
    0.0,
    77.38671391400021,
    77.33447470600004,
    77.37705626299976,
    77.44299535999926,
    0.0,
    0.0,
    0.0,
    0.0,
    77.26473486299983,
    77.17038842299917,
    77.28050005300065,
    77.23668760200053,
    77.19760932600002,
    77.1352336029995,
    0.0,
    77.01881775499896,
    76.99215872799869,
    77.07629843599898,
    76.91879752899877,
    76.84638346200154,
    76.80463879600029,
    76.91371736899964,
    0.0,
    0.0,
    0.0,
    0.0,
    76.56061357499857,
    76.53732632200081,
    76.53017602100044,
    0.0,
    0.0,
    0.0,
    0.0,
    76.42258320099972,
    0.0,
    0.0,
    0.0,
    76.11527220599964,
    0.0,
    0.0,
    0.0,
    75.88465284499944,
    0.0,
    0.0,
    0.0,
    0.0,
    75.66064988700055,
    0.0,
    0.0,
    75.51685242799977,
    75.49894587299968,
    75.45788423699923,
    75.42926672499925,
    0.0,
    0.0,
    0.0,
    75.20586788199944,
    75.17747330100065,
    75.06218276300024,
    74.99088001699965,
    0.0,
    0.0,
    74.78069391700046,
    74.7884720209986,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    74.49930445000064,
    0.0,
    0.0,
    74.30391070399855,
    74.26650159100063,
    74.19878657900153,
    74.42781625200041,
    74.39904248800121,
    0.0,
    0.0,
    0.0,
    0.0,
    73.960453615,
    74.07703769399996,
    73.8729569340012,
    73.81345047399918,
    73.81466680500125,
    73.66729238799962,
    73.76754959000027,
    74.02036500000031,
    73.97545743599949,
    73.98517431099935,
    73.9390736430014,
    73.91043100499883,
    73.91006993300107,
    74.16776773399943,
    0.0,
    74.4812516940001,
    74.61162088600031,
    74.7493286129993,
    74.78904001299998,
    74.89810314399983,
    74.99292932500066,
    74.9530106000002,
    75.22297156199966,
    75.22392828500051,
    0.0,
    0.0,
    75.09502479000002,
    75.17988716099899,
    0.0,
    75.07139535800161,
    75.06609514299998,
    75.09718105400134,
    75.07431959799942,
    75.05712741300158,
    75.17564811599914,
    75.16657529999975,
    0.0,
    75.12120541900003,
    75.0987898809999,
    0.0,
    75.08737074899909,
    75.05572850099998,
    75.01095162399906,
    0.0,
    0.0,
    0.0,
    75.5395155389997,
    75.48673832699933,
    75.57989180699951,
    75.5557388899997,
    0.0,
    0.0,
    75.3985773000004,
    75.39738121500159,
    75.31712728100138,
    75.55734635100089,
    0.0,
    75.3852873880005,
    75.42174240199893,
    75.24031369299882,
    75.35994729999948,
    75.34872141699998,
    75.25855606599907,
    75.3507120910017,
    75.30436225300036,
    75.38759065799968,
    75.34818520599947,
    75.14127351999923,
    75.1189421199997,
    75.07650712100076,
    75.15702997100016,
    75.0514988089999,
    75.16514986900074,
    75.41413973999988,
    75.39224173000002,
    75.47662282599958,
    75.43792627599942,
    75.36143434299993,
    75.34617706900099,
    75.42369624300045,
    75.40403027500179,
    75.53418097499889,
    75.446514027999,
    75.61267457500071,
    0.0,
    0.0,
    0.0,
    0.0,
    75.418759133001,
    75.3462935589996,
    75.40761664099955,
    75.39978031999999,
    75.3921758409997,
    75.3835950240009,
    75.31391482300023,
    75.25570240399975,
    75.162298792,
    75.22398334200079,
    75.06771664600092,
    75.17526950899992,
    75.12514589000057,
    75.18342651399871,
    75.0493848340011,
    75.17222529100036,
    75.12064481300149,
    74.95056023300094,
    75.05013538000094,
    75.04537931699997,
    74.8411824679988,
    74.8164944020009,
    74.68802307899932,
    74.712452931999,
    74.61773863400049,
    74.52502163600002,
    74.34176387199841,
    74.56537021300028,
    74.54255087699858,
    74.42506857699846,
    74.41596301699974,
    74.46379364199856,
    74.41968922400156,
    74.41645464700014,
    74.53711594699962,
    74.38331868900059,
    0.0,
    74.79573048800012,
    74.70015242500085,
    74.82867722599985,
    74.78861936800058,
    74.91657632900024,
    74.87562506199902,
    74.85158806300024,
    74.81328060499982,
    75.04254538100031,
    75.16772077299902,
    75.08994384499965,
    75.16042076000122,
    75.27392254699953,
    75.31187803600005,
    75.28882567899927,
    75.41757063899968,
    75.17387799099924,
    75.1340245249994,
    74.89883461099998,
    75.00861215399891,
    74.92019583699948,
    75.01285980499961,
    75.183403645,
    75.17839954400006,
    75.15435361299933,
    75.18235043899949,
    75.16701394200027,
    75.15175163300046,
    75.37289885800055,
    75.23681599700103,
    75.22453487699931,
    75.46939562300031,
    75.46884300300007,
    75.3512503969996,
    0.0,
    0.0,
    75.83756608300064,
    75.85159198899964,
    75.84168727399992,
    75.79145695499938,
    75.8800682960009,
    75.86584760699952,
    75.84896241800016,
    75.90985660000115,
    75.79577718200017,
    75.77638112299974,
    75.70321335900007,
    75.7367473739996,
    75.67655563399967,
    75.55646533199979,
    75.52892286300084,
    75.62336240500008,
    75.39472973800002,
    75.33501196700126,
    75.46373513400067,
    75.66366144099993,
    75.58296136399986,
    75.71869169599995,
    75.64058727600059,
    75.71389705199908,
    75.62597038599961,
    75.75602104000063,
    75.86234373700063,
    76.09267399300006,
    75.95234937200075,
    75.84182452700043,
    75.75510831199972,
    75.8764466470002,
    75.85928935599986,
    75.68763590799972,
    75.81113534699944,
    75.74733177799862,
    75.98948249499881,
    75.98394124100014,
    76.0960129060004,
    76.04072874600024,
    75.95319964699956,
    76.00273785399986,
    75.93327103000047,
    75.7164401480004,
    75.65757669300001,
    75.73349353899903,
    75.60780261400032,
    75.59004822800125,
    75.71703688400157,
    75.74295609799992,
    75.71869394699934,
    75.81957423600034,
    76.04457537499911,
    75.85342583599959,
    75.80394559600063,
    75.92313118699894,
    75.65008357299848,
    75.63456724500065,
    75.59769685399988,
    0.0,
    76.01784194100037,
    76.09439249200113,
    76.04899649800063,
    76.04590754499986,
    76.2688458699995,
    76.17312055500042,
    76.30117794999933,
    76.29223836900019,
    76.22715025999969,
    76.16205365800124,
    76.34607284600133,
    76.25416598800075,
    76.35006943699955,
    76.33743340799992,
    76.21953495399976,
    76.16869479999878,
    76.06295772500016,
    76.03669270300088,
    76.03392912399977,
    0.0,
    76.68565901799957,
    76.66174587200112,
    76.80955834399902,
    76.80646208899998,
    77.08073234299991,
    77.06585775599888,
    77.05857809599911,
    77.03114684899992,
    77.04941458999929,
    77.00412642400079,
    76.962627582001,
    77.24730058299974,
    77.23842699499983,
    77.21607213600146,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    76.98405993300003,
    0.0,
    0.0,
    0.0,
    76.74853090299985,
    0.0,
    76.64946078400135,
    0.0,
    0.0,
    76.40247237399853,
    76.65270710599907,
    76.7292584379993,
    76.66654128399932,
    76.76296434299911,
    76.67391574500107,
    76.80274800200095,
    76.71677849099979,
    76.6766712360004,
    76.65492360099961,
    76.64643680700101,
    76.62203380599931,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    76.65625439700125,
    0.0,
    77.14324077399942,
    77.2552519130004,
    0.0,
    0.0,
    76.99144465100107,
    76.97239697500117,
    77.05485940100152,
    0.0,
    77.45549638599914,
    77.35429581899916,
    77.47419040899877,
    77.5954381570009,
    77.69136899899968,
    77.61218396000004,
    77.5750331420004,
    77.79216921400075,
    77.67873515500105,
    77.7913262789989,
    77.76112290499987,
    77.70777521200034,
    77.68534140500014,
    77.6336422330005,
    77.90799185799915,
    77.82029977500133,
    77.85952661699957,
    77.71071062699957,
    77.60323667000011,
    77.59914689299876,
    0.0,
    77.56203022099908,
    77.62368869800048,
    77.54054891300075,
    77.49764989600044,
    77.17146228999991,
    77.0247381299996,
    76.93736859599994,
    77.06770597099967,
    77.08956755200052,
    0.0,
    78.03245048200006,
    77.973193935999,
    77.9415204729994,
    77.81391493599949,
    77.82455864500116,
    77.76310477900006,
    77.88609791599993,
    77.80052728699957,
    77.69568104399877,
    0.0,
    78.19277624899951,
    78.090644539001,
    78.18979108199892,
    78.15431427799922,
    78.3468254849995,
    78.3309626420014,
    78.55282033599906,
    78.51958339700104,
    0.0,
    78.35002769700077,
    0.0,
    78.14769757199974,
    0.0,
    78.50738393099891,
    78.59310329000073,
    78.54533125999842,
    0.0,
    0.0,
    78.43038034299934,
    0.0,
    78.77216111499911,
    78.60185466400071,
    78.62520145000053,
    78.70212577299935,
    78.56986723199952,
    78.58822950300055,
    78.57656373399914,
    78.54125587700037,
    78.67186545200093,
    78.92009229400173,
    0.0,
    79.14349400600076,
    78.95644743699995,
    78.94896170200082,
    79.07084753400159,
    78.9969096040004,
    79.22248576399943,
    79.20651932699911,
    79.31515769100042,
    79.30135642099958,
    79.29772333299843,
    79.42402626600051,
    79.27254184099911,
    79.26882010200097,
    0.0,
    0.0,
    0.0,
    79.00840795399927,
    79.24286035499972,
    79.33940540299955,
    79.43204737999986,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    78.94077718699918,
    0.0,
    78.9618253259996,
    78.91407173000152,
    0.0,
    78.66087975700066,
    0.0,
    78.71007560399994,
    78.58818211300058,
    78.58122607699988,
    78.45689781600049,
    78.55039752700031,
    78.53807619599866,
    78.37430187700011,
    78.405740350001,
    78.4005337969993,
    78.35257054400063,
    78.19687763900038,
    78.16431415099942,
    78.28470387400012,
    78.48828407899964,
    0.0,
    78.47689428900048,
    0.0,
    78.28268136299994,
    78.25422877700112,
    78.20987774099922,
    78.20396705599887,
    0.0,
    0.0,
    78.03226793700014,
    78.0879673390009,
    78.0148239680002,
    78.005206025,
    77.9526117940004,
    78.16084706900074,
    0.0,
    78.4603486750002,
    78.39033101600035,
    0.0,
    78.09933699099929,
    77.94326589100092,
    78.052030765999,
    78.02320227699965,
    77.99900981500105,
    77.92486580900004,
    77.9000455489986,
    78.03959416200087,
    78.01037197500045,
    77.90924136699869,
    77.98412600399934,
    77.78967937300149,
    77.7852019639995,
    0.0,
    78.15313532000073,
    78.03845896199891,
    77.98496172699925,
    77.97763882199979,
    77.87811517900082,
    78.10512369099888,
    78.09636076199968,
    78.04379712399896,
    0.0,
    78.42003762400054,
    78.35134197099978,
    0.0,
    78.25312355999995,
    0.0,
    0.0,
    78.11326751100023,
    77.88532441699863,
    77.91360209400045,
    77.83019435200003,
    77.77791028300089,
    77.7238977449997,
    77.68080540600022,
    77.78033134799989,
    77.77959088600073,
    77.76998252399972,
    77.85898286500014,
    78.00414026899853,
    78.12867142100004,
    77.9409207689987,
    0.0,
    0.0,
    77.83375927999987,
    0.0,
    77.74268380499961,
    77.8657104440008,
    77.69158266799968,
    77.67785510299836,
    77.53991646199938,
    0.0,
    0.0,
    77.80922077099967,
    77.76296863400057,
    77.6660372740007,
    77.611507085001,
    0.0,
    0.0,
    77.48685313500027,
    77.47192264600017,
    77.3281962330002,
    77.31576258300083,
    77.42904379100037,
    77.69853208200038,
    0.0,
    77.53286511899933,
    0.0,
    77.45999946200027,
    77.42029346600066,
    0.0,
    77.40595473900066,
    77.28297420200033,
    77.19732531999944,
    77.17184212700158,
    77.08139726000081,
    76.98362583100061,
    76.90384840299885,
    77.06882314500035,
    76.86628530499911,
    76.79046516100061,
    76.91115391400126,
    76.95080244400015,
    77.06281237400071,
    77.04668954799854,
    77.00163833999977,
    77.24479714100016,
    77.22931711899946,
    0.0,
    0.0,
    0.0,
    0.0,
    77.06804501900115,
    77.00015893300042,
    77.21266679200016,
    77.32636423000076,
    77.26981964299921,
    77.20715967600154,
    77.20585575899895,
    77.17627593200086,
    77.12124282100012,
    0.0,
    0.0,
    77.09243539300041,
    77.09189504900132,
    77.08291281600032,
    77.20565314000123,
    77.10440930700133,
    77.12739678700018,
    77.06603311899926,
    76.91614304300128,
    76.91513056500116,
    76.90775345099973,
    76.99734354300017,
    76.86898718499833,
    76.81752104099905,
    76.92572330099938,
    76.92199863600035,
    76.89821946099983,
    76.79840109600082,
    76.76805184800105,
    76.74128129899873,
    76.95823209400078,
    76.9121176360004,
    76.8799326089993,
    76.85001725199982,
    77.04628803100059,
    76.84724779700082,
    76.9637861629999,
    76.84988442599933,
    76.83107284000107,
    76.92834518999916,
    76.92744924500039,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    76.6311247880003,
    0.0,
    0.0,
    76.58783028499965,
    76.67921710099836,
    76.65163604100053,
    76.52865870800088,
    76.65379421299986,
    76.5934742540012,
    0.0,
    76.52711082799942,
    76.44054321899966,
    76.42501112100035,
    0.0,
    0.0,
    76.22834509099994,
    76.19891600700066,
    76.0729855440004,
    76.06253725500028,
    0.0,
    0.0,
    0.0,
    76.08069691200035,
    76.03370995200021,
    76.10143241999867,
    76.08275465600127,
    76.30504223000025,
    76.27487339599975,
    76.11769583300156,
    76.19706800800122,
    76.17842412299979,
    76.10417923499881,
    76.21134675699977,
    76.21080213999994,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    76.0910621160001,
    76.21737009400022,
    0.0,
    76.0504604279995,
    76.13763783799914,
    76.1311877449989,
    76.06600793799953,
    76.18675708199953,
    76.15317286400023,
    76.26950100199974,
    76.30857555399962,
    76.30281027300043,
    0.0,
    0.0,
    76.18548942099915,
    76.16680551600075,
    0.0,
    0.0,
    76.02444353200008,
    76.12486311700013,
    76.21223199800079,
    76.04632073799985,
    76.28803881100066,
    76.39354734699918,
    0.0,
    0.0,
    76.5029279219998,
    76.41047736499968,
    0.0,
    0.0,
    76.22071808299916,
    0.0,
    0.0,
    0.0,
    0.0,
    76.04292307300057,
    76.27711329599879,
    76.25428552300036,
    76.24777759000062,
    76.20754068099995,
    76.1578388300004,
    76.42754872700061,
    0.0,
    76.30609998299951,
    76.27121887300018,
    0.0,
    0.0,
    76.15627822100032,
    76.00750034499833,
    75.99906297999951,
    75.86001841699908,
    75.79800088999946,
    75.85975065400089,
    75.84668785199938,
    75.83188709499882,
    75.80584144000022,
    75.80174741100018,
    75.73437017099968,
    75.82801385899984,
    75.73835422100092,
    75.65022152500023,
    75.737691205999,
    75.99188685700028,
    75.9100547149992,
    75.90232014899993,
    0.0,
    0.0,
    76.04963623299955,
    76.02797755999927,
    75.99798478500088,
    75.96797126199999,
    75.89221684299991,
    75.8916013629987,
    0.0,
    0.0,
    75.89810566699998,
    0.0,
    0.0,
    0.0,
    0.0,
    75.56635765000101,
    0.0,
    0.0,
    75.39865906799969,
    0.0,
    75.27549084599923,
    75.19514780499958,
    75.1261524140009,
    75.18818062799983,
    75.13551721400108,
    75.13119255399943,
    75.1242298140005,
    75.22149093100052,
    75.43127683700004,
    75.41560811099953,
    75.26045626199993,
    75.24304186399968,
    75.36934147099964,
    0.0,
    75.14103592599895,
    0.0,
    0.0,
    74.84651705999931,
    74.8391875920006,
    0.0,
    0.0,
    0.0,
    74.78906491100133,
    74.71541094900022,
    74.80263674700109,
    75.07766649699988,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    74.77749921000031,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    74.63986078200105,
    0.0,
    74.54979282899876,
    74.37091830899953,
    74.36672436300069,
    0.0,
    0.0,
    74.36740826599998,
    0.0,
    0.0,
    0.0,
    0.0,
    74.11195090199908,
    74.13967958600006,
    74.08695932299997,
    74.21286435399998,
    0.0,
    74.86990260600032,
    75.1058797200003,
    0.0,
    0.0,
    0.0,
    75.13244502000089,
    0.0,
    75.00609386699944,
    0.0,
    0.0,
    75.12126563399943,
    75.17081376100032,
    75.12530987600076,
    0.0,
    0.0,
    0.0,
    0.0,
    74.80147076699905,
    74.90622582500146,
    75.02597071700075,
    75.04513836299884,
    75.15532881099898,
    75.0950127190008,
    75.0809030929995,
    75.02146284300034,
    74.96799384899896,
    0.0,
    74.84884691300067,
    74.71252584600006,
    0.0,
    0.0,
    74.71876701300062,
    74.84244874199976,
    0.0,
    0.0,
    74.7650027389991,
    74.85404359399945,
    0.0,
    0.0,
    0.0,
    0.0,
    75.03543590499976,
    75.11356289499963,
    75.09785500899852,
    74.98857508299989,
    75.15075006900042,
    75.14845955400051,
    75.13635496300049,
    75.02362032400015,
    75.12897160899956,
    75.01395904499987,
    74.9114342720004,
    0.0,
    0.0,
    0.0,
    74.90500138400057,
    75.01080971299962,
    0.0,
    75.18256471700079,
    0.0,
    75.30943177399968,
    75.26451622499917,
    0.0,
    75.23388121599965,
    75.3526628540003,
    0.0,
    0.0,
    0.0,
    75.22081036599957,
    75.28902838800059,
    0.0,
    0.0,
    0.0,
    75.25457163899955,
    75.44485238400011,
    75.39076699299949,
    0.0,
    75.28921710699979,
    75.17129211300016,
    75.07413988500048,
    75.10753925099925,
    75.09329342799901,
    75.01142622600128,
    75.00103342399962,
    74.96229517900065,
    74.95292992900067,
    0.0,
    0.0,
    0.0,
    74.96527258099923,
    0.0,
    0.0,
    74.80004742999881,
    74.73431201399944,
    74.73126081400005,
    74.61746591500014,
    0.0,
    75.20737593200101,
    75.14388180499918,
    75.12492589700014,
    75.03752336399884,
    75.13328951599942,
    75.09120228999927,
    75.07650102600019,
    75.04417942300097,
    75.1170870549995,
    75.09430763399905,
    75.07902913999897,
    75.19867733299907,
    75.2235054720004,
    0.0,
    75.16482413000085,
    75.14821100300105,
    75.10957564099954,
    0.0,
    74.93538953799907,
    74.72936736300107,
    74.6940656480001,
    74.66825701599919,
    74.74904068799879,
    74.65132568599984,
    74.6454738579996,
    74.60138266000104,
    74.49265365300016,
    74.59925617299996,
    0.0,
    74.93649430900041,
    74.93118626299838,
    75.00084009800048,
    74.86299533199963,
    74.92119467399971,
    75.034628849,
    74.96526359800009,
    74.94842852599868,
    74.94286141799967,
    74.89589919799982,
    74.95211435999954,
    74.90661483500116,
    75.16648832499959,
    0.0,
    0.0,
    0.0,
    0.0,
    74.79641376099971,
    74.9156772589995,
    74.84110010599943,
    74.8693046540011,
    75.00161289599964,
    74.93272879199867,
    74.91544352799974,
    74.90286555899911,
    0.0,
    0.0,
    0.0,
    74.74068106199957,
    74.72538712900132,
    74.793985626,
    74.9591155929993,
    74.91571076000037,
    74.70465059799972,
    74.7836750080005,
    74.83354007900016,
    74.81482210800095,
    74.9018993539994,
    75.1400619369997,
    0.0,
    75.44139415300015,
    75.44042809500024,
    0.0,
    76.08556172299905,
    0.0,
    0.0,
    0.0,
    77.09222350799973,
    77.08503141700021,
    76.9900049480002,
    76.91792236699985,
    77.07687569799964,
    77.04092070399929,
    77.02942324799915,
    76.96121744899938,
    77.17575607599974,
    77.26026899600038,
    77.2173662669993,
    77.21074668899928,
    77.1434406419994,
    77.24119016300028,
    77.46562330500092,
    77.42975359299999,
    77.38124116899962,
    77.35622118299943,
    77.47410476200093,
    77.4681981649992,
    77.71390997900016,
    77.63179177600068,
    77.57742189899909,
    77.60363652199885,
    77.59044480199918,
    77.51407327699962,
    77.55748118199881,
    77.92588166299902,
    77.92142774799868,
    77.75759362499957,
    77.73928284199974,
    77.85339774500062,
    77.96101645599992,
    77.85192563700002,
    77.80679393799983,
    77.80496356099866,
    77.76287060399954,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    77.7216995810013,
    0.0,
    77.72081729799902,
    77.94490221600063,
    0.0,
    0.0,
    77.81996020999941,
    77.80755231900002,
    77.91766862300028,
    77.80681475600068,
    77.70698605500002,
    77.65341529099896,
    77.76540602299974,
    77.87670777399944,
    78.1288237459994,
    78.10886670000036,
    78.14817553799912,
    78.13672237900028,
    78.07549048799956,
    78.19422160300019,
    78.2731707820003,
    78.17240196400053,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    78.32042066500071,
    78.26677248600026,
    78.4468577509997,
    78.50288248299876,
    78.41070478700021,
    78.3998678830012,
    78.25606822000009,
    78.22212637199846,
    78.17600694700013,
    78.28162595399954,
    78.14678167599959,
    78.24462449899875,
    78.20911031000105,
    0.0,
    78.42151989600097,
    78.37954368200008,
    78.48948968700097,
    78.48115260800114,
    78.75368573699961,
    78.54563169599896,
    78.65522503200009,
    78.6132566870001,
    78.60253308999927,
    78.56682769100007,
    78.554346248,
    78.52838003400029,
    78.6345708300014,
    0.0,
    79.08410404999995,
    79.19141794799907,
    79.1599199250013,
    79.01149848800014,
    0.0,
    0.0,
    78.80805053100084,
    78.69376374700005,
    78.791748353,
    0.0,
    79.03887022799972,
    79.0261225510003,
    79.1508230849995,
    0.0,
    0.0,
    79.02389387999938,
    0.0,
    78.88401286299995,
    78.6136822110002,
    78.81840498800011,
    0.0,
    79.29739000200061,
    79.16153689400016,
    79.27172589200018,
    79.36194004500067,
    79.33799192699917,
    79.6204248819995,
    0.0,
    0.0,
    79.65009831200041,
    79.63923769800022,
    0.0,
    0.0,
    79.45268402699912,
    79.44551512200087,
    79.44487958600075,
    79.33658594400003,
    79.40091185599886,
    79.38638235500002,
    0.0,
    80.49770569000066,
    0.0,
    80.42420753599981,
    80.4063416780009,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    80.12138091900124,
    80.05367828099952,
    80.13862914799938,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    79.59550617899913,
    79.56181785499939,
    0.0,
    79.38543634300004,
    0.0,
    0.0,
    79.2182974389998,
    79.16748278900013,
    79.18285940400165,
    79.03569635199892,
    78.92152028999953,
    79.18134427699988,
    79.00973478500055,
    79.15155291200062,
    79.38987033400008,
    0.0,
    0.0,
    0.0,
    0.0,
    79.60476149399983,
    79.68490019199999,
    79.6276439029989,
    79.71769378099998,
    79.70003080400056,
    0.0,
    80.04162958400048,
    80.25736172299912,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    80.00210488599987,
    0.0,
    0.0,
    0.0,
    80.00641143600114,
    79.97283977199913,
    0.0,
    0.0,
    79.81629973000054,
    79.82192848100021,
    79.81460088300082,
    79.95237012100006,
    79.71229897599915,
    79.69750552900041,
    79.81990401300027,
    80.0426036079989,
    79.80898355099998,
    79.8084542559991,
    79.85586149399933,
    0.0,
    80.46276601700083,
    80.40777172099843,
    80.63780286399924,
    80.48440630799996,
    80.46481420800046,
    80.37551572099983,
    80.31954239000152,
    80.41115348700077,
    80.53845916499995,
    80.28146602500055,
    80.24372603499978,
    80.07784478600115,
    80.20634170700032,
    80.18645079000089,
    80.30822298299972,
    80.58671566199882,
    80.5492176939988,
    0.0,
    80.3048703229997,
    80.4218270679994,
    80.25442504000057,
    80.23329455800013,
    80.1773076999998,
    80.30764473999989,
    80.2839006940012,
    80.26660944000105,
    80.16848368299907,
    80.02161147599872,
    80.00803380700017,
    80.07003365699893,
    79.95095660299921,
    80.01591497799927,
    79.97409662700011,
    80.05555021100008,
    79.98855676800122,
    79.97710414699941,
    0.0,
    80.06886489700082,
    79.96008159400117,
    80.20576032099962,
    80.4472653720004,
    80.42780254200079,
    0.0,
    80.46572473599917,
    0.0,
    0.0,
    81.45775566599877,
    81.39615734699873,
    81.36388494800121,
    0.0,
    82.2807487099999,
    82.52907683800004,
    82.52758614699997,
    82.59481356700053,
    82.83900713200092,
    82.75184626400005,
    82.82418457700078,
    82.84261177900044,
    82.63932944100088,
    0.0,
    82.92814311799884,
    82.78704954999921,
    82.76146284599963,
    82.83220059199994,
    82.80357298499985,
    82.68609788300091,
    82.6567265169997,
    82.68524611400062,
    82.79442459299935,
    82.72020328599865,
    82.9167872449998,
    82.91518660499969,
    83.15461206599866,
    83.41032039099991,
    83.2765188049998,
    83.09053363900057,
    83.04678763899938,
    83.15213226599917,
    83.14756863500043,
    83.06623658899844,
    83.27598813199984,
    83.29789670399987,
    83.29154180499972,
    83.25067330800084,
    83.37441472499995,
    83.23171383599947,
    83.19589907299996,
    83.02834941899891,
    83.01168261500061,
    83.17595540200091,
    83.05683818899888,
    0.0,
    83.72509393300061,
    83.61479701100143,
    83.57706632000009,
    83.44047597899953,
    83.56451179000032,
    0.0,
    83.5452405699998,
    0.0,
    0.0,
    83.33201584299968,
    83.28433139999834,
    83.23534770399965,
    0.0,
    0.0,
    82.94702794399927,
    82.93764690399985,
    83.00596923100056,
    82.7766249590004,
    82.65058254300129,
    82.55763845699948,
    82.75419686299938,
    82.73979233000136,
    82.7243276499994,
    82.7752077160003,
    82.89194677500018,
    82.7854453839991,
    82.69008403299995,
    82.6857752399992,
    82.67099160600083,
    0.0,
    0.0,
    0.0,
    0.0,
    82.68840087900026,
    0.0,
    0.0,
    0.0,
    0.0,
    82.53231911600051,
    0.0,
    0.0,
    0.0,
    0.0,
    82.35851038299916,
    0.0,
    0.0,
    0.0,
    0.0,
    82.6755840199985,
    82.80054844400001,
    0.0,
    82.71854297800019,
    82.4473543639997,
    82.4870535530008,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    82.13710913400064,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    82.01796705699962,
    82.13824516000022,
    0.0,
    81.90376179600025,
    82.00858165299906,
    0.0,
    0.0,
    81.84297325199987,
    81.83199777899972,
    81.82493168300061,
    81.94232983799884,
    0.0,
    81.79640005199872,
    81.79333059099918,
    81.91050680700027,
    0.0,
    81.85104416499962,
    81.81688455600124,
    81.70774377099951,
    0.0,
    0.0,
    0.0,
    81.81016857699979,
    0.0,
    81.78298272500069,
    0.0,
    0.0,
    0.0,
    0.0,
    81.92516765099936,
    0.0,
    0.0,
    81.93394564099981,
    81.90349823999895,
    81.87020033200133,
    81.86015118400064,
    81.72455718099991,
    81.84626069099977,
    0.0,
    81.82320317200174,
    81.79253636300018,
    81.88723265600129,
    81.93084627900134,
    81.91480298799979,
    81.96941262099972,
    81.96831878299963,
    81.96287201499945,
    0.0,
    81.80807802100026,
    0.0,
    0.0,
    82.2502474970006,
    82.3535319370003,
    82.2053521910002,
    82.18187245099944,
    82.17079784899943,
    82.24361765299909,
    82.10190234500078,
    82.08624888400118,
    82.05444869100029,
    81.97788070800016,
    0.0,
    82.61514343800081,
    82.60887007299971,
    82.78775051899902,
    82.73542290799924,
    82.65962582700013,
    82.52416804399945,
    82.64483383799961,
    82.63191494399871,
    82.56838249599969,
    82.68730970900106,
    82.67247517299984,
    82.76462817299944,
    82.88499861200035,
    82.66907734400047,
    82.76453355400008,
    82.92546785400009,
    82.77705311700083,
    82.87588744999994,
    82.86902997400102,
    82.862041968001,
    82.80675127500035,
    82.85933960199873,
    82.83805011100048,
    0.0,
    0.0,
    0.0,
    82.62662727600036,
    82.67090190199997,
    82.76255034300084,
    82.53703174000111,
    82.48807673200099,
    82.45929300500029,
    82.53422411800057,
    82.62730564199956,
    82.60386622500118,
    82.71149050699933,
    82.50286204499935,
    82.5547890350008,
    82.53361018000032,
    82.6805640370003,
    82.69921904600051,
    82.62368106800022,
    82.61242444399977,
    82.5112322920013,
    82.55186708700057,
    82.4659181499992,
    82.41622116700091,
    82.40132309799992,
    82.48357684900111,
    82.4343113570012,
    82.38688893300059,
    82.41963827899963,
    82.29826959000093,
    82.39883448999899,
    82.16712974999973,
    82.16262643600021,
    82.11116157400102,
    82.06846663100077,
    82.14916452100078,
    82.13707334199898,
    82.34710638999968,
    82.44310367500111,
    82.36175784199986,
    82.2357210070004,
    82.20930444499936,
    0.0,
    0.0,
    82.25575201799984,
    0.0,
    82.15425814299851,
    0.0,
    0.0,
    0.0,
    0.0,
    82.14363389699975,
    0.0,
    0.0,
    0.0,
    81.94133359799889,
    81.93661089499983,
    0.0,
    81.78992880899932,
    81.96783402700021,
    0.0,
    81.86430188699887,
    81.83944580299976,
    81.65121092699883,
    81.6234826559994,
    0.0,
    81.64634101900083,
    81.49576337500002,
    81.46619204799936,
    81.5917416960001,
    81.50549151100131,
    81.57344710299913,
    81.55972054999984,
    81.66441189699981,
    81.62167215500085,
    81.72147845400104,
    0.0,
    81.52844306900079,
    81.59027393499855,
    81.55574609099858,
    81.62616831299965,
    81.41821052799969,
    81.16112327600058,
    81.23932060299921,
    81.19265273699966,
    81.33611326699975,
    81.31734279599914,
    81.26212065899927,
    81.20753969500038,
    81.0537006680006,
    81.10781786299958,
    81.19610848199954,
    81.13832394499877,
    81.0978391159988,
    81.05747149599847,
    80.97505907300001,
    80.9264316610006,
    81.08063530599975,
    81.32446303199868,
    81.39870026999961,
    81.37635956900158,
    81.30421787900013,
    81.41769381999984,
    81.35530247799943,
    81.3467134879993,
    81.33448231399962,
    81.13014505700085,
    81.20825136299936,
    81.28025472900117,
    81.46418714900028,
    0.0,
    81.80638489600096,
    81.71212913899944,
    81.69237656400037,
    81.94008218700037,
    82.06933562999984,
    82.34866614299972,
    82.09317831800035,
    81.98252574000071,
    82.10730968600001,
    81.98983862500063,
    81.98550487399916,
    81.87154833599925,
    81.85805962599989,
    81.8018202660005,
    82.0485206329995,
    81.97412421900117,
    81.97343269699923,
    81.95020087900048,
    0.0,
    0.0,
    81.77666800599945,
    0.0,
    0.0,
    0.0,
    0.0,
    81.72179827000036,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    81.68401527999958,
    81.74728486700042,
    0.0,
    81.57938387799913,
    0.0,
    82.1069903209991,
    0.0,
    0.0,
    82.09933283499959,
    82.40981027700036,
    82.35682992599868,
    82.41968150200046,
    82.40793570699861,
    82.5077906080005,
    82.61028041300051,
    82.57810498400067,
    82.7750442460001,
    82.89909738200004,
    83.11303791099999,
    83.06602839299921,
    83.05047706799996,
    83.16587192000043,
    83.1579312140002,
    83.14040936400124,
    0.0,
    0.0,
    0.0,
    83.16347742399921,
    82.75979266499962,
    82.7159379929999,
    82.81387816200004,
    82.92081178800072,
    82.88502954499927,
    82.84630554199975,
    82.83378312299828,
    82.83703180999873,
    0.0,
    83.36641559899908,
    83.36019270299948,
    0.0,
    83.27489068499926,
    83.20357276200048,
    83.30117111500113,
    0.0,
    83.07939841000007,
    83.03191715200046,
    0.0,
    0.0,
    0.0,
    82.99435108499893,
    82.96889000600095,
    0.0,
    82.93858798399924,
    0.0,
    0.0,
    0.0,
    83.11223194599916,
    83.05029967399969,
    82.89662445700014,
    82.77667835300053,
    82.6146620390009,
    82.6160173169992,
    82.57974417100013,
    82.39536789600061,
    82.34642413100119,
    82.46057150300112,
    82.39235605899921,
    0.0,
    0.0,
    82.35525500600124,
    82.40646473400011,
    0.0,
    0.0,
    82.22146570999939,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    82.1242387070015,
    82.02144002100067,
    81.90590660799899,
    81.88391989199954,
    81.87942250800006,
    0.0,
    82.86504695000076,
    82.81418753300022,
    82.76740225399953,
    82.75961685400034,
    0.0,
    0.0,
    0.0,
    82.48721192799894,
    82.43178958099998,
    82.30939797700012,
    82.28071780200116,
    82.38319039899943,
    82.37852961600038,
    82.35440209199987,
    0.0,
    82.37555493299988,
    82.31385963600042,
    82.31309760399927,
    82.25046657100029,
    82.2180998290005,
    0.0,
    82.16038445400045,
    81.94881049600008,
    81.92918078399998,
    81.90976416800004,
    81.80600825500005,
    81.78676479099886,
    81.91440835499998,
    81.83346622300087,
    81.94468540900016,
    0.0,
    0.0,
    0.0,
    0.0,
    81.7040123099996,
    81.69192168900008,
    0.0,
    81.58238641999924,
    0.0,
    81.42525558399939,
    81.36084032600047,
    0.0,
    81.38362873400001,
    0.0,
    81.30722680200051,
    80.75962970799992,
    80.74209969799995,
    0.0,
    80.59147909800049,
    80.54404732700095,
    80.46389381399968,
    80.42307974600044,
    80.37006928899973,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    80.32027380799991,
    80.18366766499821,
    80.13971802499873,
    80.38699138499942,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    80.20471664800061,
    80.32143228699897,
    80.10656082800051,
    80.0578904519989,
    80.02086855000016,
    80.26230485700034,
    80.11342300199976,
    80.05925121800101,
    80.04578320600012,
    80.02338653799961,
    80.11896262499977,
    0.0,
    0.0,
    80.1752220920007,
    0.0,
    0.0,
    80.41814666199934,
    80.30277703200045,
    80.57270777500162,
    80.32459811899935,
    80.28156187999957,
    80.36137458899975,
    80.30777026200121,
    80.24776439900052,
    80.29729977999887,
    80.12900177099982,
    0.0,
    80.37249273599991,
    80.39024783199966,
    80.35705808800049,
    80.35189415999957,
    80.3124695309998,
    80.44188936799947,
    80.42774657399968,
    80.54131772400069,
    80.46577658299975,
    80.36679021300006,
    80.32336665999901,
    80.27171328099939,
    80.2318408029987,
    80.20864299999994,
    80.18894042200009,
    0.0,
    0.0,
    0.0,
    80.42788518599991,
    80.45225357500021,
    80.40816391800035,
    80.39740243599954,
    80.34506119199978,
    80.38591942999847,
    80.64133569299884,
    80.51243752200025,
    80.44361601899982,
    80.49086557599912,
    0.0,
    0.0,
    80.36455004199888,
    80.21613358600007,
    80.31691216800027,
    80.30490323100094,
    80.14624672399987,
    80.12099577899971,
    80.13207179500023,
    80.10320664300161,
    80.10030447100144,
    79.95755438200104,
    79.90054287199928,
    80.10391293300017,
    80.04955619500106,
    79.93852658900141,
    0.0,
    80.28050003499993,
    80.27555738400042,
    80.26128292900103,
    80.28873779999958,
    80.22812644200167,
    80.13335764999829,
    79.82697625900073,
    79.84604405500068,
    79.83488705300078,
    79.64555454199945,
    80.04709831999935,
    80.02867779600092,
    79.90810770799908,
    79.88885585400021,
    79.77887699200073,
    79.76774118699905,
    79.88203779200012,
    79.98125077499935,
    79.84423962499932,
    80.15626813900053,
    80.27078329700089,
    80.25328446599997,
    80.18299121499876,
    80.0962497319997,
    80.07813922499918,
    0.0,
    80.22473505699963,
    80.17714829100078,
    80.27964987099949,
    80.27733474100023,
    80.16215315399859,
    80.1291246389992,
    80.1202081219999,
    80.2073406419986,
    80.08028582999941,
    80.03110590899996,
    80.01722196999981,
    79.9775206309987,
    79.97549330499896,
    79.92198072199972,
    79.79978309200123,
    79.75310926699967,
    79.7076821519986,
    79.59243713799879,
    79.68311786999948,
    79.6823728269992,
    79.8296231280001,
    79.86629010599972,
    79.70025296600033,
    79.67112169599932,
    79.5123688599997,
    79.51997031099927,
    79.41376488199967,
    79.49225085099897,
    79.75759778300016,
    79.75608073500007,
    79.57217051200132,
    79.6922551280004,
    79.68647735299965,
    79.93101597799978,
    79.91320562700093,
    79.97796326499883,
    79.9175208910001,
    79.85698583500016,
    80.21760117999838,
    80.21053509600097,
    80.08475920900128,
    80.05893915100023,
    80.44627314600075,
    80.43830749699919,
    80.4140450319992,
    80.32578633199955,
    80.25628333799978,
    80.38661566299925,
    80.41727441399962,
    80.39874054500069,
    80.339209759999,
    80.33433849999892,
    80.25390289300049,
    80.37057920999905,
    80.44948766299967,
    80.42120076799984,
    80.39111088800018,
    80.38741261399991,
    80.42732149299991,
    0.0,
    80.77550168000016,
    80.6490234619996,
    80.7036624350003,
    80.68537168699913,
    80.68051251699944,
    80.7855804009996,
    80.68037351400017,
    80.78199557500011,
    80.72813639000015,
    80.74626020399955,
    80.71189938899988,
    80.73418180199951,
    80.6998956970001,
    80.94101483300074,
    80.7328240450006,
    80.71800216699921,
    80.71269406500141,
    80.76822618299957,
    80.68699883599947,
    80.63774061000004,
    80.82676244300092,
    80.76900876000036,
    80.71181987300042,
    80.45241389600051,
    80.44459243500023,
    80.70346263399915,
    80.67761333700037,
    80.77297621199978,
    80.76994274900062,
    80.6851022360006,
    80.63029929000004,
    80.73347405000095,
    80.8299749859998,
    80.82254549400022,
    80.80783914399944,
    80.66749344799973,
    0.0,
    81.19846546600093,
    81.32366390599964,
    81.51018474299963,
    81.42645523300052,
    81.68000241399932,
    81.60093855200103,
    81.83309012999962,
    81.71678043900101,
    81.55050520700024,
    81.660646585,
    81.6442127549999,
    81.49793770799988,
    81.41251642499992,
    81.21393697899839,
    81.3283794529998,
    81.25011174799874,
    81.09881268599929,
    81.06691083499936,
    81.14280333300121,
    81.08975837599974,
    80.7865553770007,
    80.71348545299952,
    80.70373426200058,
    80.69591637600024,
    80.70335974699992,
    80.66210351600057,
    80.52187750699886,
    80.50430419900113,
    0.0,
    80.45055701799902,
    81.22091966500011,
    81.27381677499943,
    81.35724010600097,
    81.48071506700035,
    81.37388248900061,
    81.43232702999921,
    81.33661324100103,
    81.28658218999954,
    0.0,
    81.63527865099968,
    81.66234291299952,
    81.91659786799937,
    81.76108515600026,
    81.7405802659996,
    81.65526890799993,
    81.60587566300092,
    81.59520960599912,
    81.55203362199973,
    81.7747280349995,
    81.75339145100043,
    81.71214811699974,
    81.66044032599893,
    81.59515117100091,
    81.78599181200116,
    81.99265644200023,
    81.98484511300012,
    81.94356709900057,
    81.93392786500044,
    81.83935530000053,
    81.80776370400054,
    81.77214778199959,
    81.81805991099827,
    81.7814881939994,
    81.85958590299924,
    82.0832028700006,
    81.98991432000003,
    82.12108583199915,
    82.24520434600163,
    82.20037997799955,
    82.10298756400152,
    82.00176574000034,
    81.9119602310002,
    81.84141225499843,
    81.83247504100109,
    81.96203946700007,
    81.84121872399919,
    81.7839846859988,
    81.67896592000034,
    81.63641057200039,
    81.59490277399891,
    81.58793822899861,
    81.6534986709994,
    81.61456706900026,
    81.38731205899967,
    81.50190334099898,
    0.0,
    81.70806319300027,
    81.679471301999,
    81.79071445299996,
    81.7622534660004,
    81.66681110900026,
    81.65725814500001,
    81.91793195100036,
    81.80026786799863,
    81.79686214700087,
    81.89080772799934,
    81.86516363100054,
    81.67905156199959,
    0.0,
    0.0,
    0.0,
    81.91371647800042,
    81.9074906299993,
    0.0,
    0.0,
    0.0,
    81.72029130699957,
    81.67050903900054,
    81.56366431499919,
    81.51941636099946,
    0.0,
    0.0,
    81.68908925600044,
    81.60353107099945,
    0.0,
    81.68210000399995,
    81.66281325899945,
    81.49389023799995,
    0.0,
    0.0,
    0.0,
    81.3077807110003,
    81.23007284599953,
    81.21525301899965,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    81.07772573399961,
    81.0404103159999,
    81.23903453399907,
    81.17222510899956,
    81.29676706200007,
    81.2584247499999,
    81.19510194300165,
    81.1304511950002,
    81.11431347600046,
    81.1906738130001,
    81.24469062500066,
    81.36657640699923,
    81.39146854299906,
    81.60497240699988,
    81.50910124799884,
    81.52191581399893,
    81.48861309899985,
    81.30102409400024,
    0.0,
    81.76363281200065,
    81.82833810699958,
    82.08674978199997,
    82.03100354299931,
    82.1569598390015,
    81.92504209799881,
    81.87842706900119,
    82.10354163900047,
    82.08532657700016,
    82.17547090399967,
    82.15682386200024,
    0.0,
    0.0,
    0.0,
    0.0,
    81.78822405000028,
    81.77221643600024,
    81.58340498100006,
    81.61492765500043,
    81.7248194090007,
    81.99755142800132,
    0.0,
    82.08968245799952,
    81.91765834599937,
    0.0,
    0.0,
    82.11917018500026,
    82.02635567400102,
    81.97948164899935,
    82.07723463699949,
    82.00620791700021,
    81.96526578599878,
    0.0,
    0.0,
    81.706697222,
    81.51240674299879,
    81.49885290200109,
    81.50671151000097,
    81.34395037800095,
    81.19158766600049,
    81.28701051200005,
    81.24896526500015,
    81.34766137299994,
    81.40724613699967,
    81.72921673699966,
    81.69478440100102,
    81.6840996739993,
    81.59233238200068,
    81.48896818899993,
    81.2424147419988,
    81.16830729600042,
    81.1144320149997,
    81.11109170800046,
    81.08897953300038,
    81.34238888399886,
    81.3796248919989,
    81.31298642299953,
    81.3090931480001,
    81.43286956699922,
    81.34005615699971,
    81.33311285799937,
    81.24174142099946,
    81.25597234899942,
    81.24719276200085,
    81.2431480790001,
    81.29169051899953,
    81.26778641599958,
    81.37525401499988,
    81.48256862299968,
    81.44536840499859,
    81.34956200099987,
    81.29520183900058,
    81.2648047370003,
    81.13670930899934,
    81.26716419799959,
    81.23483781100003,
    81.32880886800012,
    81.36599967300026,
    81.26142973499918,
    81.23662057699948,
    81.17266877099973,
    81.2887999120012,
    81.40859009700034,
    81.39268534399889,
    81.3581059320004,
    81.17046287199992,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    81.76778404799916,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    81.28137888499987,
    0.0,
    0.0,
    0.0,
    81.06331640500139,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    81.01983586899951,
    0.0,
    0.0,
    81.00899475200094,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    80.50537100200017,
    80.47805920899918,
    80.7341990040004,
    0.0,
    0.0,
    0.0,
    80.46398648699869,
    0.0,
    0.0,
    80.36252045299989,
    0.0,
    80.1462676760002,
    0.0,
    80.19561493299989,
    80.31274817799931,
    80.25247610199949,
    80.24128259499957,
    80.22221018200071,
    80.1940181709997,
    80.17211083899929,
    79.93261695599904,
    80.05051639300109,
    80.04307292500016,
    80.11426922200008,
    80.05209455100157,
    80.11947565199989,
    80.23093059699931,
    80.03748598499988,
    80.01785488200039,
    79.99173657499887,
    80.36254831500082,
    80.29633273599939,
    80.28317550800057,
    80.38811539000017,
    80.313039097,
    0.0,
    80.32816644900049,
    80.42712446500082,
    80.54008838999835,
    80.40263757799949,
    80.39090525900065,
    80.31590672400125,
    80.39581082199948,
    80.30713194099917,
    80.32944622200012,
    80.32616777299882,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    80.14137810000102,
    80.32718808299978,
    80.26242035200085,
    80.38206074000118,
    80.28597750799963,
    80.22474636100014,
    80.46350627500033,
    80.44153933600137,
    80.25666233000084,
    80.50648748799904,
    80.4591253310009,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    80.2807058010003,
    80.19370592099949,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    81.05806610199943,
    81.17956700099967,
    81.17196204100037,
    81.14007489899996,
    81.00409405399841,
    80.97270695000043,
    80.89711515300041,
    80.80700843500017,
    80.89776040299876,
    0.0,
    81.60770837000018,
    81.69870920299945,
    81.82001144999958,
    81.81531444600114,
    81.7846809670009,
    81.75416650099942,
    81.69167068800016,
    81.78304815999945,
    81.77343149499939,
    81.98726969000018,
    81.94360832599887,
    0.0,
    82.1296610469999,
    82.12454838200028,
    82.14298479300123,
    82.39769427200008,
    82.59836500299934,
    82.57590783900014,
    82.37034869299896,
    0.0,
    0.0,
    0.0,
    82.03334684200127,
    0.0,
    0.0,
    0.0,
    0.0,
    82.47345470499931,
    0.0,
    82.45095096600016,
    82.44062253999982,
    82.54190330200072,
    0.0,
    0.0,
    0.0,
    82.56700201000058,
    82.56140249500095,
    82.43013104599959,
    82.36247528399872,
    82.43132896799943,
    82.42152044999966,
    82.49422111199965,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    82.22089025999958,
    0.0,
    82.42055568199976,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    82.01533875700079,
    82.04577688899917,
    81.99270917499962,
    81.9122293090004,
    81.87395288399966,
    81.80677167300018,
    82.07982905099925,
    0.0,
    0.0,
    81.91666463599904,
    81.98273524999968,
    0.0,
    81.6538540649999,
    81.59118920400033,
    81.74266205399908,
    81.67674861600062,
    81.67405453900028,
    81.70112262600014,
    0.0,
    81.61509891100104,
    81.58424991900029,
    0.0,
    81.37661491399922,
    0.0,
    0.0,
    81.24634860199876,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    80.88545305600019,
    0.0,
    0.0,
    0.0,
    0.0,
    80.87308351400134,
    80.85804251099944,
    0.0,
    80.78771822300041,
    80.72756945499896,
    80.64359126300042,
    0.0,
    0.0,
    0.0,
    80.51385600399954,
    0.0,
    0.0,
    80.32890882900028,
    80.32142937699973,
    0.0,
    80.25734643200121,
    79.9199582149995,
    79.90110166299928,
    79.76714445499965,
    79.73425383700123,
    79.71170050900037,
    79.70254601499983,
    79.74188751099973,
    79.70131479200063,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    79.2988523089989,
    79.20022609700027,
    79.42939808600022,
    79.39835016100005,
    79.26269842900001,
    79.36504545900061,
    79.32342337900081,
    79.2902511450011,
    79.50591459600037,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    79.24433610300002,
    79.10893721899993,
    79.08221642100034,
    79.1934085619996,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    78.90910404399983,
    0.0,
    78.72063178200005,
    0.0,
    0.0,
    0.0,
    0.0,
    78.77105491699876,
    0.0,
    78.58289865199913,
    0.0,
    0.0,
    78.5574655319997,
    0.0,
    78.42899825400127,
    78.38945707200037,
    78.2207148159996,
    78.12564999200004,
    78.16998585700094,
    78.15224143799969,
    78.38463312199929,
    78.25312059600037,
    0.0,
    78.28021822900155,
    78.21322308699928,
    0.0,
    78.21934282000075,
    78.06786225099859,
    78.05699082199862,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    77.60516171000017,
    77.62866278299953,
    77.49228993900033,
    0.0,
    77.69721407799989,
    0.0,
    0.0,
    0.0,
    77.55424174799919,
    77.52102654100054,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    77.28730328200072,
    77.39399186799892,
    77.31315111100048,
    77.30576578399996,
    0.0,
    0.0,
    0.0,
    77.17895452300036,
    77.17379550499936,
    77.22452262200022,
    0.0,
    0.0,
    77.25078750300054,
    0.0,
    77.16772594000031,
    77.05568567800037,
    77.04753695199906,
    77.21977892999894,
    77.27364863000003,
    77.40059744700011,
    77.3298008089987,
    77.19488309400003,
    77.19041849399946,
    77.07213161300024,
    77.10596756400082,
    0.0,
    0.0,
    0.0,
    76.91222021700014,
    76.77363033199981,
    0.0,
    0.0,
    76.45954244999848,
    0.0,
    76.57531554999878,
    0.0,
    76.49501457299993,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    75.94931293000081,
    75.92436465900028,
    75.96973245499976,
    0.0,
    0.0,
    0.0,
    0.0,
    75.65160810499947,
    75.77811374200064,
    75.83439394700144,
    75.82816663899939,
    75.92318398800126,
    0.0,
    0.0,
    0.0,
    75.7671907999993,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    75.36630748899915,
    0.0,
    75.2320292100012,
    0.0,
    0.0,
    0.0,
    0.0,
    75.19939501100089,
    0.0,
    0.0,
    0.0,
    75.0372089880002,
    75.00618561699957,
    74.81030426500001,
    74.80820740600029,
    74.79268781500105,
    74.78907149599945,
    74.741131357001,
    74.85764664899943,
    0.0,
    74.96997840599943,
    74.95826419699915,
    75.0392505359996,
    75.02109394800027,
    75.0012356240004,
    0.0,
    74.60944286499944,
    74.59780103500088,
    74.68941189699945,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    74.57869670000036,
    74.41254723800012,
    74.52522454300015,
    74.46630236400051,
    74.28941614399992,
    0.0,
    74.38243961199987,
    74.35614730199995,
    74.11457624800096,
    74.07218228599959,
    74.06543389699982,
    74.16375943799903,
    74.22823056199923,
    74.33039129999997,
    74.3810894879989,
    74.354891949999,
    74.3189589550002,
    74.26206971899956,
    74.20469096099987,
    73.73069631500039,
    73.70766994299993,
    73.66685276499993,
    73.55345488799867,
    73.67712127699997,
    73.66220169000007,
    73.63065291099883,
    73.60107340799914,
    0.0,
    73.5461595730012,
    73.48714804200063,
    73.42582394300007,
    73.64472659300009,
    73.63261531399985,
    73.71781483599989,
    73.62909358499928,
    73.72240509400035,
    0.0,
    0.0,
    0.0,
    73.58072980500037,
    73.57722569799989,
    73.56073515800017,
    0.0,
    73.63479894100055,
    73.6398188990006,
    73.36271924300127,
    73.33225975099958,
    73.55352631999995,
    73.54462064799918,
    73.352798291,
    73.45197520300098,
    73.4701820980008,
    73.46163590700053,
    73.40840352799933,
    73.3347012230006,
    73.39458378699965,
    73.3563566899993,
    73.41075117100081,
    73.37296982200132,
    73.48236611700122,
    73.59008446900043,
    73.5612039560001,
    73.45710957099982,
    73.57321122600115,
    73.53660933299943,
    73.40448422900045,
    73.29687497399937,
    73.11809965199973,
    73.21573604900004,
    73.04341242900045,
    73.02861680799833,
    72.87166697400062,
    72.80071625100027,
    0.0,
    0.0,
    0.0,
    0.0,
    72.79202223000175,
    72.78627289500037,
    72.76814887599903,
    72.65066398399904,
    72.58171549100007,
    72.28672067099978,
    72.41640724399986,
    72.39000465200115,
    72.62494819200037,
    72.58811617500032,
    72.68810841699997,
    72.6661132320005,
    72.6165351360014,
    72.73610399599966,
    0.0,
    72.81519742599994,
    72.7734670789996,
    72.71289721099856,
    0.0,
    72.67013687700091,
    72.46811569400052,
    72.73931198000173,
    72.69598407400008,
    72.69250629400085,
    72.67071695600134,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    72.62287758800085,
    72.7457308890007,
    0.0,
    0.0,
    0.0,
    0.0,
    72.37342764300047,
    72.24542984300024,
    72.12386074300048,
    72.18891631200131,
    72.13915121100035,
    72.00825829800124,
    72.00051399899894,
    71.94688408799993,
    71.78685174299972,
    71.90422457800014,
    71.88809458300057,
    71.45578517499962,
    71.44984631599982,
    71.42983912499949,
    71.53051234099985,
    71.41122231199915,
    71.3908423060002,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    71.16238976500063,
    71.04840166000031,
    70.97257446000003,
    71.24773129699861,
    0.0,
    71.10506942199936,
    71.05359897800008,
    70.93549099499978,
    70.93889052099985,
    71.19003727200106,
    71.12102023599982,
    71.05567039999914,
    71.05178783200063,
    71.12085742300042,
    71.05000363999898,
    0.0,
    71.21323426099843,
    71.15185578399905,
    71.09482827700049,
    71.07943994000016,
    70.96990913699847,
    71.19301230600104,
    71.18677933400068,
    71.25364595899919,
    71.091631022,
    71.07275869399928,
    70.98783808499866,
    70.95935068899962,
    0.0,
    0.0,
    0.0,
    70.77084413299963,
    70.76389107799878,
    70.85541824999927,
    70.91862109000067,
    70.90396418099954,
    70.6487252930001,
    70.67110844299896,
    70.85849537099966,
    70.9613483789999,
    70.98638825499984,
    70.94308704600007,
    70.80230238100012,
    70.88039552699956,
    70.99571246400046,
    70.98482843199963,
    70.96543161400041,
    70.96517555300125,
    0.0,
    0.0,
    0.0,
    0.0,
    70.96714936700118,
    70.94290386899957,
    70.89175838799929,
    70.90227137300099,
    70.79811402899941,
    70.87041613800102,
    70.8538019689986,
    70.8109484200013,
    70.75960896600009,
    70.82856939199883,
    70.69605376299842,
    70.82505861699974,
    70.90697916800127,
    71.03265264199945,
    71.02393688700067,
    71.24003642599928,
    70.93751027899998,
    71.17586043699885,
    0.0,
    71.0314481940004,
    70.99266918100147,
    0.0,
    0.0,
    0.0,
    71.42963118099942,
    71.44903316699856,
    71.61226124200039,
    71.55470674900062,
    71.65921390100084,
    71.59070698699907,
    71.52192049099904,
    71.50945209999918,
    0.0,
    72.38546904400027,
    72.59505411099963,
    72.42570218499895,
    72.38428197800022,
    72.26498709600128,
    72.50447607800015,
    72.63918320199991,
    72.5960690360007,
    72.83125681000092,
    72.92841262199909,
    72.79424834600104,
    72.74582878900037,
    72.63661873699857,
    72.70414770500065,
    72.66011714900014,
    72.64700363600059,
    72.62102184500145,
    72.69612401599989,
    72.66269741699944,
    72.6583613469993,
    72.5253098230005,
    72.53123122799843,
    72.62114546700104,
    72.56391258199983,
    72.51772222999898,
    72.52854843100067,
    72.57015851600045,
    72.51728405400172,
    72.62961282099968,
    72.35378325500096,
    72.29758181800025,
    72.36034967199885,
    72.41784663100043,
    72.33488849400055,
    72.15624803500032,
    72.17963552100082,
    72.1756660760002,
    72.28165554299994,
    72.27110544800053,
    72.51379442600046,
    72.50702441100111,
    72.60219915199923,
    72.45739017300002,
    72.41246565100118,
    72.40064116900066,
    72.64657383700069,
    72.64284978000069,
    72.75905644500017,
    72.87408606600002,
    72.78987096399942,
    72.90949191499931,
    72.94559952700001,
    72.93484606999846,
    72.91264738399877,
    73.00371819900101,
    72.99863827000081,
    72.95903079599884,
    72.82788388299923,
    72.62162049499966,
    72.6621155899993,
    72.6441384640002,
    72.6373663989998,
    72.62726159500016,
    72.75538656200115,
    0.0,
    0.0,
    0.0,
    72.49617803399997,
    0.0,
    0.0,
    0.0,
    72.49679066799945,
    0.0,
    0.0,
    72.24625818499953,
    72.6562927670002,
    72.57646435199968,
    72.47691612800008,
    72.3969349880008,
    72.39707444199848,
    0.0,
    0.0,
    0.0,
    72.2133828570004,
    72.17604514800041,
    71.97473535900099,
    71.9690811140008,
    71.87296403599976,
    71.86025774200061,
    71.9620997359998,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    71.82435501600048,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    71.65961857799994,
    71.78192985500027,
    0.0,
    71.46932512300009,
    71.49329713900079,
    71.40267708600004,
    71.36768785900131,
    71.50470572000086,
    71.61327517400059,
    71.68234464600027,
    71.66958765500021,
    0.0,
    72.04452362199845,
    72.26331116499932,
    72.22550768800102,
    72.19465997999941,
    72.18454482699963,
    72.29351086499992,
    72.28844504800145,
    72.27014550999957,
    0.0,
    72.14038240300033,
    0.0,
    0.0,
    72.3311519609997,
    0.0,
    72.19370721799896,
    72.1253401920003,
    72.17851268800041,
    72.1530600850001,
    72.3026514230005,
    72.22053474599852,
    72.31773254200016,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    72.0610951180006,
    72.03186819499933,
    72.03067216999989,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    72.46051014499972,
    0.0,
    0.0,
    0.0,
    72.40449098200042,
    72.33429999800137,
    72.33658256099989,
    72.28413344,
    72.22480378900036,
    72.07439519900072,
    72.0724276309993,
    72.15266745500048,
    0.0,
    72.0464114360002,
    72.16133192599955,
    0.0,
    72.29774987400015,
    0.0,
    0.0,
    72.16809342799934,
    72.15257421599927,
    72.41899260100035,
    0.0,
    72.63402806699924,
    72.67478304200085,
    72.6219395070002,
    72.61002728700078,
    0.0,
    72.48446681200039,
    0.0,
    72.36374916299974,
    72.4261340969988,
    0.0,
    72.359957906001,
    72.25118442500025,
    72.0841210540002,
    72.3295375939997,
    72.22821652399944,
    72.20731377500124,
    72.1899896570012,
    72.14286741000069,
    72.12364328100011,
    71.995954299,
    72.13378795600147,
    72.23883609199947,
    72.18311216300026,
    72.12715312,
    0.0,
    72.01701944600063,
    0.0,
    72.67481218799912,
    72.61654033600098,
    72.59005499699924,
    72.51368970099975,
    72.5053469100003,
    72.29760885799988,
    72.41195152699947,
    72.39120227000058,
    72.2511045350002,
    72.22979074899922,
    72.14247495000018,
    72.39176206499906,
    0.0,
    0.0,
    72.21618182199927,
    72.14494097900024,
    72.10077678099879,
    72.04421282700059,
    72.05705581599977,
    72.12693376800053,
    72.12625727200066,
    72.11651737899956,
    72.07164500600084,
    0.0,
    71.8600727539997,
    71.7369742660012,
    71.82574728799955,
    71.68697681099911,
    71.45829881399914,
    71.32717358700029,
    71.44710381799996,
    71.64144927800044,
    71.63053274899903,
    71.57263276000049,
    71.45106647399916,
    71.55167697199977,
    71.75037604700083,
    71.94519675900119,
    71.88210752899977,
    71.88134400799936,
    71.79714576900005,
    72.06506577900109,
    0.0,
    0.0,
    0.0,
    0.0,
    71.83800766899913,
    71.96705051800018,
    71.96060928599945,
    71.83896195800116,
    72.10418580000078,
    72.0780508959997,
    71.95056719199965,
    71.99926515599873,
    0.0,
    72.06883459100027,
    72.09669996299999,
    72.19149494700105,
    72.15867648200037,
    72.15391754099983,
    72.13608955300151,
    0.0,
    72.16354246500123,
    72.13638416100002,
    72.04946208799993,
    72.09407565500078,
    72.02378595099981,
    72.0926581219992,
    72.05386180799906,
    72.04126733900011,
    72.09767733700028,
    72.17560804400091,
    72.10775815299894,
    0.0,
    72.15772566800115,
    72.141862632001,
    72.08314637399963,
    72.44531849299892,
    72.71170788900054,
    72.76571607799997,
    72.6690412400003,
    72.57548997499907,
    72.55538703099955,
    72.53964268900017,
    72.45378235000135,
    72.48554093500024,
    0.0,
    0.0,
    73.00584659699962,
    0.0,
    0.0,
    72.89598726800068,
    72.88530754000021,
    72.72142462999909,
    72.70027249899977,
    72.673759547999,
    72.65788591199998,
    72.71255346699945,
    72.52873914100019,
    0.0,
    72.39281471899994,
    72.3802558389998,
    72.35247792600057,
    72.33111049099898,
    72.20569601399984,
    72.44901968799968,
    72.52260354999999,
    72.46488224799941,
    72.41040296000028,
    72.40996955300034,
    72.21294933899844,
    0.0,
    72.67469599699871,
    72.79314799199892,
    72.91888549000032,
    0.0,
    72.84832537500006,
    72.97360085199944,
    72.96220092199837,
    73.22174807599913,
    73.3148625419999,
    73.4199153110003,
    73.38146535000124,
    73.2537971640013,
    73.37765898399994,
    73.37254187000144,
    73.35420351200082,
    73.26984301300035,
    73.22998331099916,
    73.17391375799889,
    73.12402304500029,
    72.9784649510002,
    0.0,
    72.81952387199999,
    72.8637652310008,
    72.96291898300115,
    73.14956034500028,
    73.03856519100009,
    73.00539573800052,
    73.04669751800066,
    72.89556721600093,
    72.88316363000013,
    72.87112394500036,
    72.98300621900125,
    72.97309210300045,
    72.96071409599972,
    72.92903218700121,
    0.0,
    72.63140082899918,
    72.5616641329998,
    72.52529014100037,
    72.45471156700114,
    72.57086958999935,
    72.35827897799936,
    72.15619821699875,
    72.09466918199905,
    72.34357080799964,
    72.30443163700147,
    72.13280805900104,
    72.24749350000093,
    72.35362775300018,
    72.43447929700051,
    72.54807280099885,
    72.51747324100143,
    72.39335832699908,
    72.36396667500048,
    72.35861863799983,
    72.62456399700022,
    72.61953197799994,
    72.88329567599976,
    72.90766294399873,
    72.89399261899962,
    73.1071427400002,
    73.05841570200027,
    73.29703279500063,
    73.27179216199875,
    73.21883416299897,
    73.18450048799968,
    73.1752191329997,
    73.27666600999873,
    73.29849533800007,
    73.37132393899992,
    73.36206195600062,
    73.35758933700163,
    73.3320108809985,
    73.42140832800033,
    0.0,
    0.0,
    0.0,
    73.1863226660007,
    73.17598326900043,
    73.09892998400028,
    73.09020168399911,
    73.05139176000012,
    73.12333213999955,
    73.20247806000043,
    0.0,
    0.0,
    0.0,
    0.0,
    73.01102080400051,
    72.983812941,
    72.96703480999895,
    73.04680599600033,
    73.00991875100044,
    0.0,
    0.0,
    73.00557117300013,
    72.96232333300031,
    72.95927264100101,
    72.85829876199932,
    72.90181306399973,
    72.99468996099858,
    72.94601462600076,
    72.81466395199823,
    73.08598936700037,
    0.0,
    0.0,
    73.04631206799968,
    72.98547128199971,
    73.045067432,
    0.0,
    73.18949459299984,
    0.0,
    73.04108642600113,
    73.04023216600035,
    73.16611520100014,
    73.05917216200032,
    73.05631998999888,
    72.93575968000005,
    72.82750229300109,
    72.89144291900084,
    0.0,
    72.91814208100004,
    0.0,
    0.0,
    72.6171673480003,
    72.57399393099877,
    72.6560593969989,
    72.48771321499953,
    72.47158691500044,
    0.0,
    0.0,
    72.6026425529999,
    0.0,
    72.6475410009989,
    0.0,
    0.0,
    0.0,
    0.0,
    72.50678328899994,
    72.49101014299958,
    0.0,
    0.0,
    72.51707290000013,
    72.38983083399944,
    72.50866270099868,
    72.50530775700099,
    72.4296188590015,
    72.23192002499854,
    72.33980298799906,
    72.5094600829998,
    72.47531206200074,
    0.0,
    72.4816122200009,
    72.47252404900064,
    72.46882706600081,
    0.0,
    0.0,
    0.0,
    72.30964155299989,
    72.23793651899905,
    72.12239694199889,
    72.33170496599996,
    72.30641048199868,
    72.57163493900043,
    72.55542290700032,
    72.58130260600046,
    72.55071811800008,
    0.0,
    0.0,
    72.37984969600075,
    72.32548552499975,
    72.31921029499972,
    0.0,
    0.0,
    0.0,
    72.0258758330001,
    0.0,
    0.0,
    72.33625654500065,
    0.0,
    0.0,
    72.3516528880009,
    0.0,
    0.0,
    0.0,
    0.0,
    72.18157669799984,
    72.11030994499924,
    72.21511802700115,
    72.28939300899947,
    0.0,
    0.0,
    0.0,
    71.6223049729997,
    71.43116312599886,
    71.5298119909985,
    71.51180928900067,
    71.61656407200098,
    71.61212142499971,
    71.59083201300018,
    71.6960608570007,
    71.68459763000101,
    71.81292227400081,
    71.8842824659987,
    71.99558264699954,
    71.74649988400051,
    71.68566659399949,
    71.65228034500069,
    71.73336476800068,
    71.70825887299907,
    71.73044371600008,
    71.73000774899992,
    71.67602892700052,
    71.55468415300129,
    71.38962003400047,
    71.3212359829995,
    71.38344554500145,
    71.29882831699979,
    71.28737028299838,
    71.35522335299902,
    71.24210350499925,
    71.16147502100102,
    71.15507718000117,
    71.3790210799998,
    71.37560117599969,
    71.48997444899942,
    71.36122457199963,
    71.27067009799975,
    71.26471751700046,
    71.34465285700026,
    71.25346010499925,
    71.11206090399901,
    71.10716452300039,
    71.06431863000034,
    71.11085468999954,
    70.93792737799959,
    70.72666599799959,
    70.63155602099869,
    70.65232085400021,
    70.56453893400067,
    70.62047496000014,
    70.57509052200112,
    70.82618588599871,
    70.89074628699927,
    71.01629741400029,
    70.8977784689996,
    70.86005116700107,
    70.76334896700064,
    70.892224352001,
    70.89174005799941,
    70.94477967000057,
    70.79974840199975,
    70.74695854299898,
    70.74346601700017,
    70.70474820300115,
    70.69118099200023,
    70.17372774599971,
    70.14513367499967,
    70.04550657000073,
    70.00103640799898,
    70.11265177800124,
    70.19607494699994,
    70.01141140400068,
    70.38670147899938,
    70.35622058399895,
    70.42978886700075,
    70.3495922940001,
    70.47563254899978,
    70.46941275300014,
    70.56683846799933,
    70.53735778800001,
    70.51711964700007,
    70.61719371099935,
    70.55519024599926,
    70.50622837999981,
    70.327243533,
    70.45391518900033,
    70.57201703200008,
    70.5482875939997,
    70.505731792,
    70.48094823099927,
    70.46090863099926,
    70.38990871799979,
    70.31098830600058,
    70.23927148700022,
    70.19647248000001,
    70.18142541099951,
    70.14442672100085,
    70.12443044599968,
    70.10802918000081,
    70.09924004099958,
    70.09562728700075,
    70.16757677600071,
    70.14631782600009,
    70.01594378699883,
    70.14179709000018,
    69.96808431799946,
    70.21007492299941,
    70.0462270070002,
    70.15686795699912,
    70.16579039600038,
    70.22698565199971,
    70.31987730000037,
    70.28188993599906,
    70.37792278500092,
    70.36377715399976,
    70.27247637400069,
    0.0,
    0.0,
    0.0,
    69.9745141530002,
    0.0,
    0.0,
    69.95312296300108,
    69.85963755400007,
    69.76597039199987,
    69.75738564200037,
    69.56021542300005,
    69.50363893600115,
    69.49539609800013,
    69.63130765200003,
    69.75137323700073,
    69.61641150799915,
    69.60905437399924,
    69.72208396300084,
    69.69877918800012,
    69.59432960800041,
    69.444554574,
    69.40763626999978,
    69.40105531200061,
    69.24082773200098,
    0.0,
    0.0,
    69.283556503,
    69.24991231200147,
    69.22987123800158,
    69.3545157110002,
    0.0,
    69.31615480499931,
    69.412945778,
    0.0,
    69.2075496080015,
    69.17561718199977,
    69.1668313930004,
    69.1152557080004,
    69.06463200799953,
    69.17073316999995,
    69.00814245500078,
    69.16334055100015,
    69.23616164800114,
    69.42140224899958,
    69.67861379200076,
    69.64337489699938,
    69.58160079800109,
    69.78487455200047,
    69.74090937499932,
    0.0,
    0.0,
    0.0,
    69.60528166599943,
    69.5956147830002,
    0.0,
    69.56940713699987,
    69.5482199579983,
    69.57641912200052,
    69.39779410600022,
    69.36788261200127,
    69.33169800699943,
    69.30439898700024,
    69.31984454100166,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    68.94680435400005,
    0.0,
    68.88054707800075,
    68.87666592999994,
    0.0,
    0.0,
    0.0,
    68.86793910699998,
    68.75139255800059,
    68.69366330899902,
    68.80330241699994,
    0.0,
    68.62724909999997,
    68.7222667850001,
    0.0,
    68.58521187899896,
    0.0,
    0.0,
    68.50334143200052,
    68.46741006400043,
    68.54933218699989,
    68.52978701999928,
    68.6334909319994,
    68.62545921199853,
    68.66411751899977,
    68.92930828400131,
    68.83604023299995,
    68.92091231400082,
    69.03460356699907,
    69.00263742599964,
    0.0,
    0.0,
    0.0,
    0.0,
    69.03658857499977,
    69.0051320829989,
    69.07341721899866,
    0.0,
    69.2945592770011,
    69.24402716100121,
    68.98624490900147,
    68.8710487190001,
    68.94693755799926,
    0.0,
    0.0,
    0.0,
    68.86669095999969,
    0.0,
    0.0,
    0.0,
    68.96802618400034,
    0.0,
    0.0,
    68.83835075699972,
    0.0,
    68.7039313239984,
    68.94074211499901,
    0.0,
    68.74857650099875,
    68.7443319390004,
    68.74192249899897,
    68.81117418100075,
    68.71724919899862,
    68.66027620000023,
    68.52423193100003,
    68.49387899700014,
    68.43470516299931,
    68.4285043660002,
    68.67446104599912,
    68.75935663599921,
    68.69834878899928,
    68.68230124399997,
    68.6558832619994,
    68.60222572999919,
    68.55324861300141,
    68.51454394100074,
    68.603091717001,
    68.58155789599914,
    68.5360387769997,
    68.44629443099984,
    68.68360728000152,
    0.0,
    68.6156885319997,
    0.0,
    0.0,
    68.53338278000047,
    68.23833695299982,
    68.19533314799992,
    68.46682120200057,
    68.39280048,
    68.39078512100059,
    68.37725117700029,
    68.29205652100063,
    68.28458653800044,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    67.88820529200166,
    67.99936248700033,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    68.4555193819997,
    68.39154161899933,
    68.32956656399983,
    68.43226362899986,
    68.55364315099905,
    68.5353166219993,
    68.41324408699984,
    68.37081797499923,
    68.3879346850008,
    68.63555180099866,
    68.62545129000137,
    68.62444835899987,
    0.0,
    68.20173632099977,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    67.75079196099978,
    67.85750621999978,
    0.0,
    67.8350982789998,
    0.0,
    0.0,
    0.0,
    67.94820096299918,
    68.04506489599953,
    0.0,
    0.0,
    67.71923209899978,
    67.70357302000048,
    0.0,
    0.0,
    0.0,
    67.44213624700024,
    67.41133219200128,
    67.44112984300045,
    0.0,
    67.33243004500036,
    67.23309444300139,
    67.13428272000056,
    67.17842621700038,
    67.10450671400031,
    0.0,
    66.95350658900134,
    0.0,
    0.0,
    0.0,
    66.6823445709997,
    0.0,
    66.59610810000049,
    66.42010312499951,
    66.50036105899926,
    66.42769441700148,
    66.51372130299933,
    66.4403772379992,
    66.41473933999987,
    66.5239007909986,
    66.49700705800024,
    66.74967217199992,
    66.85518588899868,
    66.83115861900114,
    66.84170666499995,
    66.77720710200083,
    66.77239989600093,
    66.84120649400029,
    66.86687026600157,
    66.86335593200056,
    0.0,
    67.53940419099854,
    67.2515940379999,
    67.14057538600173,
    67.11848378500144,
    67.2456783889993,
    67.21722293300081,
    67.2116598699995,
    67.28810721899936,
    67.59462649700072,
    67.57786161100012,
    67.56625617399914,
    67.54031990600015,
    67.66612397799872,
    67.56782346699947,
    67.40865461700014,
    67.48670828899958,
    67.48147797399906,
    67.40810071300075,
    67.31523456200011,
    67.43591369499882,
    67.40889859399977,
    67.5291575400006,
    67.58682306499941,
    67.5854143659999,
    67.568706869999,
    67.48219518299993,
    67.37304816400137,
    67.29517647099965,
    67.17215059400041,
    67.287795663,
    67.12804917500034,
    67.21498649900059,
    67.47288207800011,
    67.46844641400094,
    67.58486038000046,
    67.54724627999894,
    67.42466338700069,
    67.50447311500102,
    67.61759903599886,
    67.51118233099987,
    67.56879412799935,
    67.2426412929999,
    67.17442877299982,
    67.17549877500096,
    67.13437615300063,
    67.05361910799911,
    66.96605502700004,
    67.22683240399965,
    67.21571892400061,
    67.1677599959985,
    67.03833387099985,
    66.98124227800145,
    66.84573247200024,
    66.89150218500072,
    66.85112071600088,
    66.81576195600064,
    66.81332999799997,
    67.04836008600068,
    66.94038058500155,
    66.92211207400032,
    66.89946784600033,
    66.79607745300018,
    66.72181697300039,
    66.71019846099989,
    66.66860149700005,
    66.62641524300125,
    66.58457907899901,
    66.44163323599969,
    66.30720815799941,
    66.42210657599935,
    66.28379580799992,
    66.4955658609997,
    66.40868427600071,
    66.46081229099946,
    66.38355947199852,
    66.24749005999911,
    66.23284510600024,
    66.4486689230016,
    66.44176326400157,
    0.0,
    66.8628135229992,
    66.83799127299972,
    66.82215043700126,
    66.78688982899985,
    66.89083882799969,
    66.97291599500022,
    67.16600035699958,
    67.14600197900108,
    67.12195618000078,
    67.22065632799968,
    67.20457650499884,
    67.32825419300025,
    67.27323667500059,
    67.28718271599973,
    67.39216646000023,
    67.66045406199919,
    67.65809052600162,
    67.34602559199993,
    67.33718318499996,
    67.2965429800006,
    67.61693091699999,
    67.60158211599992,
    67.7685649490013,
    67.75085891500021,
    67.70824604599875,
    67.8252105570009,
    67.80644861300061,
    67.77422245299931,
    67.76974520600015,
    67.76004468200153,
    67.83789617900038,
    67.77286881799955,
    67.69935743599854,
    67.90638551499978,
    67.9498599360013,
    67.93719059599971,
    67.90012072399986,
    67.9837748050013,
    67.74733210699924,
    67.72722270400118,
    67.62891254199894,
    67.58774463200098,
    67.48570603500048,
    67.45754398999998,
    67.3080676619993,
    67.42724816100053,
    0.0,
    67.85303208100049,
    67.84964564499933,
    67.9452237960013,
    67.85381216599853,
    67.83977866200075,
    67.79909376100113,
    67.67229496499931,
    67.64322286199967,
    67.75025002700022,
    67.88592473000062,
    67.83226177600045,
    67.79925478199948,
    67.89628185000038,
    67.71300785999847,
    67.82358240599933,
    67.77945850000106,
    67.68860660899918,
    67.63077040499957,
    67.71153074799986,
    67.64943110999957,
    67.63415534399974,
    67.68938038700071,
    67.71329287799927,
    67.69682339099927,
    67.79103625899916,
    67.89203020999958,
    67.9999519940011,
    68.11692515199866,
    68.04478826600098,
    68.03117919000033,
    68.24993703200016,
    68.23271805999866,
    68.2219278119992,
    68.20086881200041,
    68.43431790700015,
    68.42338652000035,
    68.28837138000017,
    67.98717528999987,
    67.9525685710014,
    67.91848656299953,
    68.00172158799978,
    68.1929962489994,
    68.06572454099842,
    67.97408529200038,
    0.0,
    67.95721053099987,
    67.97581572699892,
    67.91112834100022,
    68.03362340399872,
    68.1557456139999,
    67.92412207599955,
    67.9121700680007,
    68.02781674300059,
    67.98558362900076,
    67.92884426700039,
    67.92165278000175,
    67.79551388900109,
    67.91052320400013,
    67.85279106300004,
    67.80882655999994,
    67.8068516330004,
    68.07375141599914,
    67.986362525,
    68.24772960799964,
    68.14434912300021,
    68.26700196400088,
    68.29882792400167,
    68.35804538800039,
    68.34419958699982,
    68.41763915900083,
    68.40644840300047,
    68.37097481399906,
    68.49445625199951,
    68.37995967699862,
    68.31376953200015,
    68.27114966800036,
    68.21553522899922,
    68.159840024,
    68.24348814299992,
    68.21228297200105,
    68.2102403939989,
    68.25615424199896,
    68.2979381389996,
    68.20363084199926,
    68.14902249100123,
    68.04097916799947,
    68.06744893399991,
    68.02100051200068,
    68.01164341200092,
    68.08522881499994,
    68.06818756900066,
    0.0,
    68.62606881600004,
    68.54632172799938,
    68.5305116569998,
    68.51683014300033,
    68.43553213499945,
    68.37534978599979,
    68.510425425,
    68.55804270899898,
    68.53154769399953,
    68.5188553930002,
    68.44185204399946,
    68.38757172899932,
    68.43449847999909,
    68.42385837700022,
    68.5113889180011,
    68.50812172900078,
    68.46494896699915,
    68.4299034759988,
    68.50643526100066,
    68.48294515499947,
    68.37704124499942,
    68.37349708500005,
    68.63311512200016,
    0.0,
    69.31315938800071,
    69.43500411700006,
    69.39984905300116,
    69.5201425310006,
    69.49476362400128,
    69.48732148800082,
    69.45282502099872,
    69.42812081900047,
    69.51345472200046,
    69.47054851299981,
    69.41551213599996,
    69.4146962220002,
    69.36742168199999,
    69.42740380800024,
    69.40961939099907,
    69.5079508430008,
    69.5032012899992,
    69.54462881799918,
    69.49431290200118,
    69.56543221999891,
    69.49039593099951,
    69.61374593300025,
    69.61042365700087,
    69.48595002099864,
    69.48511989000144,
    69.4700643239994,
    69.34278501500012,
    69.46092135900108,
    0.0,
    70.42710292899937,
    70.2479466420009,
    70.12466301299901,
    70.36753340399991,
    70.4759435119995,
    70.41775833300017,
    70.34292423899933,
    70.45304759899955,
    70.36950622800032,
    70.34780948400112,
    70.28135424600077,
    70.24776286299857,
    70.27935749599965,
    70.09648364399982,
    70.07104475500091,
    70.03528338099932,
    70.27204050999899,
    70.31336430999909,
    70.08017594699959,
    70.0776268339996,
    69.90898136700162,
    69.89936949700132,
    69.83897827799956,
    70.07619581699873,
    70.20225194699924,
    70.31750907499918,
    70.28630171000077,
    70.39277037300053,
    70.36136602599981,
    0.0,
    70.26700476100086,
    70.2231294409994,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    69.88412596800117,
    0.0,
    0.0,
    69.68806375500026,
    0.0,
    69.60434720900048,
    0.0,
    0.0,
    0.0,
    0.0,
    69.45184514500033,
    69.41150973700132,
    0.0,
    69.25471437300075,
    0.0,
    69.56393498000034,
    69.27769404300125,
    69.20156959700034,
    69.27315262900083,
    69.15938612399987,
    69.13358224500007,
    69.2068031380004,
    69.21907154299879,
    69.19604794500083,
    69.12353556299968,
    69.11352478899971,
    69.0837245799994,
    68.99285880999923,
    69.11323746099879,
    0.0,
    68.96658365300027,
    68.82177627000056,
    68.71205300400106,
    68.6924911820006,
    68.75485533400024,
    68.71376819800025,
    68.55154718800077,
    68.63810636299968,
    0.0,
    68.6368194229999,
    68.52931917800015,
    68.48264404399924,
    68.54253933099972,
    68.48173408300136,
    68.54529067600015,
    68.52425380000022,
    68.43752857599975,
    68.55586666999989,
    68.41429083500043,
    68.50505152900041,
    68.36924537400046,
    68.44059851200109,
    0.0,
    68.83346425199852,
    68.82325462600056,
    69.01160708300085,
    68.9888135630008,
    69.11145282500001,
    69.012803136,
    69.0065985709989,
    69.09779134000019,
    69.08522953400097,
    69.0687394259985,
    69.06295339400094,
    69.10406963999958,
    69.20065086999966,
    69.17059248300029,
    69.03362133800147,
    69.39779207599895,
    69.29803542599984,
    69.15807199399933,
    69.10540871299963,
    68.82197481000003,
    68.94258406399967,
    68.90150943199842,
    68.84370545799902,
    68.93206414499946,
    68.82339976600088,
    69.06503940499897,
    68.97125286899973,
    68.92162276400086,
    68.90214663000006,
    68.8712049980004,
    68.98554008100109,
    68.94823790699957,
    68.76436755199938,
    68.87417136600016,
    68.81630340400079,
    68.75022590200024,
    68.69770274800067,
    68.79288033100056,
    68.74391235099938,
    68.7383916810013,
    68.72118882099858,
    68.78922899099962,
    68.77246341200043,
    68.9543647240007,
    68.94335854699966,
    68.81941611500042,
    68.91215387500051,
    68.77016118200117,
    68.75523159799923,
    68.84061137000026,
    68.80362119600068,
    68.77653895600088,
    68.75534607599911,
    68.98670312899958,
    69.09259948999897,
    69.32497541200064,
    69.2131623589994,
    0.0,
    68.98969145699994,
    68.95922339299977,
    69.17389628400088,
    69.15968526299912,
    0.0,
    69.03695694499947,
    0.0,
    0.0,
    68.81644924600005,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    68.43221088999962,
    68.42980962599904,
    68.53405540499989,
    68.49223303100007,
    0.0,
    68.33067858600043,
    0.0,
    0.0,
    68.4282026460005,
    68.40716403700026,
    68.36211955599902,
    68.35229655299918,
    68.37857428799907,
    68.62325400699956,
    68.49453550900034,
    68.71893704699869,
    68.61996285600071,
    68.87332090199925,
    68.83566477000022,
    68.67593110500093,
    0.0,
    0.0,
    0.0,
    68.49067811199893,
    68.40277588000026,
    68.52214608699978,
    68.54774999899928,
    68.4763063549999,
    68.49099029200079,
    68.46989239599861,
    68.34531956700084,
    68.34106512899962,
    68.1821691840014,
    67.96532062900042,
    68.0732924469994,
    68.05308372500076,
    68.1701034760008,
    68.14155033799943,
    67.98118570500083,
    67.97996016399884,
    67.91284332900068,
    68.03949315800128,
    67.95869593200041,
    67.93140395400042,
    68.00791511600073,
    67.95887622699956,
    68.23292295300053,
    68.2026288220004,
    68.09869234299913,
    67.95089475799978,
    67.9017922740004,
    67.79658280000149,
    67.88816227500138,
    67.93882287199995,
    67.92980983599955,
    67.99254975400072,
    67.83550638499946
  ],
  "itls": [
    0.005687467368452896,
    0.0029110195216913858,
    0.0023637533328534723,
    0.13233232666667996,
    0.13378649505883752,
    0.13291166741661678,
    0.1338606389999768,
    0.13427539433329608,
    0.1347138737143853,
    0.1351581200002069,
    0.13434033127272083,
    0.13391443925002022,
    0.13174224585704256,
    0.13196665375016892,
    0.14093739366665733,
    0.13171896899984858,
    0.13396360566649593,
    0.13950581774997772,
    0.14141956565387004,
    0.14279962771425267,
    0.14279962771425267,
    0.14811153492309342,
    0.14811153492309342,
    0.14781617624998944,
    0.14781617624998944,
    0.134729818000172,
    0.14399836410002537,
    0.13860988830302548,
    0.15354955044454577,
    0.1447192088333193,
    0.1487801160831926,
    0.1410693136000191,
    0.15180485000018962,
    0.13957432340276277,
    0.13957432340276277,
    0.134062578999975,
    0.134062578999975,
    0.1324603359989851,
    0.13844857349977246,
    0.13727662187488932,
    0.13846400400052516,
    0.13488319290471346,
    0.13331920499967964,
    0.1365455566668364,
    0.13422795224994388,
    0.13422795224994388,
    0.13693195839999436,
    0.1361756388332651,
    0.14236353899953733,
    0.13574018586950842,
    0.13736723333325548,
    0.13727492633339958,
    0.1407867392499611,
    0.1407867392499611,
    0.13505191210520265,
    0.1336421260000082,
    0.13745689773529246,
    0.13158798200007973,
    0.13158798200007973,
    0.1316071632223207,
    0.1316071632223207,
    0.13145660440022766,
    0.13379651590912545,
    0.1376415682083234,
    0.1376415682083234,
    0.13764156662261295,
    0.13626421199998934,
    0.13516588499998547,
    0.13516588499998547,
    0.13791256257694,
    0.1365236009999838,
    0.1365236009999838,
    0.13494387955567314,
    0.1299275266665063,
    0.1337600819997533,
    0.1363144866154471,
    0.1356415840000409,
    0.1370629457999712,
    0.13606702362494616,
    0.13624393220015918,
    0.13673575845004962,
    0.13788040383333283,
    0.1372329830000025,
    0.13689725715392762,
    0.13786263820002204,
    0.13498190800055454,
    0.13498190800055454,
    0.13955186200000752,
    0.13126848925003287,
    0.13182857299943862,
    0.13182857299943862,
    0.13897616984377237,
    0.13897616984377237,
    0.13752827964708558,
    0.13712879552943325,
    0.13728988146151375,
    0.13680650249989412,
    0.138267726399863,
    0.13649503950000508,
    0.13713115919999835,
    0.13806726999993973,
    0.1375207267501537,
    0.13759164214293595,
    0.13759164214293595,
    0.13837962189991232,
    0.13959584583335527,
    0.13959584583335527,
    0.13372202000027755,
    0.13372202000027755,
    0.143981834000139,
    0.14164749266698587,
    0.14061703799998213,
    0.14194998153848595,
    0.14194998153848595,
    0.14041545681803572,
    0.14041545681803572,
    0.13661021600000822,
    0.13793368896554528,
    0.13358382849946793,
    0.1384861425555115,
    0.14164928733331786,
    0.1449359253332053,
    0.13492966399947667,
    0.14307635690001916,
    0.14107058491663338,
    0.14107058491663338,
    0.13718531805968825,
    0.06909150000046793,
    0.12864627772220652,
    0.1374042745762797,
    0.13739360167796727,
    0.1356817531428706,
    0.1354836334285643,
    0.13754839300013877,
    0.1354122464286515,
    0.1275720840003487,
    0.1275720840003487,
    0.13854917842867767,
    0.13854917842867767,
    0.13718636007699667,
    0.1401787352858394,
    0.13506188544997713,
    0.13863631640015228,
    0.13872883049998563,
    0.1366734845556089,
    0.14094657216658865,
    0.14094657216658865,
    0.1329860405217598,
    0.13882426750024024,
    0.13882426750024024,
    0.13229268020004384,
    0.13248903438094808,
    0.13248903438094808,
    0.13250472731249374,
    0.13236224668425597,
    0.13148020614283137,
    0.1348783923666512,
    0.1348783923666512,
    0.13747365014584526,
    0.13246967721430078,
    0.13283913088889676,
    0.13283913088889676,
    0.1371705330937516,
    0.1371705330937516,
    0.1328831612728126,
    0.1331922339995799,
    0.1303227319999678,
    0.13280235609090596,
    0.13175483244453468,
    0.13087727099991753,
    0.1331911785554338,
    0.13285326849927515,
    0.13652348083996912,
    0.13277241549985774,
    0.13287848549983514,
    0.13882008122219405,
    0.13332890992303595,
    0.13079050200030906,
    0.13169463466692832,
    0.13169463466692832,
    0.13512399319988616,
    0.1335051173636285,
    0.13309782508334442,
    0.13800649397725548,
    0.14013768374195112,
    0.13977817384375157,
    0.13758080609520784,
    0.1338440671999706,
    0.13698435287494704,
    0.13765636728567188,
    0.1339485094000338,
    0.13717649820000588,
    0.14349590500023623,
    0.13241370187506618,
    0.1323629313999845,
    0.13681320037314654,
    0.1423616594166409,
    0.1373627887868843,
    0.14000597999984166,
    0.12994123399948876,
    0.1400988869166516,
    0.13958526762485235,
    0.14216876116673424,
    0.1436699249999947,
    0.14084440714291954,
    0.14115281644444622,
    0.14115281644444622,
    0.1442297623572293,
    0.14426518435720936,
    0.14611152230008884,
    0.14611152230008884,
    0.13895159899993814,
    0.13818945757894222,
    0.13904812300006597,
    0.14220862250022037,
    0.14220862250022037,
    0.14459142607693837,
    0.14459142607693837,
    0.1464227988888322,
    0.14402064136365053,
    0.15246642914280528,
    0.13913893808338193,
    0.13913893808338193,
    0.13337207914290566,
    0.1333792791429005,
    0.13362587633370518,
    0.13362587633370518,
    0.1333002580001145,
    0.1320868162501938,
    0.13404311822230536,
    0.13407269300000085,
    0.13189311033299114,
    0.13413580343242487,
    0.13169662099971902,
    0.13411775679996935,
    0.13437121337500457,
    0.1343055266667458,
    0.1294685920001939,
    0.13458956747370776,
    0.1340103579285434,
    0.13531029169989778,
    0.13488376199992755,
    0.13488376199992755,
    0.13002586940019684,
    0.13002586940019684,
    0.13243859699991845,
    0.13243859699991845,
    0.13424135775996546,
    0.1283387009998478,
    0.13302393699996173,
    0.13463585107144485,
    0.13431760646157132,
    0.13420515536365035,
    0.1331867605000904,
    0.13459226585000578,
    0.13592768174999037,
    0.1350352850217662,
    0.13459931776188092,
    0.13530203542852956,
    0.13598957487511143,
    0.1338157825555552,
    0.13396771371429037,
    0.133610469294153,
    0.13396973428565875,
    0.13343962733324588,
    0.13581995985701464,
    0.1366907970000284,
    0.13452910499957701,
    0.13662181724976108,
    0.13662181724976108,
    0.13553651216655757,
    0.13593153420006274,
    0.13593153420006274,
    0.13565960533317897,
    0.14183496100122284,
    0.1343677339000351,
    0.13437506688237857,
    0.13416832046665755,
    0.1346172356667618,
    0.13153577699995367,
    0.1346185868311862,
    0.1353874430005817,
    0.134691509424988,
    0.12973699000031047,
    0.13490747553847682,
    0.1341274122608846,
    0.13611293353333168,
    0.13472788844450811,
    0.1346665157143434,
    0.13658444566681283,
    0.13537000150017775,
    0.13537568684005236,
    0.13513411362509942,
    0.1334601062500269,
    0.13342588793750565,
    0.13416451855563435,
    0.13413302510525682,
    0.13413302510525682,
    0.13488918580005702,
    0.13544698035712782,
    0.13577795349920052,
    0.13564485670834378,
    0.1318617981251009,
    0.1286142765002296,
    0.1286142765002296,
    0.1332007685001372,
    0.13284774599924276,
    0.13600044299999825,
    0.1339535508182466,
    0.12893483933354824,
    0.1340839574000711,
    0.13355129436372823,
    0.13424779358335096,
    0.1363443457179155,
    0.13333237949996146,
    0.13539237734524553,
    0.13809509217646657,
    0.13809509217646657,
    0.13355209099972853,
    0.13355209099972853,
    0.13611282490477433,
    0.13573282229990583,
    0.1366541882564492,
    0.13900017093749284,
    0.13821892666682187,
    0.1427464990010776,
    0.13914278999982344,
    0.13675287745453799,
    0.14165757266669565,
    0.14380579733339496,
    0.13656533821047465,
    0.13656533821047465,
    0.1366492447499695,
    0.135956056772722,
    0.13614942205554648,
    0.13614942205554648,
    0.13315669933323684,
    0.13633414699870627,
    0.13430448594283786,
    0.13430448594283786,
    0.13224993200128665,
    0.134356017483902,
    0.13135791299996177,
    0.13140766216671787,
    0.13140766216671787,
    0.13380534649998785,
    0.13380534649998785,
    0.1352730681891862,
    0.13467245960018773,
    0.13491872104168579,
    0.13578456733335365,
    0.13224005733324398,
    0.13526498575004098,
    0.13526498575004098,
    0.13158195527284988,
    0.13050515024997367,
    0.133324136166569,
    0.12903492725035903,
    0.12903492725035903,
    0.12831076700058475,
    0.12930622800013225,
    0.13470373912499176,
    0.13677459416673324,
    0.1368344131666769,
    0.12847377099994142,
    0.13411541592309872,
    0.12996563460001198,
    0.12982890539969957,
    0.12982890539969957,
    0.13213829114283726,
    0.13647587299991365,
    0.13752599199991286,
    0.13165090500024235,
    0.12764098200023,
    0.1386015211251106,
    0.1296819350000078,
    0.13974502149994805,
    0.1355732453333379,
    0.13617998150039057,
    0.14144091250000201,
    0.13607533043750664,
    0.13700557346661904,
    0.14098876277764955,
    0.1366169464736949,
    0.1366169464736949,
    0.1321485045384459,
    0.1321485045384459,
    0.1337629959998594,
    0.12852510650009208,
    0.13517755983333093,
    0.13190626539981168,
    0.13209738779987673,
    0.1321286640000339,
    0.1321286640000339,
    0.13216525399994597,
    0.1307038429986278,
    0.1312457966250804,
    0.1312457966250804,
    0.1324028779999935,
    0.1324847381665677,
    0.13292851679998421,
    0.13233881878568354,
    0.13572993205659414,
    0.13572993205659414,
    0.13572993205659414,
    0.13411017150019688,
    0.13411017150019688,
    0.13195065255563854,
    0.13377886649993798,
    0.13456794488460078,
    0.13641270341538006,
    0.1360578858048695,
    0.13568147722223026,
    0.13568147722223026,
    0.13606160852054616,
    0.13606160852054616,
    0.13394533157121,
    0.1357048890000442,
    0.13499932427277433,
    0.13470307833328357,
    0.13541465829994195,
    0.13577791441669737,
    0.13634134914276988,
    0.13556244888887806,
    0.13556244888887806,
    0.13541096700009803,
    0.13779125796078434,
    0.13735029242837168,
    0.13735029242837168,
    0.1373316962856604,
    0.13373371499983477,
    0.13708025229995352,
    0.1367479720605788,
    0.13644664124997993,
    0.13644664124997993,
    0.13646523222221865,
    0.13803538766690812,
    0.1352674689997002,
    0.13781300133329447,
    0.1350188248889026,
    0.1349007852500108,
    0.13664880674197424,
    0.12801798100008455,
    0.13460043577773226,
    0.1336352131998865,
    0.1336352131998865,
    0.1338691093333182,
    0.13870870099994395,
    0.1367843527499796,
    0.13705816515385566,
    0.13688187758331574,
    0.1361103416249989,
    0.13665242722224016,
    0.1386360125002284,
    0.14001224263632717,
    0.13952781188891095,
    0.13895895989990095,
    0.13632675700137042,
    0.13864465666665637,
    0.13872703784615553,
    0.1388934997142834,
    0.13490594299992154,
    0.1367000349545461,
    0.13780964877777377,
    0.13728389059979235,
    0.13773186122226536,
    0.13641499814275448,
    0.13666263446672625,
    0.1416913275999832,
    0.1364779826665957,
    0.1379908204515584,
    0.13541284650000307,
    0.1387237761000506,
    0.1387237761000506,
    0.14343812025026637,
    0.14343812025026637,
    0.13433615020003345,
    0.13433615020003345,
    0.136313026777619,
    0.13759029733334197,
    0.1372614151200105,
    0.1372614151200105,
    0.13434943350909057,
    0.1376981337142795,
    0.13395180645589147,
    0.13395180645589147,
    0.1415185127998484,
    0.1415185127998484,
    0.14408378200018238,
    0.1345689970392271,
    0.13553297125008612,
    0.14356927139997425,
    0.14356927139997425,
    0.1351152912105279,
    0.13442548984994573,
    0.1354859763329538,
    0.13687418437507404,
    0.14472216100148216,
    0.1447587900001963,
    0.13388888494110313,
    0.13388888494110313,
    0.13247103176917546,
    0.13247103176917546,
    0.1329240608749842,
    0.1331199339995995,
    0.13256851622221197,
    0.13178750800034322,
    0.13178750800034322,
    0.13185761800014006,
    0.13185761800014006,
    0.13095643850010674,
    0.13289543322227676,
    0.1325370636551615,
    0.13322037954170204,
    0.12957154149989947,
    0.13269189160006742,
    0.1287873139990552,
    0.13679559649972362,
    0.13283716422221106,
    0.1314750653750707,
    0.13176670012489922,
    0.13267640499980188,
    0.13270139360029135,
    0.1317708988749473,
    0.13223068845159544,
    0.1275486960003036,
    0.134448536999943,
    0.134448536999943,
    0.13288109738894288,
    0.13203752673080787,
    0.1321270901111415,
    0.1329108332940771,
    0.13203790100033075,
    0.13203790100033075,
    0.13226176624993968,
    0.13256998313336227,
    0.13203736233299423,
    0.13261317327780692,
    0.13484988542846363,
    0.13484988542846363,
    0.13295147099961468,
    0.13229528966667203,
    0.13261180431372316,
    0.1339291428889232,
    0.13258045081249747,
    0.13405976309083847,
    0.1394459573336159,
    0.1322643735861518,
    0.13037835550039745,
    0.12978020700029447,
    0.13140577712488266,
    0.13140577712488266,
    0.13134501944437538,
    0.13196241834998546,
    0.13196241834998546,
    0.13767363799979648,
    0.13161674377269347,
    0.14628482199987047,
    0.13164133973916012,
    0.13081635438454844,
    0.13093028531250184,
    0.1290982940000421,
    0.13192224449994683,
    0.13064526377759952,
    0.13210924375005106,
    0.1315272691935529,
    0.1315272691935529,
    0.12973249799961195,
    0.12973249799961195,
    0.13146623674992952,
    0.13292614475471534,
    0.1315799301817771,
    0.12873068950011657,
    0.12958116800005623,
    0.12940527579994524,
    0.13224148999870522,
    0.13241598313889982,
    0.1294006772001012,
    0.13229469260872778,
    0.13165265026667233,
    0.13247949427270875,
    0.13247949427270875,
    0.12964587839996966,
    0.13301276888887514,
    0.13301276888887514,
    0.1297813450000831,
    0.1297813450000831,
    0.13199857979998342,
    0.13270084283324954,
    0.132043497809545,
    0.13275609058337068,
    0.13275609058337068,
    0.13412328220001654,
    0.132750685321428,
    0.13391928966666455,
    0.13302875550006218,
    0.13621694025005127,
    0.1334386202001042,
    0.13387981574987862,
    0.13296054844002356,
    0.1342141889999766,
    0.13199031110535112,
    0.13498547519993737,
    0.13114110924993838,
    0.13114110924993838,
    0.13106575600016054,
    0.13106575600016054,
    0.13155844466673444,
    0.13806099000066752,
    0.13058589566652598,
    0.1309111678570584,
    0.1316051009444992,
    0.12972424649979075,
    0.13110144050006056,
    0.13110144050006056,
    0.13052112437503638,
    0.1344607242698412,
    0.135137618999579,
    0.1327116170000141,
    0.13115798000035284,
    0.13167004716660813,
    0.1356446195004537,
    0.1320971439999994,
    0.13324568224134994,
    0.13145604938458397,
    0.13196115299979283,
    0.13155415133324924,
    0.13239189249998162,
    0.12912752750071377,
    0.1332584480769583,
    0.13108140933339504,
    0.13501225549572332,
    0.13377191714816608,
    0.13129398644438575,
    0.13125645633347935,
    0.13099430316651706,
    0.1338548892856904,
    0.13183090742833364,
    0.1388142420000804,
    0.1388142420000804,
    0.1340210143461473,
    0.13012405100016622,
    0.13495753577768077,
    0.1347868443333482,
    0.13459556171431228,
    0.13509972846873097,
    0.13509972846873097,
    0.13396092725042763,
    0.13439081230008015,
    0.13490254996150514,
    0.13518495714283962,
    0.13471657659999134,
    0.13471657659999134,
    0.14006356733322414,
    0.13525082072641761,
    0.13490878948572832,
    0.1308636301997467,
    0.13416850693749893,
    0.13468992381819012,
    0.13033876033356742,
    0.13489887315378069,
    0.1351101168571144,
    0.1313649460007582,
    0.1313649460007582,
    0.13551027023688794,
    0.13463426073334026,
    0.13575276966664454,
    0.13508398390004003,
    0.13579658085706928,
    0.134425774374904,
    0.1359531282500029,
    0.13756064349990993,
    0.13572853985689498,
    0.13568016000014418,
    0.13566201589744126,
    0.13632919480005512,
    0.1344307309999959,
    0.1345131964999382,
    0.13565868071418663,
    0.1307244460003858,
    0.1355808201426823,
    0.13575799400002456,
    0.13427301371432673,
    0.13615230480027093,
    0.13551434821420116,
    0.12478978799845208,
    0.13635596899985103,
    0.13591295406895998,
    0.13582308033331478,
    0.1353635364444522,
    0.13434965241670702,
    0.13434965241670702,
    0.13574992239991843,
    0.13540151249981136,
    0.13475430207696404,
    0.1354397309999816,
    0.13469655930002772,
    0.1368263439999282,
    0.13609744916660324,
    0.13489121592451653,
    0.13750393775035263,
    0.1402148990000569,
    0.1402148990000569,
    0.1378911043077376,
    0.13592096611116883,
    0.13592096611116883,
    0.1316322799993941,
    0.13165762099924905,
    0.1388219163331491,
    0.13654167845445705,
    0.13506100317143657,
    0.13777153322209618,
    0.1376872364443342,
    0.1349315390952619,
    0.13430676917245177,
    0.1348129397727627,
    0.14213612519997695,
    0.1356433269473583,
    0.1356433269473583,
    0.13343658999959493,
    0.13236595386209454,
    0.13489199121740175,
    0.13462078433339128,
    0.13403752241025266,
    0.13200999420005247,
    0.13164511080012745,
    0.1318409804000112,
    0.1318409804000112,
    0.1326855637501012,
    0.1326855637501012,
    0.13668282733306114,
    0.1341469247631482,
    0.1341469247631482,
    0.13448890283325454,
    0.13628123650050838,
    0.1352546904098312,
    0.1318638308000421,
    0.13594882000052166,
    0.13188141293333805,
    0.13206888361118116,
    0.13206888361118116,
    0.13203609364284472,
    0.13080670079998527,
    0.13307091275009952,
    0.13237962600032915,
    0.13133497857156076,
    0.13155984410004748,
    0.13352343311998993,
    0.1330159873335409,
    0.13134323022232922,
    0.13134323022232922,
    0.1323849299988069,
    0.13559753949994047,
    0.13125359100013156,
    0.13254046599996355,
    0.1306078816000081,
    0.12938570366653343,
    0.1319499020000876,
    0.13051963150064694,
    0.13465968119229588,
    0.13176812446153446,
    0.13168740950004576,
    0.13652860938260425,
    0.13573717082050654,
    0.1332490613529123,
    0.13269146749962601,
    0.13269146749962601,
    0.13292338619994554,
    0.1351923857272678,
    0.13277275639993605,
    0.136285059580616,
    0.13521296217391943,
    0.13618526363637956,
    0.1327230544545521,
    0.13364163907135662,
    0.13286564250029187,
    0.13584310452931866,
    0.13584310452931866,
    0.1348704550000548,
    0.13269535062499926,
    0.13609218517649424,
    0.13045001799946476,
    0.1339417036666014,
    0.1369686007777394,
    0.1369686007777394,
    0.13717221415376676,
    0.13717221415376676,
    0.13635423374999947,
    0.13659026760008905,
    0.1270964625000488,
    0.13091174300037287,
    0.13826895100004655,
    0.1359783469706064,
    0.1347012195001298,
    0.13812227999997875,
    0.13990002822235206,
    0.1394018034443434,
    0.1319526120005321,
    0.1364834108709704,
    0.13882767761536413,
    0.14245143766675028,
    0.139159100111101,
    0.13953213135295406,
    0.13953213135295406,
    0.13953213135295406,
    0.13706966041998384,
    0.13706966041998384,
    0.1383203966999645,
    0.13932404900015172,
    0.13722789620005643,
    0.13592538781250596,
    0.13636861024997415,
    0.13560494174281693,
    0.14320760349983175,
    0.14320760349983175,
    0.13467939488888683,
    0.13346441845450582,
    0.13197200433326847,
    0.13150026766682762,
    0.1346968811667466,
    0.13423100029629292,
    0.1352651390000011,
    0.13521559024991348,
    0.13416888925000117,
    0.1368687187250089,
    0.13601574199977526,
    0.13459509785186835,
    0.13402552409090937,
    0.13402552409090937,
    0.13420319616001508,
    0.13157395050029663,
    0.13695455612727198,
    0.1369836518644075,
    0.1347730984998634,
    0.1347730984998634,
    0.13416368712501026,
    0.13668430461537076,
    0.13473972309086754,
    0.1368902105714369,
    0.1387221003000377,
    0.13542492521739166,
    0.14063041499957762,
    0.14063041499957762,
    0.14060502240026834,
    0.13665893944461358,
    0.13509214057142213,
    0.136040338499879,
    0.14207162919992697,
    0.13754785991663235,
    0.1487509715007036,
    0.14881166600025608,
    0.14881166600025608,
    0.13092728050014557,
    0.13092728050014557,
    0.13202998969991314,
    0.13452152907133755,
    0.13196763129999453,
    0.13196763129999453,
    0.13770208799996908,
    0.13770208799996908,
    0.13798998586959066,
    0.13798998586959066,
    0.130362373499338,
    0.13160247516649784,
    0.1378190840832758,
    0.13867635931580335,
    0.1300096230000539,
    0.1300096230000539,
    0.13211977624996507,
    0.13845421879166983,
    0.13387552319982204,
    0.13462366400017345,
    0.13396965466684682,
    0.13696116611127865,
    0.13618666799993662,
    0.138393226900007,
    0.13890905899999476,
    0.14183601000004273,
    0.14097014214283782,
    0.13721392075012773,
    0.13808671366678027,
    0.14274460050000926,
    0.1428375450999738,
    0.1428375450999738,
    0.1371404332340388,
    0.1371404332340388,
    0.13973342577769976,
    0.13973342577769976,
    0.1361446163330887,
    0.13034827550018235,
    0.13595192742307588,
    0.13630608880012005,
    0.13694629800002903,
    0.13653658523807757,
    0.13661700688096193,
    0.13644493538092883,
    0.1368134831998759,
    0.1368134831998759,
    0.1360026206669621,
    0.13619828524997502,
    0.13241044749975117,
    0.1375012427271775,
    0.13654637516669432,
    0.13753462600016064,
    0.138552123111165,
    0.13732101653854792,
    0.13680986143861032,
    0.13081209600022703,
    0.13885941694733397,
    0.13885941694733397,
    0.13750752000032662,
    0.13750752000032662,
    0.13813181700000618,
    0.13792247284000042,
    0.1391554210001162,
    0.13719565537037312,
    0.13719565537037312,
    0.1380631013571474,
    0.13461884159987675,
    0.13461884159987675,
    0.13732931844444668,
    0.15476623599998776,
    0.14046530277785982,
    0.14036556233339878,
    0.15779842224992535,
    0.13767383343747497,
    0.14220762485716218,
    0.13725926289743468,
    0.14679709350002668,
    0.14679709350002668,
    0.1327647148124811,
    0.1327647148124811,
    0.13420730983337611,
    0.13420730983337611,
    0.13370867133340247,
    0.13408979764283555,
    0.13334742041676387,
    0.13334742041676387,
    0.13286120009086683,
    0.13470227800007706,
    0.13385437866669408,
    0.12947448200065992,
    0.12947448200065992,
    0.13623866696428064,
    0.13123550359996444,
    0.13350700431249152,
    0.13422453349994612,
    0.13422453349994612,
    0.13307983650004948,
    0.13176013599968428,
    0.13246332600101596,
    0.13305748774996573,
    0.12922659600008046,
    0.13280331250007293,
    0.1335766355002003,
    0.1335766355002003,
    0.13430187700032548,
    0.1352296797499548,
    0.13334433022221978,
    0.13173503949989632,
    0.13082964133294203,
    0.13082964133294203,
    0.13082964133294203,
    0.13478865700017195,
    0.13478865700017195,
    0.13478865700017195,
    0.13316881600015526,
    0.13549322685711168,
    0.13486729319993174,
    0.13792852627270666,
    0.1381512104999274,
    0.13778093100063415,
    0.13778093100063415,
    0.13976077121424169,
    0.13976077121424169,
    0.13709606751162515,
    0.13709606751162515,
    0.13709606751162515,
    0.13291885914285168,
    0.13291885914285168,
    0.1357402906000061,
    0.1357489319333884,
    0.1357489319333884,
    0.1291894570003933,
    0.13535535165907608,
    0.13525822614298835,
    0.13624639683348505,
    0.13624639683348505,
    0.13624639683348505,
    0.13857099215392038,
    0.13857099215392038,
    0.13703344480018131,
    0.13703344480018131,
    0.13587018233336798,
    0.13587018233336798,
    0.13257398374980767,
    0.13700522710525165,
    0.1325957849999213,
    0.13701923545456587,
    0.1408634505005466,
    0.13891450899999264,
    0.13250246399972335,
    0.1365181879999808,
    0.1365691651111168,
    0.13840814853840408,
    0.1357615668378433,
    0.14607363433303058,
    0.14607363433303058,
    0.13635748759988928,
    0.1343282997499955,
    0.13558111686676663,
    0.13387050899973474,
    0.1354745311795201,
    0.13773975500003466,
    0.13761328233340464,
    0.13761328233340464,
    0.13638407899998128,
    0.12641255199923762,
    0.13978290279992506,
    0.14529394500095805,
    0.14529394500095805,
    0.13435707504163474,
    0.13625913766675998,
    0.13465001299995752,
    0.1339874869500818,
    0.13483374951515129,
    0.13333529925012044,
    0.13333529925012044,
    0.13874466749985004,
    0.13348407042862423,
    0.13527906021277267,
    0.13389112414997725,
    0.13389112414997725,
    0.13406852420012,
    0.1492576900000131,
    0.13152249500035396,
    0.13336579281812275,
    0.13336579281812275,
    0.13439984560003115,
    0.13439984560003115,
    0.13538735044443861,
    0.13543517127271282,
    0.13591199960001177,
    0.13591199960001177,
    0.13488779075002336,
    0.13549914222211454,
    0.13611336673684013,
    0.1359842634358826,
    0.13466105188891325,
    0.13648620649999227,
    0.13560839433315172,
    0.1353836520005037,
    0.1353836520005037,
    0.1353836520005037,
    0.13514862099982566,
    0.13514862099982566,
    0.13679115507693496,
    0.13590170897145332,
    0.13590170897145332,
    0.13421925700034384,
    0.1375928278570687,
    0.13625161061533547,
    0.13625161061533547,
    0.1361285879564726,
    0.1377697799998714,
    0.13708817722241898,
    0.14121630533312177,
    0.14089487774981535,
    0.1375292416841579,
    0.13512267596971386,
    0.13644660404997921,
    0.13215237100030208,
    0.13374090132202907,
    0.13373486857142866,
    0.13373486857142866,
    0.13379120949123222,
    0.13379120949123222,
    0.13542775161901469,
    0.13524251734784426,
    0.13557518542103553,
    0.13557518542103553,
    0.13423569725000561,
    0.13578214227770027,
    0.13901278399983616,
    0.13382141751431587,
    0.13895468933333177,
    0.13895468933333177,
    0.14461986500009516,
    0.13550381459972413,
    0.13560166214301717,
    0.13445046840006397,
    0.1353617751999991,
    0.13733102300011524,
    0.13521627587488183,
    0.13521627587488183,
    0.13326082366660963,
    0.13488966067089228,
    0.13488966067089228,
    0.13322263800000655,
    0.13283462144439304,
    0.1330083841429379,
    0.13493805809994228,
    0.13445629466655695,
    0.13281672450001578,
    0.1327698067999639,
    0.13435031322215865,
    0.13563253114287882,
    0.13308491442105724,
    0.1349334401249962,
    0.13462835177779198,
    0.13294195868752468,
    0.13294195868752468,
    0.1330039211724366,
    0.1330039211724366,
    0.13166928000009648,
    0.13276435900115757,
    0.13029688162487219,
    0.1307659326999783,
    0.13108476039997186,
    0.13117443372737564,
    0.1323561922593028,
    0.1307149659987772,
    0.13151490966665733,
    0.12988349000079324,
    0.12913429999995665,
    0.12913429999995665,
    0.13302504784091565,
    0.1352136401090816,
    0.1320555379165853,
    0.1320555379165853,
    0.1331977605500015,
    0.1331977605500015,
    0.13163418120002462,
    0.13161713239987877,
    0.13161713239987877,
    0.13201301714304595,
    0.1320545068571976,
    0.13256686449979802,
    0.1379296003692546,
    0.13343623941667224,
    0.13335075981823055,
    0.1333521889564904,
    0.13168088524980703,
    0.13388089682503052,
    0.13255277700009174,
    0.14015686276228526,
    0.1324480262857313,
    0.1333113484500245,
    0.13315821688896298,
    0.13327588578574381,
    0.13158811850007623,
    0.13389301836369585,
    0.13325237880017085,
    0.13612857252175434,
    0.13410774350000387,
    0.13410774350000387,
    0.13874485766128572,
    0.13244259349994536,
    0.1350635549999879,
    0.13665906349979196,
    0.13310870733322291,
    0.13021694500002923,
    0.1363722033947373,
    0.1341572732728144,
    0.13381709518175325,
    0.13861194799937948,
    0.13861194799937948,
    0.13372818066667,
    0.13482109316676846,
    0.13698500858064958,
    0.1362075739998545,
    0.13685114094117606,
    0.13422363528570713,
    0.13417342257149098,
    0.12993282299976272,
    0.13705105729029804,
    0.13384979199994027,
    0.13400419990913096,
    0.13324581077762965,
    0.1343271905002439,
    0.13766748361905184,
    0.13766748361905184,
    0.13274131060000702,
    0.13766107972414515,
    0.13089523849976104,
    0.13253016640010173,
    0.137778494181806,
    0.13889754923537326,
    0.13319780611123455,
    0.13281427599940798,
    0.13441296679993683,
    0.13646630707696134,
    0.13999785726664413,
    0.1348004433635982,
    0.1348004433635982,
    0.1337552765999135,
    0.13888308245441294,
    0.1435489778533277,
    0.1435489778533277,
    0.1396813007646843,
    0.14387664920688056,
    0.13917838704345858,
    0.1405072163749992,
    0.14206359257150325,
    0.139869589285722,
    0.14487105520001933,
    0.14487105520001933,
    0.14552943369562854,
    0.1464795861429593,
    0.1543985512503241,
    0.1543985512503241,
    0.13595951599927503,
    0.1329933536668856,
    0.1352747682220878,
    0.1424122704286544,
    0.13573300333337102,
    0.1362015495000378,
    0.13508552266709253,
    0.13628735899987987,
    0.14800085061534235,
    0.14800085061534235,
    0.13373918599972967,
    0.14737118978570965,
    0.13857240549987182,
    0.1427649443333697,
    0.1427649443333697,
    0.13518298599956324,
    0.14827301089477068,
    0.14827301089477068,
    0.14827301089477068,
    0.15885989942866477,
    0.15885989942866477,
    0.15885989942866477,
    0.14308152226190682,
    0.1398887236999144,
    0.1398887236999144,
    0.14322354399983953,
    0.13823740899958162,
    0.1438518040587737,
    0.14737582383319628,
    0.15197176850006144,
    0.15197176850006144,
    0.12749423599984766,
    0.12749423599984766,
    0.13138853000018572,
    0.13138853000018572,
    0.13215794449979512,
    0.1296640609998576,
    0.14037252182222598,
    0.1497420276363383,
    0.14653410674998213,
    0.14652363646661495,
    0.14070632951111797,
    0.1394332051964154,
    0.13938289866625078,
    0.1420937550332989,
    0.12906390600073792,
    0.15731987925005342,
    0.14800358586665727,
    0.14800358586665727,
    0.13786596885182478,
    0.12722960300015984,
    0.1368769797058585,
    0.13557994336356802,
    0.1368947501052485,
    0.13755896799999132,
    0.13590183037490533,
    0.13590183037490533,
    0.13006659699931333,
    0.13006659699931333,
    0.1350678850000501,
    0.13310345633362886,
    0.12972901625016675,
    0.13573791100000865,
    0.13670562573809417,
    0.14023392273683336,
    0.13357743500000652,
    0.14020235850011886,
    0.12844312000015634,
    0.13439402466671405,
    0.1388427477143393,
    0.1372077969411775,
    0.13936902984996777,
    0.14090565762501228,
    0.14090565762501228,
    0.13470794849990853,
    0.13573006300003213,
    0.13600132634147907,
    0.1325430763998156,
    0.13373472999955993,
    0.13373472999955993,
    0.1345832048428617,
    0.14040802045465997,
    0.13291539233311292,
    0.13819498792299084,
    0.14215251799987527,
    0.13743519713633842,
    0.13788383599967347,
    0.1364052942285655,
    0.13726473304347525,
    0.13726473304347525,
    0.13388128479485972,
    0.1292247151999618,
    0.13317154747365798,
    0.13317154747365798,
    0.13004810433327899,
    0.1350852794545393,
    0.13402335921952127,
    0.13482542391300187,
    0.13482542391300187,
    0.13448052266681365,
    0.11882205699839687,
    0.1340436299231162,
    0.13423493352005608,
    0.1341739312368334,
    0.1381086710309281,
    0.1381086710309281,
    0.1351722096471135,
    0.1351722096471135,
    0.13494312399961927,
    0.1354537357142579,
    0.14621266333354774,
    0.14621266333354774,
    0.14621266333354774,
    0.1330413422187462,
    0.1330413422187462,
    0.13083564955559268,
    0.13385501495239233,
    0.13385501495239233,
    0.1373141118799928,
    0.1373141118799928,
    0.13173387449933216,
    0.13374293345835517,
    0.13465169300070556,
    0.13468618174988478,
    0.13465801937513788,
    0.13224905199967907,
    0.13454546435294854,
    0.13041377300032764,
    0.13503251309994085,
    0.1342823727391078,
    0.13593839675013442,
    0.1336830370256417,
    0.13497749866655795,
    0.12777295400155708,
    0.134448595307731,
    0.13384109590000057,
    0.13538223492858897,
    0.13439124599996,
    0.13625533466660678,
    0.1355835448999642,
    0.13434928922227604,
    0.13981678349955473,
    0.13326899777772874,
    0.1319550796670228,
    0.13279614427268494,
    0.13351752788892352,
    0.13175302800118516,
    0.1329946845999075,
    0.1339591668332408,
    0.1342882756001927,
    0.1342882756001927,
    0.13306471333332107,
    0.1329798624737075,
    0.13336452575003932,
    0.13337691681482722,
    0.13231571418178978,
    0.13241513774983105,
    0.13266544842857306,
    0.13134838466673196,
    0.13463431784998647,
    0.1315157213997736,
    0.13183969874989998,
    0.13269707979998202,
    0.13222924516655135,
    0.13435879249982463,
    0.13435879249982463,
    0.13520556283341043,
    0.13520556283341043,
    0.1337539757500963,
    0.13287295357141765,
    0.13287481885721977,
    0.13287481885721977,
    0.13638226900002337,
    0.13304772414280056,
    0.13567670928568987,
    0.13567670928568987,
    0.13084899762498026,
    0.1332633858095332,
    0.13157848283359877,
    0.1328618061428036,
    0.12965786099994148,
    0.12993312700018578,
    0.1331729241111235,
    0.12973866399988765,
    0.12973866399988765,
    0.13357544231246266,
    0.13319953805263426,
    0.13590152662504806,
    0.13590152662504806,
    0.1339404357332872,
    0.1339735088889332,
    0.13397238169230918,
    0.1363125291428289,
    0.13249688233332158,
    0.1362035599047972,
    0.13966575066666945,
    0.13966575066666945,
    0.13316028349981934,
    0.14042090413331607,
    0.13700313054546728,
    0.13222205866683603,
    0.13157512216669906,
    0.1367687216666632,
    0.13386235824987125,
    0.13744530623807805,
    0.14564647973329556,
    0.1379392848460926,
    0.13803183417643167,
    0.13803183417643167,
    0.13792976461529458,
    0.13792976461529458,
    0.13821718489998602,
    0.13821718489998602,
    0.1461869120345188,
    0.13881127911757657,
    0.13925033946664675,
    0.13909692188238243,
    0.14205945850980975,
    0.13582973875008975,
    0.13905160523523485,
    0.13662050350012578,
    0.14181354357138584,
    0.1428181706315196,
    0.13926847792858357,
    0.1490103420740154,
    0.1454670539500512,
    0.14879455681478215,
    0.14879455681478215,
    0.14156963699997505,
    0.14156963699997505,
    0.13735982766653856,
    0.15267968456248582,
    0.15267968456248582,
    0.14091623981999873,
    0.14091623981999873,
    0.14548489874982806,
    0.14548489874982806,
    0.14085966987233328,
    0.14085966987233328,
    0.1408882336249917,
    0.1408882336249917,
    0.14990574599960382,
    0.14990574599960382,
    0.1364791816666487,
    0.1364791816666487,
    0.14227271275012754,
    0.1359172292221855,
    0.1422264120001273,
    0.13181891299999343,
    0.1338199387143201,
    0.1313155078332784,
    0.13016000999959942,
    0.13391149632435692,
    0.13425697827773952,
    0.13425697827773952,
    0.13602562750020297,
    0.13253003722214393,
    0.13435348192307664,
    0.13373920083328508,
    0.13344047177775387,
    0.133089472666749,
    0.133089472666749,
    0.1321900310000014,
    0.13696505104649817,
    0.12838930999987497,
    0.13340409427776953,
    0.13331998220004607,
    0.13393231580002976,
    0.12997140500010573,
    0.12997140500010573,
    0.13804766931425547,
    0.13483083116670969,
    0.13020010800028103,
    0.1362445946668029,
    0.13393537033334724,
    0.1355296509999688,
    0.13638223788883705,
    0.13565365857149508,
    0.13434796622217013,
    0.1353801666250547,
    0.13424334872731628,
    0.13873772510343205,
    0.1354772437142466,
    0.13516905860014958,
    0.13158897666673713,
    0.13158897666673713,
    0.1405843576086899,
    0.13820900399969105,
    0.1325781204999051,
    0.14031069009997738,
    0.13358357391674267,
    0.13334732449948206,
    0.14077584070593516,
    0.12396105399966473,
    0.12396105399966473,
    0.13361722959998587,
    0.1300705077501334,
    0.13621652199981327,
    0.13681025933328783,
    0.14058614030158972,
    0.1417308775365577,
    0.14180391715382987,
    0.1423607946285691,
    0.13891388636002375,
    0.14194641789474285,
    0.14163856187880094,
    0.14163856187880094,
    0.1311352269985946,
    0.139090652629656,
    0.13813762100107851,
    0.14637602192306076,
    0.13706615550017887,
    0.148141349363703,
    0.14134876574999825,
    0.13915884349989938,
    0.1416999415517333,
    0.1416999415517333,
    0.13324697100006233,
    0.133040920555383,
    0.13306821688901335,
    0.13031343900001957,
    0.1338038333332305,
    0.14082967795999138,
    0.14082967795999138,
    0.1346349908002594,
    0.1346349908002594,
    0.13959896267851946,
    0.13959896267851946,
    0.13207161959981023,
    0.1324099712496718,
    0.13404472949969204,
    0.1325186372500866,
    0.13362081077785762,
    0.14272192009993886,
    0.1335019214445007,
    0.12917140450008446,
    0.12917140450008446,
    0.14014117306248863,
    0.14417453511113207,
    0.12905811599921435,
    0.12904854150019673,
    0.13525975700031267,
    0.1350276639996082,
    0.15357308460006608,
    0.1496334318573125,
    0.14064907792595072,
    0.14075450621273009,
    0.1508252079091273,
    0.1332434080013627,
    0.16324737874992934,
    0.16324737874992934,
    0.13323239774990725,
    0.13818493370831675,
    0.13468886950022352,
    0.13384072249997794,
    0.1346893589998217,
    0.1346893589998217,
    0.13559792366686452,
    0.13739738831998694,
    0.1378527846875386,
    0.1336057984000945,
    0.13672490070002824,
    0.13876955951855052,
    0.1378127548000131,
    0.1334552516250369,
    0.132182138272831,
    0.13336019840025984,
    0.12892747200021404,
    0.1323599574284994,
    0.13338454300007166,
    0.13340454775000885,
    0.13837408728948886,
    0.13773099080002188,
    0.13380582880017755,
    0.14116706225001963,
    0.133283221000186,
    0.12880836600015755,
    0.1397835740908704,
    0.13834312400103954,
    0.1390665545000047,
    0.13865387069999996,
    0.14004351240000687,
    0.1435926795715464,
    0.1435926795715464,
    0.138915841214276,
    0.138915841214276,
    0.14035714408335784,
    0.12886273199910647,
    0.12886273199910647,
    0.13927269414631244,
    0.13602520299991738,
    0.14625833672735924,
    0.14625833672735924,
    0.13687621258067073,
    0.13687621258067073,
    0.14363211466661596,
    0.1392706982501295,
    0.13632712164287245,
    0.13634041628561785,
    0.13673686340000132,
    0.13566143499995703,
    0.13566143499995703,
    0.1361548709259363,
    0.1344451072141705,
    0.13358927924991804,
    0.13358927924991804,
    0.13416084999994382,
    0.1362767717691895,
    0.13533154749984533,
    0.13621205965000627,
    0.13621205965000627,
    0.13604638400101976,
    0.1369502475483328,
    0.1355022587179589,
    0.13663745587496123,
    0.1389190749999519,
    0.13699284523532054,
    0.1372369297140332,
    0.13931032077764233,
    0.1373216167999999,
    0.13589981882140428,
    0.13695934443751412,
    0.1375130503749915,
    0.1375130503749915,
    0.13736466666670735,
    0.13752640544448191,
    0.13911669379995145,
    0.13813673949994154,
    0.1454194854995876,
    0.1454194854995876,
    0.13583777037490563,
    0.13486828307409102,
    0.13530653502440568,
    0.13791169345445684,
    0.13779379144438686,
    0.13498174233330548,
    0.13711127050009964,
    0.13852663500001655,
    0.1353309513871218,
    0.132849322999391,
    0.13488440721741188,
    0.1359524680937625,
    0.1359524680937625,
    0.1322780899999998,
    0.1311020949999147,
    0.13258745100029046,
    0.13088315062509537,
    0.1360265753725495,
    0.1360265753725495,
    0.13410623881819364,
    0.13067625342851638,
    0.13067625342851638,
    0.13163650100000268,
    0.13163650100000268,
    0.12898029900043184,
    0.13519722839128404,
    0.13398151753846413,
    0.13398151753846413,
    0.1299343503333148,
    0.12993941649983753,
    0.12993941649983753,
    0.1319005819996164,
    0.13645878196426306,
    0.13488031827265248,
    0.1352000049992057,
    0.1352000049992057,
    0.13637624222226602,
    0.13509323749985924,
    0.13676322755099118,
    0.1369391786000051,
    0.13634524069241777,
    0.1373542040908598,
    0.1378729360416552,
    0.13190424500135123,
    0.13756538981810576,
    0.1372261287692359,
    0.13554158399983862,
    0.13554158399983862,
    0.13014476199987257,
    0.13662082138468506,
    0.13700980622221928,
    0.13757431444436305,
    0.1391619667500663,
    0.13880032550005125,
    0.13880032550005125,
    0.13715588995834574,
    0.1382820265383858,
    0.13686184461110112,
    0.1371210663225699,
    0.13935927733352096,
    0.13772344639992298,
    0.13772344639992298,
    0.138872928000031,
    0.138872928000031,
    0.1419274748001044,
    0.1419274748001044,
    0.1348900642500439,
    0.13485147952174567,
    0.13141464500014471,
    0.13539074947619242,
    0.1355317524500606,
    0.1355317524500606,
    0.13571122799995855,
    0.1361590804166705,
    0.13540520324992636,
    0.134770696600026,
    0.13552995211123037,
    0.13552995211123037,
    0.13550006744440501,
    0.13414851500056102,
    0.13709577100053139,
    0.13623846807688375,
    0.1360981657727197,
    0.1312757773333336,
    0.1312757773333336,
    0.12518208000074083,
    0.13136473899976409,
    0.13136473899976409,
    0.13766981145454338,
    0.13612188299998706,
    0.1382817371911776,
    0.13846056765518808,
    0.13533176146148224,
    0.13284555575000923,
    0.1355747565000153,
    0.135252631000003,
    0.13544491066659248,
    0.1380785377916709,
    0.13144276949969935,
    0.13799485899987,
    0.1354213612001331,
    0.14069023813329598,
    0.13897505000022647,
    0.13883534687719426,
    0.1385467280000566,
    0.13977873383343345,
    0.13892154281810773,
    0.13892154281810773,
    0.13799009135000234,
    0.13799009135000234,
    0.13782539368753532,
    0.14168421855558538,
    0.1290138839995052,
    0.14197092999994412,
    0.15048865200014916,
    0.13921935752177492,
    0.1420738386999801,
    0.1420738386999801,
    0.13102993075017366,
    0.13805959391664954,
    0.13192239449972476,
    0.12673935600014374,
    0.12854401666663762,
    0.13674788778790212,
    0.13305488333359486,
    0.13305488333359486,
    0.13737955999931728,
    0.13623871811119492,
    0.13623871811119492,
    0.13186415449990818,
    0.13186415449990818,
    0.13760139071434555,
    0.13760139071434555,
    0.13797321933331355,
    0.13240575100098795,
    0.13241954333352624,
    0.13975092006060577,
    0.13703132145456037,
    0.13480956000012156,
    0.13772050724992368,
    0.13848834490909212,
    0.13710917734997566,
    0.14526801774991327,
    0.14526801774991327,
    0.14526801774991327,
    0.13888978099991314,
    0.13888978099991314,
    0.1374391866458685,
    0.13750942402131183,
    0.13750942402131183,
    0.13236302222220628,
    0.13236302222220628,
    0.12098695399981807,
    0.12098695399981807,
    0.12098695399981807,
    0.13456156327282026,
    0.13248369099983393,
    0.13248369099983393,
    0.13914767023071853,
    0.13577831544433946,
    0.13961517166656753,
    0.13961517166656753,
    0.14199531106666352,
    0.13739431214812445,
    0.1380841598528979,
    0.13729083486113167,
    0.13773073270589092,
    0.14040062729168312,
    0.13766599583323114,
    0.13852804719695225,
    0.146332489300039,
    0.1462986066665811,
    0.13793411450023996,
    0.14605177390909707,
    0.14106419625022681,
    0.1433939577500496,
    0.1381364451666741,
    0.13780553975000961,
    0.14221053764702127,
    0.15120687700012544,
    0.1431913892497505,
    0.13745025110344206,
    0.14126171505877744,
    0.14317538299928856,
    0.1470164232222386,
    0.1470164232222386,
    0.13632512359999965,
    0.13319261400010873,
    0.13770882060016448,
    0.13686530566671232,
    0.13484720547057805,
    0.1377968755998154,
    0.1377968755998154,
    0.13400819524986218,
    0.13273262045830356,
    0.13338919499983604,
    0.13025815000037255,
    0.13508466582856532,
    0.13508466582856532,
    0.13364199500028917,
    0.13364199500028917,
    0.1325741545882492,
    0.13745642898000368,
    0.1365959930454582,
    0.1335446097273234,
    0.13556554844446375,
    0.1356076760370747,
    0.13519203550004022,
    0.1337471689999802,
    0.12976083024977925,
    0.13545188895452817,
    0.13021668033333197,
    0.13138453100009428,
    0.13502036125804984,
    0.1314074925000265,
    0.13145310999971116,
    0.1377748305641058,
    0.13109149466678596,
    0.1353217453928924,
    0.13585102254992307,
    0.13579936713042273,
    0.13618871355548537,
    0.13512090073333335,
    0.13231567949969758,
    0.13633819674627132,
    0.14592615335706277,
    0.13380678954540184,
    0.13769853272726157,
    0.137719105409112,
    0.1373968004807536,
    0.13876150894597034,
    0.1327910540909546,
    0.1359789299749991,
    0.1359789299749991,
    0.13615566133332668,
    0.13615566133332668,
    0.13564081839998834,
    0.1332795818334489,
    0.1332795818334489,
    0.1381689365333538,
    0.13676287799899,
    0.15473240633339932,
    0.13735590439129106,
    0.13883916716667954,
    0.13960242209098148,
    0.1381116138665675,
    0.1381116138665675,
    0.14444736166660732,
    0.14033416592857456,
    0.13903918877266816,
    0.1390879001818107,
    0.14024467357142253,
    0.14167968822221155,
    0.148454228799892,
    0.13983719354539723,
    0.11710296700013194,
    0.13416459914284987,
    0.13383500309614996,
    0.13700116275003893,
    0.13487382271419587,
    0.13727436051350023,
    0.13406021950004288,
    0.133262940111106,
    0.13767286609676846,
    0.13778659686205832,
    0.13421877766662269,
    0.1357735328214338,
    0.13453740425029537,
    0.1415176881999893,
    0.1382592262068948,
    0.14229883699996349,
    0.14229077900003737,
    0.14229077900003737,
    0.13365508299975773,
    0.13618922871449154,
    0.14189006700022824,
    0.13673712924992287,
    0.13673712924992287,
    0.13732452139993256,
    0.13837727043331446,
    0.14040790726310087,
    0.14040790726310087,
    0.14040790726310087,
    0.1437483830769242,
    0.1437483830769242,
    0.1437483830769242,
    0.13488366157149098,
    0.13009634999980335,
    0.133911233406252,
    0.13434215589281198,
    0.13483459349996943,
    0.13483459349996943,
    0.13364484563631282,
    0.13363379787506346,
    0.1346252125882422,
    0.13334608200000275,
    0.13456219399995462,
    0.13437539373683793,
    0.1339381689995207,
    0.13330349225715118,
    0.13503682255557375,
    0.13503682255557375,
    0.1346127126667448,
    0.1346127126667448,
    0.1344976211334142,
    0.1346917329074131,
    0.13487343983342726,
    0.13487343983342726,
    0.13427095230760572,
    0.13734568099971511,
    0.1345149150666657,
    0.1340273131666739,
    0.13436644990906643,
    0.1360858346670284,
    0.13343769991671353,
    0.13343769991671353,
    0.13620235333352562,
    0.13620235333352562,
    0.13461476638638653,
    0.13470773000008193,
    0.1348331784000038,
    0.13330451425928105,
    0.13412009584846435,
    0.13151592500010642,
    0.13410582853333228,
    0.13442281115555185,
    0.13179102037497614,
    0.1315771166999184,
    0.13303488850033318,
    0.13571203450010216,
    0.13192398373333467,
    0.1345171191428779,
    0.1304344628333638,
    0.13455235731036172,
    0.13275175608335607,
    0.13297927989477007,
    0.1321065366667123,
    0.1321065366667123,
    0.13096382249977978,
    0.13469226938096177,
    0.13275503691662985,
    0.13275503691662985,
    0.13278904026665259,
    0.13424964016667218,
    0.13553743346157995,
    0.13385478150030394,
    0.13580915921949516,
    0.13525609358331772,
    0.13525609358331772,
    0.13087590299983276,
    0.13502290875858936,
    0.13646852733351503,
    0.1347902681428668,
    0.1350415319999835,
    0.1350415319999835,
    0.13506898199996023,
    0.1311766678333394,
    0.1325131062307124,
    0.12750608900023508,
    0.13121030683335752,
    0.13539180151854924,
    0.1357313902272753,
    0.1348329263396494,
    0.13490392622225045,
    0.13375106740022602,
    0.1356546848182089,
    0.1327140878573638,
    0.1327140878573638,
    0.1358179530000468,
    0.13436727488887198,
    0.13616931073338492,
    0.13554977120002148,
    0.12939384699984657,
    0.12939384699984657,
    0.13318465637485133,
    0.13318465637485133,
    0.13080960049956047,
    0.13606170446151877,
    0.13636913904544848,
    0.13673959926660853,
    0.13467322579999746,
    0.13362904057144728,
    0.13362904057144728,
    0.13597913563329106,
    0.13738536266666618,
    0.1371669260000393,
    0.13017528633342104,
    0.12952283550021093,
    0.13563281087038007,
    0.13563281087038007,
    0.13634593135898634,
    0.13634593135898634,
    0.14550321849947068,
    0.14550321849947068,
    0.14605317150017072,
    0.13471820726926337,
    0.13778096276473661,
    0.13778096276473661,
    0.13432085299993762,
    0.13432085299993762,
    0.13493306172726574,
    0.133545582250008,
    0.13407062487499388,
    0.13797657524992246,
    0.13802069524990657,
    0.13480491600005604,
    0.1400164319996596,
    0.13507183029404962,
    0.13065132799965795,
    0.13065132799965795,
    0.13065132799965795,
    0.13028062349985703,
    0.13028062349985703,
    0.13389083111766975,
    0.13389083111766975,
    0.1342691424838596,
    0.13448543133332957,
    0.1367889426052754,
    0.1367889426052754,
    0.13418771588230277,
    0.13603443755224062,
    0.13313097616658828,
    0.13363172057142947,
    0.1340952945200115,
    0.13312203683320453,
    0.1342130275555704,
    0.13425102323078766,
    0.13360326414268847,
    0.13392658200064034,
    0.13660948876000475,
    0.13202971999999136,
    0.12983932599945547,
    0.12983932599945547,
    0.1327234640714648,
    0.1314762184999078,
    0.13782267299939122,
    0.13485382524993383,
    0.1344741410555596,
    0.12865923599929374,
    0.13813996257690284,
    0.13827407500000846,
    0.136744094695646,
    0.136744094695646,
    0.13760319578575167,
    0.13760319578575167,
    0.13748295615148504,
    0.13499387708331292,
    0.1367090563111156,
    0.1321220434992938,
    0.13830679781817293,
    0.13497532635717238,
    0.1401346328125328,
    0.13496215399988745,
    0.13332814400018833,
    0.1366473585934088,
    0.13808045148147763,
    0.13396822825006893,
    0.13553276090005967,
    0.13980987077775353,
    0.13557489600013164,
    0.13786314849994596,
    0.13771223564863494,
    0.13668521699998695,
    0.1363203528570531,
    0.1367944097777841,
    0.13125820200002636,
    0.13125820200002636,
    0.14487635611112637,
    0.14393088311104899,
    0.14393088311104899,
    0.1343094837141377,
    0.13498461733327835,
    0.13442521923081166,
    0.13442521923081166,
    0.13214239250009996,
    0.13531210644003294,
    0.13531210644003294,
    0.13548269069997332,
    0.135159583679997,
    0.13563333266655617,
    0.14296561300034227,
    0.1343272815556702,
    0.1349768765554068,
    0.1266444129996671,
    0.135475267127673,
    0.13498551339281611,
    0.13535566841186236,
    0.13561601736359025,
    0.13559435244122356,
    0.13690171985711327,
    0.1341594747998897,
    0.13493439330435966,
    0.13521897966671126,
    0.13554840424393017,
    0.13620259562503634,
    0.13553313614290477,
    0.1355241006000142,
    0.1369453514284292,
    0.1380229387500549,
    0.13865045049988112,
    0.13865045049988112,
    0.13370182337507686,
    0.13497741411123976,
    0.13439062049974382,
    0.13397255049979626,
    0.13560534266677374,
    0.128336018000482,
    0.13421323222226217,
    0.1360100605333072,
    0.1349148977692144,
    0.1348347803335249,
    0.1329309735001516,
    0.13477863323085051,
    0.13542236095647397,
    0.13470877964287606,
    0.1355207872857136,
    0.13773021540000627,
    0.1361277109999719,
    0.1355200488570907,
    0.13730487675002223,
    0.13599164974993982,
    0.1359936054998343,
    0.13332738650024112,
    0.136330088000028,
    0.13525063709088994,
    0.12982076699972822,
    0.13365000014268194,
    0.13385820318184083,
    0.13385820318184083,
    0.1385575139993307,
    0.13122398599989538,
    0.13566149607686384,
    0.13567945434617565,
    0.13166637100039225,
    0.1363695778333446,
    0.1363695778333446,
    0.1359165095454955,
    0.1359165095454955,
    0.136174742043453,
    0.13601549281818073,
    0.13745545655547176,
    0.13625467775000288,
    0.13641210133331091,
    0.13671458019441868,
    0.13729468533327033,
    0.13729468533327033,
    0.13919749900014722,
    0.13647882533324365,
    0.13603599392860946,
    0.13595409900012279,
    0.13595409900012279,
    0.13437247166681723,
    0.13274303799971676,
    0.13616725367858504,
    0.13915995250044944,
    0.13671155770007318,
    0.13585467266663423,
    0.13601105683331602,
    0.14427449499999057,
    0.13666034429627838,
    0.13601744330760715,
    0.1374227080666363,
    0.13738255733369442,
    0.13738255733369442,
    0.1373338366875032,
    0.13677721295243828,
    0.13751456674996612,
    0.1368467169999753,
    0.1368467169999753,
    0.13617142000020976,
    0.13834546911109807,
    0.1374020942499783,
    0.1370034890005627,
    0.13681984320004023,
    0.13681984320004023,
    0.13060625800062553,
    0.13060625800062553,
    0.13477260972411323,
    0.13245723650015861,
    0.13635384608000095,
    0.13797832256665668,
    0.13901237422234974,
    0.13901237422234974,
    0.1364734441666466,
    0.1364734441666466,
    0.13344028100004834,
    0.13313567209082644,
    0.13297944321428595,
    0.1344380724444313,
    0.1324290459997428,
    0.13602555199986455,
    0.13440178083358964,
    0.13656755959265057,
    0.134819078000094,
    0.134819078000094,
    0.13506321216679376,
    0.13507151242837218,
    0.1325046655713647,
    0.13786010359999637,
    0.13405795124981523,
    0.13266533750015697,
    0.1369818643103419,
    0.132917481444464,
    0.13708095185002095,
    0.13379518416665329,
    0.1318028776668143,
    0.1378121736667405,
    0.15226189954542366,
    0.13086623799972585,
    0.13161954099996365,
    0.1380337419473347,
    0.13710866805879907,
    0.15675069644445708,
    0.1373565489230504,
    0.1431605443332147,
    0.1607036327500282,
    0.14268410479999147,
    0.14056770249999317,
    0.13025003175016536,
    0.13821027081246484,
    0.14010334947373562,
    0.13460561100024884,
    0.17659525039998697,
    0.14023609014280478,
    0.14022940143752294,
    0.1364018375531893,
    0.13692714349963353,
    0.14208241139986058,
    0.1417666055453579,
    0.1376965870322531,
    0.1379594619130607,
    0.13771128509260624,
    0.13145268812500036,
    0.0022665619999315822,
    0.13430387222231527,
    0.13430387222231527,
    0.1348427274117378,
    0.1356814752222514,
    0.13394173800043063,
    0.13530315168759444,
    0.13527581033334476,
    0.13527581033334476,
    0.13484452423066473,
    0.13484452423066473,
    0.13515163165214725,
    0.13558823566664716,
    0.13491953216665328,
    0.13589223580952203,
    0.13589223580952203,
    0.13537470379997102,
    0.1397540600009961,
    0.13671835000013743,
    0.1365138224286316,
    0.13467884879992198,
    0.13583700700110057,
    0.13583700700110057,
    0.13069906157137925,
    0.12733605399989756,
    0.13356717928555945,
    0.1320883869999913,
    0.13414834344446178,
    0.13627951690911935,
    0.1346160294999988,
    0.13277152099908562,
    0.13456770925001496,
    0.13309463474979566,
    0.1348678518947724,
    0.13635716822217445,
    0.1351663558461251,
    0.13480774726667732,
    0.1348324831999586,
    0.1363906527618989,
    0.1342999496469822,
    0.1373402721112345,
    0.1373402721112345,
    0.1368248506666229,
    0.1341337032499723,
    0.133354138625009,
    0.13139393299995086,
    0.13109307720005745,
    0.13600597772222467,
    0.13600597772222467,
    0.1318698498000231,
    0.13496592800038343,
    0.140800727000169,
    0.13254018509996968,
    0.1327913544545564,
    0.12885391100007837,
    0.13002869599995392,
    0.13002869599995392,
    0.13186508085709647,
    0.13314116375022422,
    0.13646258695651972,
    0.13336846850006623,
    0.13742585729164603,
    0.13587279740002653,
    0.13587279740002653,
    0.13637996037505218,
    0.13701856319228403,
    0.13701856319228403,
    0.13523524350005442,
    0.13523524350005442,
    0.1337547057272869,
    0.1337547057272869,
    0.13611084266664908,
    0.13602297475017622,
    0.13696692456250048,
    0.13809926022218455,
    0.13722058190626285,
    0.14104319430771284,
    0.13705096624239974,
    0.1388996198333593,
    0.1450158581251344,
    0.13122311033354586,
    0.1364641655238215,
    0.13670014666665034,
    0.1420856131818172,
    0.14831416866642635,
    0.14831416866642635,
    0.1336247506666647,
    0.13320840099991724,
    0.13457094511999457,
    0.13462143399920024,
    0.13369022263627398,
    0.13360185425017335,
    0.13368945399997756,
    0.13368945399997756,
    0.13245555799949216,
    0.13723678872223968,
    0.13723678872223968,
    0.13046679699982633,
    0.13352502439993258,
    0.13749424220000542,
    0.1325342918333566,
    0.13368885166710243,
    0.13812914876922525,
    0.13273966874999132,
    0.13500469393750336,
    0.1316294022221377,
    0.1316294022221377,
    0.1354391060909124,
    0.1354391060909124,
    0.1354391060909124,
    0.13769378764287207,
    0.1363622979629495,
    0.13679891007151518,
    0.13679891007151518,
    0.13588011976921385,
    0.13669772066653726,
    0.13669772066653726,
    0.13669772066653726,
    0.12802948450007534,
    0.12802948450007534,
    0.12802948450007534,
    0.1380428446666176,
    0.1380428446666176,
    0.1423310717500499,
    0.13750869539130098,
    0.13871656714296218,
    0.13871656714296218,
    0.13585091544438102,
    0.13672506479997537,
    0.13705079928565414,
    0.13913110975756188,
    0.138889641750211,
    0.1356659076664073,
    0.13617177544458375,
    0.1426273150009365,
    0.1426273150009365,
    0.14180402494115268,
    0.14180402494115268,
    0.13414274072734275,
    0.13820738899994467,
    0.13736509379996278,
    0.13736509379996278,
    0.1379295319143109,
    0.12838806333274988,
    0.1413125628888439,
    0.14058693639131176,
    0.14058693639131176,
    0.14172907199999826,
    0.14172907199999826,
    0.12838370499957819,
    0.13870682996872574,
    0.13207128475005447,
    0.13221577525018802,
    0.13651286519998393,
    0.1353986152352905,
    0.14225657719980517,
    0.1379618557498361,
    0.140827621000426,
    0.1464406836669999,
    0.1392370903103538,
    0.1530738910000764,
    0.13989787049922597,
    0.13989787049922597,
    0.13454739073337502,
    0.13454739073337502,
    0.13454739073337502,
    0.13361019283335432,
    0.13575450268751865,
    0.13591365299988764,
    0.13591365299988764,
    0.1345311319523933,
    0.1345311319523933,
    0.12731431100019108,
    0.13527048279993323,
    0.13527048279993323,
    0.1356919108000511,
    0.1360589560833129,
    0.1331686618913132,
    0.1331686618913132,
    0.13320397700003508,
    0.13417385318757624,
    0.13338015242862594,
    0.13338015242862594,
    0.12713415550024365,
    0.13265254210870372,
    0.1345980377500382,
    0.13814831750005396,
    0.1342004308888944,
    0.13816918124985023,
    0.13816918124985023,
    0.13128105413331165,
    0.13128105413331165,
    0.13201417200002652,
    0.13201417200002652,
    0.13331557255555204,
    0.13208100433318273,
    0.13001858500138042,
    0.13181267195241594,
    0.13181267195241594,
    0.13156025235483895,
    0.13192896914997618,
    0.1314786686001753,
    0.13241496007140086,
    0.1340327043749312,
    0.13185429504549326,
    0.13162960048000968,
    0.13295482441662898,
    0.13515897879988187,
    0.13215014214308343,
    0.1322884841999136,
    0.1322884841999136,
    0.132310469090898,
    0.133310682666585,
    0.13380388804109491,
    0.1340333215002829,
    0.13267560084610663,
    0.13423350557137123,
    0.13466853499994613,
    0.1303178880000761,
    0.13120505786670644,
    0.13092903370595785,
    0.1316964210000151,
    0.13116442584620158,
    0.13240836300064984,
    0.13156522200006293,
    0.13051512327266127,
    0.13051512327266127,
    0.1315506103333367,
    0.13056063866679324,
    0.13056063866679324,
    0.13043025477782066,
    0.13059637699989252,
    0.13031029666672111,
    0.1293365604000428,
    0.13007022725014394,
    0.13007022725014394,
    0.1307630656665424,
    0.1307630656665424,
    0.13237935376470406,
    0.13199452411537585,
    0.13260904741176038,
    0.1296875074284409,
    0.12991172239999288,
    0.1299187630000233,
    0.1321038340384593,
    0.13235703691308395,
    0.13260472535138607,
    0.1282391214999734,
    0.12967438333331907,
    0.13102065711124547,
    0.13105326924983274,
    0.13311929318751936,
    0.13284587630005262,
    0.13328985446157907,
    0.1327470110869478,
    0.13326626911111816,
    0.13256967683337278,
    0.13318012900002513,
    0.13033290533348918,
    0.1327087451071358,
    0.13214859520012395,
    0.12907284799985064,
    0.1323519347999536,
    0.13527703166679808,
    0.14001083550010662,
    0.1331831269199756,
    0.1357730644445433,
    0.13145610633364413,
    0.13145610633364413,
    0.13145610633364413,
    0.13604751520000719,
    0.13604751520000719,
    0.1321315781250405,
    0.13242721066671947,
    0.13278519669565075,
    0.13278519669565075,
    0.13008722240010684,
    0.13238936638895715,
    0.13239754011111574,
    0.13334379306246547,
    0.13259149529414357,
    0.13639740650001772,
    0.13639740650001772,
    0.13035798799986273,
    0.13002610225021272,
    0.13248006311126423,
    0.13250387944450873,
    0.13216358499994385,
    0.13243320333337275,
    0.13243320333337275,
    0.12818178000088665,
    0.1360470945901845,
    0.13253682419999677,
    0.13401134181253838,
    0.1345457842963461,
    0.1345457842963461,
    0.13270274255551662,
    0.1328608061248815,
    0.1328608061248815,
    0.13452713779997794,
    0.13403326723080403,
    0.12917965500128048,
    0.1333869377499468,
    0.1351029021110056,
    0.1315550079998502,
    0.13696361635488902,
    0.13396760266671967,
    0.13470542888889112,
    0.13470542888889112,
    0.1363065370908523,
    0.13784731551219542,
    0.13678212276919602,
    0.13689154849998886,
    0.13543238860002021,
    0.13793064680030512,
    0.13761352453842007,
    0.13321101300061855,
    0.1294491989992821,
    0.1349439536667584,
    0.136810288857045,
    0.13416674955543487,
    0.13668489227537697,
    0.13515400855572401,
    0.13523515557140595,
    0.132110276500498,
    0.14032618782353073,
    0.13794890010000624,
    0.13991025219984293,
    0.13991025219984293,
    0.13772144175004541,
    0.13772144175004541,
    0.13772144175004541,
    0.13880933784208824,
    0.1363561952000964,
    0.13865355100006127,
    0.13687831616665458,
    0.13240577766676628,
    0.13906517920004263,
    0.1354619289998785,
    0.1318305294998936,
    0.13993909977782298,
    0.13724856974509106,
    0.13578786949983623,
    0.1365007418157802,
    0.14320163941662636,
    0.14320163941662636,
    0.14320163941662636,
    0.13831264207146887,
    0.13831264207146887,
    0.1483525274998101,
    0.14022220955565798,
    0.14022220955565798,
    0.14022220955565798,
    0.133289378666935,
    0.133289378666935,
    0.133289378666935,
    0.13246622966653376,
    0.13219697075010117,
    0.13840840337502414,
    0.13439362649993805,
    0.13439362649993805,
    0.13517040250007994,
    0.12640387499959616,
    0.13630029127583337,
    0.13723285612498634,
    0.13609695311121564,
    0.13609695311121564,
    0.13993688583347344,
    0.13993688583347344,
    0.13201721256257315,
    0.13506048000005347,
    0.13289568686668646,
    0.13160494740004652,
    0.12898977433360415,
    0.12898977433360415,
    0.1362211505882656,
    0.13498224059259412,
    0.1296587520000685,
    0.1354796208529211,
    0.1339014630834754,
    0.13225385642856832,
    0.13225385642856832,
    0.1335455993998039,
    0.13370573479987796,
    0.1340575574443695,
    0.1375578030001634,
    0.13344989609091004,
    0.13370967016665722,
    0.13620769991306905,
    0.13620769991306905,
    0.13935335209085184,
    0.1372770024667261,
    0.13759610200031602,
    0.135441543037711,
    0.13618650999997045,
    0.13211319849961,
    0.13619405823999842,
    0.13615910799944686,
    0.13615910799944686,
    0.13741785949999516,
    0.1390599473333067,
    0.1450046624002425,
    0.14154369062498517,
    0.14384166183360017,
    0.14179539442842984,
    0.14179539442842984,
    0.11980253318175858,
    0.12183424275008292,
    0.12183424275008292,
    0.10105085150007653,
    0.1104472985001242,
    0.13226792942857304,
    0.1361528850002287,
    0.13323663519998566,
    0.12816187299995363,
    0.13014348800015796,
    0.1306213547999505,
    0.1306213547999505,
    0.13041153800016522,
    0.13273040099981395,
    0.1341329320800287,
    0.13460205625005983,
    0.13416777677775826,
    0.13432022878571712,
    0.13535636358331735,
    0.135346650000065,
    0.13455437159997624,
    0.13504886316665457,
    0.12833148749996326,
    0.13367775594828157,
    0.13486363776932053,
    0.1353711861999424,
    0.13561240518754403,
    0.1379213592499582,
    0.13520972499986783,
    0.1350279018889119,
    0.13597630362505697,
    0.1350433890555299,
    0.13996873550013333,
    0.13298332275007851,
    0.13433991200054152,
    0.1327762816666412,
    0.13487693741672047,
    0.13480686600002326,
    0.13467889179992198,
    0.13378697581576585,
    0.135152691750136,
    0.1332202559997313,
    0.1332202559997313,
    0.13460052400002426,
    0.1324187329992128,
    0.13548167154559368,
    0.13548167154559368,
    0.1341491707575408,
    0.13567426300005536,
    0.134378857411695,
    0.1337973921428264,
    0.13499402299996952,
    0.13499402299996952,
    0.1337385284814782,
    0.1337385284814782,
    0.13470490100007737,
    0.13470490100007737,
    0.1333467730000848,
    0.13189192999986213,
    0.13189192999986213,
    0.1352860429999257,
    0.13456983099990794,
    0.1331651270789543,
    0.12754961300015566,
    0.12759950750023563,
    0.13447924312504256,
    0.12804919100017287,
    0.13340370284000527,
    0.1396127104999323,
    0.13369951100139588,
    0.1330272090017388,
    0.1343377570001394,
    0.1345553996567078,
    0.13670791499998813,
    0.13549039790896958,
    0.13454721359994437,
    0.13436507580008766,
    0.13544186899995717,
    0.13544186899995717,
    0.13541001074963788,
    0.13384289372730895,
    0.13578831428562158,
    0.13238498194444523,
    0.13829927149981813,
    0.13653446220014304,
    0.13393869689989515,
    0.12957083049968787,
    0.1309042277998742,
    0.13087610866674973,
    0.1343875405490347,
    0.13102360325001428,
    0.13230669571428388,
    0.1318838099642952,
    0.13595235729807287,
    0.13034937611114905,
    0.13057499628562905,
    0.13144396271432665,
    0.13183718277772036,
    0.12975434875033898,
    0.1322288624999146,
    0.1326392987741729,
    0.12998983600118663,
    0.1337809567105643,
    0.13114124533300733,
    0.13219488019985876,
    0.13119098800016218,
    0.131458722500156,
    0.13243979033318787,
    0.13252485800007385,
    0.13252485800007385,
    0.13226181385705008,
    0.1330724686363696,
    0.13283769466670492,
    0.13319011828571092,
    0.13313261199982662,
    0.13313261199982662,
    0.13621681400036323,
    0.13408559999970748,
    0.12990671533346662,
    0.13118830377778876,
    0.13180430962484024,
    0.13349379676926149,
    0.12961430325003676,
    0.12564483449932595,
    0.1327141826001025,
    0.13522127102563294,
    0.13593207700023413,
    0.13593207700023413,
    0.137440746316679,
    0.13580310488567712,
    0.13139177528552995,
    0.13009634666680844,
    0.13627397366663327,
    0.1277060446670172,
    0.1276499760006118,
    0.1276499760006118,
    0.12843250049991184,
    0.1277929663338,
    0.1277929663338,
    0.1304253468749721,
    0.13636850182138005,
    0.13516222613337353,
    0.13516222613337353,
    0.1363601083928318,
    0.1390567096136279,
    0.13524261173686108,
    0.13524261173686108,
    0.13514719347050927,
    0.1325403651111022,
    0.13624681303225505,
    0.1327571382221827,
    0.13813943822222224,
    0.1299230135000471,
    0.13044179580028867,
    0.13048308933381728,
    0.13747216389983805,
    0.1291873284999383,
    0.13849377475007713,
    0.14027698883787584,
    0.1384918447999553,
    0.13803280554549763,
    0.134760600250047,
    0.13844201421423868,
    0.1396394134375214,
    0.13758967687499535,
    0.13960868553489447,
    0.14012963731249783,
    0.13962314924992825,
    0.14865374700002576,
    0.13841734105268474,
    0.13841734105268474,
    0.13767430292304758,
    0.13767430292304758,
    0.1287355264994403,
    0.1376783735833366,
    0.1376768443333276,
    0.1386434070833881,
    0.1402955800998825,
    0.1382901502000095,
    0.13546402800056967,
    0.13562284681245274,
    0.13562284681245274,
    0.13403290400007487,
    0.13403290400007487,
    0.13691847482690578,
    0.13691847482690578,
    0.13170195366637927,
    0.13260885800082178,
    0.13215227711104185,
    0.1374242075970014,
    0.1328897331109652,
    0.13826394726668997,
    0.1358906833000219,
    0.1320518681428179,
    0.1419987545999902,
    0.13968468075996499,
    0.12984285699985776,
    0.13737037516668554,
    0.13375185114273336,
    0.13375185114273336,
    0.13128211266666767,
    0.13128211266666767,
    0.13481280999985756,
    0.13481280999985756,
    0.14966289709991543,
    0.14223117784211736,
    0.13861672379971424,
    0.1490736987143464,
    0.13984666708332347,
    0.14329996094450811,
    0.14193033078950784,
    0.14193033078950784,
    0.13581098533359182,
    0.1356902037998225,
    0.1354728910009726,
    0.13178046285715286,
    0.13151759423528667,
    0.13151759423528667,
    0.13437115792003168,
    0.13095009250000658,
    0.12509577550008544,
    0.1304789184614492,
    0.13478942217242829,
    0.13478942217242829,
    0.13325238349989377,
    0.12967743833360146,
    0.1319384942499937,
    0.1314673043572319,
    0.13052050142843136,
    0.1323787741250726,
    0.13210645621046224,
    0.13142165624988897,
    0.13236219487498602,
    0.13236219487498602,
    0.13481066387178614,
    0.12303255400001945,
    0.12303255400001945,
    0.1361973679473809,
    0.13535064007688702,
    0.131482208000047,
    0.13247402225003194,
    0.13344865750013923,
    0.13729004296225678,
    0.1370224170000256,
    0.12954926550082746,
    0.13186586100012695,
    0.13186586100012695,
    0.1318871203332795,
    0.13798599508334064,
    0.13718805099961173,
    0.13110924389984574,
    0.13568576031252633,
    0.13250940244446005,
    0.132489806222212,
    0.13648532609088512,
    0.13828481151283947,
    0.13151239762510158,
    0.13888776213889287,
    0.13857496048485424,
    0.13912280180486006,
    0.13852318468420172,
    0.13196543774984093,
    0.13196543774984093,
    0.13887768379998824,
    0.14109552457141813,
    0.1379372600000092,
    0.1455030353998154,
    0.13870781688900832,
    0.13600595168182653,
    0.13794198914810193,
    0.13945971775001453,
    0.13869749726666972,
    0.13997984744444827,
    0.1386543269615616,
    0.14011688509080242,
    0.1407446119999674,
    0.13811995776471603,
    0.13811995776471603,
    0.13880343291665062,
    0.13368723499994908,
    0.13368723499994908,
    0.13717235513161685,
    0.13757495993021895,
    0.1370254258813706,
    0.13495805968750574,
    0.13506345894123062,
    0.13506345894123062,
    0.13571421277770745,
    0.1357321280715301,
    0.14019839838884865,
    0.13436942799853568,
    0.1387550354997984,
    0.1378906857142803,
    0.1388178057499577,
    0.13497665772725173,
    0.1408663506153971,
    0.13581534999998854,
    0.13780055416664255,
    0.14235827138467216,
    0.1280725460001122,
    0.1280725460001122,
    0.13395410000066477,
    0.13548808800010192,
    0.13843559688233226,
    0.1385557071176556,
    0.14444037558344766,
    0.14612310877762663,
    0.13859123406899895,
    0.1454125866999675,
    0.12146230000143987,
    0.1432043305000358,
    0.14736310074999892,
    0.1381722374000674,
    0.14215510611757054,
    0.14215510611757054,
    0.15241835600014988,
    0.14956655599962687,
    0.14956655599962687,
    0.13592166809524184,
    0.13592166809524184,
    0.13405986678571935,
    0.13405986678571935,
    0.13769977316648388,
    0.13452505146669863,
    0.13762010016641094,
    0.13762010016641094,
    0.1359207170908948,
    0.1359207170908948,
    0.1290744984999037,
    0.13400175312494866,
    0.13071522055543028,
    0.13061191228579055,
    0.1367937793695645,
    0.13198852300010913,
    0.13488770094449543,
    0.13075960112496432,
    0.1369402182173898,
    0.13479845924996425,
    0.13099422349993498,
    0.13099422349993498,
    0.13468837899997127,
    0.13468837899997127,
    0.1299270190002062,
    0.1333278196666975,
    0.13484789574996675,
    0.1299474111665404,
    0.1358551711999098,
    0.13176947039974038,
    0.13592690735718602,
    0.13656143537514254,
    0.1328208988001279,
    0.13685550599984708,
    0.1359382741500667,
    0.13680466200003139,
    0.13815049944443875,
    0.13815049944443875,
    0.13729072500002357,
    0.1353138320000653,
    0.1352763334998599,
    0.13919991780021518,
    0.1408036490001905,
    0.1371208338571575,
    0.13665504489999875,
    0.13492219496157093,
    0.13466979337499652,
    0.1344974559997354,
    0.13632763524992697,
    0.13433724766643232,
    0.13433724766643232,
    0.13476818699928117,
    0.13731846700102324,
    0.13355498344450703,
    0.14291557792309434,
    0.13462570268182555,
    0.14291387307695494,
    0.13519820330002402,
    0.13400366149994625,
    0.13496723021049356,
    0.13496723021049356,
    0.13877369692857297,
    0.13445936922208704,
    0.13445936922208704,
    0.13380151483337008,
    0.13894163252634348,
    0.13442098646664818,
    0.1338031676665802,
    0.13918825699996282,
    0.13469146378572208,
    0.1356556508000722,
    0.13634546533315492,
    0.1268371059995843,
    0.1268371059995843,
    0.13541407471426023,
    0.13640177533367628,
    0.13640177533367628,
    0.1368578368570265,
    0.1401087477368396,
    0.13458214977779587,
    0.14068403256248985,
    0.13454670800092572,
    0.1364140611667608,
    0.1359665373329335,
    0.14064677903843403,
    0.13464749781815044,
    0.13949111199963227,
    0.13949111199963227,
    0.13794828132499787,
    0.13374320799994166,
    0.13176787200003068,
    0.14332715111110397,
    0.1378630922727511,
    0.14303207452940114,
    0.13724781000018993,
    0.13425838500006648,
    0.13613520875014729,
    0.13751627800047572,
    0.14000000976666344,
    0.13970518103445195,
    0.1441849787368387,
    0.14365612956248697,
    0.16294964166627324,
    0.1439161699411617,
    0.14270756937503393,
    0.13616717693548708,
    0.14172322300146334,
    0.13867212182539954,
    0.15184982825030602,
    0.1430186995715173,
    0.1387733361296139,
    0.1387733361296139,
    0.13440793879999546,
    0.13570550879994697,
    0.1339929466896514,
    0.13329063700075494,
    0.137379329200121,
    0.13270007999926747,
    0.13934747683348783,
    0.13902313849985148,
    0.13398827299897675,
    0.13261587320002946,
    0.13805653034476814,
    0.12103671000113536,
    0.13330036166674594,
    0.1383456130606095,
    0.13374474370002645,
    0.13374474370002645,
    0.13334708019974642,
    0.13532584025006145,
    0.13306165014286567,
    0.13190580400005275,
    0.1308153488888719,
    0.13230878573340304,
    0.1323035157334137,
    0.127751172999524,
    0.1387431085172309,
    0.13154800580014125,
    0.13290410547062279,
    0.1314090476248566,
    0.1314090476248566,
    0.13407524833382922,
    0.13248386679988472,
    0.1320395185000507,
    0.1405256772963589,
    0.13369154066701108,
    0.13240483500012487,
    0.13577669527775368,
    0.13577669527775368,
    0.14081860638887317,
    0.14222748794438506,
    0.13341604892299913,
    0.13341604892299913,
    0.13888856877144592,
    0.1350445287777499,
    0.1346940808461323,
    0.13206133371438358,
    0.1341223689999294,
    0.1352465111666182,
    0.1422776720555703,
    0.13573132654544845,
    0.13054705600006855,
    0.13827235300000626,
    0.14405820647372916,
    0.13490135819993157,
    0.1411994866666646,
    0.14810235659988394,
    0.14810235659988394,
    0.1408949690000251,
    0.1408949690000251,
    0.14329032579998965,
    0.14329032579998965,
    0.14160678942854638,
    0.1407822352307565,
    0.16129740020005556,
    0.1613038539999252,
    0.1358869619998586,
    0.15277827862496451,
    0.15147911099989464,
    0.15147911099989464,
    0.15278244437490685,
    0.13717701527995815,
    0.13767529790906832,
    0.13809747190906352,
    0.13965420499880565,
    0.13825772681246917,
    0.13825772681246917,
    0.13593423233335974,
    0.13593423233335974,
    0.13593423233335974,
    0.13725718278265445,
    0.1308147326665979,
    0.1331927194443981,
    0.136066589100119,
    0.13626490906062827,
    0.13813505277782193,
    0.12802181650022249,
    0.13929292021049677,
    0.13929793383340439,
    0.14026589542858606,
    0.13937538787513404,
    0.13683843134379003,
    0.1288949270001467,
    0.1397110057498594,
    0.1392162075625265,
    0.14122797824999603,
    0.13519195139997464,
    0.13519195139997464,
    0.13976921840003342,
    0.1367322170508333,
    0.13781676673079346,
    0.14289041881817288,
    0.13682942794827702,
    0.13691750717646523,
    0.1448131129998526,
    0.149228605000341,
    0.14301163750042178,
    0.14301163750042178,
    0.1396653207144222,
    0.1349953624138489,
    0.1349953624138489,
    0.13631645018918986,
    0.13176250499964226,
    0.13176250499964226,
    0.1352020075555629,
    0.13527637266654186,
    0.13540321680011402,
    0.13540321680011402,
    0.1341332241249802,
    0.12945952100017166,
    0.13564311916676766,
    0.13706713400097215,
    0.1324483363332547,
    0.13444302746938774,
    0.1350306105555319,
    0.1328227990999949,
    0.13436705000003712,
    0.13289648040008614,
    0.13395198520011037,
    0.13282206264284468,
    0.1354479895587835,
    0.13235954090014274,
    0.12623236699982954,
    0.12623236699982954,
    0.13223981659994025,
    0.1328739854999791,
    0.1358234858400101,
    0.1324239461999241,
    0.13191429809994587,
    0.1337761512000725,
    0.1326346255000317,
    0.1332200879998709,
    0.1377075316668197,
    0.13679695874998288,
    0.13383010449979338,
    0.14065908299926377,
    0.136460942533328,
    0.13694079509100862,
    0.13694079509100862,
    0.14023926087497784,
    0.14181814233324985,
    0.14181814233324985,
    0.13843216524992386,
    0.13533521210809193,
    0.14352657033335467,
    0.13691824707690942,
    0.14068330162490383,
    0.13044325600094453,
    0.13532471018179698,
    0.13532471018179698,
    0.13184132800051884,
    0.13314040999975987,
    0.13314040999975987,
    0.1348690571904583,
    0.1348690571904583,
    0.13269218549976358,
    0.1349150993333058,
    0.13495581784206334,
    0.1319396550006786,
    0.1337202195384704,
    0.13445594399996075,
    0.13407347900000685,
    0.1341274415581422,
    0.1341274415581422,
    0.13419685285719293,
    0.13536993444439657,
    0.13272175431256983,
    0.13489634100005787,
    0.13356792300005005,
    0.13407593938887252,
    0.13430761933341273,
    0.1347031334166786,
    0.13424486018866788,
    0.1328387108998868,
    0.1328387108998868,
    0.1331939738824183,
    0.1338181798334214,
    0.13548101071423194,
    0.13548101071423194,
    0.13414648099978876,
    0.13495640710521242,
    0.1346612081249532,
    0.1320801339999889,
    0.13446563613046159,
    0.13152389445448617,
    0.13442137838890428,
    0.13556252911760514,
    0.1287568336665572,
    0.13467383988886972,
    0.1351665808571332,
    0.13466375361536054,
    0.13473687377278443,
    0.13291121391663788,
    0.13500341890903655,
    0.13535501323808385,
    0.13285787412496575,
    0.13499826454542266,
    0.13453951632254757,
    0.1367018094665885,
    0.13434411484905587,
    0.1346230093077163,
    0.13455159432606192,
    0.13502783816663091,
    0.13454995970005257,
    0.13479289856521695,
    0.13479289856521695,
    0.13138985999830766,
    0.13656045249990711,
    0.1348438343548262,
    0.13027942100052314,
    0.13511935875612835,
    0.135206672999976,
    0.135206672999976,
    0.13571923204168948,
    0.13507935864703646,
    0.13853396299982706,
    0.1383171269999366,
    0.1383171269999366,
    0.13174137642870068,
    0.1308194918571774,
    0.1308194918571774,
    0.13486156899944035,
    0.1309982710008626,
    0.1346523550000711,
    0.13375902421427913,
    0.13375902421427913,
    0.13383204446150698,
    0.13076848754545525,
    0.13462071953326812,
    0.1388772641194145,
    0.1346958749999203,
    0.12911394974980794,
    0.1328989180001372,
    0.1342344470856915,
    0.12859362883349,
    0.13366772752631637,
    0.1270756670000992,
    0.1362852994615633,
    0.13185185600013938,
    0.13714883085698862,
    0.13902323734939537,
    0.13614670288889438,
    0.13033749575015463,
    0.13013533699995605,
    0.13837994233330797,
    0.13856435475008766,
    0.13273398899946187,
    0.14023438042854,
    0.14023438042854,
    0.1284870729996328,
    0.1345207155217118,
    0.13852640844440126,
    0.1345479482608979,
    0.1345479482608979,
    0.13480083863636205,
    0.13480083863636205,
    0.13480083863636205,
    0.14027832035846483,
    0.1357685044000391,
    0.13188091659976636,
    0.13345586944000387,
    0.1357019510005557,
    0.13248474023077086,
    0.1300053404997925,
    0.1300053404997925,
    0.13407772302778337,
    0.13147637966661327,
    0.13461302869567907,
    0.13426998546156726,
    0.13399163911761955,
    0.1326588050000542,
    0.1298893119992499,
    0.13298640971437894,
    0.13259193589983626,
    0.13440052988233434,
    0.13274019539985601,
    0.13295829266664644,
    0.13352304250020097,
    0.13479648851611156,
    0.1421559480487947,
    0.1421559480487947,
    0.13360388366648598,
    0.14090015425531321,
    0.13359801771444577,
    0.13792846599972108,
    0.13792846599972108,
    0.13053745842859957,
    0.13467288404761002,
    0.1342436294615674,
    0.13100644320002175,
    0.1313599585000702,
    0.1292453209989617,
    0.1292453209989617,
    0.13586665057144792,
    0.13333613349959705,
    0.13523013679996437,
    0.1307673910014273,
    0.1307673910014273,
    0.1359186112000316,
    0.13766503134483454,
    0.13660249416655765,
    0.13389210449986422,
    0.1459795259997918,
    0.1459795259997918,
    0.13541813970005023,
    0.13541813970005023,
    0.13371320350051974,
    0.13510899618185332,
    0.13510899618185332,
    0.1399099603331706,
    0.1399099603331706,
    0.1337982517777871,
    0.13232206999964546,
    0.13232206999964546,
    0.13330748833323014,
    0.15024148242101595,
    0.14383810900001442,
    0.14920972014286754,
    0.13463598050020664,
    0.15094225452632695,
    0.13532914819988945,
    0.1347229299999526,
    0.1401057397142722,
    0.1360843372499403,
    0.1360843372499403,
    0.1449949553077134,
    0.13552790250014368,
    0.13530489933327772,
    0.13911418942864526,
    0.141938172333337,
    0.14419555116667956,
    0.14013739255056004,
    0.15825184053853894,
    0.15825184053853894,
    0.14434312957148773,
    0.15812548853850436,
    0.1411106876842001,
    0.1411106876842001,
    0.14401999615001843,
    0.1589557608889057,
    0.14172898625001834,
    0.14172898625001834,
    0.13160565810012487,
    0.13243896499989205,
    0.13243896499989205,
    0.13591056239477584,
    0.13587442349997123,
    0.13220006274991647,
    0.13891908200002945,
    0.13108160800038604,
    0.12941769280005247,
    0.1307133580001391,
    0.1307133580001391,
    0.13065530439998838,
    0.1311074234545231,
    0.13799221457893987,
    0.12864238749989454,
    0.13722016363639836,
    0.13812574598780816,
    0.13812574598780816,
    0.13672484782759495,
    0.12970090899943898,
    0.13066916349998792,
    0.13114255800019237,
    0.12992612500056566,
    0.13722445871430214,
    0.13956456212497415,
    0.13165434099998188,
    0.13329638675001357,
    0.13840357130762782,
    0.13845987265003715,
    0.13692300117648248,
    0.1383664319999601,
    0.13869297882608764,
    0.1366775810487658,
    0.13404912359983429,
    0.1396739359410918,
    0.14190802269233524,
    0.13526975249988027,
    0.12915420699937386,
    0.14146811984615992,
    0.14473594810006035,
    0.1370845997000288,
    0.14444758010013176,
    0.1433031382727098,
    0.14122417262501585,
    0.14914258571427905,
    0.1492961620000902,
    0.1492961620000902,
    0.13438511157145122,
    0.13853285635442159,
    0.13853285635442159,
    0.13303710583325787,
    0.13418177854542923,
    0.13185471549968497,
    0.13712460825000664,
    0.13410537173685474,
    0.13402300875001552,
    0.13351133899959677,
    0.1355047851110511,
    0.13526284299996405,
    0.1341482086110975,
    0.1341482086110975,
    0.13581253950026925,
    0.13456124892302165,
    0.13877486733326805,
    0.1381315958620564,
    0.13415863633332872,
    0.1361825466249229,
    0.12940105550023873,
    0.13727403754837136,
    0.13464371328570582,
    0.1351536250667171,
    0.1351536250667171,
    0.1384472363157935,
    0.13315325322218996,
    0.13943187661112055,
    0.1311158480002632,
    0.1311158480002632,
    0.13779591033335237,
    0.136387756928603,
    0.1382383855999554,
    0.1360984191666527,
    0.13617208992302318,
    0.13964903848714946,
    0.13964903848714946,
    0.13556262330002938,
    0.13556262330002938,
    0.13556262330002938,
    0.13612533737500598,
    0.1379753522000101,
    0.13871062699985892,
    0.14359143388881218,
    0.1401745737454555,
    0.1401745737454555,
    0.14072202971432748,
    0.1353680659995007,
    0.13356011449923244,
    0.1302727149995917,
    0.1413620289999513,
    0.13919053819999033,
    0.13803908499903628,
    0.13803908499903628,
    0.12918390925005951,
    0.13792770240006574,
    0.12732837600015046,
    0.12732837600015046,
    0.13312668175012732,
    0.13312668175012732,
    0.13312668175012732,
    0.13335246933335534,
    0.12932718999945791,
    0.1403258048799762,
    0.13755706852937102,
    0.13755808700004898,
    0.13755808700004898,
    0.1386708328000168,
    0.1386708328000168,
    0.1414526919999844,
    0.1414526919999844,
    0.1395991543334579,
    0.13950106888882552,
    0.14079909616672617,
    0.13964134388899968,
    0.13825471645445345,
    0.13825471645445345,
    0.13825471645445345,
    0.13440428866670118,
    0.13440428866670118,
    0.13881278940905098,
    0.14258480266673562,
    0.14298708381829783,
    0.14259898955565908,
    0.14341965000003257,
    0.14341965000003257,
    0.13916964663638448,
    0.14437386966680302,
    0.13982470081248266,
    0.1435195927274022,
    0.14082086335708613,
    0.14593953628562822,
    0.14701527657156735,
    0.14107742247056998,
    0.14107742247056998,
    0.13918310214285157,
    0.13918310214285157,
    0.1326249204444644,
    0.13729641220003638,
    0.13403085600002668,
    0.1372732284473482,
    0.14049562247618314,
    0.13313386522228635,
    0.14227231069232332,
    0.13443630588901417,
    0.13447151422224124,
    0.1344064242223087,
    0.14210647369229543,
    0.14013316962495992,
    0.13114348419985616,
    0.14420661040003324,
    0.1337106285000118,
    0.1390576981538498,
    0.13781508282856,
    0.13964576950002083,
    0.14589831191672906,
    0.1318251140000939,
    0.14074893147621229,
    0.14074893147621229,
    0.13435214556666325,
    0.1370134477777659,
    0.13468966612504119,
    0.13682088718170152,
    0.13786336544439515,
    0.13786202011114154,
    0.13786202011114154,
    0.13600839870581266,
    0.1364708849444772,
    0.1364708849444772,
    0.1364708849444772,
    0.1336430179599847,
    0.1336430179599847,
    0.13324419599995876,
    0.13250050750048104,
    0.13250050750048104,
    0.1335985492857747,
    0.1335985492857747,
    0.1326080371666952,
    0.13351373460003135,
    0.13351373460003135,
    0.13317993419987034,
    0.13335375811761074,
    0.13338890246149487,
    0.13572206162507428,
    0.14029485799983377,
    0.13365277800009304,
    0.13354224100003192,
    0.13409097700006148,
    0.13404641679990165,
    0.13300255824992746,
    0.13388184088238203,
    0.1314826194284251,
    0.13269999093330018,
    0.12916689566676118,
    0.1290656192500137,
    0.1290656192500137,
    0.13301648973076505,
    0.1285764989997915,
    0.13298645990909624,
    0.13363046702855041,
    0.13398303300000716,
    0.13366061833342732,
    0.13314657285714238,
    0.13319001442856201,
    0.13317483304002964,
    0.13398137746510255,
    0.134532748699894,
    0.13319091700001687,
    0.13319091700001687,
    0.13379728094231233,
    0.13496195942856762,
    0.1354035733747878,
    0.1333921890000056,
    0.13391285840002637,
    0.1331064175909143,
    0.12793918900024437,
    0.13408169512499626,
    0.1334645757272235,
    0.13256241000006133,
    0.13291843719998725,
    0.1339089805715048,
    0.13409514459703703,
    0.13371939242850722,
    0.1341274232063514,
    0.13383482157692364,
    0.13237861141669782,
    0.1311580767498981,
    0.1337236882726839,
    0.13309933211106303,
    0.13394397844447464,
    0.13202194633322506,
    0.13380608634780283,
    0.1336082177333689,
    0.1336082177333689,
    0.13063890600005834,
    0.1338592388420741,
    0.1331970204665898,
    0.1339651682999829,
    0.13385165450017666,
    0.1335781679411893,
    0.13421479637503353,
    0.13444515733337742,
    0.1339783497647017,
    0.1339783497647017,
    0.13451257759457017,
    0.13371159277792483,
    0.13371159277792483,
    0.13330777266673977,
    0.13181988060023286,
    0.13181988060023286,
    0.13381210483324443,
    0.132945504111275,
    0.132919882777666,
    0.13496281435709534,
    0.1346665377500358,
    0.1328912487778224,
    0.13563152666696018,
    0.13536292022217822,
    0.13479651775014645,
    0.13441868761108505,
    0.13506295775005128,
    0.13134209599957103,
    0.13427587911627237,
    0.13360850879998906,
    0.13382696704344277,
    0.1324345330012875,
    0.13399709809097907,
    0.1350854274117891,
    0.13467605923527598,
    0.13467605923527598,
    0.1362502305556619,
    0.13492870953126612,
    0.13905252076271563,
    0.13905252076271563,
    0.13617228355542466,
    0.14784067875007167,
    0.13363773287505865,
    0.13470500142856118,
    0.13440924935486925,
    0.13488098366663812,
    0.1348523416363605,
    0.1348523416363605,
    0.13369239159523463,
    0.13628036142862193,
    0.13335400066656197,
    0.1341856656666399,
    0.13275155166653954,
    0.13275155166653954,
    0.08161813550032093,
    0.09976800233319712,
    0.12080284344443094,
    0.13021719210714114,
    0.13321136555573,
    0.13332723212488418,
    0.13129543771408084,
    0.13474726711097496,
    0.133621854483863,
    0.133621854483863,
    0.12978191266665817,
    0.1339696611785907,
    0.13510988255560127,
    0.13422564970005624,
    0.13503007787494425,
    0.13499909412496436,
    0.13597111162494002,
    0.13752960653624358,
    0.13812421660004476,
    0.13726258330007113,
    0.13237457499963057,
    0.1353311749999193,
    0.14309829162499454,
    0.13436334604163372,
    0.1390637738181712,
    0.14049926875031815,
    0.1343939416666318,
    0.1329470014998151,
    0.13747941382811746,
    0.1350112773334331,
    0.13476580650058168,
    0.13327840366660634,
    0.13487465100115514,
    0.13402462666676407,
    0.14421893730769414,
    0.13304233975001503,
    0.1431138091724404,
    0.13355782210001052,
    0.13355782210001052,
    0.14297221003446262,
    0.1319355703999463,
    0.13228020944441393,
    0.13238387981255073,
    0.13337766154555455,
    0.13327068250055163,
    0.1422448198386959,
    0.13420663163158583,
    0.13186881262504357,
    0.13186881262504357,
    0.1343476393332013,
    0.1329464775000512,
    0.13848918000076083,
    0.1334446831111159,
    0.1342180411429581,
    0.1342180411429581,
    0.13447839616674173,
    0.1389287831428804,
    0.13430564400005096,
    0.12919595499988645,
    0.14107056797219128,
    0.14107056797219128,
    0.149958921058843,
    0.13441768116657235,
    0.13336669000000256,
    0.14056642860000465,
    0.1371528732497609,
    0.1357027769990964,
    0.1523999782000222,
    0.1523999782000222,
    0.13788338900121744,
    0.13304737599992222,
    0.13070401985714852,
    0.15151197846668463,
    0.13864471284810123,
    0.1370069024998884,
    0.129053888499584,
    0.1329444315000122,
    0.12836241200056975,
    0.13102150400027313,
    0.1377112309523837,
    0.16489329633340175,
    0.15713900558330351,
    0.1503791939411552,
    0.14510284507996402,
    0.14510284507996402,
    0.1417175080294007,
    0.1702735383748859,
    0.15956759645450802,
    0.14699562024998158,
    0.14699562024998158,
    0.1578278055000434,
    0.1578278055000434,
    0.13355887979996622,
    0.13355887979996622,
    0.13412943333363123,
    0.13652551750055864,
    0.13353044399991632,
    0.13470161546152107,
    0.13470161546152107,
    0.13364510635710758,
    0.134054797600038,
    0.134054797600038,
    0.13440731566667333,
    0.13334628688004158,
    0.1359806604216949,
    0.1325755714665623,
    0.1339180586607134,
    0.13507431924995217,
    0.13507145624998884,
    0.13150717566653233,
    0.1339972433750063,
    0.13311009719513006,
    0.139219026000319,
    0.13252358350018767,
    0.13063135771439452,
    0.13322448799994568,
    0.14658943900030863,
    0.13280926388890496,
    0.13217317494450576,
    0.1309190142501393,
    0.1337048234285508,
    0.1337048234285508,
    0.13315510599986738,
    0.13315510599986738,
    0.13407251940006973,
    0.12919098749989644,
    0.13109068133356536,
    0.1326180055714628,
    0.13665318075362703,
    0.1339555726000981,
    0.1322940055000572,
    0.1322940055000572,
    0.13345257366664656,
    0.13345257366664656,
    0.1363328330416683,
    0.1338180927778012,
    0.13490304483336027,
    0.13621138825010348,
    0.13250932470584623,
    0.1305121040004451,
    0.1329239527586369,
    0.13192096166666387,
    0.1364126486888886,
    0.1364126486888886,
    0.13225283647058378,
    0.13103220777783361,
    0.13240304920000198,
    0.13192005107144464,
    0.1323738435003179,
    0.13130327999897418,
    0.13320975599999657,
    0.1331017087500186,
    0.12921080050000455,
    0.13730868875556754,
    0.13730868875556754,
    0.12846569700013788,
    0.1373165985000014,
    0.1373165985000014,
    0.1328650394210088,
    0.1330700606666748,
    0.13345160855005817,
    0.13345160855005817,
    0.12932591833305196,
    0.13304071127276984,
    0.13338647531580997,
    0.13373739960875158,
    0.13320310688888842,
    0.13391500222728195,
    0.13265838250026718,
    0.13364038511119564,
    0.13430934608337944,
    0.13412587674997667,
    0.1340137959999227,
    0.1340137959999227,
    0.13057381650014577,
    0.13057381650014577,
    0.132967156166463,
    0.132967156166463,
    0.13374109440010215,
    0.13234618933327308,
    0.11852702700161899,
    0.1320532047141439,
    0.13459686220012373,
    0.1342714141818843,
    0.14028564099862706,
    0.14028564099862706,
    0.14015188295450737,
    0.13935566147364098,
    0.13410230333344467,
    0.13410230333344467,
    0.1333842586922961,
    0.14005403111535158,
    0.13215423540023039,
    0.13281645445452092,
    0.13488719199995103,
    0.13988147885297889,
    0.13394916130766013,
    0.13030194549992302,
    0.13334304122225957,
    0.1402457986666625,
    0.1421787444999912,
    0.1339218858888166,
    0.1339218858888166,
    0.1387370340007692,
    0.1417895880999822,
    0.14056065859998246,
    0.14191667171430059,
    0.14200244784210794,
    0.14589902191664805,
    0.13172269233291445,
    0.13172269233291445,
    0.1430325124444304,
    0.13270641500002966,
    0.13689899600012723,
    0.13876789714283536,
    0.13623702366688425,
    0.14225436590913887,
    0.14225436590913887,
    0.1504023838889326,
    0.15986869139996998,
    0.14323969331579925,
    0.14323969331579925,
    0.1351101100002173,
    0.13864491874983287,
    0.13864491874983287,
    0.1371349549996618,
    0.1371349549996618,
    0.1371349549996618,
    0.13713547680017654,
    0.1367646660666651,
    0.13791441977769459,
    0.13630110499996756,
    0.1367226247778793,
    0.13384513975006485,
    0.1356539378000889,
    0.13662560074078134,
    0.13623232780009858,
    0.13538814242105887,
    0.13538814242105887,
    0.1384182432439269,
    0.14067985899964697,
    0.14047493366645844,
    0.13715452512496995,
    0.13782753400028014,
    0.13730646557688977,
    0.13481514919985785,
    0.1335574272222099,
    0.1335574272222099,
    0.13664696236848708,
    0.13664696236848708,
    0.13718522349972773,
    0.13211871875000725,
    0.14014058166670415,
    0.13667840321295444,
    0.1340807279000728,
    0.1340807279000728,
    0.1374289690822031,
    0.14053127647829292,
    0.14053127647829292,
    0.13686933959577297,
    0.13686933959577297,
    0.13848677299997422,
    0.1414793131500119,
    0.1414793131500119,
    0.1340072898751714,
    0.14052076328000113,
    0.138833700083372,
    0.1318649370005005,
    0.1432615125882234,
    0.14068208971418375,
    0.14068208971418375,
    0.1444655524992413,
    0.14413399786668984,
    0.14413399786668984,
    0.14309869016657709,
    0.14309869016657709,
    0.1367188089989213,
    0.1367188089989213,
    0.1367188089989213,
    0.1341488991110964,
    0.1331194254211081,
    0.13362062278572143,
    0.13362062278572143,
    0.13346163666634916,
    0.1290336935007872,
    0.12191249399984372,
    0.12191249399984372,
    0.1332564087000719,
    0.13610954690564128,
    0.13342003940744218,
    0.13303501284004596,
    0.13278845342105533,
    0.1325631227142107,
    0.1325631227142107,
    0.13178589000017382,
    0.13232443768754365,
    0.13243349125002624,
    0.13741006657143034,
    0.1361761785999988,
    0.1322078340999724,
    0.13241478166673915,
    0.1297630905000915,
    0.13266216216667695,
    0.13246747778573212,
    0.13461176163640298,
    0.13376635900021938,
    0.14178296599948226,
    0.13460052768001332,
    0.13368789255552352,
    0.13387335199995504,
    0.131150956714399,
    0.1340398769998501,
    0.13481340983313808,
    0.13481340983313808,
    0.12829090300056123,
    0.13373170530772208,
    0.13236459271424142,
    0.13486344507145986,
    0.13684261303704395,
    0.13684261303704395,
    0.13708345687503729,
    0.13466144018176154,
    0.13634364112499497,
    0.13581716493342053,
    0.13532845753840006,
    0.13532845753840006,
    0.13720557738301106,
    0.13793020265714273,
    0.13827245285183717,
    0.1389688098620511,
    0.1354926330001366,
    0.1317256347501825,
    0.13584597100089013,
    0.13034277999940969,
    0.13713072107408084,
    0.13810276688234488,
    0.13775084549997701,
    0.1382007413500105,
    0.13656025519994727,
    0.13785700683720914,
    0.13700681299997086,
    0.14003095366630683,
    0.14003095366630683,
    0.12908736399913323,
    0.13601100640007643,
    0.1349677225001263,
    0.13679232628575327,
    0.13600254599987238,
    0.13714786905797338,
    0.1370608203997108,
    0.13949208356525164,
    0.1394705074999365,
    0.1394705074999365,
    0.14044051920027414,
    0.14065974483340446,
    0.14065974483340446,
    0.13726841890002106,
    0.1376185885263495,
    0.14295213599962153,
    0.13682279871422257,
    0.14287985369992384,
    0.14287985369992384,
    0.13585083112004212,
    0.13585083112004212,
    0.13211925228564983,
    0.13305445766673074,
    0.1320173230769097,
    0.1358099605312475,
    0.13313435849990388,
    0.13313435849990388,
    0.13608038025371055,
    0.13237284819988418,
    0.1348675288636514,
    0.1348675288636514,
    0.12979839800027548,
    0.13468655492865114,
    0.13152689433324363,
    0.13152689433324363,
    0.13526459638099672,
    0.13505585604998488,
    0.13133841850003591,
    0.1321208019999176,
    0.1321208019999176,
    0.13182330800009368,
    0.13182330800009368,
    0.1359609768889843,
    0.13611375716664043,
    0.136875660307711,
    0.13843519462488985,
    0.13734401850000294,
    0.13855884683349964,
    0.13648081328570005,
    0.1364903322499913,
    0.13498938265386712,
    0.13655449931252406,
    0.13655449931252406,
    0.14043620400025247,
    0.13613492941666058,
    0.13544988649994139,
    0.13669108127269833,
    0.13669108127269833,
    0.13565171564705986,
    0.13733808614707038,
    0.1332784036363922,
    0.1332784036363922,
    0.1340821961109921,
    0.14339501236356061,
    0.13289918716661,
    0.13377545988886494,
    0.13335574099999742,
    0.13335574099999742,
    0.13625793853847987,
    0.1330905894999887,
    0.1364101552972971,
    0.1361816074999903,
    0.13291471199954685,
    0.13246962057149045,
    0.1299853585001074,
    0.1299853585001074,
    0.1312730110999837,
    0.12913868599935086,
    0.1325868325002375,
    0.12990639800045756,
    0.12990639800045756,
    0.13773016915796402,
    0.13825830420932486,
    0.1316458975555482,
    0.13710649544002082,
    0.13710649544002082,
    0.1536477529999419,
    0.13201745657118277,
    0.1305655193750681,
    0.13766374165219453,
    0.14375380866658816,
    0.13836008090623864,
    0.13157941500048764,
    0.1373822647936553,
    0.13783737900002963,
    0.13830447515790997,
    0.13802300861901867,
    0.13802300861901867,
    0.14013895633327897,
    0.13948998529995152,
    0.13883492300002134,
    0.1465960881250794,
    0.13992396611764193,
    0.14485185611091664,
    0.13982492252637857,
    0.1408488893666193,
    0.14623953337491002,
    0.374025883998911,
    0.14622584475000622,
    0.10099889000002804,
    0.11607156412492259,
    0.10663125979990581,
    0.10673529099985898,
    0.13322240808323235,
    0.13613588050066028,
    0.13230926199997026,
    0.13424849633338454,
    0.13801217721312078,
    0.13229669657136714,
    0.1320415236248209,
    0.1320415236248209,
    0.13292397577788506,
    0.13292397577788506,
    0.13776638599999083,
    0.1358335581052846,
    0.13661406724073727,
    0.13457621721434926,
    0.13544166454547932,
    0.13111188299990317,
    0.13111188299990317,
    0.13346235159988282,
    0.1331686819994502,
    0.13696243088001211,
    0.13696243088001211,
    0.13911478954546372,
    0.13911478954546372,
    0.13911478954546372,
    0.13626279024992982,
    0.1377709608823352,
    0.1321401249997507,
    0.13952357975003907,
    0.13688567316664071,
    0.13837673944443749,
    0.1389259523332132,
    0.13751268250007342,
    0.13751268250007342,
    0.13197850600045058,
    0.13197850600045058,
    0.1434129060000487,
    0.13713007923806367,
    0.13713007923806367,
    0.13713007923806367,
    0.14310876521436253,
    0.14310876521436253,
    0.14492047579988138,
    0.14492047579988138,
    0.14844936519984914,
    0.14844936519984914,
    0.15354043799986053,
    0.15354043799986053,
    0.15354043799986053,
    0.13428627890909245,
    0.13258043742107953,
    0.1329252238333538,
    0.1373092293336716,
    0.137695449999228,
    0.1338324166666401,
    0.13752519700028643,
    0.13732445299865503,
    0.13508077440019406,
    0.13320761876919,
    0.13217029273911737,
    0.13249722400026562,
    0.13226509368427,
    0.13361277657142118,
    0.13258731472221066,
    0.13464515524992748,
    0.13400909900004385,
    0.13138551379997807,
    0.13136072661528977,
    0.13136072661528977,
    0.13172381988887435,
    0.13312614518758892,
    0.13450864422224254,
    0.1325521326429485,
    0.13181574233324986,
    0.13370055442101147,
    0.13232667946151475,
    0.12956093885700934,
    0.12915624000015669,
    0.12808492000112892,
    0.13403112890470462,
    0.13255720030010706,
    0.13513724384210946,
    0.13469800873913892,
    0.13511968964514615,
    0.13511968964514615,
    0.13079262400060543,
    0.13416547949987034,
    0.12937791500007734,
    0.13531648006244268,
    0.131193956000061,
    0.13150708700050018,
    0.13399902383328785,
    0.13552692033348043,
    0.13432117789998302,
    0.13435306999999738,
    0.12558690600053524,
    0.13536214496428198,
    0.13536214496428198,
    0.1365489590833325,
    0.13589964400021667,
    0.1361330236538309,
    0.1362393867000719,
    0.1362393867000719,
    0.13265085274997546,
    0.1367006167499767,
    0.13628586667852818,
    0.13301093600057357,
    0.13301093600057357,
    0.1373631045714449,
    0.13846057712498805,
    0.13846057712498805,
    0.1356821860833103,
    0.1356821860833103,
    0.13683930949991918,
    0.13590088000000833,
    0.140208061499834,
    0.14062248549998912,
    0.1360292074285618,
    0.13600064889997157,
    0.1358227991851756,
    0.13150907766672995,
    0.13483138663152777,
    0.13405903335712668,
    0.10035715000049095,
    0.1340486802856893,
    0.13655205510526444,
    0.13702367036355348,
    0.14095577943589888,
    0.14095577943589888,
    0.13510281283318668,
    0.13206526599969948,
    0.13405326533332604,
    0.13579680974999064,
    0.1393841031250044,
    0.13219457149989466,
    0.13634016492296025,
    0.14120110174075376,
    0.13604119196694708,
    0.13829911744445175,
    0.14343560999986948,
    0.13708609209094325,
    0.13708609209094325,
    0.13683510819998143,
    0.13683510819998143,
    0.13690169599976798,
    0.13690169599976798,
    0.1361125194998749,
    0.1361125194998749,
    0.13990526149998253,
    0.13493264600001567,
    0.13657298441664048,
    0.1346629121427603,
    0.13763735133337227,
    0.13347535299908486,
    0.14478108566670148,
    0.1399755535557132,
    0.13211786500050948,
    0.1353092059998744,
    0.13925000533345155,
    0.14256782333339085,
    0.1438982374997977,
    0.1438982374997977,
    0.14078208013337037,
    0.14079614379305236,
    0.14079614379305236,
    0.13780464014286867,
    0.13776710828564578,
    0.13526991600003385,
    0.13552513781814923,
    0.13471533658066032,
    0.13731742700110772,
    0.1359300392631619,
    0.14172149183317137,
    0.13727484320006625,
    0.13727484320006625,
    0.13599619716660527,
    0.13527028181249534,
    0.13527028181249534,
    0.13135960399995383,
    0.13135960399995383,
    0.13377972806256366,
    0.13377972806256366,
    0.13352697499976784,
    0.13313393605879836,
    0.12918517499989926,
    0.13082674871449335,
    0.13155514975005644,
    0.1335434177499792,
    0.13001034949957102,
    0.1331120512121274,
    0.13329344834781534,
    0.13379148507153463,
    0.13374473303701961,
    0.13476136477765976,
    0.13393376808002358,
    0.13407611852937193,
    0.13451585568178748,
    0.1363501312857157,
    0.1337599075714674,
    0.13736249979992862,
    0.1355481596668445,
    0.13380653723078678,
    0.13645812437493987,
    0.1363850165000713,
    0.13750232557140407,
    0.1333902054634009,
    0.13817294199998287,
    0.13817294199998287,
    0.13321154422222511,
    0.12997541225013265,
    0.13233719299993632,
    0.13186087180001776,
    0.13333555004161704,
    0.13392579700005378,
    0.13252524358333378,
    0.13069649799945182,
    0.13319576960008514,
    0.13290567354834498,
    0.13507208177765684,
    0.13215034525001101,
    0.13559355449979194,
    0.13357118238463256,
    0.135691746575003,
    0.135691746575003,
    0.13575576200006859,
    0.13739615740014416,
    0.13739615740014416,
    0.13260171421738368,
    0.13653737699951307,
    0.13232889812502435,
    0.13239701029169737,
    0.13363005199997652,
    0.13363005199997652,
    0.1320006521000323,
    0.12504351600000518,
    0.1296346529998118,
    0.1296346529998118,
    0.13191690190014924,
    0.1330824907954593,
    0.1331962763000047,
    0.13179415237497474,
    0.13199039785701774,
    0.1329930904998946,
    0.1318521591998433,
    0.132164828166727,
    0.13438824287504758,
    0.13255931740910787,
    0.1328856595000616,
    0.13336861228947927,
    0.13336861228947927,
    0.13414971622952462,
    0.13414971622952462,
    0.13595604250015944,
    0.1332996134062796,
    0.13401094966664256,
    0.1358355901666073,
    0.13318741197434017,
    0.1318259363636323,
    0.1318259363636323,
    0.1387196794994452,
    0.13313933165515884,
    0.13127593492306636,
    0.13006320566677865,
    0.12996778122235103,
    0.1305910793331956,
    0.1327921163333072,
    0.14183984500050428,
    0.12579748299958737,
    0.12840680074987176,
    0.12877099450015522,
    0.13174973723524838,
    0.1309974947776532,
    0.12928844980015128,
    0.13100513122218319,
    0.13320550571427572,
    0.13673631690741145,
    0.12908031500001016,
    0.13072867021427165,
    0.13023579950004205,
    0.12919172100009746,
    0.12936131075002777,
    0.1268179960006819,
    0.13173146728591487,
    0.1298769119998724,
    0.13682953539286505,
    0.13382586356668374,
    0.13385967554161957,
    0.13188836925003974,
    0.130028399999901,
    0.13400153397616946,
    0.13436838490006267,
    0.13285198309081767,
    0.13285198309081767,
    0.12951118099954328,
    0.12951118099954328,
    0.13464594959996248,
    0.1331985206999889,
    0.12844695466628764,
    0.13321402209985536,
    0.13321402209985536,
    0.12875498799985508,
    0.13254885700007435,
    0.1345024874761813,
    0.13362641688884955,
    0.13015964299993357,
    0.13681674080218506,
    0.13219673555552922,
    0.13386512327269884,
    0.13484309966666583,
    0.13524335200054338,
    0.13537789594733782,
    0.13596332916677056,
    0.13707862088873904,
    0.13655744749994483,
    0.13505375941178285,
    0.13652484275007737,
    0.13681062000008146,
    0.1374369461667205,
    0.13674696257164345,
    0.1332477570000871,
    0.13047915649985953,
    0.13569833454560218,
    0.13607032479994813,
    0.13660978677782826,
    0.14222007850003138,
    0.13452306800008956,
    0.13320302031580036,
    0.13423948000005717,
    0.13338653940008954,
    0.13350967499900435,
    0.13295011514284333,
    0.13295011514284333,
    0.1326722455005438,
    0.1326722455005438,
    0.1327603757142372,
    0.13925394380649161,
    0.138833466090904,
    0.14057554959996196,
    0.13980754148279034,
    0.13183083000149054,
    0.13837900316669524,
    0.13837900316669524,
    0.133697242749804,
    0.13346108700011428,
    0.13346108700011428,
    0.14159162745454523,
    0.13855338808571105,
    0.13420762024998112,
    0.13605976866650357,
    0.13341144655553056,
    0.1312680001999979,
    0.1312680001999979,
    0.13894173700003876,
    0.13626148269227437,
    0.13626148269227437,
    0.1332425524997234,
    0.14031241326316185,
    0.13340520325004945,
    0.13340520325004945,
    0.13195821125009388,
    0.13457073033350753,
    0.13293866999993043,
    0.13546300300004077,
    0.14407031941171974,
    0.1394114436470594,
    0.14175141981823716,
    0.14145806681815223,
    0.14336803031581344,
    0.14336803031581344,
    0.15328078066684409,
    0.14235897814996862,
    0.153952881999885,
    0.17524173271444202,
    0.14098617008572287,
    0.14098617008572287,
    0.14766306366679297,
    0.14766306366679297,
    0.13855376246773365,
    0.1467718857143804,
    0.1467718857143804,
    0.17674257899974086,
    0.17674257899974086,
    0.3809483999993972,
    0.13326913513725125,
    0.13326913513725125,
    0.1336603866669369,
    0.1356549380147151,
    0.1356549380147151,
    0.13467696380030247,
    0.1341256246001649,
    0.13282931211102145,
    0.13656561002774956,
    0.13563692156337862,
    0.13335991349981668,
    0.13335991349981668,
    0.13337006016657446,
    0.13260290733342117,
    0.13260290733342117,
    0.1375471588748951,
    0.13751921924995258,
    0.13586556185714832,
    0.13987141474990494,
    0.13933652187506596,
    0.1398364673529132,
    0.1409428649997911,
    0.13930308699991656,
    0.14315694709098767,
    0.1434148114999516,
    0.14182537999992442,
    0.14182537999992442,
    0.14220655399913085,
    0.14220655399913085,
    0.14220655399913085,
    0.1378399337141413,
    0.1378399337141413,
    0.1277997460001643,
    0.1274671720002516,
    0.12715592099993955,
    0.12715592099993955,
    0.12898593150021043,
    0.12898593150021043,
    0.13485613009090064,
    0.13485613009090064,
    0.13495969594115356,
    0.13495969594115356,
    0.130387337142955,
    0.12918855099997018,
    0.1370278020999952,
    0.13193766949996188,
    0.13074200371426872,
    0.13074200371426872,
    0.1319030424615798,
    0.13271260393753437,
    0.131882428300014,
    0.13390572739990603,
    0.12942789499993523,
    0.13236305076465857,
    0.1326247488750596,
    0.13199492500007182,
    0.13199492500007182,
    0.1323125685453719,
    0.13384473000041908,
    0.13772737700128346,
    0.13772737700128346,
    0.13478685140003108,
    0.12791030650078028,
    0.12791030650078028,
    0.13154081750008118,
    0.13504663909677014,
    0.13304613855547764,
    0.13114836233338187,
    0.13169716160009556,
    0.13136003149975295,
    0.1320695632002753,
    0.13474256105000676,
    0.13215594139983294,
    0.13479407709983207,
    0.13479407709983207,
    0.13513706283341284,
    0.13495093120000093,
    0.1355735544736825,
    0.13567852064287372,
    0.13544783240031394,
    0.1386806404680875,
    0.13587762256247515,
    0.13439979574968675,
    0.13569767999999588,
    0.13569767999999588,
    0.13563086585717038,
    0.13658782058902869,
    0.13658782058902869,
    0.135944235583338,
    0.1388145999999324,
    0.1370425583461558,
    0.1370425583461558,
    0.1384950213529259,
    0.13682868000001977,
    0.13275624499965488,
    0.13284457566624042,
    0.1353975193928818,
    0.1342695049998939,
    0.1342695049998939,
    0.13478201640009502,
    0.13557292228571377,
    0.13484627466681964,
    0.13642173385185877,
    0.13642173385185877,
    0.13555005670004902,
    0.13511731475000488,
    0.13580008310000266,
    0.13477228091657403,
    0.1361526314737459,
    0.1371093001427133,
    0.13962648994285182,
    0.13655198569564242,
    0.13655198569564242,
    0.13692363321043607,
    0.13692363321043607,
    0.13750024025011953,
    0.1416443350008194,
    0.13620459958322803,
    0.13591543623064914,
    0.13969951803031136,
    0.13997033200030273,
    0.13577132142849482,
    0.13504802320003365,
    0.13517888944443257,
    0.1368824233572273,
    0.13547524783340728,
    0.13237786233366933,
    0.13719346063639518,
    0.13706933642866456,
    0.13720070873326526,
    0.13776728146149253,
    0.13776728146149253,
    0.1403064606087276,
    0.14322585633332588,
    0.14173429605264237,
    0.13805574690906558,
    0.13805574690906558,
    0.1418089220001093,
    0.13816409767648163,
    0.14541285871421547,
    0.14541285871421547,
    0.14541285871421547,
    0.13255604000005405,
    0.13255604000005405,
    0.1431393043333325,
    0.1431393043333325,
    0.14344828260000214,
    0.14344828260000214,
    0.13416605366667986,
    0.13413597733334529,
    0.1339169947222116,
    0.1334602758695679,
    0.13857942999948136,
    0.1339997195000251,
    0.1336239434665913,
    0.13373417427266593,
    0.1327488790001163,
    0.13750934800009418,
    0.1341608194444335,
    0.13441949320003915,
    0.1337020932726525,
    0.13380676499998248,
    0.13242383451512124,
    0.13510552903529008,
    0.14107270099884772,
    0.13567346819982049,
    0.13185972700011916,
    0.1325575793750886,
    0.13218390350001838,
    0.1330313877143843,
    0.13670555699991382,
    0.13404063899979518,
    0.12947646900101972,
    0.131032568250248,
    0.1312193923331506,
    0.13195923507695484,
    0.13150075819988463,
    0.1328102226226584,
    0.13191032975009875,
    0.13355368600059592,
    0.1323245347141762,
    0.13152762549998442,
    0.1318157528572296,
    0.13115871600014847,
    0.13162326040001063,
    0.13186149222221705,
    0.13201715591670413,
    0.13201715591670413,
    0.13159194549977352,
    0.1290080359995045,
    0.13118644412497815,
    0.13118644412497815,
    0.13656305906428576,
    0.1345563383877431,
    0.1288850998000271,
    0.1288850998000271,
    0.1286381193337244,
    0.13273186786205643,
    0.12791810749968135,
    0.1322354847691783,
    0.13252790516662571,
    0.1326569515428543,
    0.13464084833334103,
    0.13269431611757576,
    0.13291506188903035,
    0.13338955686667758,
    0.13324741746150837,
    0.13026447999982338,
    0.13390687288887826,
    0.13616981883327148,
    0.13379109722215313,
    0.13286365136363285,
    0.13810116199965705,
    0.1342895307498111,
    0.13209684477765726,
    0.13570194433365637,
    0.13351749108339087,
    0.13188214371426252,
    0.13472842124320852,
    0.13285242173677894,
    0.13304553236666833,
    0.1330873937895376,
    0.1330873937895376,
    0.1332757028947909,
    0.1332757028947909,
    0.1326777733332468,
    0.13351636944443507,
    0.1333895037499436,
    0.1365100205714173,
    0.13082901800044056,
    0.13405533633340383,
    0.13235427899999194,
    0.12775843999952485,
    0.1328218948888712,
    0.13625409192305737,
    0.13656368136250877,
    0.13306466199992428,
    0.13226257899987104,
    0.13298846499856154,
    0.13637031962502988,
    0.13773154320514527,
    0.13344360044458073,
    0.13589491880004062,
    0.13270704400005903,
    0.1328457370000251,
    0.1326583276363222,
    0.13098666600126307,
    0.13072793099854607,
    0.13370561933334102,
    0.13370561933334102,
    0.13370561933334102,
    0.13148053466678297,
    0.13148053466678297,
    0.1359801375714423,
    0.1366849078946727,
    0.1312340925001081,
    0.1312340925001081,
    0.13587424919049745,
    0.13587424919049745,
    0.1318749867998122,
    0.13196289099999245,
    0.14011204066668548,
    0.14011204066668548,
    0.1369823224999891,
    0.12986989799992443,
    0.13317895625004894,
    0.13489445850003298,
    0.13489445850003298,
    0.14428030912517897,
    0.13921229874995333,
    0.14030672230001073,
    0.1399745894999569,
    0.1381128004995844,
    0.14143472627272952,
    0.1405242238845928,
    0.1405242238845928,
    0.1405242238845928,
    0.13880162716668565,
    0.13880162716668565,
    0.12900821099901805,
    0.12914513433376365,
    0.13985601846664697,
    0.12891446799949335,
    0.13163738257130067,
    0.13163738257130067,
    0.14168950261535848,
    0.13665994969996972,
    0.13282758075001766,
    0.13889780722721215,
    0.1346090491111277,
    0.1346090491111277,
    0.13533695499972964,
    0.14120386114284753,
    0.13500378312505745,
    0.13811598204349296,
    0.1368328990999847,
    0.13699982240384018,
    0.13230396649942122,
    0.1373886932199821,
    0.1373886932199821,
    0.14668548233385081,
    0.14954649100010492,
    0.13983909072218617,
    0.14133394424970902,
    0.14203785666662347,
    0.1362474798846121,
    0.1362474798846121,
    0.13343895791672367,
    0.13324146457891498,
    0.13703637430264853,
    0.13267558469236135,
    0.13267558469236135,
    0.13623618349993194,
    0.1328557986875012,
    0.13245031257143378,
    0.14164834000075643,
    0.13068444514309313,
    0.13056042587504635,
    0.12784868600010668,
    0.12848620600016147,
    0.12848620600016147,
    0.13141629339988867,
    0.13156314661528784,
    0.12625920900003015,
    0.12625920900003015,
    0.13816330705003566,
    0.13816330705003566,
    0.13173484200024177,
    0.1321213726669157,
    0.13131863579983474,
    0.13131863579983474,
    0.13082977349995417,
    0.13828769604997432,
    0.13028054900132702,
    0.13779196806666125,
    0.13687894780488888,
    0.12889876199915307,
    0.13446043877775082,
    0.1351447138000367,
    0.13475890700040813,
    0.14154767227277756,
    0.13785016261906657,
    0.13475254633320016,
    0.13734290600041277,
    0.16412170985703206,
    0.14479189377784174,
    0.14479189377784174,
    0.17004067066651865,
    0.14693134799995278,
    0.14387020620015392,
    0.14003908605000107,
    0.1379749843636918,
    0.15381994275003308,
    0.1397831990713842,
    0.13891419862500243,
    0.12641037100001995,
    0.13194835399978425,
    0.1333161653529875,
    0.13259063278578,
    0.13085189599996738,
    0.13085189599996738,
    0.1335491907272874,
    0.1335491907272874,
    0.13413323900022078,
    0.1353184227619273,
    0.1336886654165331,
    0.1336886654165331,
    0.13823008548487534,
    0.13697480299994086,
    0.13697480299994086,
    0.13554986100001162,
    0.14017502043992863,
    0.13623286615382732,
    0.1361319451176207,
    0.13057654600015667,
    0.13057654600015667,
    0.13573880980002287,
    0.13656945923069613,
    0.1397483398148459,
    0.1397483398148459,
    0.13896537083786137,
    0.13896537083786137,
    0.13654366722221312,
    0.1380050088750977,
    0.13774208133327193,
    0.13657310399988395,
    0.1386334454991811,
    0.13969080578262155,
    0.13969080578262155,
    0.15212343685717705,
    0.15212343685717705,
    0.14599546463630925,
    0.14039142399997218,
    0.14041194249966793,
    0.14041194249966793,
    0.13306459766681655,
    0.13467745460002334,
    0.1343040559111412,
    0.13470247533324356,
    0.13482269042859635,
    0.1295010982498752,
    0.13421484696300467,
    0.13421484696300467,
    0.1350812037499054,
    0.1350812037499054,
    0.13322075260002747,
    0.13334331559999554,
    0.13666039249983442,
    0.13466484660526284,
    0.1346918550002556,
    0.13494829645833306,
    0.13452769653570482,
    0.13597717416663122,
    0.13601912222212478,
    0.13444746637211463,
    0.1360851726364093,
    0.1347201078148188,
    0.13409468999998353,
    0.13409468999998353,
    0.13380097697143875,
    0.13335046349993718,
    0.13279126600003413,
    0.1337960741999268,
    0.13324289753836638,
    0.13324289753836638,
    0.13365631008340037,
    0.13369331852173555,
    0.1333092579998265,
    0.13315062885729795,
    0.13366568500002055,
    0.1338294725293749,
    0.13181194624985437,
    0.13181194624985437,
    0.13233590628572398,
    0.1345781631129167,
    0.13369393588894768,
    0.13901395900029456,
    0.1345223389000239,
    0.13087902200004464,
    0.13362942738092984,
    0.13060080749983172,
    0.13313715664285805,
    0.13387387016670496,
    0.13400195334997989,
    0.13397693245455725,
    0.13525790772975008,
    0.13525790772975008,
    0.13509497839986578,
    0.13509497839986578,
    0.13471205287498833,
    0.1306208530004369,
    0.1345748420000226,
    0.1341744230556085,
    0.13408947166671067,
    0.1341259477222694,
    0.13254372266662054,
    0.13287280016659983,
    0.1337295847999485,
    0.13447623276191562,
    0.13770758266703828,
    0.13496841705263682,
    0.13452776374992936,
    0.13562278862964713,
    0.134320564529416,
    0.13110199599987027,
    0.13110199599987027,
    0.13462310885708056,
    0.13346114750008078,
    0.13386618691674812,
    0.134733165594593,
    0.13641718688894697,
    0.13580696880001142,
    0.13513648393333522,
    0.13482341428581485,
    0.13559684550000384,
    0.13643741416662022,
    0.13420582844446471,
    0.13436347519510913,
    0.13456813664705644,
    0.13484552413954293,
    0.13359338233385643,
    0.13626576000004004,
    0.13553322236002713,
    0.13668633100004465,
    0.1354409139999916,
    0.136399589749999,
    0.13629248752630174,
    0.13517739391994837,
    0.13711993420001817,
    0.13711993420001817,
    0.13711993420001817,
    0.1358879458333225,
    0.1358879458333225,
    0.1351973437027187,
    0.13654684416663562,
    0.13522367709087615,
    0.13522367709087615,
    0.13522367709087615,
    0.13502872355557985,
    0.13502872355557985,
    0.13502872355557985,
    0.1385887524545317,
    0.1385887524545317,
    0.1385887524545317,
    0.1385887524545317,
    0.1355673604117756,
    0.1355673604117756,
    0.1355673604117756,
    0.13807960566676533,
    0.1348694636296083,
    0.1348694636296083,
    0.13764120755553855,
    0.13764120755553855,
    0.1352648503235447,
    0.1352648503235447,
    0.13390884008322246,
    0.13390884008322246,
    0.13421949849998782,
    0.13404797868747664,
    0.13102354949933215,
    0.13484653254051188,
    0.13484653254051188,
    0.13528600099994037,
    0.13349066692860237,
    0.13441187281817044,
    0.13441187281817044,
    0.14060867299940583,
    0.14060867299940583,
    0.13439008999994256,
    0.13430229653847794,
    0.13417358199997884,
    0.1329523287273663,
    0.1329523287273663,
    0.13217457261537044,
    0.13217457261537044,
    0.13197924986670842,
    0.13421578214287624,
    0.13193674975006311,
    0.1319115659999415,
    0.13515701219999196,
    0.1321041278749817,
    0.1321041278749817,
    0.1351266050000413,
    0.1351266050000413,
    0.1351266050000413,
    0.1351266050000413,
    0.13221292081818153,
    0.13221292081818153,
    0.13221292081818153,
    0.13221292081818153,
    0.1335271224997996,
    0.1335271224997996,
    0.13327509208329502,
    0.1342131566664951,
    0.1355436533823355,
    0.13268548399992142,
    0.1350887408518449,
    0.13149804366670045,
    0.13585645641675606,
    0.13565225512502366,
    0.13585043344452666,
    0.13188541599993187,
    0.13539061015385065,
    0.13727958066657367,
    0.13740038483350267,
    0.1353255709286064,
    0.13745556032259745,
    0.13765128986669878,
    0.13653834411120946,
    0.13650343544456214,
    0.13598924626925368,
    0.1378674255454164,
    0.1378674255454164,
    0.14225277199984704,
    0.1310812449992227,
    0.1310812449992227,
    0.13729697522224646,
    0.13707146397142164,
    0.13707146397142164,
    0.13722212411125334,
    0.13722212411125334,
    0.13722212411125334,
    0.13525497022217475,
    0.13525497022217475,
    0.13525497022217475,
    0.13525497022217475,
    0.13525497022217475,
    0.1366254045925517,
    0.1366254045925517,
    0.1366254045925517,
    0.1366254045925517,
    0.1366254045925517,
    0.13467391469230977,
    0.13467391469230977,
    0.13467391469230977,
    0.1365518637499008,
    0.13592575636836332,
    0.13792832677278388,
    0.13704876640736915,
    0.13704876640736915,
    0.13428313988237384,
    0.13428313988237384,
    0.13511137964295422,
    0.14389382599983946,
    0.13646311596151534,
    0.13765428635291327,
    0.13705391442856904,
    0.13835034726320086,
    0.13536733797829345,
    0.13536733797829345,
    0.132463964000029,
    0.13055918200007,
    0.13171364499976335,
    0.13662320259256241,
    0.1369894378750208,
    0.1369894378750208,
    0.1356792347948776,
    0.1375575782727868,
    0.1375575782727868,
    0.13776496638092794,
    0.13776496638092794,
    0.11375083099846961,
    0.13949061675469598,
    0.13217488640002556,
    0.13709736771436706,
    0.13854481153333228,
    0.133254436000243,
    0.13864988288888627,
    0.13831388021054936,
    0.14361362462500438,
    0.14361362462500438,
    0.13919824231254552,
    0.13919824231254552,
    0.13919824231254552,
    0.13694025999939186,
    0.13436610322221693,
    0.13226218250019883,
    0.13334603142108167,
    0.1370474084375246,
    0.13163423480000347,
    0.13446963533331452,
    0.13589192142847292,
    0.1341070762500749,
    0.13454500572714262,
    0.13454500572714262,
    0.13262464400031604,
    0.1357402039993758,
    0.13357465772729815,
    0.13647281236000708,
    0.13647281236000708,
    0.13907197388464107,
    0.13067178599885665,
    0.13253277433331176,
    0.1298825569992914,
    0.13669670784216387,
    0.13887484263638974,
    0.13887484263638974,
    0.12810660499962978,
    0.1388128080999195,
    0.13443212550009775,
    0.14369240441662137,
    0.14369240441662137,
    0.13429510549985935,
    0.13429510549985935,
    0.14046480799999883,
    0.14046480799999883,
    0.14046480799999883,
    0.13533021574994564,
    0.1415632707856795,
    0.1323254597999039,
    0.1316828010003519,
    0.1421412154827051,
    0.14403075513038618,
    0.14403075513038618,
    0.13268616016648593,
    0.13268616016648593,
    0.13268616016648593,
    0.13268616016648593,
    0.14552568050003173,
    0.14552568050003173,
    0.14552568050003173,
    0.14410623717397,
    0.14164994670906955,
    0.14164994670906955,
    0.14189213482759128,
    0.14189213482759128,
    0.14846143730010225,
    0.14846143730010225,
    0.14498659147622156,
    0.14498659147622156,
    0.15090772599978663,
    0.15090772599978663,
    0.15090772599978663,
    0.14375555605556656,
    0.14375555605556656,
    0.14375555605556656,
    0.14248672001998786,
    0.1424914742799956,
    0.15737891740027407,
    0.14299213866676533,
    0.16229088466671884,
    0.16229088466671884,
    0.16229088466671884,
    0.16229088466671884,
    0.13954185866662425,
    0.13954185866662425,
    0.13954185866662425,
    0.13954185866662425,
    0.1341333359999529,
    0.1405938146841723,
    0.1379955464418704,
    0.13814461084998583,
    0.13329553385717322,
    0.13750974196294988,
    0.1340237759999251,
    0.13128311400032544,
    0.13458697181820092,
    0.13450128859985852,
    0.13454493259996525,
    0.13503905400011718,
    0.13503491050050798,
    0.13503491050050798,
    0.1623793992223202,
    0.1392772835789449,
    0.134613778199855,
    0.134613778199855,
    0.13234208999953503,
    0.13805214558972997,
    0.13805214558972997,
    0.13676299750022736,
    0.1398363180644904,
    0.14153090247822073,
    0.1055019989998982,
    0.1312047966666796,
    0.1361905921923188,
    0.13603845827277505,
    0.12830432666669367,
    0.12830432666669367,
    0.1279646650000359,
    0.13037565783330743,
    0.12948920099915995,
    0.12948920099915995,
    0.13275104749991443,
    0.13275104749991443,
    0.1363854944230787,
    0.13084932228567986,
    0.13101117600005333,
    0.1357842385832555,
    0.13575691513794702,
    0.13705818795658517,
    0.13661064375014575,
    0.13936742615372238,
    0.12719638599992322,
    0.1360979468846171,
    0.132818247999694,
    0.132818247999694,
    0.14081751800003986,
    0.14081751800003986,
    0.14081751800003986,
    0.14081751800003986,
    0.14329050875016947,
    0.14329050875016947,
    0.14329050875016947,
    0.14329050875016947,
    0.13881794799999625,
    0.13881794799999625,
    0.13881794799999625,
    0.14127721300028498,
    0.14127721300028498,
    0.14127721300028498,
    0.13603124660003232,
    0.14425040566675307,
    0.14425040566675307,
    0.13585167717642702,
    0.13585167717642702,
    0.14077278849981667,
    0.13525887347359936,
    0.14082669349954813,
    0.14082669349954813,
    0.13450036071429036,
    0.1337692955554909,
    0.13242817960002867,
    0.13534574133823565,
    0.13225862520835108,
    0.13435282840910903,
    0.132451158571452,
    0.132451158571452,
    0.13445150624988855,
    0.131438372500088,
    0.131438372500088,
    0.13223866512498716,
    0.13223866512498716,
    0.13223866512498716,
    0.13045411966716833,
    0.12945184025011258,
    0.1349607174666744,
    0.12662029399871244,
    0.12662029399871244,
    0.12662029399871244,
    0.1296051817503212,
    0.1296051817503212,
    0.1296051817503212,
    0.13201905866662855,
    0.13197843253328756,
    0.13007321333316213,
    0.12999017766681695,
    0.132783304473713,
    0.132783304473713,
    0.1302844400001959,
    0.1302844400001959,
    0.13272789285708445,
    0.13272789285708445,
    0.13144348033347342,
    0.1329818433332548,
    0.13647051507548483,
    0.13647051507548483,
    0.13647051507548483,
    0.13345254820014815,
    0.13345254820014815,
    0.13345254820014815,
    0.13386879077774616,
    0.1340642916663152,
    0.1340642916663152,
    0.1340642916663152,
    0.1340642916663152,
    0.1340642916663152,
    0.1360837689615157,
    0.1360837689615157,
    0.1360837689615157,
    0.1360837689615157,
    0.1360837689615157,
    0.1360837689615157,
    0.1360837689615157,
    0.1360837689615157,
    0.1360837689615157,
    0.13597710244001063,
    0.13597710244001063,
    0.13597710244001063,
    0.13597710244001063,
    0.13597710244001063,
    0.13597710244001063,
    0.13656624531579023,
    0.13656624531579023,
    0.13396982633336543,
    0.1355240169745754,
    0.12816556699999637,
    0.12816556699999637,
    0.12816556699999637,
    0.13259148499976922,
    0.13259148499976922,
    0.13268771933326207,
    0.1331208161000177,
    0.13633661637493333,
    0.13633661637493333,
    0.13633661637493333,
    0.13563386774967512,
    0.13563386774967512,
    0.13563386774967512,
    0.13563386774967512,
    0.13563386774967512,
    0.13585580300014044,
    0.13585580300014044,
    0.13585580300014044,
    0.13585580300014044,
    0.13585580300014044,
    0.13585580300014044,
    0.13435353662498528,
    0.13435353662498528,
    0.13435353662498528,
    0.1337169746667415,
    0.1364014083333348,
    0.1364014083333348,
    0.1364014083333348,
    0.13192101850017934,
    0.13192101850017934,
    0.13192101850017934,
    0.1335586338002031,
    0.1340269057140436,
    0.1356475196662359,
    0.1368411479473396,
    0.1374856468386673,
    0.13835036178573187,
    0.13642102750000049,
    0.13903358137486066,
    0.13591351133375915,
    0.14039979549997952,
    0.13653619508474193,
    0.1418548407500566,
    0.14005990888896727,
    0.14005990888896727,
    0.13563715358141898,
    0.13563715358141898,
    0.1220564329996705,
    0.13488317666673943,
    0.13481211066634083,
    0.13499652671427093,
    0.13499412285714893,
    0.13305919250001352,
    0.13305919250001352,
    0.13305919250001352,
    0.1355155597143104,
    0.1355155597143104,
    0.13958633019992703,
    0.13958633019992703,
    0.13946383775009963,
    0.13946383775009963,
    0.13605450790241663,
    0.13552177715791913,
    0.14079090400006558,
    0.14079090400006558,
    0.1422341934285214,
    0.1422341934285214,
    0.13588638199998418,
    0.1336762410001029,
    0.1336762410001029,
    0.13609601774469218,
    0.13609601774469218,
    0.13948362452944874,
    0.13948362452944874,
    0.13948362452944874,
    0.13697987044441914,
    0.13697987044441914,
    0.13570935500012218,
    0.1366646053332564,
    0.13554934123077636,
    0.13554934123077636,
    0.13554934123077636,
    0.13674182690920134,
    0.13674182690920134,
    0.13674182690920134,
    0.13512787966667222,
    0.13512787966667222,
    0.13513796350025586,
    0.13362300057892035,
    0.13451606502128421,
    0.13382685592854873,
    0.13409981261541432,
    0.13419605786205874,
    0.13419163277420362,
    0.1341863588999331,
    0.13406903691657135,
    0.13414274608339838,
    0.13488731014279307,
    0.13325556752629622,
    0.13674911700036319,
    0.13398056933328917,
    0.13398056933328917,
    0.13409902466668833,
    0.1341475639997043,
    0.13213267236361306,
    0.1327047370999935,
    0.1327047370999935,
    0.1344101344137894,
    0.1344101344137894,
    0.13273695315393313,
    0.13294470250002632,
    0.13444188500034215,
    0.135239531368394,
    0.13471254840000516,
    0.13471254840000516,
    0.13471254840000516,
    0.13433561605886687,
    0.13433561605886687,
    0.13433561605886687,
    0.13423525750001247,
    0.13423525750001247,
    0.13166766399990593,
    0.1313656368335311,
    0.13548334323072944,
    0.12996382949950203,
    0.1311652931110277,
    0.13116688929985684,
    0.13523563394203625,
    0.12971250933333067,
    0.13179852100029166,
    0.12884134149953752,
    0.13536028383330428,
    0.13502940937496533,
    0.13500323159091335,
    0.13272011575008946,
    0.13526880287497534,
    0.13650965912506763,
    0.13499354790001233,
    0.13696314467744097,
    0.13542671321426628,
    0.13241179383324683,
    0.1327304373332178,
    0.1311774942001648,
    0.13307487050042255,
    0.13307487050042255,
    0.13667883077778242,
    0.13748259110713792,
    0.13566346254166697,
    0.14165694180010177,
    0.14165694180010177,
    0.13586995915216982,
    0.13817944542857472,
    0.13625667459093,
    0.1363299384500351,
    0.1363299384500351,
    0.13233361427277981,
    0.13343181562481732,
    0.13370828330768675,
    0.13416911392856232,
    0.13549401899945224,
    0.13313350233329402,
    0.13313350233329402,
    0.13534112772221205,
    0.13532484774998466,
    0.13457093899887695,
    0.13778780935289808,
    0.13735684900075285,
    0.13664302666666117,
    0.1354618513783813,
    0.13583321651664543,
    0.13526069649997924,
    0.13849351978569757,
    0.13529899686486838,
    0.13711995563751317,
    0.13602502122214194,
    0.136263022625144,
    0.1409544788461622,
    0.13910241399995962,
    0.13151925224974548,
    0.13881359078576289,
    0.1357758972143139,
    0.1357758972143139,
    0.1395723519999592,
    0.1395723519999592,
    0.140633537818179,
    0.142609366499831,
    0.13791377830770776,
    0.14232460988892448,
    0.14232460988892448,
    0.14232460988892448,
    0.13277958357691835,
    0.13277958357691835,
    0.13208746106671848,
    0.1308409344445762,
    0.13112587242851856,
    0.13308492688231446,
    0.13303400023527073,
    0.13262953524993767,
    0.13190696125002432,
    0.13202431566666442,
    0.13304745045454844,
    0.13311207910010125,
    0.13619617935848577,
    0.13286556733328325,
    0.12962749500002246,
    0.13480199440018623,
    0.13735427356895624,
    0.13325178981821492,
    0.13314593526315308,
    0.13336481459991772,
    0.13956337600029656,
    0.13443370191665358,
    0.132174320625154,
    0.13239641553837617,
    0.13423915999980332,
    0.13192873449952458,
    0.1346231532497768,
    0.143407870998999,
    0.13246582049996505,
    0.13465676712003188,
    0.13449009666666306,
    0.13213816744448398,
    0.13213816744448398,
    0.1284931290010718,
    0.1358647436000562,
    0.13358829054546237,
    0.13842455304165924,
    0.13296672699993906,
    0.13254187349994026,
    0.12727329399967857,
    0.1273557009990327,
    0.13627668863641287,
    0.12928340299913543,
    0.13542241028569282,
    0.13544504949991928,
    0.13184207149970462,
    0.13184207149970462,
    0.13772850982500132,
    0.13642203509103143,
    0.13642203509103143,
    0.13370775499970478,
    0.1391010262222052,
    0.13933249379169865,
    0.13574603758327916,
    0.13574603758327916,
    0.1382767623792837,
    0.14639550199960163,
    0.13873848886208273,
    0.13755553642866808,
    0.13873412734486418,
    0.13873412734486418,
    0.130964851400131,
    0.13505659122226157,
    0.13919267230555002,
    0.13945879300081288,
    0.13032713000029617,
    0.13039442149965907,
    0.13039442149965907,
    0.13568820000000414,
    0.1315130240000144,
    0.13906599627270308,
    0.14263740555563548,
    0.13924238216663476,
    0.13734136975017464,
    0.1396028344211357,
    0.13902275872723377,
    0.1372394514996813,
    0.1399196275405474,
    0.14161704907149084,
    0.13549701400006597,
    0.13549701400006597,
    0.14034125393939603,
    0.14034125393939603,
    0.1359896996667279,
    0.1391296150013659,
    0.13512167600007766,
    0.1388434380005492,
    0.13557551512508326,
    0.1354183786665999,
    0.13627702199998262,
    0.1517821110010118,
    0.14009091243747207,
    0.12092139899868926,
    0.13330688788887024,
    0.14037633040386657,
    0.14037633040386657,
    0.14037633040386657,
    0.14037633040386657,
    0.1399045487856451,
    0.1399045487856451,
    0.1399045487856451,
    0.1399045487856451,
    0.1399045487856451,
    0.13899679833327053,
    0.13899679833327053,
    0.13899679833327053,
    0.13501199999973323,
    0.13501199999973323,
    0.14011811507687247,
    0.14011811507687247,
    0.13595510099973276,
    0.13983175585703325,
    0.14353911855545853,
    0.14182306840011732,
    0.14245632788879448,
    0.14307751076921704,
    0.1392261823636793,
    0.1425233802500164,
    0.14131815369983086,
    0.14131815369983086,
    0.14131815369983086,
    0.14131815369983086,
    0.14131815369983086,
    0.1444175538666362,
    0.1444175538666362,
    0.1444175538666362,
    0.1444175538666362,
    0.1444175538666362,
    0.13848921919998247,
    0.13823796212500383,
    0.13823796212500383,
    0.13718028233314625,
    0.13718028233314625,
    0.13499385618752058,
    0.13937583342859788,
    0.13937583342859788,
    0.13328987549994054,
    0.13263821149939758,
    0.13262729614299523,
    0.14389196719994288,
    0.13215538900003593,
    0.1425492821538053,
    0.1417459882307482,
    0.1417459882307482,
    0.13216076620010425,
    0.13336540475029324,
    0.1391947711186515,
    0.13758835699991323,
    0.14443503681823958,
    0.1427653309354707,
    0.16690564171429806,
    0.14070923884782646,
    0.15511518719995365,
    0.13406384959998832,
    0.12966294933357858,
    0.15512921230001667,
    0.15512921230001667,
    0.14534729819997666,
    0.13846401701430294,
    0.15106971499998118,
    0.18230186059990955,
    0.16055200912501277,
    0.14721537816664446,
    0.14581211718177656,
    0.15593455500002165,
    0.15105434357142908,
    0.15105434357142908,
    0.13857684139984486,
    0.13629900632559142,
    0.13629900632559142,
    0.1377970328333807,
    0.1377970328333807,
    0.13138263300061226,
    0.13588388926470596,
    0.13786361533342037,
    0.14237883599980705,
    0.14237883599980705,
    0.1314529138002399,
    0.1305907419991854,
    0.13473596044443387,
    0.13227078199997777,
    0.13871915252938755,
    0.13791379095831266,
    0.1372582724001404,
    0.1372582724001404,
    0.1381773800000398,
    0.1381773800000398,
    0.1381773800000398,
    0.13814412282606456,
    0.13814412282606456,
    0.13931557200021416,
    0.13539942147059159,
    0.13903819990909225,
    0.13903819990909225,
    0.13838332133329662,
    0.13838332133329662,
    0.13838332133329662,
    0.13581272969986458,
    0.13595302857122857,
    0.13686265840005946,
    0.13531201655556893,
    0.13565667426664732,
    0.13376868200066383,
    0.13477914785714043,
    0.13626183935723798,
    0.13511070599997765,
    0.13487501411105363,
    0.13487501411105363,
    0.1356343751251643,
    0.1356343751251643,
    0.13514552258326754,
    0.14622084300026472,
    0.1461199490004219,
    0.1346267656001146,
    0.13344960911999806,
    0.13446252366662115,
    0.13361008033340718,
    0.13281664370006183,
    0.13358652199985954,
    0.1323569096427621,
    0.1356385550000899,
    0.1356385550000899,
    0.1356385550000899,
    0.13367255933341463,
    0.13367255933341463,
    0.13367255933341463,
    0.131167017444467,
    0.131167017444467,
    0.131167017444467,
    0.131167017444467,
    0.131167017444467,
    0.131167017444467,
    0.131167017444467,
    0.12827875099992525,
    0.12827875099992525,
    0.12827875099992525,
    0.12827875099992525,
    0.12827875099992525,
    0.12827875099992525,
    0.1300925269997606,
    0.1335515726665714,
    0.1335515726665714,
    0.13357356145828211,
    0.13357356145828211,
    0.13385677336364923,
    0.13385677336364923,
    0.13171622571436664,
    0.13506182559258714,
    0.13506182559258714,
    0.12872150900057022,
    0.12872150900057022,
    0.13386232960001507,
    0.13386232960001507,
    0.13307649783322026,
    0.1330666205834253,
    0.1330666205834253,
    0.13498721875999764,
    0.13350640522225554,
    0.13350640522225554,
    0.13515269576472586,
    0.13515269576472586,
    0.13340207950022887,
    0.13467720700009522,
    0.13339888088881302,
    0.13438532069994835,
    0.13438532069994835,
    0.13523646799997854,
    0.13523646799997854,
    0.1370513498888815,
    0.13441034701998433,
    0.13606849570836252,
    0.1403410110015102,
    0.13624467761907172,
    0.13624467761907172,
    0.12907796200033772,
    0.12907796200033772,
    0.12907796200033772,
    0.13551126387494605,
    0.1370505775833711,
    0.1370505775833711,
    0.1327217987500262,
    0.13592113783336876,
    0.13628966599935666,
    0.13633684040008423,
    0.13841731477764874,
    0.13708508958325183,
    0.13708508958325183,
    0.13631929641183782,
    0.140843385000023,
    0.14038459687503746,
    0.14038459687503746,
    0.1358475492105706,
    0.1358475492105706,
    0.1352368792499874,
    0.13580762594114382,
    0.13583006915005172,
    0.13566982393751914,
    0.13907340237506105,
    0.13814873683319698,
    0.13814873683319698,
    0.13292717485715652,
    0.13349752042865606,
    0.13349752042865606,
    0.13363026237493614,
    0.13363026237493614,
    0.1334520674615935,
    0.1334520674615935,
    0.13344050929999868,
    0.12880874399979803,
    0.133965076000095,
    0.13324636116673597,
    0.13324636116673597,
    0.1330699709545694,
    0.1350207080833267,
    0.13317337474197097,
    0.1338508788946791,
    0.13340492153128025,
    0.13340492153128025,
    0.13329605740909756,
    0.1333312211666756,
    0.1333312211666756,
    0.13350633879105514,
    0.13350633879105514,
    0.13350633879105514,
    0.133674368166794,
    0.13369906650018493,
    0.1338889060908431,
    0.13367068899990248,
    0.13367068899990248,
    0.13367068899990248,
    0.13285705477776194,
    0.13285705477776194,
    0.1331412903142856,
    0.13290008087506067,
    0.13325008336540542,
    0.13325008336540542,
    0.13327757652940123,
    0.13327757652940123,
    0.13047126499986916,
    0.13047126499986916,
    0.13339129262499227,
    0.13394730985705142,
    0.1324180597503073,
    0.1324180597503073,
    0.1332874269215858,
    0.1332874269215858,
    0.13329788200007897,
    0.1327282803846314,
    0.1327282803846314,
    0.1333120470000722,
    0.13323875460009732,
    0.13424365399987437,
    0.13312931687505625,
    0.13312931687505625,
    0.13334901871426805,
    0.13284912271423568,
    0.13367958726413012,
    0.13197840724990328,
    0.13289927277785157,
    0.13259440599995287,
    0.13149547400007577,
    0.13149547400007577,
    0.1333715803333083,
    0.13569425875039087,
    0.13274431137840628,
    0.13172832363637677,
    0.13172832363637677,
    0.13172832363637677,
    0.13602848399932554,
    0.13602848399932554,
    0.13602848399932554,
    0.1323409339091251,
    0.1305623787777424,
    0.1327731000001222,
    0.13260389254554122,
    0.13260389254554122,
    0.13369160519998532,
    0.13308926599893312,
    0.13334241062504285,
    0.13334241062504285,
    0.1325568197777708,
    0.1325568197777708,
    0.1327428721538476,
    0.13250114462493912,
    0.13436610937492333,
    0.13436610937492333,
    0.13504747157146216,
    0.13344619260005858,
    0.13048980399980792,
    0.13433789500004423,
    0.12883335500009707,
    0.13365440679999666,
    0.13360955480002304,
    0.13436820058329127,
    0.13440157122224466,
    0.1331472879166237,
    0.13466475812515455,
    0.13466475812515455,
    0.13465020349985934,
    0.13412740653341945,
    0.13524660199982463,
    0.13440802824970888,
    0.13588352566633452,
    0.13205538237502878,
    0.13308636144433372,
    0.1332164846364983,
    0.1335930592857559,
    0.13342707228574519,
    0.1336147677999179,
    0.1336147677999179,
    0.1310911255004612,
    0.1310911255004612,
    0.1310911255004612,
    0.1310911255004612,
    0.13410736283337124,
    0.13410736283337124,
    0.13410736283337124,
    0.13410736283337124,
    0.13410736283337124,
    0.1300004513335201,
    0.1300004513335201,
    0.1342631225555427,
    0.1347671922857054,
    0.1338558761999957,
    0.1338558761999957,
    0.13494994137499816,
    0.13494994137499816,
    0.13438484431581424,
    0.13382347969225242,
    0.1346007106129095,
    0.1346007106129095,
    0.13440320300000358,
    0.13440320300000358,
    0.1344215240525572,
    0.13511791658334005,
    0.13451090166684784,
    0.13451090166684784,
    0.13451090166684784,
    0.13387446273330472,
    0.13387446273330472,
    0.13466406000043207,
    0.1328284234445568,
    0.13270227350009614,
    0.13080546444446858,
    0.13166205718185997,
    0.13093616599975835,
    0.1333947476154068,
    0.1300207345002491,
    0.1312688160000107,
    0.13366099700033374,
    0.13408425503845278,
    0.13408425503845278,
    0.13408425503845278,
    0.13408425503845278,
    0.13057967466678141,
    0.13057967466678141,
    0.13057967466678141,
    0.1289581850014656,
    0.1289581850014656,
    0.13102708583331454,
    0.1314753884998936,
    0.13433033687503362,
    0.1314718769999672,
    0.13260276166693075,
    0.13475403650008957,
    0.13517197162491357,
    0.13445679946432523,
    0.13570687271424373,
    0.13570687271424373,
    0.13570687271424373,
    0.137010790000204,
    0.137010790000204,
    0.137010790000204,
    0.13745663774989225,
    0.13745663774989225,
    0.13450718790619476,
    0.1367735094443358,
    0.1348044644999997,
    0.13445186750004723,
    0.13403424015380622,
    0.13403424015380622,
    0.135780670800159,
    0.135780670800159,
    0.13628243566665788,
    0.13628243566665788,
    0.13485034099994664,
    0.13485034099994664,
    0.13485034099994664,
    0.13485034099994664,
    0.13485034099994664,
    0.1333085994544738,
    0.1333085994544738,
    0.1333085994544738,
    0.13549935177998124,
    0.13387170616665067,
    0.1343267876665474,
    0.13498060071443824,
    0.13363848488875696,
    0.13363848488875696,
    0.1362188906734854,
    0.1302059086671458,
    0.1302059086671458,
    0.13489193320001505,
    0.13489193320001505,
    0.13437828871428792,
    0.13435186975016222,
    0.13410427249982604,
    0.13350945407686454,
    0.13483559511102308,
    0.1333241135556212,
    0.1367040192758552,
    0.13442573000005117,
    0.1340400550833086,
    0.1340400550833086,
    0.1361537146670647,
    0.1361537146670647,
    0.13178366899956018,
    0.1370009447254786,
    0.13419048687501345,
    0.1323762080000261,
    0.13032981200012728,
    0.13032981200012728,
    0.1318588482999985,
    0.1318588482999985,
    0.13254475900005977,
    0.13335676741674737,
    0.13796504447821897,
    0.13652411635292297,
    0.13652411635292297,
    0.13652411635292297,
    0.13652411635292297,
    0.13652411635292297,
    0.13652411635292297,
    0.13652411635292297,
    0.13527440025018223,
    0.13527440025018223,
    0.13527440025018223,
    0.13527440025018223,
    0.13527440025018223,
    0.13527440025018223,
    0.13527440025018223,
    0.13790398564287898,
    0.13784143726920425,
    0.13539386050024405,
    0.13411653420007497,
    0.1373654936428682,
    0.13378115181810493,
    0.1339089953335133,
    0.1343404156662776,
    0.1328905185554403,
    0.13307134699971357,
    0.13272842033317525,
    0.13826590712000325,
    0.12905418100126553,
    0.12905418100126553,
    0.13909070950004124,
    0.13909070950004124,
    0.13909070950004124,
    0.1338046288001351,
    0.1338046288001351,
    0.1338046288001351,
    0.1338046288001351,
    0.1329823434998616,
    0.1329823434998616,
    0.13375774539999838,
    0.13522266775021308,
    0.13522266775021308,
    0.13522266775021308,
    0.13522266775021308,
    0.13727548678260695,
    0.13727548678260695,
    0.13727548678260695,
    0.13727548678260695,
    0.13727548678260695,
    0.13727548678260695,
    0.13727548678260695,
    0.13874879722583677,
    0.13874879722583677,
    0.13874879722583677,
    0.13874879722583677,
    0.13844456823076493,
    0.13844456823076493,
    0.1324977320000471,
    0.1324977320000471,
    0.14194729160008138,
    0.14194729160008138,
    0.14194729160008138,
    0.14194729160008138,
    0.1319183643336146,
    0.1319183643336146,
    0.1319183643336146,
    0.13981050877777712,
    0.13885101235294262,
    0.14113879718752287,
    0.14113879718752287,
    0.13542779210001754,
    0.1361971630000577,
    0.1361971630000577,
    0.1361971630000577,
    0.13725970959967526,
    0.13725970959967526,
    0.13725970959967526,
    0.13451229962493017,
    0.13451229962493017,
    0.1360040776665604,
    0.1360040776665604,
    0.13644863547826547,
    0.13858709299984184,
    0.13858709299984184,
    0.13858709299984184,
    0.13560183254840893,
    0.13560183254840893,
    0.13560183254840893,
    0.13650428899994663,
    0.13897458522215958,
    0.13642570135717896,
    0.1394501901249896,
    0.13673207966682335,
    0.13758789772724744,
    0.13725371662508223,
    0.13455441199948837,
    0.13455441199948837,
    0.1380123833999581,
    0.1335534762501993,
    0.1335534762501993,
    0.13861046665718146,
    0.13861046665718146,
    0.14342043016677053,
    0.14342043016677053,
    0.14342043016677053,
    0.14795683024976825,
    0.14795683024976825,
    0.14795683024976825,
    0.14795683024976825,
    0.13457929685717404,
    0.13457929685717404,
    0.13457929685717404,
    0.1345284107142756,
    0.13504652199999329,
    0.13739671822221916,
    0.1352331678332727,
    0.13097335699967516,
    0.13452454993324256,
    0.13137638600043525,
    0.13137638600043525,
    0.13777961045239603,
    0.1341914629999034,
    0.1341914629999034,
    0.1341914629999034,
    0.13629929499984428,
    0.13629929499984428,
    0.1394881924998117,
    0.1394881924998117,
    0.1394881924998117,
    0.13391765449978266,
    0.13391765449978266,
    0.133337162999851,
    0.133337162999851,
    0.1390282165517294,
    0.13790087005260207,
    0.13790087005260207,
    0.13790087005260207,
    0.14482620933328386,
    0.14482620933328386,
    0.13803181599996606,
    0.13803181599996606,
    0.13803181599996606,
    0.15049521899995202,
    0.15049521899995202,
    0.15049521899995202,
    0.14260774393102926,
    0.14260774393102926,
    0.14298833830907826,
    0.13877925169230693,
    0.1419182571666574,
    0.1432789188750121,
    0.1389701927575626,
    0.14370292121436382,
    0.14112658671425984,
    0.14112658671425984,
    0.13891996774280935,
    0.13891996774280935,
    0.13891996774280935,
    0.1443936645384663,
    0.1443936645384663,
    0.1443936645384663,
    0.1443936645384663,
    0.15959454539988654,
    0.15959454539988654,
    0.15959454539988654,
    0.14139532521049228,
    0.14139532521049228,
    0.1350980584445804,
    0.1324801316665495,
    0.13455508522722745,
    0.135134992444566,
    0.13464113299996824,
    0.13604374139995343,
    0.1365664924443182,
    0.13153346099958677,
    0.13613577696771478,
    0.13613577696771478,
    0.13013357400013775,
    0.13610180515388492,
    0.13577409291671452,
    0.13577409291671452,
    0.13492357037500824,
    0.13492357037500824,
    0.12682430099994235,
    0.12682430099994235,
    0.14136848882855182,
    0.12939667099999497,
    0.13709203936361353,
    0.1392332052500933,
    0.13185437599895522,
    0.13604611972227254,
    0.1440377350000314,
    0.1446756297500542,
    0.1446756297500542,
    0.14194357996227996,
    0.14194357996227996,
    0.13157718833341883,
    0.13225732399951085,
    0.13255863655568748,
    0.13256457522220444,
    0.13292522728573072,
    0.1345739295002204,
    0.13358354560004954,
    0.13358354560004954,
    0.13282226649971562,
    0.13350558439997257,
    0.13680270100030612,
    0.1347687559997818,
    0.141045159644063,
    0.141045159644063,
    0.141045159644063,
    0.1421945617777965,
    0.1421945617777965,
    0.1421945617777965,
    0.1421945617777965,
    0.13372108133323005,
    0.14169700637035862,
    0.14216925768424085,
    0.14639199231031194,
    0.1344097753335518,
    0.13768861357142928,
    0.13768861357142928,
    0.13768861357142928,
    0.13553442066646917,
    0.13553442066646917,
    0.13542644959998143,
    0.14970033499999277,
    0.14079300627269153,
    0.14079300627269153,
    0.14811842663999414,
    0.14811842663999414,
    0.1377930727499006,
    0.14095914766706605,
    0.1440195057750316,
    0.1440195057750316,
    0.14456597713888186,
    0.14456597713888186,
    0.1451561099091288,
    0.1451561099091288,
    0.1450285404545701,
    0.1450285404545701,
    0.1450285404545701,
    0.1351826529999716,
    0.1351826529999716,
    0.1366741973889576,
    0.13641029772737634,
    0.13640208709082138,
    0.1344022911111501,
    0.13641179099977307,
    0.1365093188888851,
    0.1366969351052639,
    0.1365613594324394,
    0.13657207433334406,
    0.13648855770831383,
    0.13831600650064502,
    0.13644206454558694,
    0.1366658818749329,
    0.13605224677768193,
    0.13693594687179145,
    0.13696561040001143,
    0.13591697733318142,
    0.1350133469998885,
    0.1377702833332781,
    0.13700092377265802,
    0.13802117699924565,
    0.13802117699924565,
    0.1376008707777348,
    0.1341236755006321,
    0.1373893752497679,
    0.1373893752497679,
    0.13715176553845454,
    0.13810308357891413,
    0.13758870817855495,
    0.13794553142854835,
    0.13638385611112527,
    0.13745722544445016,
    0.13699189877782678,
    0.1368256086364206,
    0.1377463632631445,
    0.1358303211428782,
    0.1358303211428782,
    0.1358303211428782,
    0.1358303211428782,
    0.13490648249990045,
    0.13490648249990045,
    0.13490648249990045,
    0.13490648249990045,
    0.13628966322216407,
    0.13628966322216407,
    0.13628966322216407,
    0.1368463306250002,
    0.1368463306250002,
    0.13675148513040924,
    0.13741640713342348,
    0.13741640713342348,
    0.13906605034286,
    0.13684108500031775,
    0.1388830741818145,
    0.13710680324993518,
    0.13892740788893812,
    0.13892740788893812,
    0.13475748166638368,
    0.13475748166638368,
    0.1398603908965642,
    0.13616279310008395,
    0.13748365760002343,
    0.13842794737502118,
    0.13842794737502118,
    0.13842794737502118,
    0.13842794737502118,
    0.13842794737502118,
    0.13555678266675386,
    0.13555678266675386,
    0.13555678266675386,
    0.13555678266675386,
    0.13555678266675386,
    0.1355223175833089,
    0.12794355300138704,
    0.13627993016689288,
    0.1417581128667128,
    0.12901125299868,
    0.13217213133369418,
    0.14243824360716775,
    0.14238890666665274,
    0.13379146399984165,
    0.13379146399984165,
    0.13716511799998443,
    0.13716511799998443,
    0.13716511799998443,
    0.13198764700018728,
    0.12796199200056435,
    0.14198303161538206,
    0.14376984100009496,
    0.14259015322224716,
    0.1428667426364634,
    0.14460618862494812,
    0.14278591813430766,
    0.1395619089998945,
    0.14456668987509147,
    0.14872001633314844,
    0.14291227688894045,
    0.14328828643749603,
    0.14328828643749603,
    0.143172657968762,
    0.13669070637502045,
    0.14128137609093921,
    0.1381595127500077,
    0.1381595127500077,
    0.1458892708181917,
    0.1458892708181917,
    0.14563209629630836,
    0.14353213622234762,
    0.14353213622234762,
    0.13410573374994783,
    0.1440397163333492,
    0.1440397163333492,
    0.1440397163333492,
    0.14320382669225531,
    0.14320382669225531,
    0.14320382669225531,
    0.1464036117777141,
    0.14799466738094497,
    0.14826630177776678,
    0.14826630177776678,
    0.1375244650002969,
    0.1375244650002969,
    0.13816893424996124,
    0.14402067587502643,
    0.1428421798667235,
    0.13401647150021745,
    0.13401647150021745,
    0.14158216175757954,
    0.14158216175757954,
    0.14158216175757954,
    0.14158216175757954,
    0.15518978649993187,
    0.15518978649993187,
    0.14384009610002976,
    0.14384009610002976,
    0.14083560502704867,
    0.14254393082755368,
    0.14254393082755368,
    0.13808519138463174,
    0.13808519138463174,
    0.13808519138463174,
    0.13376756087495778,
    0.12705576400003338,
    0.12705576400003338,
    0.12705576400003338,
    0.12705576400003338,
    0.12705576400003338,
    0.13367729137485185,
    0.13367729137485185,
    0.13367729137485185,
    0.13367729137485185,
    0.13694436619989575,
    0.13499604639982862,
    0.13499604639982862,
    0.13499604639982862,
    0.13499604639982862,
    0.14423861808642902,
    0.14423861808642902,
    0.14423861808642902,
    0.14423861808642902,
    0.1355615449999732,
    0.1355615449999732,
    0.13850254607691917,
    0.13850254607691917,
    0.13831293057137373,
    0.13831293057137373,
    0.1389446660666484,
    0.13642394819980835,
    0.13642394819980835,
    0.13935285467500763,
    0.14123707522210477,
    0.14790984200044477,
    0.1419902280003953,
    0.14379657788878022,
    0.14379657788878022,
    0.14379657788878022,
    0.14691309288887336,
    0.14691309288887336,
    0.14691309288887336,
    0.13674120887492336,
    0.13990259743474345,
    0.13847625918920992,
    0.14244105374973515,
    0.14244105374973515,
    0.13907472363155793,
    0.12963089400000172,
    0.12963089400000172,
    0.12963089400000172,
    0.12963089400000172,
    0.13881801764865806,
    0.13881801764865806,
    0.13881801764865806,
    0.13881801764865806,
    0.13881801764865806,
    0.13881801764865806,
    0.13808290066663176,
    0.13808290066663176,
    0.13808290066663176,
    0.13808290066663176,
    0.13928819341670837,
    0.13928819341670837,
    0.14673220315517968,
    0.1443342385454426,
    0.14529500866673414,
    0.14522223277789534,
    0.14656679537506534,
    0.14607033016636706,
    0.13984143815005154,
    0.13984143815005154,
    0.14323179070015613,
    0.14328896169990912,
    0.14328896169990912,
    0.14902357417947945,
    0.13817695999932766,
    0.15177224149999802,
    0.13634437774999242,
    0.13702832457160444,
    0.13606151299991326,
    0.15032307853568586,
    0.1366483011249784,
    0.1514985930882497,
    0.15352632124142537,
    0.15000828594997984,
    0.13873358220007503,
    0.14969297599964193,
    0.13635355323080708,
    0.14083138529915434,
    0.13355413855545825,
    0.14939623079487482,
    0.14939623079487482,
    0.13389329420006107,
    0.1329664104287076,
    0.1340575602000172,
    0.13569854663629402,
    0.14467015376561676,
    0.1339629166668601,
    0.1325693284998124,
    0.1352075794000484,
    0.13545163388900822,
    0.15333459496872592,
    0.13559667233352635,
    0.13946089727274244,
    0.16211034975003713,
    0.13716087322225373,
    0.15523271639286967,
    0.13077988299846766,
    0.15621141600004868,
    0.14948481735000313,
    0.14948481735000313,
    0.14014294049957243,
    0.14014294049957243,
    0.141225535000558,
    0.17623736489986186,
    0.1761498842999572,
    0.1761498842999572,
    0.15259605833334994,
    0.15259605833334994,
    0.1602418413334211,
    0.1602418413334211,
    0.14727319607144246,
    0.14727319607144246,
    0.13802698157139406,
    0.13802698157139406,
    0.13999008011099554,
    0.13999008011099554,
    0.13948739433332472,
    0.13614379675004784,
    0.1374898406923491,
    0.13826609475861537,
    0.14175116083333705,
    0.13684532819997913,
    0.13684532819997913,
    0.13666460541175826,
    0.13439674852944497,
    0.13439674852944497,
    0.1363852536000195,
    0.1363852536000195,
    0.1360942727501424,
    0.1360942727501424,
    0.13500328823073898,
    0.1381039990001227,
    0.135256017500069,
    0.134055810888943,
    0.13651198283332633,
    0.13366789377768226,
    0.1336913736668066,
    0.13760733960007202,
    0.13760933379999188,
    0.1373879791764707,
    0.13837221281255552,
    0.13676435187494462,
    0.13676435187494462,
    0.12953954699969472,
    0.12953954699969472,
    0.14082808399998611,
    0.13769183000000512,
    0.13880338975013728,
    0.1375894744117378,
    0.14749822283344352,
    0.1375037023749428,
    0.13812383519998547,
    0.13812383519998547,
    0.1476457916663397,
    0.1476457916663397,
    0.13029560249970018,
    0.13029560249970018,
    0.13478790649999914,
    0.13142781322231814,
    0.1293515284996829,
    0.1293515284996829,
    0.13226970733315588,
    0.13226970733315588,
    0.13187663360004082,
    0.13187663360004082,
    0.13206530300036926,
    0.13667961073809107,
    0.13667961073809107,
    0.13250132499979372,
    0.13250132499979372,
    0.13482519766673956,
    0.1330464259999644,
    0.13221126449995305,
    0.13221676899993326,
    0.1365585921276819,
    0.1355744988999504,
    0.13623553533337449,
    0.13541873859994666,
    0.1348555753000255,
    0.13497421550000582,
    0.13421625063644818,
    0.13514287958830262,
    0.13639357099987137,
    0.13447744344994134,
    0.13447744344994134,
    0.13447744344994134,
    0.1354729777083321,
    0.1354729777083321,
    0.1354729777083321,
    0.1354729777083321,
    0.1354729777083321,
    0.1354729777083321,
    0.1354729777083321,
    0.1354729777083321,
    0.145660524500272,
    0.145660524500272,
    0.145660524500272,
    0.145660524500272,
    0.145660524500272,
    0.145660524500272,
    0.145660524500272,
    0.1362852879024658,
    0.1362852879024658,
    0.1362852879024658,
    0.1302035693999642,
    0.1302035693999642,
    0.13405622524995428,
    0.13405622524995428,
    0.13245727800040186,
    0.13245727800040186,
    0.13245727800040186,
    0.13245727800040186,
    0.13426268213049258,
    0.13426268213049258,
    0.13426268213049258,
    0.13426268213049258,
    0.13426268213049258,
    0.13426268213049258,
    0.13702943391180109,
    0.13702943391180109,
    0.13702943391180109,
    0.13788547199997733,
    0.13788547199997733,
    0.12883442450038274,
    0.13369331116640146,
    0.13369331116640146,
    0.1384393585000138,
    0.1384393585000138,
    0.13368992581804792,
    0.13368992581804792,
    0.13423002089984948,
    0.13423002089984948,
    0.12900787699982175,
    0.13579314700001094,
    0.13791745950038603,
    0.13791745950038603,
    0.13686362997367196,
    0.13477935244453773,
    0.1346171690768712,
    0.1346171690768712,
    0.1346171690768712,
    0.13807010689655225,
    0.13807010689655225,
    0.13807010689655225,
    0.13530608906670144,
    0.13530608906670144,
    0.13530608906670144,
    0.13067222233318412,
    0.13067222233318412,
    0.13067222233318412,
    0.13067222233318412,
    0.1320170404997043,
    0.1320170404997043,
    0.1318293704998723,
    0.13209667750015797,
    0.13690388681578425,
    0.13536945328568045,
    0.13708551269998376,
    0.13708551269998376,
    0.13088879200040537,
    0.1296789779989922,
    0.1296789779989922,
    0.14106194750002032,
    0.1385207286799414,
    0.1385207286799414,
    0.13019998900017526,
    0.14126651155553796,
    0.14126651155553796,
    0.14321243554546859,
    0.14321243554546859,
    0.1438587081249807,
    0.1438587081249807,
    0.13584149859998434,
    0.13584149859998434,
    0.1347857233334556,
    0.1347857233334556,
    0.1347857233334556,
    0.14417215339999528,
    0.14841438957150135,
    0.13575004313252176,
    0.14450404888884805,
    0.14450404888884805,
    0.13433963319047984,
    0.13255449792685373,
    0.1334301386440668,
    0.1334301386440668,
    0.12830951900104992,
    0.1333986209499926,
    0.13373089950000577,
    0.13279323517242025,
    0.13279323517242025,
    0.13260980774991063,
    0.13635045012698457,
    0.12918976599939924,
    0.13322897199986983,
    0.13289870492315878,
    0.13380548746149892,
    0.1322196299534817,
    0.1324434318889366,
    0.1322756721860652,
    0.1322756721860652,
    0.1318659860856964,
    0.13218318960001246,
    0.1319631586087306,
    0.1333062699995935,
    0.1333062699995935,
    0.1333062699995935,
    0.13491734677760783,
    0.13491734677760783,
    0.13209235524982432,
    0.13226967800073908,
    0.13284455856251043,
    0.13471802460007892,
    0.1324193729474485,
    0.1324193729474485,
    0.13264105777771976,
    0.13396301100010533,
    0.13352217916668624,
    0.13352217916668624,
    0.13112395457158396,
    0.13225704528127835,
    0.12089529900003981,
    0.13079520207681455,
    0.13107093409998924,
    0.13188350671433519,
    0.13356377923403845,
    0.13149459112491968,
    0.13118512905556498,
    0.1336150686086947,
    0.13367992307498752,
    0.13104335346664206,
    0.13104335346664206,
    0.1355003701739169,
    0.13064534799923422,
    0.132361808500112,
    0.132361808500112,
    0.13211154364281746,
    0.13263647180006954,
    0.13263647180006954,
    0.13237816874075012,
    0.13149750854542866,
    0.13195029970001998,
    0.12939540900030502,
    0.13381927134372518,
    0.12968731199980538,
    0.13083228466666696,
    0.13045529700139014,
    0.13045529700139014,
    0.13232501920833784,
    0.13232501920833784,
    0.13232501920833784,
    0.1314213077499744,
    0.1314213077499744,
    0.1314213077499744,
    0.13239748595449122,
    0.13239748595449122,
    0.13239748595449122,
    0.13239748595449122,
    0.13239748595449122,
    0.13421277640743398,
    0.13421277640743398,
    0.13421277640743398,
    0.13421277640743398,
    0.13262187804994027,
    0.1364514520188644,
    0.1364514520188644,
    0.14729208033329794,
    0.1471910366668049,
    0.1471910366668049,
    0.13038099666664493,
    0.13038099666664493,
    0.13473511734614127,
    0.13098459866644893,
    0.13334179418745862,
    0.1337475078571082,
    0.13663378655357,
    0.13292585800005932,
    0.13169995239986748,
    0.13169995239986748,
    0.12973574299940083,
    0.12973574299940083,
    0.13315549011106972,
    0.13315549011106972,
    0.13227631477780555,
    0.13227631477780555,
    0.13428408099995673,
    0.13275386000012596,
    0.13275386000012596,
    0.1326791677998699,
    0.13389240842869704,
    0.1185325608888282,
    0.11964833860001818,
    0.12441490749993786,
    0.13341647966656942,
    0.13421101814284547,
    0.13421101814284547,
    0.134192465333399,
    0.1374190414999248,
    0.13793518522576168,
    0.13567431933309612,
    0.13682719800004528,
    0.13570417366706047,
    0.13570417366706047,
    0.13656933390914425,
    0.12834325699986948,
    0.1336973035999108,
    0.1336973035999108,
    0.13756290744231592,
    0.13721145657148423,
    0.13718438539999625,
    0.1377771060000338,
    0.1328666785002497,
    0.13856898732430292,
    0.13856898732430292,
    0.1396107650000431,
    0.1396107650000431,
    0.13523542771430844,
    0.13470095699995,
    0.13485302312506064,
    0.1373418445000425,
    0.13174511199940753,
    0.13298528444445562,
    0.14016362009087144,
    0.13943876899994442,
    0.13943876899994442,
    0.13192816250011674,
    0.13776904788892352,
    0.1396243992380949,
    0.1344142098332668,
    0.1399977392372991,
    0.13855102638708852,
    0.13370743650011718,
    0.14171652514000016,
    0.14022703699993144,
    0.14022703699993144,
    0.14080783352940618,
    0.14080783352940618,
    0.14080783352940618,
    0.14080783352940618,
    0.13951606849968812,
    0.13951606849968812,
    0.13951606849968812,
    0.13951606849968812,
    0.13951606849968812,
    0.13951606849968812,
    0.1457026882856423,
    0.1457026882856423,
    0.1457026882856423,
    0.1457026882856423,
    0.14607536055559145,
    0.14607536055559145,
    0.147203211714181,
    0.147203211714181,
    0.147203211714181,
    0.1419292585005678,
    0.1419292585005678,
    0.1419292585005678,
    0.13482305540019296,
    0.13135674099976313,
    0.13543028672221327,
    0.13538999138887042,
    0.14050622461535311,
    0.13434472999870195,
    0.13434472999870195,
    0.13311006511119355,
    0.13477295211103207,
    0.12959972733369796,
    0.12959972733369796,
    0.13574117600001046,
    0.1300771435007846,
    0.14256913569233104,
    0.13767625571407344,
    0.13767625571407344,
    0.13767625571407344,
    0.13694562344446443,
    0.13694562344446443,
    0.13694562344446443,
    0.13599295460007851,
    0.1376897103998999,
    0.13871430955542666,
    0.13800230762490173,
    0.14003943983334466,
    0.13882646514269123,
    0.1401429707000716,
    0.1401429707000716,
    0.1359461239999291,
    0.13775892250009747,
    0.13775892250009747,
    0.14519622633340784,
    0.13599879174989837,
    0.14533080328571182,
    0.14533080328571182,
    0.13548896049996983,
    0.13540425300016068,
    0.13540425300016068,
    0.13540425300016068,
    0.1435125906249747,
    0.1435125906249747,
    0.13692639799996364,
    0.13692639799996364,
    0.13878823866677217,
    0.13878823866677217,
    0.13878823866677217,
    0.13908214021870435,
    0.13908214021870435,
    0.12729925399980857,
    0.14436049477778093,
    0.14436049477778093,
    0.1396805898666571,
    0.1379298830983853,
    0.1354294017997745,
    0.13559183920006035,
    0.1409238645217398,
    0.12640454299980775,
    0.13706038174996138,
    0.13706038174996138,
    0.1499265350000944,
    0.1499265350000944,
    0.15896057455554707,
    0.15896057455554707,
    0.1386293709166845,
    0.1386293709166845,
    0.1386293709166845,
    0.1386293709166845,
    0.1386293709166845,
    0.15978172275004,
    0.15978172275004,
    0.15978172275004,
    0.15978172275004,
    0.16002531099972353,
    0.15979046433373392,
    0.13912574868291125,
    0.15516476699991066,
    0.15516476699991066,
    0.1311744802221963,
    0.1311744802221963,
    0.12760883000009926,
    0.1323773044000215,
    0.1323773044000215,
    0.1323773044000215,
    0.1294852182500108,
    0.1294852182500108,
    0.13469767660294832,
    0.13468493821053193,
    0.13030249499994775,
    0.13214117999996233,
    0.1293418408749858,
    0.13432276804348436,
    0.13432276804348436,
    0.12950050555567336,
    0.12878792416662085,
    0.13100345419989026,
    0.13463597023811807,
    0.1308377789991937,
    0.1308377789991937,
    0.13495335323998006,
    0.12930716312484947,
    0.1294899095000801,
    0.12875791699980255,
    0.1354192879411772,
    0.1328260265998324,
    0.13548120483331635,
    0.12791783233296883,
    0.12791783233296883,
    0.12791783233296883,
    0.12791783233296883,
    0.13571711100000053,
    0.13571711100000053,
    0.13571711100000053,
    0.13571711100000053,
    0.13571711100000053,
    0.1355552009999883,
    0.1355552009999883,
    0.1354840061111207,
    0.13545032894439324,
    0.13545032894439324,
    0.13519016799997188,
    0.13519016799997188,
    0.11097001199959777,
    0.11097001199959777,
    0.132645851999996,
    0.132645851999996,
    0.12774846575030097,
    0.13578622185715566,
    0.13749878839998927,
    0.1386381430002075,
    0.1368654197692824,
    0.1368654197692824,
    0.1368654197692824,
    0.1368654197692824,
    0.13614622149998468,
    0.13614622149998468,
    0.13614622149998468,
    0.13614043102628975,
    0.1365534956206955,
    0.14705666750069213,
    0.14705666750069213,
    0.14705666750069213,
    0.14705666750069213,
    0.14705666750069213,
    0.14705666750069213,
    0.13620300948574107,
    0.13620300948574107,
    0.13620300948574107,
    0.13620300948574107,
    0.13620300948574107,
    0.13470590100005211,
    0.13612722372975417,
    0.1363009274545303,
    0.13251657399996475,
    0.13703795976193978,
    0.13560030598038045,
    0.13651876088239506,
    0.13702242085717098,
    0.1379694963572027,
    0.13866460999997798,
    0.13866460999997798,
    0.13977621033336618,
    0.13977621033336618,
    0.13977621033336618,
    0.13515392866671996,
    0.13515392866671996,
    0.13929681799891114,
    0.1347519013478355,
    0.13643412525016174,
    0.13483917788895874,
    0.13483917788895874,
    0.1356957302142681,
    0.13013498699910997,
    0.13736217788896787,
    0.1390941643333766,
    0.1390941643333766,
    0.1355613219499901,
    0.13069528225014437,
    0.1336792904666557,
    0.1336792904666557,
    0.13513519995450968,
    0.135229058596483,
    0.13444554889993016,
    0.13461704070731484,
    0.13522050321744641,
    0.13463966584000445,
    0.13378645253336194,
    0.13772573540009034,
    0.13650178905877777,
    0.13765915520016278,
    0.1352216464799858,
    0.1352216464799858,
    0.1352216464799858,
    0.13207336166649636,
    0.13207336166649636,
    0.1337168041998666,
    0.13620543661538528,
    0.13417009199974927,
    0.13843355899916787,
    0.13843355899916787,
    0.13171260480012278,
    0.13500065295651756,
    0.13500124613046469,
    0.13140350399953604,
    0.13140350399953604,
    0.13140350399953604,
    0.13468851896426973,
    0.13468851896426973,
    0.13574238449998827,
    0.13574238449998827,
    0.13704609122214606,
    0.13478799499898741,
    0.14200465620015165,
    0.13538504616664998,
    0.13538504616664998,
    0.13440721466698355,
    0.13693295127268357,
    0.13693295127268357,
    0.1387121274999572,
    0.1358011034146507,
    0.1358011034146507,
    0.1336185896363366,
    0.13262667133343106,
    0.13469612735713912,
    0.12377389299945207,
    0.12377389299945207,
    0.13393474314815884,
    0.134540267400007,
    0.13513265064707145,
    0.13539155433333386,
    0.13427722277770548,
    0.1342779068333281,
    0.13080123133355906,
    0.13390969617638107,
    0.1359042718718112,
    0.13594384193183115,
    0.13217679549961758,
    0.13520119173076986,
    0.13452125846670243,
    0.1358235082856741,
    0.134098008666519,
    0.1382711563334548,
    0.13318225199994535,
    0.13453078495236004,
    0.1345634641666038,
    0.13779240824987937,
    0.13779240824987937,
    0.13330464099999517,
    0.13063637733345482,
    0.13618477916649377,
    0.132929005110984,
    0.13496668774996579,
    0.13580787718523493,
    0.12824590650052414,
    0.1339717498749451,
    0.13435640991656328,
    0.13314023000020825,
    0.13585325336366208,
    0.13468472929998826,
    0.1347828096364868,
    0.13607430007694069,
    0.1350566486428631,
    0.13484950754553376,
    0.13677560382755724,
    0.13614085710005383,
    0.13520885739999358,
    0.13602463880956098,
    0.13382070466670687,
    0.13153950200012332,
    0.13707125114820815,
    0.13510575669988611,
    0.13481116816668268,
    0.1361780760000134,
    0.13683451493750454,
    0.13641604100030236,
    0.13614487444445128,
    0.13504774050003712,
    0.13466608424960214,
    0.13775504862496746,
    0.13667901242869057,
    0.1365656542857323,
    0.13592859458624623,
    0.13835368519976327,
    0.1378893396249623,
    0.13625133548150728,
    0.1400235729997803,
    0.13374457899953995,
    0.13825945281827112,
    0.13594679781487717,
    0.13641948900052134,
    0.13636083657131945,
    0.13636083657131945,
    0.1364319566216452,
    0.13691160069230626,
    0.13947671566650874,
    0.13947671566650874,
    0.13715245966644338,
    0.1361285726429092,
    0.1364449758750652,
    0.13573243983329222,
    0.1366263346071069,
    0.13651948688877585,
    0.13204642800034586,
    0.13738931347272063,
    0.13738931347272063,
    0.14142250974964554,
    0.14142250974964554,
    0.13332013499991893,
    0.1334079053636246,
    0.1334079053636246,
    0.13672990370492907,
    0.13890048200119054,
    0.13369399440016422,
    0.13394370116657228,
    0.13118814500012377,
    0.13425797475019863,
    0.13617974266657662,
    0.13650060245460985,
    0.13432533977781227,
    0.13595068003335958,
    0.1365592188947056,
    0.13170225525004753,
    0.13693273500002062,
    0.13169683837509183,
    0.13756095191487513,
    0.13204110699997626,
    0.13204110699997626,
    0.1318822560000886,
    0.1318822560000886,
    0.1318822560000886,
    0.13798529257578732,
    0.13794606190699701,
    0.14038559599975997,
    0.1387940641001478,
    0.13332558020010765,
    0.13883479122220402,
    0.13883479122220402,
    0.13704582400000967,
    0.13947549560004216,
    0.13947549560004216,
    0.14032414317243191,
    0.13720365858823833,
    0.14791640433334882,
    0.14791640433334882,
    0.13387762599995767,
    0.13712662233350179,
    0.13346288244449372,
    0.1373500276664951,
    0.13209212142854604,
    0.13641081222092824,
    0.13564327919298275,
    0.13855403924992515,
    0.1385727313332609,
    0.13405628249984147,
    0.13776556400080153,
    0.13776556400080153,
    0.1311678476002271,
    0.13036197120018186,
    0.14343514077780936,
    0.13042176299995845,
    0.14144968481824352,
    0.12919817199993608,
    0.1292229464997945,
    0.14770154985697964,
    0.1359459706470493,
    0.1394484636669707,
    0.13779374822585058,
    0.14424437188891817,
    0.13801846877416415,
    0.14064613675000145,
    0.14064613675000145,
    0.13594506526786582,
    0.13594506526786582,
    0.1407585414209806,
    0.134755498269232,
    0.13086330333317164,
    0.12943657300093037,
    0.13597267046655664,
    0.13537593216361446,
    0.1348367686207047,
    0.1348367686207047,
    0.134880476483886,
    0.134880476483886,
    0.1334453618888397,
    0.1334453618888397,
    0.13380313853835665,
    0.13379379599990154,
    0.13379379599990154,
    0.13379625872717457,
    0.133738874666354,
    0.133738874666354,
    0.1344678895455383,
    0.1342737427999964,
    0.1335162087826061,
    0.13335902796153767,
    0.13335902796153767,
    0.13357560371436453,
    0.13398511042838177,
    0.13054451399966638,
    0.13210146007692786,
    0.13315392822217595,
    0.13315392822217595,
    0.13292610210010025,
    0.13356341922210252,
    0.1356970110000475,
    0.13555009225001413,
    0.1342707962001441,
    0.13273751333347011,
    0.13193672250008603,
    0.13230527290910354,
    0.1322502072000134,
    0.13262754928577383,
    0.12892395199924067,
    0.13274444726666842,
    0.13322030566663065,
    0.13183773999965828,
    0.13388174285708893,
    0.1300240779996784,
    0.13308719430006022,
    0.1292276269996364,
    0.1326853817141195,
    0.1335001909546091,
    0.13447153499995088,
    0.13360035969999445,
    0.1335350693334476,
    0.13416862114276487,
    0.13611172566682703,
    0.13611172566682703,
    0.1347256521426711,
    0.1347256521426711,
    0.13408808722225432,
    0.13333223250003812,
    0.1333259159999381,
    0.13381673011099338,
    0.13397470038468712,
    0.13386806123526185,
    0.13376566654534888,
    0.1314509310000176,
    0.1342489839048323,
    0.13355121999984476,
    0.1340093151666224,
    0.1340093151666224,
    0.1340093151666224,
    0.12200218600082735,
    0.12200218600082735,
    0.12200218600082735,
    0.13348748317644898,
    0.13348748317644898,
    0.13348748317644898,
    0.13478422438465015,
    0.13478422438465015,
    0.13487609188236735,
    0.13436523150012364,
    0.13469329785714632,
    0.13469329785714632,
    0.13256292485701643,
    0.13256292485701643,
    0.1330985470000087,
    0.1330985470000087,
    0.13754202563640403,
    0.1344518554999013,
    0.13774966781249987,
    0.13774966781249987,
    0.13774966781249987,
    0.13398417169222598,
    0.13398417169222598,
    0.13161458000013226,
    0.13788066546424357,
    0.13788066546424357,
    0.13788066546424357,
    0.13788066546424357,
    0.13518952049980726,
    0.13518952049980726,
    0.13518952049980726,
    0.1349680974999501,
    0.13787424245164137,
    0.1344324304443742,
    0.12829429600060394,
    0.12829429600060394,
    0.13858513689992832,
    0.13941494079990663,
    0.1385156636922777,
    0.1405624134166222,
    0.1405624134166222,
    0.1410773433846351,
    0.14137794554550387,
    0.1316018775005432,
    0.14198647033329811,
    0.14623032216665402,
    0.14139849091664777,
    0.14240780366667927,
    0.14240780366667927,
    0.12776378499984276,
    0.1394429072499861,
    0.13647977499992217,
    0.13128602850019888,
    0.1324076776666819,
    0.13667279344453062,
    0.13522669423539757,
    0.13893922370150008,
    0.13732764137512277,
    0.13971544094443675,
    0.14970718799850147,
    0.14970718799850147,
    0.14970718799850147,
    0.14997775700066995,
    0.14997775700066995,
    0.14997775700066995,
    0.13753030600006846,
    0.1411555506001605,
    0.1340124865384076,
    0.13623586866682066,
    0.13623586866682066,
    0.13349862088883432,
    0.13349862088883432,
    0.13349862088883432,
    0.13349862088883432,
    0.14475936344448806,
    0.14475936344448806,
    0.13812072610524315,
    0.13851633711116543,
    0.13908518429998368,
    0.13316009799927997,
    0.1405180561998956,
    0.1405180561998956,
    0.14594074011094765,
    0.14594074011094765,
    0.14502478555550624,
    0.1401097034399936,
    0.15190594233323887,
    0.14238488041670885,
    0.1320217146670378,
    0.14490088488896113,
    0.12996014950022072,
    0.1572328186000959,
    0.13944420726313597,
    0.0933364130002398,
    0.0933364130002398,
    0.12347782506670531,
    0.0929680610000408,
    0.0929680610000408,
    0.13221376990904074,
    0.13412426975037306,
    0.13259826587500356,
    0.1360076995294067,
    0.13963533806453332,
    0.1317794586000673,
    0.13065579033334668,
    0.13080988649994651,
    0.14150253709092134,
    0.14150253709092134,
    0.14123859454169482,
    0.13145726322222295,
    0.13117035425011636,
    0.13387465800042264,
    0.14113202599997748,
    0.14113202599997748,
    0.13841944461703262,
    0.13841944461703262,
    0.14205713200003214,
    0.14207094560863523,
    0.1305646059990977,
    0.14669434584608937,
    0.13106410616637731,
    0.13092616299945803,
    0.1478724698182222,
    0.1312906990006013,
    0.1312906990006013,
    0.13989594618918066,
    0.13989594618918066,
    0.1537895597777808,
    0.14316633612308158,
    0.14316633612308158,
    0.14758531757148116,
    0.14758531757148116,
    0.15018996054542103,
    0.16173237075008728,
    0.15472861599967777,
    0.15472861599967777,
    0.15472861599967777,
    0.15472861599967777,
    0.15472861599967777,
    0.15472861599967777,
    0.15472861599967777,
    0.13660329260019352,
    0.13660329260019352,
    0.13660329260019352,
    0.13660329260019352,
    0.13660329260019352,
    0.13660329260019352,
    0.13660329260019352,
    0.13660329260019352,
    0.13660329260019352,
    0.1294468140004028,
    0.1294468140004028,
    0.1294468140004028,
    0.1294468140004028,
    0.1294468140004028,
    0.1348060679166944,
    0.1348060679166944,
    0.1348060679166944,
    0.1348060679166944,
    0.1348060679166944,
    0.13566602322222293,
    0.13566602322222293,
    0.13566602322222293,
    0.13566602322222293,
    0.13591668977783733,
    0.13591668977783733,
    0.13591668977783733,
    0.13591668977783733,
    0.13591668977783733,
    0.13591668977783733,
    0.13569171777776823,
    0.13569171777776823,
    0.13569171777776823,
    0.13569171777776823,
    0.13554944700002428,
    0.1310514084998431,
    0.1310514084998431,
    0.1310514084998431,
    0.1310514084998431,
    0.1310514084998431,
    0.1399017889998504,
    0.1399017889998504,
    0.1399017889998504,
    0.1399017889998504,
    0.1399017889998504,
    0.1399017889998504,
    0.13282862500000192,
    0.13533739455548735,
    0.1354386169987265,
    0.13538607088897456,
    0.13142164049986604,
    0.13377025149975452,
    0.1428291898444311,
    0.1401283652777844,
    0.12689373300054285,
    0.135605757857255,
    0.13495024520016158,
    0.13170240799991006,
    0.13170240799991006,
    0.131018504000167,
    0.1377009363334057,
    0.13612593491673883,
    0.14002898250055296,
    0.1290545009997004,
    0.1399041379997167,
    0.1361731305714784,
    0.13643854099996133,
    0.13685692300012825,
    0.13685692300012825,
    0.13344184909097254,
    0.1314927904000797,
    0.1314927904000797,
    0.14256126073329747,
    0.13661417115382882,
    0.14661277562073996,
    0.14661277562073996,
    0.1372439326666305,
    0.14168310588889105,
    0.14168310588889105,
    0.14168310588889105,
    0.14168310588889105,
    0.13410240828566852,
    0.13410240828566852,
    0.13410240828566852,
    0.13410240828566852,
    0.13661145249989204,
    0.14829458900003373,
    0.1413550520010176,
    0.13431846540006517,
    0.14940629184610982,
    0.14169553254836384,
    0.1518566489090021,
    0.1353352015003111,
    0.14988392024997665,
    0.15022975269565234,
    0.15022975269565234,
    0.15022975269565234,
    0.15022975269565234,
    0.15575261800000184,
    0.15575261800000184,
    0.15575261800000184,
    0.15575261800000184,
    0.15575261800000184,
    0.15575261800000184,
    0.15575261800000184,
    0.14690884757146705,
    0.14690884757146705,
    0.14690884757146705,
    0.14690884757146705,
    0.14267677383329808,
    0.13007187000039266,
    0.13007187000039266,
    0.15705832287517296,
    0.15705832287517296,
    0.14913352574997893,
    0.14800181423085562,
    0.15107007063637534,
    0.15107007063637534,
    0.1366460148461696,
    0.13081880699974135,
    0.1303636255006495,
    0.1292667210000218,
    0.13547299738460283,
    0.1386275901071323,
    0.14126893700005086,
    0.1381823438387073,
    0.13786310415622438,
    0.138242508625126,
    0.1413632168182217,
    0.1413632168182217,
    0.13689704414708317,
    0.13689704414708317,
    0.13945290866680202,
    0.13945290866680202,
    0.14352774366670928,
    0.13588944240000272,
    0.13505369940477457,
    0.13505369940477457,
    0.13505369940477457,
    0.15060074499979237,
    0.15060074499979237,
    0.15060074499979237,
    0.15060074499979237,
    0.13433655750001586,
    0.13433655750001586,
    0.13433655750001586,
    0.13433655750001586,
    0.13389914000026693,
    0.13389914000026693,
    0.13271219636537632,
    0.13271219636537632,
    0.13271219636537632,
    0.13266535910000432,
    0.13266535910000432,
    0.13266535910000432,
    0.13255857305878582,
    0.1334152329230934,
    0.13528484549988207,
    0.1327637663103062,
    0.13787627700003213,
    0.13787627700003213,
    0.13787627700003213,
    0.13787627700003213,
    0.13787627700003213,
    0.1325544751153547,
    0.1325544751153547,
    0.1325544751153547,
    0.1325544751153547,
    0.1325544751153547,
    0.1325544751153547,
    0.1325544751153547,
    0.13229596225535212,
    0.13229596225535212,
    0.13229596225535212,
    0.13229596225535212,
    0.13373617822213013,
    0.1329456680000779,
    0.1329456680000779,
    0.1329688585384037,
    0.13255514224446313,
    0.1320531549166238,
    0.1320531549166238,
    0.13130083899947445,
    0.13130083899947445,
    0.13378019319970919,
    0.13378019319970919,
    0.13242276849996415,
    0.13214559450007074,
    0.12709943099980592,
    0.12709943099980592,
    0.1311083785003575,
    0.1311083785003575,
    0.13227635020011802,
    0.13227635020011802,
    0.13200136120834335,
    0.13200136120834335,
    0.1322795862854816,
    0.1322795862854816,
    0.132219733599959,
    0.132219733599959,
    0.132219733599959,
    0.132219733599959,
    0.132219733599959,
    0.132219733599959,
    0.13295902986671232,
    0.13295902986671232,
    0.13295902986671232,
    0.13295902986671232,
    0.13295902986671232,
    0.13295902986671232,
    0.12954953000007663,
    0.12954953000007663,
    0.12954953000007663,
    0.13203707158330266,
    0.13203707158330266,
    0.1317861181111463,
    0.13980375699975411,
    0.13163077216662109,
    0.13163077216662109,
    0.13163077216662109,
    0.13250125088334244,
    0.13250125088334244,
    0.13250125088334244,
    0.13158064071441394,
    0.13158064071441394,
    0.13198411391673895,
    0.13198411391673895,
    0.13198411391673895,
    0.12551359200006118,
    0.12551359200006118,
    0.132253421839996,
    0.132253421839996,
    0.13118811325011848,
    0.13187682533316547,
    0.13331355050013372,
    0.13222177700000054,
    0.13222177700000054,
    0.13222177700000054,
    0.13222177700000054,
    0.13222177700000054,
    0.1347518279999349,
    0.1347518279999349,
    0.1347518279999349,
    0.1347518279999349,
    0.1347518279999349,
    0.13247099116658015,
    0.13159497044448976,
    0.13183675613327067,
    0.13183675613327067,
    0.13271220177779874,
    0.13297044377271627,
    0.13253673650001474,
    0.13253673650001474,
    0.13253673650001474,
    0.13253673650001474,
    0.13253673650001474,
    0.13424737300010747,
    0.13424737300010747,
    0.13424737300010747,
    0.13424737300010747,
    0.13512636933349617,
    0.13437190300010116,
    0.13258175199916877,
    0.13258175199916877,
    0.13258175199916877,
    0.13258175199916877,
    0.13087799576924924,
    0.13087799576924924,
    0.13087799576924924,
    0.13087799576924924,
    0.1301264618570193,
    0.1301264618570193,
    0.1301264618570193,
    0.1325328662181908,
    0.1325328662181908,
    0.1325328662181908,
    0.1325328662181908,
    0.1325328662181908,
    0.13150157216659863,
    0.13150157216659863,
    0.13150157216659863,
    0.13150157216659863,
    0.1283389914997315,
    0.1283389914997315,
    0.1317218785006844,
    0.13134827260000748,
    0.13171234846161567,
    0.13171234846161567,
    0.13252145969230555,
    0.1318776535000931,
    0.1318776535000931,
    0.1320447955004056,
    0.1327102599565399,
    0.1327102599565399,
    0.13275524100011657,
    0.1325284250185211,
    0.13051237679974292,
    0.13051237679974292,
    0.13051237679974292,
    0.13051237679974292,
    0.13051237679974292,
    0.13051237679974292,
    0.13333941400014737,
    0.13333941400014737,
    0.13333941400014737,
    0.13333941400014737,
    0.13333941400014737,
    0.13209462966672922,
    0.13055347933307834,
    0.13055347933307834,
    0.12999177333343445,
    0.12999177333343445,
    0.12999177333343445,
    0.1328238457826165,
    0.1328238457826165,
    0.13235957957151964,
    0.13235957957151964,
    0.13235957957151964,
    0.13235957957151964,
    0.1346269701428225,
    0.1346269701428225,
    0.1346269701428225,
    0.1346269701428225,
    0.13345474049992845,
    0.13279276508334684,
    0.13331833900156198,
    0.13331833900156198,
    0.13331833900156198,
    0.13275858850877403,
    0.13275858850877403,
    0.1330648281875142,
    0.1330648281875142,
    0.1330648281875142,
    0.1381249127502997,
    0.1381249127502997,
    0.1381249127502997,
    0.13275137750943547,
    0.13413021699998354,
    0.13368599055997038,
    0.1338214582381278,
    0.13118290937495658,
    0.12906274899978598,
    0.12993745583359365,
    0.12905106724974758,
    0.13223282088886965,
    0.13002345728559053,
    0.13303358696970408,
    0.13303358696970408,
    0.13303358696970408,
    0.13329662806493367,
    0.13329662806493367,
    0.13470481900003506,
    0.13470481900003506,
    0.13470481900003506,
    0.13130343550005819,
    0.13130343550005819,
    0.13130343550005819,
    0.13130343550005819,
    0.13232963309102078,
    0.13232963309102078,
    0.13232963309102078,
    0.13232963309102078,
    0.13385415868742712,
    0.13385415868742712,
    0.13385415868742712,
    0.13301643254544615,
    0.13338855955549256,
    0.13338855955549256,
    0.13338855955549256,
    0.13338855955549256,
    0.13154081240027155,
    0.13154081240027155,
    0.13154081240027155,
    0.13398021653338218,
    0.13286930762265944,
    0.13352880599995842,
    0.13352880599995842,
    0.13352880599995842,
    0.1353452257999379,
    0.1353452257999379,
    0.1353452257999379,
    0.1353452257999379,
    0.1353452257999379,
    0.1353452257999379,
    0.13210087366678636,
    0.13210087366678636,
    0.13210087366678636,
    0.13210087366678636,
    0.13210087366678636,
    0.133344846421096,
    0.133344846421096,
    0.133344846421096,
    0.13333672123521598,
    0.13333672123521598,
    0.13333672123521598,
    0.13333672123521598,
    0.13333672123521598,
    0.13265652351160392,
    0.13265652351160392,
    0.13314516563159964,
    0.13563711322219912,
    0.12947697449999396,
    0.1366299375001745,
    0.13391855974987266,
    0.1336129289499695,
    0.13495074480015318,
    0.13495074480015318,
    0.1286951185002181,
    0.13650101450002694,
    0.1356407794998328,
    0.13331236635003735,
    0.13725842860003468,
    0.13725842860003468,
    0.13550827666666818,
    0.13344709949994163,
    0.13344709949994163,
    0.13344709949994163,
    0.13344709949994163,
    0.13344709949994163,
    0.13344709949994163,
    0.13344709949994163,
    0.13344709949994163,
    0.1306640541249635,
    0.1306640541249635,
    0.1306640541249635,
    0.1306640541249635,
    0.1306640541249635,
    0.1306640541249635,
    0.1306640541249635,
    0.13176208318178728,
    0.1319202541667437,
    0.1319492753124223,
    0.1319492753124223,
    0.13233731229633527,
    0.13203338150015043,
    0.1323260805455158,
    0.13544164911537593,
    0.13116157249987737,
    0.1320142967742281,
    0.13248853914280648,
    0.13125702850001372,
    0.13166977722216366,
    0.13317761245312454,
    0.13320973100002073,
    0.13320973100002073,
    0.1278337774992906,
    0.13311943357894052,
    0.13311943357894052,
    0.13164098800007196,
    0.1302149429993733,
    0.13342363833999116,
    0.13236991819998367,
    0.13489722099984647,
    0.1323188004998883,
    0.1323188004998883,
    0.1332197035454473,
    0.1332197035454473,
    0.1365310609999142,
    0.1317738251111425,
    0.13224381488887754,
    0.1322005909998552,
    0.1322005909998552,
    0.13237339218744637,
    0.13237339218744637,
    0.13237339218744637,
    0.13191694930010273,
    0.13191694930010273,
    0.13191694930010273,
    0.13316081365627497,
    0.13316081365627497,
    0.1322590087778129,
    0.1328387089500211,
    0.1323410405555276,
    0.13202868812493307,
    0.13169302287496976,
    0.12944320700080425,
    0.13195881823530192,
    0.13297509624999293,
    0.13080104400069104,
    0.13033994285693293,
    0.1306360010003118,
    0.13069144199996824,
    0.13083700424999734,
    0.13359809957686453,
    0.1316139186666179,
    0.1338439133200154,
    0.13100643500001752,
    0.13100643500001752,
    0.13334281263163766,
    0.13212670590000924,
    0.13205353128588676,
    0.13367062372223396,
    0.133720602804359,
    0.13344782909998684,
    0.13329407062497012,
    0.13230733933333896,
    0.1252421270000923,
    0.1252421270000923,
    0.13123166559998936,
    0.13123166559998936,
    0.13123166559998936,
    0.13123166559998936,
    0.13278242100022908,
    0.13278242100022908,
    0.13278242100022908,
    0.1328233669992187,
    0.1336202697999397,
    0.1336202697999397,
    0.1346198054499837,
    0.1332006385000568,
    0.13695539368033127,
    0.1341114227499626,
    0.13396012296775991,
    0.13385479220831561,
    0.1375699128332902,
    0.13481391831584533,
    0.1340446509999987,
    0.13615721975020278,
    0.13615721975020278,
    0.137376452999888,
    0.13389272240004044,
    0.12979347400141705,
    0.12979347400141705,
    0.1353469953749027,
    0.1348048812223068,
    0.13372867910002242,
    0.12939956424997945,
    0.13333930782144826,
    0.1329334539090765,
    0.1329334539090765,
    0.1329334539090765,
    0.1329334539090765,
    0.12929223399987677,
    0.12929223399987677,
    0.12929223399987677,
    0.12929223399987677,
    0.12929223399987677,
    0.12929223399987677,
    0.13801512892309686,
    0.13801512892309686,
    0.13801512892309686,
    0.12904357299976255,
    0.12722321399996872,
    0.13034955100010848,
    0.13375540418517765,
    0.1348895657776868,
    0.13481740833352282,
    0.13362648589288387,
    0.1341813138666718,
    0.14054661740741453,
    0.1361680834001163,
    0.13656490566669768,
    0.13656490566669768,
    0.13066232399978617,
    0.13066232399978617,
    0.13765252324992616,
    0.13583775454538805,
    0.13583775454538805,
    0.13583775454538805,
    0.13583775454538805,
    0.13437084246664502,
    0.13437084246664502,
    0.13437084246664502,
    0.13398700072000794,
    0.1434568679997028,
    0.13457247390015253,
    0.13457247390015253,
    0.13813725907694346,
    0.1307361930012121,
    0.13742193833362157,
    0.1369039017504292,
    0.1369039017504292,
    0.13349856724997672,
    0.13349856724997672,
    0.13319560349999746,
    0.14182192702272997,
    0.13449768999998923,
    0.13449768999998923,
    0.14480501196158002,
    0.14480501196158002,
    0.1370663625002635,
    0.13340605442863307,
    0.13460288822231328,
    0.13331044637516243,
    0.133144975857119,
    0.14623377478259816,
    0.13903258649952477,
    0.1338420397777453,
    0.13842325977612516,
    0.13086201599980996,
    0.13086201599980996,
    0.13086201599980996,
    0.1390420459993038,
    0.1390420459993038,
    0.13360623733335938,
    0.13417878049995124,
    0.14258059494871608,
    0.14258059494871608,
    0.13186763454558043,
    0.13383720617650183,
    0.13397933299984288,
    0.1312783533333762,
    0.13142298000002484,
    0.14099178122730585,
    0.13226313549989754,
    0.14108053286666594,
    0.13935234863157875,
    0.13317632854556327,
    0.13317632854556327,
    0.14303615277781823,
    0.14303615277781823,
    0.14303615277781823,
    0.14303615277781823,
    0.14686612176928276,
    0.14686612176928276,
    0.14686612176928276,
    0.1364871170007973,
    0.1364871170007973,
    0.1370036541112414,
    0.1370036541112414,
    0.13437437250013318,
    0.14880808509527318,
    0.14880808509527318,
    0.1460064235000876,
    0.13535165199973562,
    0.13618913800019072,
    0.13618913800019072,
    0.16232923999996274,
    0.1508742950000548,
    0.14696733399978257,
    0.15338413774998116,
    0.1571328120000544,
    0.1571328120000544,
    0.16713363140006549,
    0.15584605356252723,
    0.15584605356252723,
    0.15584605356252723,
    0.15069157636373182,
    0.15069157636373182,
    0.15069157636373182,
    0.15069157636373182,
    0.146443100933296,
    0.14033326033313642,
    0.14033326033313642,
    0.14412948399967718,
    0.14452589949996764,
    0.14452589949996764,
    0.14452589949996764,
    0.13292856928204017,
    0.13292856928204017,
    0.1354140900002676,
    0.1334801076458234,
    0.13248627511105346,
    0.12996093219990143,
    0.13077120322223992,
    0.13077120322223992,
    0.13204687478576357,
    0.1323565178260216,
    0.13055286100006924,
    0.13179113900010775,
    0.13503027767104103,
    0.13286646582755252,
    0.13352403565854395,
    0.13276189732430402,
    0.1323802443750992,
    0.13229938299999047,
    0.13429430255770897,
    0.13229565272724192,
    0.13381873529268465,
    0.13381873529268465,
    0.1311080114996912,
    0.13319733464283803,
    0.13021990483321133,
    0.13299170924983628,
    0.13381128508569548,
    0.13381128508569548,
    0.13279989920010848,
    0.13282442379968415,
    0.13270673824990808,
    0.13442475511106344,
    0.1332707213332469,
    0.1324035626875002,
    0.13254159562495715,
    0.13465192766670953,
    0.13467566474992054,
    0.13792550199832476,
    0.13326323299997966,
    0.13311582111771927,
    0.13370124872219297,
    0.13469547776474108,
    0.13469547776474108,
    0.13355330699982915,
    0.13007411750004394,
    0.13076668109087305,
    0.13113804833321613,
    0.1332599774999835,
    0.1311201250000522,
    0.1311201250000522,
    0.1308349279999675,
    0.13302819849999045,
    0.13294436956243771,
    0.13306830576934423,
    0.13328410666660298,
    0.13596286553729442,
    0.1350116776250161,
    0.13611180818460036,
    0.1322455400004401,
    0.134098524933385,
    0.13266490299974976,
    0.135295870157949,
    0.13592548024998904,
    0.13592548024998904,
    0.13592548024998904,
    0.13549495245827833,
    0.13549495245827833,
    0.13549495245827833,
    0.13549495245827833,
    0.13462351600005953,
    0.13462351600005953,
    0.13462351600005953,
    0.13605005953334814,
    0.13605005953334814,
    0.13167162733346535,
    0.1322768181248648,
    0.13551308213330535,
    0.13217234619987722,
    0.13562638349958434,
    0.13562638349958434,
    0.13562638349958434,
    0.13317161074974138,
    0.13317161074974138,
    0.13582078099989303,
    0.13343397833341442,
    0.13245993939999606,
    0.13371863833344833,
    0.1419418540008337,
    0.1372466120323107,
    0.1372466120323107,
    0.1372466120323107,
    0.1372466120323107,
    0.1372466120323107,
    0.1372466120323107,
    0.1372466120323107,
    0.13641841139997268,
    0.13641841139997268,
    0.13641841139997268,
    0.13641841139997268,
    0.13641841139997268,
    0.13641841139997268,
    0.13641841139997268,
    0.13399876139992556,
    0.13399876139992556,
    0.13761801945163885,
    0.1381117925999206,
    0.1376658536665976,
    0.13754147668422725,
    0.1374158172222653,
    0.13781083714288148,
    0.14204206724980395,
    0.1368262305145568,
    0.1368262305145568,
    0.13948666482354063,
    0.14011918399955903,
    0.1366011370566137,
    0.13776530985731889,
    0.13607112359968596,
    0.13637748542225583,
    0.1399801748460819,
    0.13739122580766258,
    0.13739122580766258,
    0.1340707616667108,
    0.1340707616667108,
    0.13419192999936058,
    0.13419192999936058,
    0.13419192999936058,
    0.13430319000023397,
    0.13482712099994387,
    0.13482712099994387,
    0.14235635600016394,
    0.1324082510000153,
    0.1362860817441901,
    0.1362860817441901,
    0.1362860817441901,
    0.1362860817441901,
    0.1391632747777799,
    0.1391632747777799,
    0.1391632747777799,
    0.1391632747777799,
    0.13807482140000502,
    0.13886515783330347,
    0.13886515783330347,
    0.13886515783330347,
    0.13886515783330347,
    0.13886515783330347,
    0.13886515783330347,
    0.14180520700028865,
    0.14180520700028865,
    0.14180520700028865,
    0.14180520700028865,
    0.14180520700028865,
    0.14180520700028865,
    0.14180520700028865,
    0.14180520700028865,
    0.13437706990001363,
    0.13437706990001363,
    0.13464785055556502,
    0.13468912766657012,
    0.13502785700005077,
    0.13513103745456398,
    0.1367774130555214,
    0.136873377000029,
    0.13697270777781037,
    0.13697270777781037,
    0.13971488066666402,
    0.13971488066666402,
    0.13971488066666402,
    0.13488249955561413,
    0.13488249955561413,
    0.13529564655735038,
    0.13529564655735038,
    0.1382048020000184,
    0.13310017200001312,
    0.13310017200001312,
    0.13056932100031796,
    0.13558907100000048,
    0.13515290757147472,
    0.131900164333274,
    0.131900164333274,
    0.13274955700035207,
    0.13274955700035207,
    0.13499941043744457,
    0.13467172897292806,
    0.13467172897292806,
    0.13503209266673366,
    0.13691525189988168,
    0.13625036867741133,
    0.13488016920006582,
    0.1350323992142616,
    0.1350323992142616,
    0.13930476114286908,
    0.13930476114286908,
    0.13517541994446625,
    0.13489434985293722,
    0.13932517600005667,
    0.135544052307663,
    0.1355363687333415,
    0.13681214099994,
    0.13681214099994,
    0.14623349700013932,
    0.14623349700013932,
    0.13382782541672592,
    0.13485126158696442,
    0.13600640247457674,
    0.1325339797273376,
    0.134005044444469,
    0.134005044444469,
    0.13287942066664174,
    0.13389980015999753,
    0.13389980015999753,
    0.13326829299876408,
    0.13326829299876408,
    0.13430279288897712,
    0.13430279288897712,
    0.13433944196555692,
    0.13433944196555692,
    0.1315641159999359,
    0.1315641159999359,
    0.13640225285713797,
    0.13522327586676208,
    0.12909226949977892,
    0.13501927955561163,
    0.13501927955561163,
    0.13503312099985326,
    0.13503312099985326,
    0.1354100744090994,
    0.13429262264999126,
    0.13616541062492615,
    0.1357100069999433,
    0.1357100069999433,
    0.13623063281821404,
    0.13642438374972699,
    0.13841366350000803,
    0.135494602000108,
    0.13812144199982868,
    0.13491239300128655,
    0.13444487699998717,
    0.13444487699998717,
    0.1363151828783786,
    0.1363151828783786,
    0.1359468453214114,
    0.1358791963333109,
    0.135032839500127,
    0.135032839500127,
    0.135032839500127,
    0.13395071649983947,
    0.13395071649983947,
    0.13395071649983947,
    0.13395071649983947,
    0.13290815114305587,
    0.1363111697187378,
    0.13642909476596074,
    0.135465633366645,
    0.13606502234783283,
    0.13243515200065303,
    0.13243515200065303,
    0.1312870908889939,
    0.13023400899995372,
    0.13728426606453029,
    0.13027770500048064,
    0.13065328200173099,
    0.13610662026658246,
    0.13610662026658246,
    0.1348133268573812,
    0.1369300000005751,
    0.13681655059091016,
    0.13676184564444863,
    0.12905220399989048,
    0.1380657985999278,
    0.13681515188889332,
    0.13586906512500718,
    0.13533250511116218,
    0.137644234999936,
    0.13818353145457382,
    0.13818353145457382,
    0.13888072199988527,
    0.13919595203995414,
    0.13645552171432687,
    0.13916671080005472,
    0.13781563775861788,
    0.13950449772225207,
    0.1405384694285853,
    0.1381865028570246,
    0.1381865028570246,
    0.13972783068426284,
    0.142466089999895,
    0.14209972300007698,
    0.14209972300007698,
    0.13299140099999412,
    0.13299140099999412,
    0.13299140099999412,
    0.13716493328571405,
    0.13716493328571405,
    0.13811270077783572,
    0.13456330277767847,
    0.1364915565319144,
    0.1364915565319144,
    0.13817655316658298,
    0.13817655316658298,
    0.13735885638094,
    0.13735885638094,
    0.13977101684619042,
    0.13472613619996993,
    0.13116444900151691,
    0.13550242299970705,
    0.13683684916472616,
    0.14148842422218877,
    0.13950460300020495,
    0.14269069633337494,
    0.14118041440015078,
    0.1324131519995717,
    0.13688897131707076,
    0.13688897131707076,
    0.13484158264288584,
    0.13553558805880825,
    0.13876276549990507,
    0.13876276549990507,
    0.13375062260007933,
    0.1337822814445341,
    0.13590487279106495,
    0.1323219562222625,
    0.13330678649994557,
    0.13379330988896576,
    0.13502242544442802,
    0.13200582240024233,
    0.13375950533332392,
    0.1354937291578512,
    0.135807873066733,
    0.13563236528573594,
    0.13634454673909047,
    0.13469206612512608,
    0.13470742575009353,
    0.13645733800006252,
    0.13645733800006252,
    0.13388701633327096,
    0.13388701633327096,
    0.13783981000051426,
    0.13025038249998033,
    0.13005097799941723,
    0.13005097799941723,
    0.13443526733317412,
    0.13611729204545886,
    0.1353956294473583,
    0.13671274799993885,
    0.137379126333326,
    0.13658277349986747,
    0.1383890411250377,
    0.13845870428589738,
    0.13845870428589738,
    0.1361226422727255,
    0.1361226422727255,
    0.13737268683325965,
    0.13601085541665725,
    0.13713062580009136,
    0.13525873092003166,
    0.1356482219041139,
    0.13564834709723073,
    0.13782511700082978,
    0.13690383050015953,
    0.13737297077770766,
    0.1353645750800206,
    0.13456605574992864,
    0.13494401838453576,
    0.13494401838453576,
    0.1361240779999207,
    0.13633008105452146,
    0.1365601060000093,
    0.13526816949979548,
    0.13412614106243836,
    0.13412614106243836,
    0.1315470039990032,
    0.13375847205883046,
    0.13377033623531615,
    0.1320338918998459,
    0.1319301802001064,
    0.13199414500013518,
    0.13199414500013518,
    0.14012141380001897,
    0.14012141380001897,
    0.13350518960008534,
    0.1335067471110152,
    0.12958057399919198,
    0.13246662374967855,
    0.13247192824974263,
    0.13330001587496554,
    0.13175910366650592,
    0.13722932718419065,
    0.13722932718419065,
    0.13722932718419065,
    0.12990715533366406,
    0.12990715533366406,
    0.13666586360001626,
    0.13301302942844423,
    0.13674961377775482,
    0.13169269950003581,
    0.13412710499978858,
    0.13409633800013884,
    0.13409633800013884,
    0.13409633800013884,
    0.13563362215385355,
    0.13563362215385355,
    0.13563362215385355,
    0.13403560422213762,
    0.13668295983332732,
    0.13615457485710586,
    0.13615457485710586,
    0.13615457485710586,
    0.13762383651511767,
    0.13762383651511767,
    0.13704471247998298,
    0.12888551200012444,
    0.13328344633343173,
    0.13753180723527775,
    0.13885624649992678,
    0.1390386885004773,
    0.1353755555090836,
    0.1375634817500213,
    0.1375634817500213,
    0.1375634817500213,
    0.12954394900043553,
    0.12954394900043553,
    0.1370359604998157,
    0.1370359604998157,
    0.13906427400070243,
    0.13906427400070243,
    0.13868029839999507,
    0.133547171166659,
    0.13287730866674488,
    0.13858531711108904,
    0.1331393284999649,
    0.13421269683324985,
    0.1396704355000414,
    0.13026284599982318,
    0.13026284599982318,
    0.1335606464999728,
    0.1335606464999728,
    0.13677244666663077,
    0.13677244666663077,
    0.1401401988332509,
    0.13606681833334733,
    0.13935029599997506,
    0.14083025345445838,
    0.14083025345445838,
    0.14121564477762957,
    0.14121564477762957,
    0.14121564477762957,
    0.1806978924996656,
    0.1806978924996656,
    0.1806978924996656,
    0.18063210149966835,
    0.18063210149966835,
    0.18063210149966835,
    0.14076958811764437,
    0.14076958811764437,
    0.14033112111105261,
    0.14033112111105261,
    0.13807101360868293,
    0.13804028308330393,
    0.15461083300033351,
    0.15461083300033351,
    0.13930849164999018,
    0.1437424110000494,
    0.0024451810004393337,
    0.1381286749998253,
    0.1381286749998253,
    0.1380702079000912,
    0.13356102914284357,
    0.1342308459999393,
    0.1342308459999393,
    0.1342308459999393,
    0.13617949500076065,
    0.13617949500076065,
    0.13376263124240667,
    0.1351416887999221,
    0.13327919254167378,
    0.13392314466667207,
    0.1288859570013301,
    0.1314492080000491,
    0.13344189127590275,
    0.1375381906250368,
    0.1375381906250368,
    0.14771030666694665,
    0.14771030666694665,
    0.13313119634375425,
    0.13665727088886748,
    0.13665727088886748,
    0.13665727088886748,
    0.13665727088886748,
    0.13172352066673435,
    0.13172352066673435,
    0.13172352066673435,
    0.13172352066673435,
    0.13172352066673435,
    0.13115510133340852,
    0.13115510133340852,
    0.13115510133340852,
    0.13115510133340852,
    0.13115510133340852,
    0.13029987875006555,
    0.13029987875006555,
    0.13029987875006555,
    0.1315596635555536,
    0.12905621249956312,
    0.12905621249956312,
    0.12905621249956312,
    0.13182390359997953,
    0.13182390359997953,
    0.1309059028332437,
    0.1309059028332437,
    0.1313793108001846,
    0.1327388899996246,
    0.13319446047617453,
    0.1317450218573088,
    0.1317450218573088,
    0.13225808511106152,
    0.13290626110342443,
    0.12926383949979936,
    0.13100944877765464,
    0.1317958119998366,
    0.1332430341874821,
    0.13277726762498787,
    0.13069212144445272,
    0.12747447999936412,
    0.12747447999936412,
    0.13147698739994668,
    0.13360552259525452,
    0.13360552259525452,
    0.13273268359989743,
    0.1324849433125337,
    0.1324849433125337,
    0.1317159048823455,
    0.13239899141931785,
    0.13359671502274234,
    0.1332095524615467,
    0.13383199585292888,
    0.13350264936841422,
    0.12829392999992706,
    0.1318116965999555,
    0.1335160416000387,
    0.13359933699998972,
    0.13340863644678277,
    0.13340863644678277,
    0.13256966485719854,
    0.12781105099929846,
    0.13084249099983936,
    0.12993793733342804,
    0.13394337167566747,
    0.13240154849991087,
    0.13194575333303268,
    0.1329256780000623,
    0.1335699290000201,
    0.1341041457777734,
    0.1343828205066772,
    0.13394139199954225,
    0.13394139199954225,
    0.13196979099989725,
    0.13198474662499393,
    0.13198474662499393,
    0.13062616780007374,
    0.1338995416665259,
    0.13058426275028978,
    0.13455418177788184,
    0.13228118483311846,
    0.13451088731819089,
    0.13318260539999754,
    0.1341715242727911,
    0.1345056027001192,
    0.13455456536844154,
    0.13460887766666052,
    0.1339841629996954,
    0.1348471093809903,
    0.13162587700026052,
    0.13309660719993796,
    0.13635152700044273,
    0.1348272522083486,
    0.1346427675172326,
    0.13202708214287537,
    0.13212764357142856,
    0.13070737188880027,
    0.13416401829999813,
    0.13416401829999813,
    0.13354502594120277,
    0.13178351062492766,
    0.13178351062492766,
    0.13050126139969506,
    0.13109279000006305,
    0.13386246807893162,
    0.13489472554548146,
    0.1343073910000105,
    0.13525386811104706,
    0.13218028240007698,
    0.1346767033845446,
    0.13428728183718577,
    0.12958305250049307,
    0.13541861100006478,
    0.1276528069993219,
    0.13653422942869448,
    0.1326468432503134,
    0.13428701130303097,
    0.1339689257499938,
    0.1380785178000224,
    0.13504604470371204,
    0.13559932509104494,
    0.13435547642422369,
    0.13807736900016607,
    0.13807736900016607,
    0.13874134500019863,
    0.13504420686670832,
    0.13504420686670832,
    0.13549357873076728,
    0.13602065855553114,
    0.13538193171422921,
    0.13313627600003505,
    0.1366518856785617,
    0.13297309933356397,
    0.13193264233329197,
    0.13193264233329197,
    0.1335792615000173,
    0.13447028322859425,
    0.13363012836001872,
    0.13363012836001872,
    0.13363012836001872,
    0.13455935981132053,
    0.13455935981132053,
    0.13455935981132053,
    0.1317676284999834,
    0.1317676284999834,
    0.12983535499915888,
    0.13361390060866973,
    0.1380946754998149,
    0.13200956611116352,
    0.13200956611116352,
    0.13360188941669549,
    0.13056846800009225,
    0.13306230954532855,
    0.13336104446156802,
    0.13336104446156802,
    0.13278908299980685,
    0.13458445103844077,
    0.13466457264288087,
    0.13228085399896372,
    0.13426163781811987,
    0.13252163499987546,
    0.1306073379995117,
    0.1306073379995117,
    0.13438055288888454,
    0.13438055288888454,
    0.13431838048003555,
    0.1372178220161356,
    0.12940234033339948,
    0.12940234033339948,
    0.13620122080028524,
    0.1359029103001376,
    0.1359029103001376,
    0.1347374315651984,
    0.13672961889988072,
    0.13595885479990102,
    0.13220129699948302,
    0.1321598515005462,
    0.1375910050001039,
    0.1375910050001039,
    0.13494123700002092,
    0.13368418962500073,
    0.13441488871415327,
    0.1348529385999947,
    0.13734793600027237,
    0.13474850685711967,
    0.13355741166666726,
    0.1302304506668103,
    0.1302304506668103,
    0.1302304506668103,
    0.134475041333341,
    0.134475041333341,
    0.1333820161667063,
    0.1333820161667063,
    0.13077437277772536,
    0.1295354195002195,
    0.1295354195002195,
    0.13000304759989376,
    0.132300970444501,
    0.12952887866655752,
    0.13806981731999257,
    0.1349067957857447,
    0.1349067957857447,
    0.1349067957857447,
    0.1349067957857447,
    0.1349067957857447,
    0.13181312149996907,
    0.13181312149996907,
    0.13181312149996907,
    0.13181312149996907,
    0.13181312149996907,
    0.13181312149996907,
    0.13408688279996567,
    0.13408688279996567,
    0.13408688279996567,
    0.13408688279996567,
    0.1349476338421147,
    0.1349476338421147,
    0.12975039799857768,
    0.12975039799857768,
    0.13101694899887661,
    0.13101694899887661,
    0.1359787353902481,
    0.13663324030003424,
    0.13663324030003424,
    0.1335534169999543,
    0.1335534169999543,
    0.13736498322214175,
    0.13736498322214175,
    0.1363401711999662,
    0.1388545947333316,
    0.136689894500023,
    0.1368239146668202,
    0.13797449780031457,
    0.14501800700054446,
    0.1362797907499953,
    0.1353805370624741,
    0.13723284088235446,
    0.13587995999963218,
    0.13577250645456926,
    0.13577250645456926,
    0.13577250645456926,
    0.13212604000000283,
    0.13212604000000283,
    0.13212604000000283,
    0.13493643208327435,
    0.13471138216002146,
    0.13471138216002146,
    0.13464166516647916,
    0.13443113949997496,
    0.132839688999411,
    0.13453951960000268,
    0.1344991259999612,
    0.1344991259999612,
    0.1344991259999612,
    0.13909485543906447,
    0.13909485543906447,
    0.13909485543906447,
    0.13909485543906447,
    0.1355061066666773,
    0.1355061066666773,
    0.1355061066666773,
    0.1355061066666773,
    0.13440764684617953,
    0.13440764684617953,
    0.13440764684617953,
    0.13449031200010117,
    0.13449031200010117,
    0.13449031200010117,
    0.13626765340013663,
    0.13626765340013663,
    0.13460232237503078,
    0.13455957000041963,
    0.13459529731244402,
    0.1396333564998713,
    0.1396333564998713,
    0.13841141268427523,
    0.13391036585718602,
    0.13997611359257092,
    0.13187463699978252,
    0.14158374145460006,
    0.13987850696872783,
    0.13408088977788188,
    0.13949621033328488,
    0.1372136162857974,
    0.1420818139523319,
    0.1343226156250239,
    0.14034469315391526,
    0.13414188849947095,
    0.14265198679995592,
    0.1399064339019627,
    0.1399064339019627,
    0.1399064339019627,
    0.1399064339019627,
    0.1416585344230463,
    0.1416585344230463,
    0.1416585344230463,
    0.1416585344230463,
    0.1323338704996786,
    0.14943361950008693,
    0.13196508399960294,
    0.1319651409994549,
    0.1319651409994549,
    0.14248350600001172,
    0.14248350600001172,
    0.14248350600001172,
    0.14248350600001172,
    0.1517016113999489,
    0.1517016113999489,
    0.1517016113999489,
    0.1517016113999489,
    0.15252756088880737,
    0.15252756088880737,
    0.15252756088880737,
    0.15252756088880737,
    0.15252756088880737,
    0.15252756088880737,
    0.1371024731874968,
    0.1371024731874968,
    0.1371024731874968,
    0.1371024731874968,
    0.1371024731874968,
    0.13187021724979786,
    0.13533912346149288,
    0.13289854216660993,
    0.13701388553571242,
    0.13450482964703148,
    0.1344619794999744,
    0.13415498379999918,
    0.13478330100003535,
    0.13357846549934038,
    0.13818661183358927,
    0.13450069064284825,
    0.13450069064284825,
    0.1343327452307746,
    0.1343327452307746,
    0.1343327452307746,
    0.1343327452307746,
    0.13109264000013354,
    0.13109264000013354,
    0.13109264000013354,
    0.13109264000013354,
    0.13109264000013354,
    0.13109264000013354,
    0.13109264000013354,
    0.13054886099992777,
    0.13054886099992777,
    0.13054886099992777,
    0.13054886099992777,
    0.13185042645454814,
    0.13185042645454814,
    0.1366836706999493,
    0.1366836706999493,
    0.13110329142857932,
    0.13110329142857932,
    0.13110329142857932,
    0.13169632587505475,
    0.13169632587505475,
    0.13546734359614185,
    0.132697237916697,
    0.132697237916697,
    0.13697397817138282,
    0.13236105812507049,
    0.13814503820837368,
    0.13201093099996797,
    0.13936846770002376,
    0.13936846770002376,
    0.13170394760018098,
    0.13170394760018098,
    0.13170394760018098,
    0.13552727094505387,
    0.13552727094505387,
    0.13552727094505387,
    0.13979488405263846,
    0.12930252700061828,
    0.13987782073682434,
    0.13312823080013914,
    0.13312823080013914,
    0.13991301124997335,
    0.1399886624761469,
    0.14163318209102727,
    0.13681885699952545,
    0.1431297990000328,
    0.13012008250007057,
    0.1331900833332232,
    0.13078293199941982,
    0.13078293199941982,
    0.1307657230008772,
    0.14446721075000823,
    0.135181039499912,
    0.14000976209999863,
    0.14000976209999863,
    0.13502042581818718,
    0.13503224345450607,
    0.1435034354999516,
    0.12848568399931537,
    0.14024018499990884,
    0.13912337400001384,
    0.13912337400001384,
    0.13784879380000348,
    0.1347145489999093,
    0.1347145489999093,
    0.1345208476662568,
    0.13492117450005026,
    0.13449780240007386,
    0.13395433550002572,
    0.13357503650013314,
    0.13272100283332597,
    0.13312456649998694,
    0.1329466440001852,
    0.13292123199971684,
    0.13294946271422045,
    0.13381293183335533,
    0.13381293183335533,
    0.13329371683327432,
    0.13483422571928377,
    0.13316499892313843,
    0.13415623162163193,
    0.13304375056522194,
    0.13233060255556162,
    0.13218610466659206,
    0.1327969726666197,
    0.13428988732352187,
    0.13428988732352187,
    0.13399469314286502,
    0.13088541320030345,
    0.13088541320030345,
    0.13088541320030345,
    0.13316074887495688,
    0.13316074887495688,
    0.13201770544441793,
    0.13118181399986498,
    0.1335649785002412,
    0.13421997250043205,
    0.1332225368571796,
    0.13257663700035968,
    0.13429224742101628,
    0.13262826150003093,
    0.13319569608332435,
    0.13474132629168403,
    0.13237637387510404,
    0.13169907499983916,
    0.13169907499983916,
    0.13461188313328118,
    0.13461188313328118,
    0.13515444317857014,
    0.13440977666626472,
    0.13343628044438244,
    0.13341815581820396,
    0.13426922369999375,
    0.13469931441381802,
    0.1331372088570788,
    0.13504087754347932,
    0.1352542788182208,
    0.13471184389652927,
    0.13471184389652927,
    0.13322634766700503,
    0.13541791418174398,
    0.13541791418174398,
    0.1360534703000667,
    0.1352183103334331,
    0.13591553770002066,
    0.13591553770002066,
    0.13552324349999859,
    0.1356946884286247,
    0.1362250758999835,
    0.13736559699983836,
    0.13554439384615063,
    0.13879018050010927,
    0.13526299777499845,
    0.13706707087499126,
    0.13706707087499126,
    0.13599793665385873,
    0.13438238181829962,
    0.13529764375016384,
    0.12915474400142557,
    0.13595135710637166,
    0.13502340222223413,
    0.13599696695348748,
    0.1341941141499774,
    0.13453886069230345,
    0.1357219815999997,
    0.13568044066657117,
    0.13763669699983438,
    0.13511563016678943,
    0.1349950129654738,
    0.13575531566675636,
    0.13035579999996116,
    0.1339334481110402,
    0.1339914780833169,
    0.1364555216667011,
    0.1364555216667011,
    0.13481931373913222,
    0.13265619200016468,
    0.132674625749587,
    0.13519207277770168,
    0.12869476149990078,
    0.13624263932353428,
    0.13558260866666388,
    0.1331881952501135,
    0.13626267779411994,
    0.13295769280011882,
    0.13295769280011882,
    0.1351638692653143,
    0.13495428933310905,
    0.13619267681247038,
    0.1379441747778603,
    0.13523617374468155,
    0.136884617777738,
    0.13555521400004572,
    0.14500376324986064,
    0.13575155915254905,
    0.13576867486663105,
    0.12607809400105907,
    0.13442263649994857,
    0.14163498819980305,
    0.13686606560004294,
    0.14542871625008047,
    0.14542871625008047,
    0.13499880854997173,
    0.13499880854997173,
    0.13498177549990942,
    0.1323169251249965,
    0.13268520275005358,
    0.13524036559374508,
    0.13240441772722988,
    0.13592145275862125,
    0.13582496422722298,
    0.13582496422722298,
    0.13178767877778025,
    0.13178767877778025,
    0.12972613599959004,
    0.13248241842848074,
    0.13180100899990066,
    0.13225874771420162,
    0.1329565384999114,
    0.1329565384999114,
    0.13572700433996943,
    0.13586291132813244,
    0.13350493200010127,
    0.13311068733310094,
    0.13700846299980185,
    0.13512005911765942,
    0.13430562088878004,
    0.1342816104997837,
    0.1335147967998637,
    0.1335147967998637,
    0.13823289339727549,
    0.1393494752501283,
    0.14064169500003723,
    0.13233147100011897,
    0.13535564378571507,
    0.13535564378571507,
    0.14339266950022042,
    0.14581213140008914,
    0.14252519399997254,
    0.14460903650009035,
    0.1385389156922219,
    0.14928911900036232,
    0.1380972445000225,
    0.09514506266653673,
    0.12561065414281206,
    0.11819873974991424,
    0.11819873974991424,
    0.1339902855453891,
    0.13298816850056028,
    0.13298816850056028,
    0.12960275200020988,
    0.13213900625032693,
    0.13403398755569165,
    0.1358383708636459,
    0.13377537337510148,
    0.12669890100005432,
    0.12669890100005432,
    0.13502851960001863,
    0.13501004816680506,
    0.1347942989996227,
    0.13701702233663696,
    0.1355823447241258,
    0.13698853624964613,
    0.13233869212513127,
    0.13187910055563,
    0.13187910055563,
    0.1320637984545928,
    0.13581779794121224,
    0.13581779794121224,
    0.13210194512498674,
    0.13735881486663856,
    0.13117337824996866,
    0.1360581681428379,
    0.13697197635714733,
    0.13548938122221443,
    0.13548938122221443,
    0.13034391499968478,
    0.13625301788892508,
    0.13004403300025538,
    0.13815667693751266,
    0.13235320999956457,
    0.1409526917777839,
    0.14095702877784788,
    0.13749855063159835,
    0.1384701256923178,
    0.13749192905882357,
    0.13845036784620718,
    0.14086328644447754,
    0.14086328644447754,
    0.14156102685722413,
    0.14154656542840321,
    0.14764142899985017,
    0.14764142899985017,
    0.1381473688667029,
    0.1381473688667029,
    0.13703826988228898,
    0.13703826988228898,
    0.14122103600129776,
    0.14119779711109004,
    0.13741558350011474,
    0.13584913815784125,
    0.13907245108324182,
    0.12978227675012022,
    0.13768492173239535,
    0.1397579263636792,
    0.1414994633103498,
    0.1366426391874711,
    0.1366426391874711,
    0.1406408356663936,
    0.13680406439998477,
    0.14230620044448491,
    0.1358540863335899,
    0.13946411500000977,
    0.13919113799966,
    0.1377423246428537,
    0.14124478593552223,
    0.14124478593552223,
    0.12829568799982857,
    0.12829568799982857,
    0.14392666326663553,
    0.12845432100039034,
    0.1287488090001716,
    0.12936567416666853,
    0.1287364460004028,
    0.13005910799984122,
    0.1334817923333402,
    0.13043003324992242,
    0.13814490018364955,
    0.1294846260000971,
    0.12958028733373794,
    0.13951339400004908,
    0.14331434866673792,
    0.14331434866673792,
    0.13202944899967406,
    0.14510231987492261,
    0.1429212779500631,
    0.13813893198150456,
    0.14333929040003568,
    0.15506322437499875,
    0.1555150021110118,
    0.14786571049990016,
    0.14779844250006136,
    0.15412658999994164,
    0.14381544194743343,
    0.14205454031815118,
    0.14053840679310992,
    0.14053840679310992,
    0.13452010362493638,
    0.13452010362493638,
    0.13412922174076677,
    0.1313230172857272,
    0.13349891136369313,
    0.13385661987490494,
    0.13385469760708343,
    0.13395871144442667,
    0.13171534020002582,
    0.13509907540000213,
    0.1344972165166534,
    0.1318326011998579,
    0.13614063999981832,
    0.13431882339279713,
    0.13469513111768344,
    0.13442362869234506,
    0.13464477183333656,
    0.13533027574976586,
    0.13585272255558165,
    0.13494958305000182,
    0.13768662966685952,
    0.13548227900008153,
    0.13556708772722975,
    0.1343119843331806,
    0.1329635114998382,
    0.13619261949997963,
    0.12798198600103206,
    0.13820736499974373,
    0.12681131399949663,
    0.12681131399949663,
    0.1354617037428917,
    0.13325340772726949,
    0.13325340772726949,
    0.13325340772726949,
    0.13325340772726949,
    0.13325340772726949,
    0.13325340772726949,
    0.13576048769237575,
    0.13576048769237575,
    0.13576048769237575,
    0.13576048769237575,
    0.13576048769237575,
    0.13576048769237575,
    0.13576048769237575,
    0.1355673214687272,
    0.1355673214687272,
    0.1355673214687272,
    0.1348597633332247,
    0.1348597633332247,
    0.1348597633332247,
    0.1348597633332247,
    0.13518332992849277,
    0.13518332992849277,
    0.13518332992849277,
    0.1312592719999278,
    0.1321754010624545,
    0.1316789056666797,
    0.13335403133335907,
    0.13504685008822837,
    0.13294635199963523,
    0.13068376216688193,
    0.13082366266644385,
    0.13420862687507906,
    0.13420862687507906,
    0.1349021342727307,
    0.13269801880014712,
    0.13542335786666324,
    0.13007895900045696,
    0.13007895900045696,
    0.13007895900045696,
    0.12960754399955476,
    0.12960754399955476,
    0.13700714441181525,
    0.14210365899998578,
    0.13805530761545434,
    0.14214797500001927,
    0.13389307312513665,
    0.13389307312513665,
    0.13776653187505872,
    0.1295365319998382,
    0.13133615625019956,
    0.1297055779996299,
    0.1312217282000347,
    0.13302112050041615,
    0.13505399628572506,
    0.1400758302858906,
    0.13513344429998142,
    0.13882644379991688,
    0.1349638936071642,
    0.13886579199990795,
    0.13886579199990795,
    0.13533508100044855,
    0.13533508100044855,
    0.1328737329999462,
    0.1335902581112249,
    0.134250143375084,
    0.134250143375084,
    0.13431086250002408,
    0.1337735780000205,
    0.1346060115,
    0.1346060115,
    0.1372327733999555,
    0.139865542500047,
    0.13270123688885682,
    0.13469567974997126,
    0.13415791418182463,
    0.13481206781479058,
    0.13481206781479058,
    0.1318722290000854,
    0.1307891584998894,
    0.1328450584666522,
    0.07158221101149817,
    0.13327291371427105,
    0.10503880800002151,
    0.09401567235937591,
    0.09401567235937591,
    0.13868580800044583,
    0.13486342861538922,
    0.13316786774991365,
    0.13252288600021225,
    0.13252288600021225,
    0.1357705100370502,
    0.1322176132222618,
    0.1349134248095132,
    0.13359643269996013,
    0.13414980210000066,
    0.13506947433331032,
    0.13413111799996436,
    0.13293973933317224,
    0.11737731877271719,
    0.11737731877271719,
    0.1349538297502022,
    0.1001030486538464,
    0.1348572516002605,
    0.1359403731579445,
    0.1359403731579445,
    0.13435562361547243,
    0.1357848868000777,
    0.1351552026000718,
    0.13659282558824892,
    0.1369503483912685,
    0.13681526585709694,
    0.13605945035997138,
    0.13646958399986034,
    0.13646958399986034,
    0.13741289033330556,
    0.13488032200002636,
    0.1377280601998791,
    0.1377280601998791,
    0.13527926366666743,
    0.13527926366666743,
    0.13665187099983692,
    0.054921251935470095,
    0.13931177466656663,
    0.13931177466656663,
    0.13056890499865403,
    0.13056890499865403,
    0.13951647722226174,
    0.13951647722226174,
    0.13951647722226174,
    0.13951647722226174,
    0.13951647722226174,
    0.13880721416656647,
    0.13880721416656647,
    0.13880721416656647,
    0.07977393347500765,
    0.13968664133305234,
    0.15838855499896454,
    0.15838855499896454,
    0.1352979361818143,
    0.1352979361818143,
    0.13911867016637794,
    0.13911867016637794,
    0.1378106728570856,
    0.05349864603772832,
    0.10847575399995549,
    0.13655075320002652,
    0.13465556433321682,
    0.06575386866668648,
    0.1339870819999002,
    0.1339870819999002,
    0.13742148199980875,
    0.03989489621276431,
    0.1325595730999339,
    0.1325595730999339,
    0.1325595730999339,
    0.058364026064561085,
    0.058364026064561085,
    0.08788647989995298,
    0.09506977147055509,
    0.12792447200020737,
    0.12960630550014685,
    0.12960630550014685,
    0.07558890305558129,
    0.13098730066667486,
    0.12948517599988918,
    0.12967361749997508,
    0.12813566099976015,
    0.045855430892905655,
    0.08152214793335588,
    0.053751246428614,
    0.02834982944185931,
    0.1328547564285795,
    0.1184204793333063,
    0.05370552580946727,
    0.12486993600032292,
    0.06084361212492695,
    0.13232977433350848,
    0.1337572336666805,
    0.06446136515380484,
    0.06446136515380484,
    0.03466435476473313,
    0.018981775428567615,
    0.055386559599901374,
    0.007977569977273643,
    0.007977569977273643,
    0.020655380875041374,
    0.020655380875041374,
    0.026431620499958324,
    0.005078187999970396,
    0.005078187999970396
  ],
  "generated_texts": [
    "<|vq_clip_12273|>this image displays a list of items in a table",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "Id ",
    "\ufffd \ufffd\ufffd\ufffd ",
    "\ufffd 1.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this image displays",
    " 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this image",
    " \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a",
    " .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  .. ",
    "<|vq_clip_12273|>this image displays a list of files and folders in a directory",
    "<",
    "<|vq_clip_12273|>this is a screenshot",
    "<",
    "<",
    "<|vq_12023|>",
    "n<|vq",
    " .. ..  ..  ..  ..  ..  ..  ..  .. ",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the first item is a blue square with a white circle, the second item is a red circle with a white square, the third item is a green circle with a white square, the fourth item",
    "<|vq_clip_12273|>",
    "at<|vq_clip_12273|>this image displays a list of items in",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is",
    "<|vq",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "",
    "<|vq_clip_12273|>this image displays a list of items in a",
    " ",
    "witness",
    "<|vq",
    " 1.0.0.0.",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_",
    "u\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person who is a friend of the user. the user is",
    "<|vq_clip_12273",
    "endant<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "<|vq_clip_12273",
    "<|vq_clip_12273",
    "<|vq_clip_",
    " ",
    "or<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"print('hello world')\". the code editor also has a line of code that says \"print('hello world')\". the script is written in",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_122",
    "```\n\nIt seems like there was a mistake in the input",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a translation of a phrase in a different language. the user is also asking for a translation of",
    ")",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"print('hello world')\". the code editor has a dark background with",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person who is",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel free to clarify or ask again!\n\nIt looks like your message got a bit mixed up.",
    "<|vq_clip_12273|>this image displays",
    "<",
    "<|vq_clip_12273|>",
    "Make<|vq",
    "\u0947<|vq_clip",
    "HOLDER<|vq_clip_12273|>this is",
    "<|",
    " \n\n```\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel free to clarify or ask",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme",
    "<|vq_clip_12273|>this is a screenshot of a chat conversation between two users. the chat is in a dark",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this image displays a list of files and folders in a computer's file explorer.",
    "<|",
    "",
    "\ufffd<|vq_clip_",
    " 1.0.",
    "<|",
    "ous",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a screenshot of",
    " \n\n \n\n  1. **\"The Great Gatsby\" by F",
    "<|vq_clip_12273|>this image displays a list of items in",
    "<|vq_clip_12273|>this code snippet is",
    "<|vq_clip_12273",
    "<|vq_clip_122",
    "<|vq_clip_",
    "<|vq_clip_122",
    "Path<|vq_clip_12273|>this is a screenshot of a code editor",
    ") `\n\n[conversation ends]",
    "\u0438\u043d<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<",
    "ed \n\nIt seems like your message got gar",
    "<|vq_clip_12273",
    "<",
    "<|",
    "<",
    "<|vq_clip_12273",
    "\ufffd ",
    " \ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>this image displays a",
    "",
    "<",
    "<|vq_clip_12273|>this is",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "<|vq",
    "<|vq_clip_12273|>this image displays a list of files and folders in a computer's file explorer. the list",
    "<|vq_clip_12273|>this is a",
    "\u0440\u0430<|vq_clip_122",
    "<|vq_clip",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this image displays",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a function called \"get_2d\" that takes in a list of numbers and returns a list of numbers. the script also has a function called \"get_2d",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column and are labeled as \"item 1\", \"item 2\", \"item 3\", \"item 4\", \"item 5\", \"item",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "ientists<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq",
    "<",
    "<",
    "\u0c3f<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip_12273|>this",
    "ings<|vq_clip",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the",
    "\ufffd ",
    "<",
    "\u09be .. ://\n\n[END OF CONVERSATION]",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    "<",
    "ering<|vq_clip_12273|>this is a screenshot of a",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text",
    "ors<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the",
    "<",
    "<|vq_clip_12273|>this image displays a table with various columns and rows. the table appears to be a data table, with columns for \"name\", \"age\", \"gender\", \"city\", \"state\", \"",
    "<|vq_clip_12273|>this image displays a list",
    " \ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<",
    "\n\n",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a specific question",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>",
    "ixed<|",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled",
    "<|vq",
    "<|vq_clip_12273",
    "/ \n\nIt seems like the text you provided is a mix of multiple languages and appears to be a random or nonsensical string of words. If you have a specific question",
    "<|vq_clip_12273|>this is a screenshot",
    "<|",
    "<|vq_clip",
    "<",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is",
    "ry<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the items are arranged in a grid, with the first item being a blue square,",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections,",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections, with",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart",
    "-",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to be added to the conversation. the user is also asking for a new user to be added to the conversation. the user is also asking for a new user to be added",
    "\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1",
    "able<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the function is called \"sum\" and it takes two arguments, \"a\" and \"",
    "ftware<|vq_12086|",
    " ",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "<|vq_clip_122",
    "ator<|vq_clip_12273",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_12273|>this",
    "<",
    "\ufffd 1.0",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum",
    "\ufffd<|vq_clip",
    ") ",
    " ",
    "<|vq_clip_12273|>this is a screenshot",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the",
    "",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|",
    "<|vq_clip",
    "<",
    " \n\nIt",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the items are arranged in a grid,",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"s",
    "<|vq_clip",
    " 1.0.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of",
    "<|vq_clip",
    "<|",
    "Size) .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  .. ",
    "\ufffd<|vq_clip_12273|>this image displays a",
    " 1.0.0.0.0.",
    "<|vq_clip_12273|>this image displays a list of 10 items that are commonly used",
    "",
    "<",
    "ic<|vq_clip_",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items include \"",
    "<|vq",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273",
    "iratory \n\nIt seems like your message got garbled or mixed up with a lot of unrelated",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d",
    "\ufffd<|vq_clip_12273|>this image displays a list of 10 items, each with",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "******************************************\n\nIt seems like your message",
    " 1.0.0.0.0.0.0.0.0",
    " \n\nIt seems like your message",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|",
    "<|vq_clip_",
    "<|vq_clip",
    " \ufffd\u09be<",
    "",
    "<|vq_clip_12273",
    "<|vq_clip_122",
    "<",
    "<|vq_clip",
    "<|",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a code editor",
    " \n\nIt seems like your message got a bit garbled. Could you",
    "<|vq_clip_12273|>",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"print('hello world')\". the code editor also has a terminal window with a command prompt. the script appears to be a simple python program that prints a message to the console. the code",
    "<|",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the items are labeled as \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", and \"10\". each item has a different color and a different shape. the table appears to be a part of a larger",
    "<|",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "Flow<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    " \n\n[END",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a",
    "re<|vq_clip_12273|",
    " \n\n**Note**: The text above is a mixture of multiple languages and appears to",
    "eneration<|vq_clip_12273|>this image displays a list of",
    "<|vq_clip_12273|>",
    " .. ..  ..  ..  ..  ..  ..  ..  ..",
    "<",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a person named \"sara\" and the other",
    " \n\n",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script",
    "<|vq_clip_12273|>",
    "<|vq",
    "<",
    " .. ..  ..  .. ",
    " 1",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is",
    "<|vq_clip_12273|>this is",
    "<|vq_clip",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>this image displays",
    "\ufffd 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>",
    "ures<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the code is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the code is written in a dark",
    "<|vq_clip_12273|>this image displays a list of items in",
    "<",
    "<|vq_clip",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a person named \"sara\" and the other",
    "\u043a\u0430<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items include \"c\", \"c\", \"c\", \"c\", \"c\",",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<|vq_clip_12273|>",
    "ia<",
    "Command<|vq_clip_12273|",
    "  \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a list of items in a table",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a",
    "<|vq_clip_12273|>this image displays a list of files and folders in a computer's file explorer. the list includes various files such as \"c:\\users",
    "",
    "<|vq_clip_12273|>this is a",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named",
    "<",
    " ",
    "<|vq_clip_12273|>this image displays a table with various columns and rows. the table appears to be a database or spreadsheet, with",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a",
    "IGHT",
    "<|vq_clip_12273",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a ",
    "ector 1.0.",
    "ed<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|>this image displays",
    "```\n\nIt looks like your message got garbled or mixed up with a lot of",
    " ",
    "<|vq_clip_12273|>this image",
    "\u0438\u043a<|vq_clip",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_",
    "g",
    "<|",
    "orward",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app.",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "<|vq_clip_122",
    "<|vq_clip_122",
    ")",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    "<|",
    "<|vq_clip_12273|>",
    " ",
    "udio \n\n```\n\nIt",
    "<|vq_clip",
    "<|vq_clip_",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a list of ",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers. the code is written in a dark theme with a black background. the function is named \"sum\" and it takes two arguments, \"a\" and \"b\". the code is written in a dark theme",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot",
    "<|",
    "\ufffd 1",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation appears to be in a language",
    "\ufffd<|vq_clip_122",
    "niek<|vq_clip",
    "<|vq_clip_12273|>this image",
    "<",
    "<|vq_clip_12273|>this is",
    "<|",
    " 1.0.0.0.",
    "stwa",
    "p<|",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this image displays a list of files and folders in a computer's file explorer. the files are organized in a hierarchical structure, with the topmost folder being \"c:\\users\\user\\documents\\my files\". the",
    "<",
    "<",
    "<",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of ",
    "<|vq_clip_12273|>this image displays a list of 10 items that are not included in the list.",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a specific question about a user named \"sudden\"",
    " 1.0.0.0.0.0.0.0.0.",
    "<",
    "<",
    " 2018 \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with a particular topic, feel free to ask! I'm here to help.\n\nIt looks like your message got a bit mixed up. If you have a specific question or need help with something, just let",
    "neys<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the first",
    "ian<|vq_clip_12273|>this",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "atic<|vq_clip_12273|>this is",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<",
    "<|vq",
    "S<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers and returns the result. the code is written in a dark theme with a black",
    "<|vq_clip_12273|",
    "<",
    "<|vq_clip_12273|",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of items. the items are displayed in a table",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a",
    "\ufffd 0\ufffd 1\ufffd 2\ufffd 3\ufffd 4\ufffd 5\ufffd 6\ufffd 7\ufffd 8\ufffd 9\ufffd 0\ufffd 1",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in",
    "ap<|vq_clip_122",
    "<|vq",
    "<|vq_clip",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    " \u12f0 \u12f0 \u12f0 \u12f0 \u12f0 \u12f0 \u12f0 \u12f0 \u12f0 \u12f0 ",
    "<|",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this",
    " ",
    " 1.0.0.0.0.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    "\ufffd 1\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of",
    "s<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_122",
    "\ufffd\ufffd<|vq_clip",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq",
    "<|vq_clip_12273|>this",
    " ",
    "\ufffd 1.0",
    "",
    "ce",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    " 1.0.0.0.0.0.0.0.0.0.0.0",
    "arystatus<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the items are arranged in a grid, with the first item being a blue square, the second item being a green circle, the third item",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column and are sorted by their respective categories. the table appears to be a part of a larger document or report. the items are listed in a column and are sorted by their respective categories. the table appears",
    "<",
    "<",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"",
    "<|vq_clip_",
    " \n\n[END OF",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a website that provides information about the 2022-2023 season of the 2022-2023 season of",
    "<|vq_clip_12273|>this image displays a list of items in a table format",
    "<|vq_clip",
    "ators<|vq_clip_12273|",
    "<|",
    "<|",
    " .. ..  ..  ..  ..  ..  ..  ..",
    "",
    "ing<|vq_clip_12273|>this is a",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    "<",
    "<|vq_clip",
    "<",
    "<|vq",
    "<|vq_clip_12273|>",
    "s 1.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app.",
    "<|vq",
    "lights<|vq_clip_12273|>this is a screenshot of",
    "<|",
    "<|vq",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    "S<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a",
    "s<",
    "<|vq_clip_12273|>this is",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a",
    "ant<|vq_clip_12273|>this is a screenshot of a website's login page. the page is divided into",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is",
    "\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1",
    "<|vq_clip_",
    "<",
    "<|vq_clip_",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "\ufffd 1.0.0.",
    "\u0651",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "ibe<|vq_clip_12273|>this",
    "off<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    " ",
    "<|vq_clip",
    " .. ..  .. ",
    "<",
    " \n\n``` \n\nThis is a very long",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"v\", \"w",
    "<",
    "s 0",
    " \u12f0 \u12f0 \u12f0 \u12f0 \u12f0 \u12f0 \u12f0 ",
    "<|",
    "sWith( 0.0.0.0.0.0.0.0.0.0.",
    " \u0c35\u0c41 \u0c38\u0c30\u0c38\u0c30\u0c24\u0c41 ",
    "<|vq_clip_12273|>this image displays a list of items",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is a screenshot of",
    "able<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a translation",
    " ",
    " ",
    "<",
    " 1.0.0.0.0.0.",
    "<|vq_clip_12273|>this is a screenshot of a website's login page. the page is divided into two sections, with the left side displaying a login form and the right side showing a list of user accounts. the login form has fields for",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<|vq_clip_",
    "``` \n\nThis is a very long and",
    "<|vq_clip_122",
    " 1",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates",
    "<|vq_clip_122",
    "ge \ufffd<|vq_clip_12273|>this image displays a list of items in a database",
    "<|vq_clip_12273|>this is a screenshot of a",
    " \n\nIt seems like your message got garbled or",
    "<",
    " .. ..",
    "<|vq_clip_12273|>",
    "<",
    "<|vq",
    "<",
    "<|vq_clip_122",
    " \n\nIt seems like your message got garbled or mixed",
    "<|vq_clip_12273|>this image displays a table with various data points related to the",
    "<|vq_clip_12273|>this is a",
    "<",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_",
    "<|vq_clip_12273|>this",
    " 1.0.0.0.",
    "<|vq_clip_12273|>this image displays a list of files and folders in a computer's file explorer.",
    "<|",
    "<|vq_clip_12273|>this image displays a list of items in a table",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    " ",
    "<|vq_clip_12273|",
    "<",
    " .. ..  ..  ..  ..  ..  ..",
    "<|",
    "<|vq_clip_12273|>",
    " \n\nIt seems like your message got a bit garbled. If",
    " 1.0.0.0.0.0.0.0.0.",
    "<|vq_clip_",
    "<|vq",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the code is written in a dark theme and has a line of code",
    "] ",
    "<|vq_clip_12273|>this image displays a table of data with",
    "<|vq_clip_",
    "<|vq_clip_12273|>this image displays",
    "<|vq",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    " 1.0.0.0.0.0.0",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code is displayed in a black background with white text. the script appears to be a part of a larger project, as it is written in a dark theme and contains a function that calculates the sum of two numbers. the code is displayed in a black background with white text. the script appears to be a part of a larger project, as it is written in a dark",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "come<|vq_clip_12273",
    "Controller<|",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "<|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of",
    "<",
    "<|vq_clip_",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<",
    " .. ",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column with the name \"item\" and the number \"1\". the table also includes a column for the name \"item\" and the number \"2\". the items are listed in a column with the name \"item\" and the number \"3\". the table also includes a column for the name \"item\" and the number \"4\". the image is a screenshot of a database query.",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers. the code is written in a dark theme with a black background. the function is named \"sum\" and it takes two arguments, \"a\" and \"b\". the code",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this image displays a list of items",
    "<|vq_clip_12273|>this is",
    " .. ",
    "iting 1.0.0.0.0.0.",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a",
    "able<|vq_clip_12273|>",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "or<|vq_clip",
    " \u33c2 \u33c2",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3",
    "/ .. ",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|",
    "<|",
    " 1.0.0.0",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items include \"c\", \"",
    "\ufffd 0\ufffd 0\ufffd ",
    " 1.0.0",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|",
    "<|vq",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the first",
    "\ufffd<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a",
    "ATION",
    "<|vq_clip_122",
    " ",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip",
    "<|vq_clip_12273|>this",
    "inal<|",
    "<|vq_clip_12273",
    " \ufffd\ufffd\ufffd \n\n``` \n\nThis is a very long and somewhat nonsensical output. It seems the AI got confused and produced a huge nonsense. The answer is not correct. The user asked for a short story about a cat named Whiskers who loves to",
    " \n\nIt seems",
    "<|",
    "<",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>",
    " ",
    "\ufffd 0",
    "<|vq",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation is in a language that appears to be a mix of english and hindi. the",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with",
    "<|vq_clip_12273|>",
    "> \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with a particular topic, feel free to clarify",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this",
    "<|vq_clip_122",
    "<",
    "<|vq_clip_12273|>this image displays a list of items",
    "<",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara",
    "<",
    "<|vq_clip_12273",
    "<|vq",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the first item is a \"c\" with a \"c\" and a \"c\" in the second column. the second item is a \"c\" with a \"c\" and a",
    " \ufffd<|vq_clip_12273|>this image displays",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this",
    "<|vq_clip_",
    "<|vq_clip_122",
    "Trace<|vq_clip_12273",
    "l) \n\n```\n\nIt seems like your",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is",
    " witness",
    "<|vq_clip_12273|>",
    "<",
    "<|",
    "<|vq",
    "\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    "] 0.0.",
    "<|vq_clip",
    "] \n\nIt seems like",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "<|vq_clip_12273|>this image displays a",
    " 0.0.",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code editor has a dark background with a black text and a white cursor. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code editor has a dark background with a black text and a white cursor. the script is written in a dark theme and contains a function that calculates the sum of two numbers.",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the first item is a \"c\" with a \"c\" in the second column.",
    "iven<|vq_clip_12273|>this image displays a list of items",
    "<|vq_clip_",
    "<",
    "<|vq_clip_12273|>this",
    "um<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this image displays a list of items in a database. the items are listed in a table format, with each",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_",
    "<|vq_clip_12273|>this image displays a list of items in",
    "<",
    "<|vq",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a website that provides information about the 2022-2023 season of the 2022-",
    " ",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<",
    "<",
    "\ufffd 0.0.0.0.0.0.",
    "\u0435\u043d<|vq_clip_12273|>this is a screenshot of a chat conversation between two users. the user is asking for a new user to be added to the chat",
    "<|vq_clip_12273|>this image displays a list of",
    "- ",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a code editor",
    " \ufffd<|vq_clip_12273|>this code snippet is from a python script that is used to create a new user in a database. the script",
    "\ufffd ",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273",
    "_POST \n\nIt seems like your message got garbled or mixed up with a lot",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "",
    "ach",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column, with each item having a different name and description. the first item is \"sci\", which is a",
    "<|vq_clip_12273|>this",
    " .. ..  .. ",
    "elength 1.0",
    "\u093e<|vq_clip_12273|>this image displays a list of files and folders in a directory. the files are named \"c\" and \"",
    "<|vq_clip_12273|>this image displays a list of items",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that",
    "<|vq",
    "",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column, with each item having a different name",
    "<|vq_clip_12273|>this is",
    "<|vq_clip",
    "lic<|vq",
    " \n\nIt seems like your",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape.",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person with a black and white background",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is",
    "ify<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers and returns the result. the code is written in a dark theme with a black background and white text.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to be added to the conversation. the user is also asking for a new user to be added to the conversation. the user is also",
    "<|vq_clip_12273",
    "\u0430\u0442\u044c",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the",
    "<|vq",
    "",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    " .. \ufffd\n\n[END OF CONVERSATION]",
    "<|vq_clip_12273|>this",
    "``` \n\n(Note: The above",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the items are related to the topic of \"the 10 most common questions about the 10 most common questions about the ",
    "<|vq",
    "\u00e4ri\u00e4",
    "",
    "<|vq",
    "<",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this",
    "istic",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app.",
    "\u0430\u0442\u044c",
    "<",
    "al<|vq_clip_12273|>this code snippet is from a python script that is used to create",
    "<|vq",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<|vq_clip",
    "shi",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a website's login page. the page is divided",
    "\ufffd 1\ufffd 1",
    " \n\n",
    "OT ",
    ") .. ..  .. ",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app.",
    "ive<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of",
    "ers<|vq_clip",
    "<|vq_clip",
    "er<|",
    "<|vq_clip_12273|>this",
    "",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer",
    "<|vq_clip_12273|>",
    "",
    " \n\n",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman.",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other",
    "<|vq_clip_12273|>this image displays a list of items in a table format.",
    "<|vq_clip_122",
    "<",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this image displays a list of files and folders",
    "<|vq",
    " \n\nIt seems like your message got gar",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman with a black hair. the",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "al",
    "<",
    "u 1",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is",
    "<|vq_clip_12273|>this image displays a",
    " \n\nIt seems like the text you provided is a mix of multiple languages and appears to be a random or corrupted text. If you",
    "",
    "<|vq_clip_12273|>this is a screenshot of",
    " \n\nIt seems like",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this code snippet is from a python script that is used to create a new user in a database. the code is written in a dark background with a",
    "```\n\nIt",
    "",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new message",
    " \ufffd<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this is a",
    "i",
    "```\n\nIt seems like your message got garbled or mixed",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|",
    "bal",
    "\ufffd 0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>this is a",
    "0\ufffd ",
    "<|",
    "<|vq_clip_12273|>",
    "<|",
    "<|vq",
    "<|vq_clip_12273",
    "<",
    "<|",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    " .. .. ",
    ") ",
    "<",
    "<",
    "<",
    "deo",
    "udiences \n\nIt seems",
    "<|vq_clip",
    " \n\n[conversation ends]",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a",
    "<|vq",
    "-<|",
    "<",
    "<|vq_clip_12273|>this is a screenshot of",
    "<",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user",
    "<",
    "",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a",
    "ues \ufffd<|vq_clip_12273|>this is",
    "<",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is",
    "<|vq_clip_12273|",
    "<|vq_clip_12273",
    "<",
    " ",
    "<",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_122",
    " ",
    "",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the",
    "<|vq_clip_",
    "Layout<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_",
    " 1.0.0.0.0.0",
    "<|vq",
    " 1.0.0.0",
    "\ufffd 0",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a specific question about a user named \"",
    "<|vq_clip",
    "",
    "ber<|vq_clip_12273|>",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\"",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "<",
    "zation<",
    "<|",
    "<|vq_clip_122",
    "<|",
    "",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a",
    "ances<|vq_clip_12273|>this image displays a list of items in a table",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to",
    "<|vq_clip_",
    "URE",
    "<|vq",
    "ideoright\ufffd 1.0",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the first item is \"1. 2. 3. 4. 5. 6. 7",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<",
    " \n\nIt seems like",
    " ",
    "<|vq",
    "<|vq_clip_12273|>this is",
    "<",
    "<|vq_clip_12273|>this image displays a table with",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers. the code is written in a dark theme with a black background and",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    " \n\n```",
    "Color ",
    "<",
    "indows",
    "ar",
    "ESTAMP \n\nIt seems",
    "\ufffd<|vq_clip_12273|>this image displays a",
    "ud 0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "<",
    "<|vq_clip",
    " \ufffd<|vq_clip_",
    "Module<|vq_clip_12273|>this is a",
    "<",
    " 1.0.0.0.0.0.0.0.0.0.0.0",
    " \n\n[END OF TEXT]",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    " \n\n// 1. Define the `User` struct\n// 2. Implement the `UserRepository` interface\n// 3. Create a `User",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other",
    "<",
    "<",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform",
    "<|vq_clip_12273|>this image displays a list of items in a table",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    "] \n\nIt seems like your message got garbled or mixed up with a lot of",
    "ate<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named",
    "<|vq_clip",
    "<",
    "<|vq",
    "<|vq_clip_122",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "he",
    "s<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the code is written in a dark background with a green text. the editor has a dark theme and a black background. the code is written in a",
    "<",
    "<|vq_clip",
    " .. ..  ..  ..  ..  ..  ..  .. ",
    "iv \n\nIt seems like your",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>",
    " \n\n```\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel free",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|",
    "remes<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers and returns",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "\u043d\u044b\u0439<|vq_clip_122",
    "<|",
    "<|vq_clip_12273|>",
    "er<|vq_clip_12273|>",
    "n<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this image displays a list of files and folders in a computer's file explorer. the files",
    "<|",
    "<|vq_clip_12273|>this image displays a list of",
    "<|",
    "<|vq_clip",
    "ividual",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections, with the left side showing a list of products and the right side",
    "<|vq_clip_12273|>this image displays a list of items in a database. the items are listed in a table format, with each item having a unique name and description. the table is divided into two columns, with the first column containing the name of",
    "<|vq_clip_12273|>this is a",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to be added to the conversation. the",
    "<",
    " 1.0.0.0.0.",
    "<|vq_clip_12273|>this",
    "<",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|",
    "\u043a\u0438\u0435 \n\n[conversation ends",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections, one for the product and the other for the product's details. the product is a 1.5g 1.5g 1.5g 1",
    " 1.0.0.0.0.0.",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"print",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a specific question about a user named \"s\" and the user is responding with a question about the user \"s\". the user is also asking for a specific question about the user \"s\" and the user is responding with a question about the user \"s\". the conversation appears to be in a casual tone, with the user asking for a specific question about the user \"s\". the user is also asking for a specific question about the user \"s\".",
    " \n\n[END OF CONVERS",
    "ArgsConstructor<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"print('hello world')\". the code editor has a dark background with a black text editor. the script is written",
    "apings)",
    "<|vq_12273|>",
    "CTICAL<",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<|",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this image displays a list",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a response",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    "<|vq_clip_12273|>this image displays a list of items in a table format.",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"item\",",
    "<|vq",
    "<|vq_clip_122",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd ",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0",
    "<|vq_clip_12273|>",
    "ian<|",
    "<|vq_clip_12273|>this",
    " \n\nIt seems the output got garbled. Let's re-run",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is",
    "<",
    "<|vq_clip_122",
    " \n\nIt seems like your message got garbled or",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the code is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a code editor",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help",
    " \n\nIt seems like there was a mistake in the input. Could you please provide the correct text or clarify your",
    "<|vq_clip_12273|>",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    "<|vq_clip_12273|>this",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the",
    " 1.0.0.0",
    "<|vq_clip_",
    "",
    "<|",
    "ical 1.0.0",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip",
    "<|vq_clip_12273|>this",
    "<|vq_clip",
    "w<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot",
    "<",
    " 1.0.",
    " 1.0.0.0.0.0.0.",
    " 1.0.",
    "<|vq_clip_12273|>",
    "<",
    ") ",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers and returns the result",
    "<",
    "",
    "INT",
    "<|vq_clip_12273|",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers.",
    " 1.0.0.0.0.",
    "",
    "<|vq_clip_12273|>",
    "ar<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip_12273",
    " \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "",
    "<|vq_clip_12273|>",
    "<",
    "",
    "<|vq_clip_122",
    "<|vq_clip_",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a person named \"sara\" and the other user is responding",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq_clip_12273|>this image displays a list of",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black background. the code editor displays a python script that is",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a ",
    "<|vq_clip",
    " \u33c2 \u33c2 \u33c2 \u33c2 \u33c2 \u33c2 \u33c2 ",
    "<|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to be added to the conversation. the user is also asking for a new user to be added",
    "ate \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>this image displays a list of items in a table",
    "ime<|vq_clip_12273",
    "en<|vq_clip_12273|",
    " ",
    "<|",
    " ",
    "<|vq_clip",
    " \n\n",
    "<|vq_clip_",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "ins<|vq_clip_12273|>this image displays a list of files and folders in a directory. the files are named \"c:\\users\\michael\\documents\\c:\\users\\m",
    "<|vq_clip_12273|>this is a screenshot of a chat conversation between two",
    "<|vq",
    "ed<|vq_clip",
    "<|",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the items are labeled as \"1\", \"2\",",
    "<|vq_clip_12273|>this image displays a list of files and folders in a",
    "k<|vq_clip_12273|>this is a screenshot of a",
    "",
    " \n\nIt seems like your message got",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black background. the code editor is displaying a python script that is",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person who is a friend of the user",
    "<|vq_clip_122",
    "<|vq",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person who is a friend of the user. the user is also asking for a photo of a person who is a friend of the user. the user is also asking for a photo of",
    "<|vq_clip_12273|>this is",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot",
    "```\n\nIt seems like your message got gar",
    "us<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    "\ufffd ",
    " 0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel free to ask!\n\nIt",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this image displays a list of items in a shopping",
    "<",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"c\", \"d\", \"e\",",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the",
    "<",
    "<|vq_clip_12273|>",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the first item is \"1. 2. 3. 4",
    "ING<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers and returns the result. the code is written in a dark theme with a black background and white text. the function is called \"sum\" and it takes two arguments, \"a\" and \"b\". the code is written in a clean and organized manner, with the function name and the arguments clearly visible.",
    "<",
    "<",
    "\ufffd 1\ufffd 2\ufffd 3\ufffd 4\ufffd 5\ufffd 6",
    "<|",
    "ane<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip",
    "<",
    "<",
    "",
    "\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1",
    "<|vq_clip_12273|>",
    "where<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "Null",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to be added to the conversation. the user is also asking for a new user to be added to the conversation. the user is also asking for a new user to be added to the conversation. the user is also",
    "<",
    "wise<|",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include",
    "\ufffd<|",
    "Size<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    " 2019 2018 2017 2016 2015 2014",
    "<|vq",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "<|vq_clip_12273|>",
    "ic<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black background. the code",
    "<|vq_clip_12273|>this is a",
    "<|",
    "\u09be<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme",
    "<|vq_clip_12273|>this is a screenshot of",
    "Bar \n\n```\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text.",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>",
    " ",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>",
    "<|",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273",
    "hops<|vq_clip",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a",
    "ang<|vq_clip_12273|>this image displays a list of items in a",
    "<|vq_clip_12273|>this is a",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black background. the code appears to",
    " 1.0.",
    "s<|vq_clip",
    "other \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "ning<|vq_clip_122",
    "<|vq_clip_12273|>",
    "<",
    " ",
    "s \ufffd ..",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this is a screenshot of",
    "<",
    "Exception<|vq",
    " .. \ufffd \ufffd \ufffd ",
    "\u0a47<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a list of files and folders in a computer",
    "<|vq",
    "<|",
    "<|vq_clip_12273|>this image displays a list of items in a",
    "<|vq",
    "<",
    "<|vq_clip_12273|>this image displays a list of items",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the",
    "\u09be",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0",
    "<",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<|vq_clip",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<",
    "assen<|vq_clip_12273|>this is a",
    "<",
    "ither",
    "<|vq_clip_12273|>this image displays a list of items in a database.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "\ufffd<|vq_clip_12273|>this image displays a list of items",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot of a code editor",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections, with the left side showing a list of products and the right side showing a list of products. the",
    " \n\nIt seems",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0",
    "ohnson<|vq_clip_12273",
    "<|vq_clip_12273|",
    ">_MIDDLEWARE<|vq_clip_12273|>this code snippet is from",
    "<|vq_clip_12273|>this is a screenshot of",
    "scure<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed",
    "<|vq_clip_12273|>this is a screenshot of a website's login page.",
    "S<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user",
    "<",
    "<|vq_clip_12273|>this image displays",
    "",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections, with the left side showing a list of products and the right side showing a list of products.",
    "<|vq_clip_12273|>",
    "<",
    " ",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer",
    "uditor \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "",
    "<|vq",
    "",
    "<",
    " \u0aae\u0ac1 \ufffd \ufffd  ",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    " 1.0",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this image displays a list of items in a table format.",
    "<|vq_clip_12273",
    " `\n\n",
    "<|vq_clip_12273|>this image displays a list of files and folders in a computer's file explorer. the files are organized in a hierarchical structure, with the main",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0",
    " ",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>",
    "OfRows) <|",
    "",
    "<|vq_clip_12273|",
    "ine<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    " ",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black background",
    "<|vq_clip_12273|>this is a",
    " ",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    "en<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this code snippet is from a python script that is used to create a new user in a database.",
    "<|vq_clip_12273|",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    "ant",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "<|vq",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq_clip_12273|>this is a",
    "<|vq",
    " witnesses \u0c35\u0c41 4 \ufffd 3 ",
    " ",
    "at",
    "<|vq_clip_12273|>this",
    "<|vq_clip_",
    "<|vq",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is",
    "<|vq_clip_12273|>this image displays a list of options for a user",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a code to be",
    "<",
    "<|",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the first item is",
    " 0",
    "<|vq_clip_12273|>this image displays a",
    " \u0c2c",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"v\", \"w\", \"x\",",
    " ",
    "<|vq_clip_12273|>this code snippet is from a python script that is used to create a new user in a database. the script is written in python and the code is displayed in a terminal window. the user is named \"user\" and the script is used to",
    "",
    "\ufffd<|vq_clip_12273|>",
    "LOADS<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<|",
    "<|vq_clip_12273|>",
    "..............\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. Could you clarify or re",
    "<",
    "<|vq_clip_122",
    "<",
    "<",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "im<|vq_clip_",
    "<|vq_clip_",
    " 1.",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq_clip_12273|>",
    "<|vq",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a screenshot of a conversation about a user named \"sarah\" who is asking for a screenshot",
    "\n\nThe conversation is extremely long and garbled. The user asked: \"I want to create",
    "\ufffd 1",
    "<|vq",
    "\ufffd 1",
    "<|vq",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|",
    "In<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "<|vq_clip_12273|>this is a screenshot of a website's login page. the page has a dark background with a white text box in the center. the text box contains a login form with fields for username and",
    "<|vq_clip_12273|>this image",
    "<|",
    "<|vq_clip_",
    "",
    "ac<|vq_clip",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "assistantIt seems like your",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_",
    "<",
    "<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the items are arranged in a grid, with each item having a different color and shape. the first item is a",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a ",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers.",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_122",
    "ations<|",
    "<|vq_clip_12273|",
    "bar<|vq_clip_12273|>this image",
    "encetion<|vq_clip_12273|>",
    " \n\nIt seems like there was a mistake in the input. Could you please clarify or provide the correct information?\n\nIt looks like there was a mix-up in the text. If you",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "List<|vq_clip_12273",
    "<|",
    "<|vq_clip_12273|>this image displays a list of items in a database. the items",
    "<|",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<",
    "\ufffd 0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<",
    " 0.0.0.0.0.0.0.0.0.0.0.0.",
    "<|",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers. it has a variable named \"",
    " 1.",
    "<|vq_clip_12273|>this image",
    " ",
    "",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a",
    "<|vq_clip",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is",
    "<|vq_clip_12273|>this is a screenshot of a website that provides information about the 2022-202",
    " ",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape.",
    "<|vq_clip_12273|>this is a screenshot of",
    "\u05d1<|vq_clip",
    "<",
    "\ufffd 0\ufffd 0\ufffd 0",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273",
    " \n\n```\n\nIt seems like your message got garbled or mixed up with a lot of unrelated",
    "<",
    "umerical",
    "<|vq_clip_12273|>this code snippet is from a python program that displays a list of items in a table. the code is written",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\"",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    " 0.0.0.0.0.0.0.0.",
    "<|vq_12273|>",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart.",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    "<|vq",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "ial<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a",
    " \n\nIt looks like your",
    "ning<|vq_clip_",
    "\n\nIt seems the output is garbled due to some random text. The code is not correct. I think the code got corrupted. Let's reimplement the solve",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the items are arranged in",
    "",
    " ",
    "avascript<|vq_clip_12273|>",
    "<|",
    ">\n\nIt seems like your message got gar",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column, with each item having a unique name and a description. the table appears to be a part of a larger database",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<|vq_clip_12273|",
    "<",
    "s",
    "<|vq_clip_12273|>",
    " ",
    " 1.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>this is a screenshot",
    "<",
    " \n\nIt seems like your",
    "<|vq_clip_12273",
    "<",
    "<|vq",
    " \ufffd \ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>this image",
    "<|",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black background. the code is displayed in a monospaced font and is surrounded",
    " 1.0.0\"\n\nIt seems like your message got garbled or mixed up with a",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "Box<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the",
    "<|",
    "<|vq_clip_12273|>this is",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0",
    "<|vq_clip_12273",
    " ",
    "<|vq",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd ",
    "ECTOR<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|>this is a screenshot of a chat conversation between two users. the user is",
    "<|vq_clip_12273|>this image displays a",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a code",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_122",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this image displays a list of items in a database. the",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "ocation",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app.",
    "<|vq_clip_12284|>this is a",
    "<|vq_clip_12273|>this",
    "|vq_clip_12273|>this",
    "<",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|",
    "<|vq_clip_12273|>this is a screenshot",
    " \n\nIt seems like there was a mistake in the input. Could you please provide the correct text or clarify",
    "<|vq_clip",
    "<",
    "<|",
    "<|vq",
    "<",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>",
    "in<|vq_clip_12273|>this image displays a list of files and folders in a directory. the files are named \"c\" and \"c\" and are located in the \"c\" folder. the files are listed in a table format with columns for file name, size, and date. the background of the image",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers. the function is written in python and the code editor is in a dark theme. the script is a part of a",
    "ed 1.0.0.0.0.0.",
    "<|vq_clip_",
    " 1.0.0.",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo",
    "<|vq",
    " \ufffd<|vq_clip_12273|>",
    "<|vq_clip_12273|>this",
    " \n\n```\n\nIt seems like your message got garbled or mixed up",
    "<|vq_clip_",
    "assistantI apologize for the confusion earlier. Let's focus on the problem at hand.\n\nWe need to find the number of ways to choose a subset of the set {1, 2, ..., n} such that the sum of the elements in the subset is divisible by 3. The answer",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is",
    " ",
    " \ufffd \ufffd  \ufffd  \ufffd  \ufffd  \ufffd  \ufffd  \ufffd  \ufffd ",
    "",
    "k<|vq_clip_12273|>this image displays a list of",
    "<|vq_clip_12273|>",
    "<|",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform",
    "<|vq_clip_12273|>this",
    "",
    "ordinates<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"item 1\", \"item 2\",",
    "<|vq_clip_",
    "<|vq",
    "ed<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a code to be",
    "\ufffd 0\ufffd 0",
    " ",
    "<|vq",
    "<|vq_clip_12273|>this image displays a list of 10 items",
    "<",
    "<",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in",
    "<|",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of items. the items are displayed in a grid format with a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers and returns the result. the code is written in a dark theme with a black background and white text.",
    "<|vq_clip_",
    "\n\nIt seems like your message got garbled or mixed up with",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "ted<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<|vq_clip_",
    "<",
    "<",
    "ated",
    "<|vq_clip_12273|>",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>this image displays a list of 10 items that are being used in a project. the items are labeled as \"1. 2. 3. 4. 5. ",
    "",
    "<|vq_clip_12273|>",
    "<",
    "<",
    "\u09be<",
    "<",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a",
    "back",
    "<|vq_clip_12273|>this code snippet is from a",
    "thic<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman.",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with a particular topic, feel free",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color",
    "<|vq_clip_12273",
    "    # 2. Find the maximum number of consecutive 1s in the binary string\n    max_consecutive_ones = 0\n    current_consecutive_ones = 0\n    \n    for bit in binary_string:\n        if bit == '1':\n            current_consecutive_ones += 1\n            max_consecutive",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>",
    "<|vq",
    "ijani<|vq_clip_12273|>",
    "<|vq_clip_",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a",
    " \ufffd<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3",
    "lar<|vq_clip_12273|>this image displays a list of items",
    "<|vq_clip_12273",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates",
    "/ .. ..  ..  ..  ..  ..  .. ",
    "<|vq",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|>this",
    "ow 1",
    "Length<|vq_clip_",
    "<|vq_clip_12273|>this is a",
    " \n\nIt seems like your message got garbled or mixed up with a lot of",
    ";|vq_clip_122",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform.",
    "<|vq_clip_122",
    "<|vq",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the first item is a \"s\" with a \"s\" in",
    "ed",
    "<|vq",
    " ",
    "<|vq_clip_12273|>this image displays a list of 10",
    " \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", and \"a\". each item has a different color and a different shape. the",
    " \n\nIt seems like the text you provided is a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape.",
    "heory<",
    "<|vq_clip_12273|>this",
    "<|vq_clip_",
    "arde<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and",
    " .. .. ",
    "<|",
    "\u0438\u0447\u0435\u043d<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that",
    "Up<|vq_clip_12273|>this image displays a list of 10 items in",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "as<|vq_clip_12273|>this is a screenshot of a conversation between",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    " \n\n",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this image",
    " \n\nIt seems like the text you provided is a mix of multiple languages and appears to be a random or corrupted text. It doesn't seem to be a coherent or meaningful passage. If you have a specific question or if",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code is displayed in a terminal window with a",
    "<|vq_clip_12273|>this image displays a list of items in a database. the items are listed in a table format, with each item having a unique name and",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman with a black hair. the user is also asking for a photo of a person named \"sara\" and the other user is responding with a",
    "<",
    "<",
    " \n\nIt seems like there was a mistake in the input. Could you please provide the correct text or",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "<|vq_clip_12273",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a",
    "u\n\n",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the",
    "<|vq_clip_12273|>this is a",
    "INATION<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this image displays a list of",
    "<",
    "<|vq_clip_12273",
    " .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  .. ",
    " \n\nIt seems like there was a mix-up in the text. If you have a specific question or need",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column with a header that reads",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this code",
    "<|vq_clip_12273|",
    "pl 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"item 1\", \"item 2\", \"item 3\", and \"item 4\". each item has a unique",
    "<|vq_clip_12273|>this image displays a list of items",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the",
    " 1.0.0.0.0.0.",
    "nesses<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a translation of a phrase in a different language. the user is also asking for a translation of a phrase in a different language. the",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot of a website that provides information about a specific product. the website is in ind",
    " \n\nIt seems the output got garbled. Let's just re",
    " 1.0.0.0.0.0.0",
    "<",
    " 1.0.0",
    "i\u00f3n<|vq_clip_12273",
    "\")<|vq_clip_122",
    "<|vq_clip_",
    "<",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this image displays a list of items in a database. the items are listed in a table format, with",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<",
    "<",
    "",
    "<|vq_clip_12273|>this is a screenshot",
    "<",
    "[END OF CONVERSATION]",
    "<|",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\",",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    "<|vq_clip_12273|>this image displays a list of items in a",
    "",
    "<|vq_clip_12273|>this is",
    "cents<|vq_clip_12273",
    " 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a specific question",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>",
    "<",
    "<",
    "OfRowsInSection<|vq_clip_122",
    "ed \n\nIt looks like your message got garbled or mixed up with",
    "ifference<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the code is written",
    "<|vq_clip_12273",
    "<",
    "<|vq_clip_12273|>this image displays a",
    "<|",
    "in \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel free to clarify or ask again!\n\nIt looks like your message got a bit mixed up. If you have a specific question or",
    "<|vq_clip_12273",
    "ed<|vq_clip_12273|>this",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"",
    "<",
    "<|vq_clip",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column, with each item having a unique name and a description. the table appears to",
    "<|vq_clip_122",
    "al<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in",
    " \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this",
    "<|vq",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other",
    "<|vq_clip_12273",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel free to clarify or ask again! I'm here to help.\n\nIt looks like your message got a bit mixed up. If",
    "\ufffd 1\ufffd 1\ufffd 1\ufffd 1",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_12273|>this is a screenshot of a",
    " ",
    "<|vq_clip_",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the first item is a \"c\" with a \"c\" and \"c\" in the second column",
    "<|vq_clip_12273|>this image displays",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a",
    " 1.0.0.",
    "re<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation appears to be in a language that is not familiar to the user. the user is asking for a photo of a person named \"sara",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app.",
    " ",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark",
    " .. ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a person named \"sara\". the conversation is in a language that",
    "<|vq_clip_12273",
    "<",
    "View\ufffd 0\ufffd 1\ufffd 2\ufffd 3\ufffd 4\ufffd ",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot",
    "al ",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape.",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"print('hello world')\". the code editor has a dark background and",
    "<|vq_clip_12273|>",
    " \n\nIt seems like",
    "onic<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273|",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of",
    "<|vq",
    "<",
    "<",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    " \n\nIt seems like your message got garbled or mixed up with a",
    "<|vq_clip_122",
    "<|vq_clip_12273|",
    "que",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation",
    "re",
    "ers<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", and \"a\". each item has a different color and is arranged in a grid. the table appears to be a part of a larger",
    " ",
    " ",
    "",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written",
    "<|vq_clip_12273|>this code snippet is from a python script",
    "<",
    "<|vq_clip_12273|>",
    "<",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    "<|vq_clip_",
    "<|vq_clip_12273|",
    "<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of items in",
    "<|",
    "<",
    "<",
    "<",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and",
    " \n\nIt seems like your message got garbled or mixed up with a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the function is called \"sum\" and it takes two arguments, \"a\" and \"b\". the script also contains a",
    "<|vq_clip_12273",
    "al<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|",
    "<|",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column, with each item having a different name and description. the table also includes a column for the name of the",
    "<|vq_clip",
    "<|vq",
    "<",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_12273",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq_clip_12273|>this image displays a list of files and folders",
    "<|",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to be added to the conversation. the user is also asking for a",
    "ally",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to",
    " 0.0.0.0.0.0.",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the function is",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<|vq_clip_12273|",
    "<|vq",
    "S<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the code is written in a dark background with a white text. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in",
    ". witness",
    "<|vq_clip_12273|>this",
    "ergency \n\nIt seems like the text you provided is a mix of multiple languages and appears",
    "<|vq_clip",
    "<|vq_clip_",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column with the name \"item\" and the quantity",
    " \ufffd\ufffd<|vq_clip",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a website that offers a free trial for a product called \"screencast\". the website is in indonesian language and the user is able to sign up for the trial. the website also offers a free trial for the product. the",
    "<|",
    "ated",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|",
    "n<|vq_clip_12273|>this code snippet is from a python script that is used to create a",
    "<|vq_clip_12273|>this is a screenshot",
    " ",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    " ",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is",
    "<|vq_clip_12273|>",
    "\ufffd<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    " 1",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    "ing<|vq_clip_12273|>this is a screenshot of a conversation",
    "prisingly<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a specific question about a",
    " \n\nIt seems like your message",
    "<|vq_clip_122",
    "ons<|vq_clip_12273|>this image displays a list of items in a table format. the",
    "ively \n\nIt seems like your message got",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a person named \"sara\" and the",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq_clip_12273|",
    "<|vq_clip_",
    " \n\n",
    "",
    "<|vq_clip_12273|>",
    "Key<|vq_clip_12273|>",
    "\ufffd<|vq_clip",
    "<|vq_clip_12273",
    "<|vq_clip",
    "<|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person who is a friend of the user. the user is",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user",
    "<|vq_clip_12273",
    "<|vq_clip_",
    "```\n\nIt looks like your message got garbled or mixed up with",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|",
    "<|vq_clip_122",
    "<|vq",
    " \u12e8<|vq_clip_",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections, with the left side showing a list of products and",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<|vq",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is",
    " ",
    "<|",
    "d",
    "<|vq_clip_12273|>this is a screenshot",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question",
    "<|",
    "<|vq_clip_12273|>this image displays",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<",
    "s<|vq_clip_12273|>this image displays a list of items in a table format. the",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a unique name and description. the first item is \"the 10th",
    "s<|vq_clip_12273|>",
    "<",
    " ",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_12273|>",
    "<",
    "ter<|vq",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a",
    "<|vq",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>",
    "Type<|vq_clip_12273|>this is",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip",
    "<",
    "<|vq_clip_12273|>this image displays a list of items",
    "<|vq_clip_12273|>this is a screenshot of a website's login page. the",
    "uluma \n\n[END OF CONVERSATION]",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated",
    "<",
    "<|vq",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items",
    "<|vq",
    "<|vq_clip_12273|>this image displays a list of",
    " ",
    "<|",
    "Hub",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"item ",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections, one for the product and the other for the product's details. the product section shows a list of products with their respective prices and descriptions. the product details section shows a list of products with their prices and details. the page also has a button to add a product to the cart. the website appears to be a part of a larger e-commerce",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a",
    "<|vq_clip_12273|>",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections",
    "~~~~~~~~~~\n```\n\nIt looks like your message got garbled or mixed up with",
    "```\n\nIt looks like your message got garbled or corrupted",
    " 1.0.0.0.0.0.0",
    "<|vq_clip_12273|>",
    "\ufffd ",
    "<|vq_clip_",
    "<|vq_clip_12273",
    "ing<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written",
    "<|vq_clip_12273|",
    "<",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|",
    "ITAL<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_",
    "ning<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq_clip_12273",
    "<|vq_clip_12273",
    "l<|vq_clip_12273|>this is a screenshot of a code editor",
    "s 1.0.0.0.0.",
    "<|",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the first item",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "  1. **\"The Great Gatsby\"**",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a website",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    " \u3299",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of",
    " 1.0.0.0.0.0.0.0.",
    "\ufffd<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d",
    "<|vq",
    "ed<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two",
    " ",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>this image displays a list of files and",
    "<|vq_clip_12273|>",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<|vq_clip_12273",
    "<",
    "ING",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "<|",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of",
    "ed<|vq_clip_12273|>",
    "<|",
    "",
    "<|vq_clip_12273|",
    "is<|vq",
    "```\n\nIt seems like your message got",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the first item is",
    "hmer<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking",
    "achte<",
    " \n\n// 1. 2. 3. 4. 5. 6. 7. 8. ",
    "\u0440<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<|vq_clip_12273|>",
    "\ufffd<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|>this code snippet is from a",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in",
    " \n\nIt seems",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this",
    "s<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the",
    "\ufffd<",
    "<|vq_clip_12273|>this",
    "<|vq",
    "' ",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is",
    " ",
    " \n\nIt seems",
    "ac",
    "<|vq_clip_12273|",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with",
    "<|vq_clip_12273|>",
    "el<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman named \"sara",
    "<",
    "re 2.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written",
    "<",
    "<",
    "<|vq_clip_12273|>this is a screenshot of",
    " \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "ACH",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers and returns the result. the code is written in a dark theme with a black background and white text",
    "\ufffd<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of files and folders in a directory. the files are named \"c\", \"c\",",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a unique name and description. the first item is \"the",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>",
    "\u0c41<|vq",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections, one for the product and the other for the product's",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include",
    "<|vq_clip_12273|>this is",
    "ilarities<|",
    "",
    "<|vq_clip_12273",
    "<|vq_clip_12273|",
    "ure<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app.",
    "ed<",
    "<|vq_clip_12273|>this image",
    "  1. **",
    "ulation<|vq",
    "<",
    "<|",
    "\u043d<|vq_clip_12273|>this image displays a list of items in a table format. the first column shows the name of the item, followed by the number of items in the list. the second column shows the number of items in the list.",
    "<",
    "<|",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding",
    "<|vq_clip_12273|>this code snippet",
    " \n\nIt",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the items are labeled as \"1\", \"2\", \"3\", \"4",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq_clip_12273|>",
    "<",
    " ",
    "<|vq_clip_12273|>this is",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape.",
    "<|vq_clip_12273|>this image displays a list",
    " ",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>",
    "<",
    "<",
    "<",
    " ",
    "<|vq",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_",
    "S<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<|vq_clip_12273|",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a website that provides information about the 2022-2023 season of the 2022",
    " \n\n[END",
    "aloniki ",
    "<|vq_clip_12273|>",
    "<|",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<",
    "S<|vq_clip_12273|>this",
    "<|vq_clip",
    "s<|vq_clip_",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that",
    "<|vq_clip",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "```",
    "rier<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of",
    "<|vq_clip_",
    "<|vq_clip_",
    "<|vq_clip_122",
    "ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. Could you clarify or rephrase what you need help with? I'm here to assist!\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. Could you clarify or re",
    "<|vq_clip_122",
    "<|vq_clip_",
    " ",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "<|vq_clip_",
    "<|vq",
    "<",
    "",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<",
    "<|vq_clip_12273",
    "\u0442<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>",
    "e",
    "<",
    "\u0442<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq",
    "<|vq_clip_12273|>this",
    "```",
    " 1.0.0.0.0.",
    "<|vq_clip_12273|>this is a",
    " \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<|vq_clip_12273|>this image displays a table with various",
    "\u043d<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme with a black background. the code appears to be a function that calculates the sum",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    "<",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    "<|",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart.",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>",
    " \n\nIt seems like the text you provided is a mix of multiple languages and appears to be a random or",
    "\ufe0f<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_122",
    "ic<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"",
    "ing<|vq",
    " \ufffd<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|",
    "ures<|vq_clip",
    "  0 0 0 0 0 0 0 0 ",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|",
    "<|vq_clip_12273|>this is a screenshot",
    "<|",
    "<|vq",
    "<|vq_clip_12273|>this image",
    "<",
    "ular<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_12273|>",
    "ig",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    "orization<|vq_clip",
    "<|vq_clip_",
    "<",
    "<|vq_clip",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip_12273|",
    "<|vq_clip_122",
    " 1.0.0",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd ",
    "<|vq",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq_clip_12273|>this",
    "PARE \n\nIt seems like your message got garbled or",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform",
    "ol<|vq_clip_12273|>",
    "\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1",
    "<|vq_clip_12273|>this is a screenshot of a website that",
    "<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d",
    "<|vq_clip_122",
    "<|",
    " \n\nIt seems like",
    "<|vq_clip_12273|>",
    " ",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    "\u0c3f",
    "<",
    "",
    "<|vq_clip_12273|>this image displays a list of items in a database. the items are listed in a table format, with each item having a unique name and description. the items are organized by their respective categories, such as",
    "<|vq_clip_12273|>this is a screenshot of a website",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the",
    "<",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a response to",
    "a \n\nIt seems like the text you provided is a mix of multiple languages and",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code is displayed in a black background with white text.",
    "",
    " \n\nIt",
    "? \n\nIt",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|vq_clip_12273|>",
    "<",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation appears to be in a language that",
    " \n\n[END OF CONVERSATION]",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart",
    "<|vq_clip_12273|>this is a screenshot",
    "<|",
    "\ufffd 1\ufffd 2\ufffd 3",
    "<|vq_clip_12273|>",
    "a<|",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column, with each",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this image displays a list of 10 items",
    "<",
    " \n\n**Answer**: The `-` operator is a binary operator that subtracts the second operand from",
    "<|vq_clip_12273|>this image displays a list of items in a database. the items are listed in a table format, with each item having a unique identifier. the first item is",
    "<|vq_clip_12273|>this is a screenshot",
    "', '\n\n",
    "<|vq_clip_12273|>this image displays a list of",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a",
    "us ",
    " ",
    "<|vq_clip_12273",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation is in a language that appears to be a mix of english and hindi.",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme",
    "<|vq_clip_122",
    "<",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform.",
    "<",
    " 1.0.0.0.0.0.0.0.0.0",
    "\ufffd<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a single line of code that says \"print('hello world')\". the code editor has a dark background and a white text. the script is written in a dark theme",
    "<|vq_clip",
    " 1.0\ufffd 1.0\ufffd ",
    "<|vq_clip_12273",
    " ",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items in a database. the items are listed in a table format, with each item having a unique name and description. the items are organized by their respective categories, such as \"",
    "ssues ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a translation of a phrase in a different language. the user is also asking for a translation of a phrase in a different language. the user is also asking for a translation of a phrase in a different language. the user is also asking",
    " 0.0.0.0.0.0.",
    "",
    " ",
    "",
    "\u09be<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "",
    "<",
    "<",
    "<|vq_clip",
    "<",
    "<|vq_clip",
    "\ufffd<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this code snippet",
    "<",
    "<|vq_clip_12273|>this",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "\" .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..",
    "<|vq_clip_12273|>this is a screenshot of a",
    "per<|vq_clip_12273|>",
    " \ufffd\ufffd\ufffd ",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a website's login page. the page has a dark background with a white text box in the center",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|",
    "<",
    "<|vq_clip_122",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    "eyboard<",
    "<|vq_clip_12273|>this is",
    " 1.0.0.",
    " 1.0.0.0.0.0.0.0.0.0.0.0",
    "",
    "<|vq_clip_12273|>this is",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0",
    "<|vq",
    "```\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with a particular topic, feel free to ask!\n\nIt looks like your message got mixed up with a lot of unrelated text",
    "<|vq_clip_122",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    " ",
    "<",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "<|vq_clip_12273|",
    "<",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is a",
    "<",
    "<|vq_clip_",
    " \n\nIt seems like there",
    "<|vq_clip_12273|",
    " 1.",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "<",
    "<|vq_clip_12273",
    "<|vq_clip",
    " \n\n```\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "\u043d\u0438\u0439<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer,",
    "<|vq_clip_12273",
    "```\n\nIt",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code is displayed in a black background with a white text. the script is",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a screenshot of a",
    "\ufffd<|vq_clip_12273|>this is a screenshot of a conversation",
    "ed 1.0",
    "<|vq_clip_12273|>",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with a particular topic, feel free",
    "<|vq_clip_12273|>",
    "32<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named",
    "<|vq_clip_",
    "<|vq_clip_",
    "<|vq",
    "ements<|vq",
    " \n\nIt seems like the text you provided is a mix",
    "./:;<=>?@[\\]^_`{|}~\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text",
    " 0\ufffd 0",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column with the title \"item\" and the second column",
    "its<|vq_clip_12273|",
    "<|vq",
    "ce",
    "<|vq_clip_12273|>this is a screenshot",
    "<|",
    "<|vq_clip_12273|>this is",
    "<",
    "ro<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of",
    "IATION<|vq",
    "ewelry<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12286|>this is a screenshot of a website that displays a list of products",
    "<",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function",
    "<|vq_clip_",
    "<",
    "<|vq",
    "<|vq_clip_12273",
    "```",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a translation of a phrase in a different language",
    "<|",
    "<|vq",
    "By<|vq_clip_12273|",
    "<|",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the first",
    "<|vq",
    "<|",
    "ceptions'",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"print('hello world')\". the code editor also has a terminal window with a command prompt. the terminal window shows the command \"python3",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_122",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a",
    "<",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is",
    " witnesses ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a code to be added to a",
    "ELY<|vq_clip",
    " 1.0.0",
    "<|vq_clip_12273|>this",
    " ",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code is displayed in a black background with",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code editor has a dark background and the text is displayed in a light blue color. the script appears to be a part of a larger project, as it is written in a dark theme and the text is displayed in a light blue color. the code editor has a dark background and the text is displayed in",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum",
    "jects<|",
    "<|vq_clip_12273|>this",
    "<|vq_clip_122",
    "ation<|vq_clip",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|",
    "<",
    "<|vq_clip",
    "<|vq_clip_",
    "\ufffd ",
    "er 0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user",
    "<|vq_clip_",
    " ",
    "\ufffd 1\ufffd 1",
    " 0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_",
    "String",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation is in a language that appears",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"item 1\", \"item 2",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is",
    "<|vq_clip",
    "<|",
    "<",
    " ..",
    "<|vq_clip",
    " ",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"item",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections,",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_",
    "<|vq_clip_122",
    "\ufffd<|vq",
    "upplementary 1.0.0.",
    "<|vq",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"s",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    " \n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you",
    "<|vq_clip_",
    "\u0107<|vq_clip_12273|>this is a screenshot",
    "\ufffd 1.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>this code snippet is from a python script that is used to create a new",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the",
    "k<|vq_clip_12273|>this image displays a list of",
    " 0\ufffd 0\ufffd 0",
    " \n\n",
    "<|vq_clip_12273|>this image displays a list of 10 items in",
    "",
    "\n\n",
    "<|vq_clip_12273|>this image displays a",
    " ",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this",
    "s<|vq_clip_12273|>",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "",
    "S<|vq",
    "<",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d",
    "<|vq_clip_12273",
    "<|",
    "<|vq_clip_12273|>",
    " \n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with a particular topic, feel free to ask! I'm here to help.\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|",
    "ORARY<|vq_clip_12273|>this is a screenshot of a conversation between two",
    " .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person who is",
    " \n\nIt seems like your message",
    "<",
    "<|vq_clip",
    "ion",
    "<|vq_clip_12273",
    "<",
    "in<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    " 1.0.0",
    "<|vq_clip_12273|",
    "> \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have",
    "<|vq_clip_12273|>this image displays a list of 10 items",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "",
    "<|vq_clip",
    "<|vq_clip_122",
    "<|",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this code snippet is from a python script",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "aciones<|vq_clip_12273|>this image displays a list of 10 items in",
    "<|vq",
    "den<|vq_clip_12273|>this image displays",
    " .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..",
    "iven",
    "<|vq",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    " \n\nIt seems like your message got garbled or mixed up with",
    "<|vq_clip_12273|",
    "ar<|vq_clip_12273|",
    "<|vq_clip_12273|>this image displays a list of 10 items in",
    " .. ..  ..  ..  .. ",
    "<|vq_clip_12273|>",
    " ",
    "\ufffd 1\ufffd 2\ufffd 3\ufffd 4\ufffd 5\ufffd 6\ufffd 7\ufffd 8\ufffd 9\ufffd 10\ufffd 11\ufffd 12\ufffd 13",
    "\n\n```",
    " ",
    "zenia<|vq_clip_12273|>this image displays a list of 10 items",
    "<|vq_clip_12273|>this image displays a list of files and folders in a computer's file explorer. the",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_",
    "ing 2019\ufffd<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer,",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<|vq",
    "<|vq_clip_12273",
    "\u043e\u0440",
    "ant<|vq_clip_122",
    " ... ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  .. ",
    "<|vq",
    "64<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections, one",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a",
    "ures 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a person named \"",
    " .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers",
    "    // 1. \u8bfb\u53d6\u6587\u4ef6\n    // 2. \u89e3\u6790\u6587\u4ef6\n    // 3. \u751f\u6210\u4ee3\u7801\n    // 4. \u8f93\u51fa\u6587\u4ef6\n    // 5",
    "<|vq_clip_",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of",
    " \n\nIt seems like",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in",
    "<|vq_clip_12273|>",
    " \ufffd<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written",
    "<|vq_clip_12273|>this image",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd ",
    " \n\n```\n\nIt seems like there's a mix of different languages and possibly some unrelated",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app.",
    "<|vq_clip_12273",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column with the name \"item\" and the quantity \"",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"v\", \"w\", \"x",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman with a black hair. the conversation is",
    "<|vq_clip_12273|>this image displays a list of items",
    " .. ..  ..  ..  ..  ..  ..  ..",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|",
    "inking<|vq_clip",
    "\u09be<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black",
    "-<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a",
    "\ufffd\ufffd 1.0.0.0.0.0.0",
    "<|",
    "<",
    "<|vq",
    " \ufffd<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "<|vq_clip_12273|>this",
    "<|",
    "<|vq_clip_12273|>this is a",
    "ity<|vq_clip_12273|",
    "View<|vq_clip_",
    "gers<|vq_clip_12273|>this image displays a list of items",
    " ",
    "<|vq_clip_12273",
    " 0.0",
    "",
    " \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<",
    "<",
    "<|vq_clip_12273|>this is a screenshot of",
    "|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a",
    "i<|vq_clip_122",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the",
    "",
    "ations<|",
    "\u0bcd<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a chat conversation between two users. the first user, \"sarah\", is asking for a photo of a person named \"sarah\" who is a friend",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation appears to be in a language that is not familiar to the user. the",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq_clip_12273",
    "<",
    "ent<|vq_clip_12273|>this is a",
    "<",
    " 1.",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this",
    " 1.0.0",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    "K<|vq_clip_12273|>this image displays a list of 10 items,",
    "\u0a40<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation is in a casual tone, with the user asking for",
    " \n\n",
    " ",
    "<|vq_clip_122",
    "<|vq",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this",
    "upted<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include",
    "<|vq_clip_12273|>",
    "\u0430\u0442\u044c<",
    "lements \n\n```\n\nIt seems like",
    "<|vq_clip",
    "<",
    "<|vq",
    "\ufffd ",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items include \"c\", \"",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273",
    " \u12e8<|vq_clip_12273|>this image displays a list of options for a user to select from. the options include \"select\", \"select\", \"select\",",
    " \u0ab5\u0aa7\u0ac1 \u0aae\u0ac1\u0aa6\u0ac1 \u0aae\u0ac1\u0aa6",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer,",
    ") 1.0.0.0.0.0.0",
    "\u00f6rung<|vq_clip_12273|>",
    "\ufffd<|vq_clip_12273",
    "<|",
    "<",
    " \n\nIt seems like there was",
    "<|vq_clip",
    "<",
    "<|vq_clip_12273|",
    "amin<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items",
    "<|",
    "ings<|vq_clip_122",
    " \n\nIt",
    "au<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is",
    "ary<|vq_clip_12273|>this",
    "<|vq",
    "<",
    ". \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel free to clarify or ask again",
    "<|vq_clip_12273",
    "i\ufffd 1",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|",
    "<|vq_clip",
    "<|vq_clip_",
    " ",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column, with each item having a different name and description. the table also includes a column for the name of the item, and a column for the description. the",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer",
    "<|vq_clip_12273|>this is a screenshot of a website that provides information",
    "estarted 1.0.0.0.0.0.0",
    "<|vq_clip",
    " 2.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo",
    "<|",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    " 1.0.",
    " 1.0.0.0",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to be added to the conversation. the user is also asking for a new user to be added to the conversation",
    "",
    "<|vq_clip_122",
    " \ufffd<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark",
    "<|",
    "<|vq_clip_122",
    "<|",
    "<|vq_clip_12273",
    "<|vq_clip_",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    " ",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to",
    "<|vq_clip_12273|><|image_border_0|>\n\nIt seems",
    "<",
    "<|vq_clip_122",
    "<|vq_clip_",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this",
    "\u0456\u0430\u043b\u044c<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a",
    "ed<|vq_clip_12273|>this is a screenshot of",
    " ",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the items",
    "<|vq_clip_122",
    " \n\nIt seems like your message got garbled or mixed up with a lot of",
    "<|vq_clip_12273|>",
    " ",
    " \n\nIt",
    " 1.0.0",
    "<|vq_clip_12273|>",
    "\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1",
    "ElementXpaths> ",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|>this is a screenshot",
    "<",
    "ed<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black",
    "<|vq_clip_12273|>",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd ",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_12273|>this image",
    "<|",
    "<|vq_clip_12273|>this is",
    "```\n\nIt looks like your message got garbled or corrupted. Could you please resend your question or",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a",
    "<|vq_clip_12273|>this",
    "<",
    "",
    "With<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a code to be added to a website, and",
    "<|vq_clip_122",
    "<|vq_clip_122",
    "<|",
    "able<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    " .. ..  ..  ..  ..",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has",
    "",
    "",
    "<|vq_clip",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that takes in a list of",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_12273|>this is a",
    "64<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>",
    "ar<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a new",
    "<|",
    "<|vq_clip_12273|>",
    "S<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_122",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the function is called \"sum\" and it takes two arguments, \"a\" and",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a response to a question about a user named \"sud\" and the user is responding with a message that says \"i am not sure if",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with a particular topic, feel free to clarify or ask again! I'm here to help.\n\nIt looks like",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    " ",
    "",
    "<|vq_clip_12273|",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    " ",
    "<|vq_clip_12273|>this image displays a list of options for a user to select from. the options include \"select all\", \"select all\", \"select all",
    "<|",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "al) .. ..  .. ",
    "",
    " 1.0.0.0.0.0.0.0.",
    "<|",
    "ED<|vq_clip_122",
    "<|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person with a black and white background. the other user is responding with a photo",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black background.",
    "s<|vq_clip_12273|>",
    " \n\nIt seems",
    " 1.0.0.0.0.",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12286|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black",
    "en<|vq_clip_12273|>",
    "<|",
    "<",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the",
    "<|vq_clip_12273|>this",
    "ata<|vq_clip_12273|>",
    "<|vq_clip_122",
    "s ",
    "S_ \n\n",
    "ed ",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "ing \n\nIt",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is",
    "<",
    "urereporting<|vq_clip_",
    "<|vq_clip_12273",
    "<",
    " \ufffd<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"s",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the items are",
    "<|vq_clip_12273|>",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to",
    "",
    "<|vq",
    "<|vq_clip_122",
    "<",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    " \u12e8",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"def main()\".",
    "\n\n",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of ",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the items are arranged in a grid, with",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person who is a friend of the user. the user is also asking for a photo of a person",
    "<|vq_clip_12273|>this",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor",
    " .. ..  ..  ..  ..  ..  ..  .. ",
    "<|vq_clip_12273|",
    "<",
    "\ufffd<|vq_clip_",
    "<|vq_clip_12273|>this code snippet is from a python script that is",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this image displays a list of items in a database. the first item",
    " \n\n**Note**: The above text is a",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this is a screenshot of a code editor",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"",
    "<|vq_clip_12273|>this is a screenshot of",
    " \ufffd<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of",
    " relevant relevant relevant relevant relevant re",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the first item is \"1. ",
    "<|vq_clip_12273|>this image displays a list of",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the code is written in a dark theme and has a line of code that says",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__main",
    " 0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this",
    "s<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<",
    "\u0430\u0442\u0435\u043b\u044c\u043d\u044b",
    "\ufffd 0\ufffd 0\ufffd 0",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation is in a language that appears to be",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black background. the code is a function",
    "<|vq_clip_12273|>this image displays a list of items in a database. the",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a website's login page. the page is divided",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "Id<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|",
    "ATION<|vq_clip_12273|>this is a screenshot",
    "<",
    "<|vq",
    "ies<",
    "<|vq",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 1.5l bottle of water, a 1.5l bottle of",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of",
    "al\u00e9k<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a",
    "Each<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the function is called \"sum\" and it takes two arguments, \"a\" and \"b\". the script also contains a",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<|vq_clip_",
    "<|vq",
    " .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "\n  \ufffd ",
    "<|vq_clip_12273|>this is a screenshot",
    "<|",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a unique name and description. the items are arranged in a grid, with each item having a different color and shape. the first item is a blue rectangle with a white text, the second item is a green rectangle with a white text, and the third item is a red rectangle with a white text. the fourth",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation",
    "<|vq_clip_",
    "<|vq",
    "<|vq_clip_12273|>",
    " 1.0.0.0.",
    "<|",
    "<|vq_clip_12273|",
    "<",
    "<|",
    "ant \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different",
    "<",
    " ",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person who is a friend of the user. the user is also asking for a photo of a person who",
    "<|vq_clip_122",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot",
    "let<|vq_clip",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers and returns",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "<|vq_clip_12273|>this is a screenshot of a code editor",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq",
    "<|vq_clip_12273|",
    " 1.0.0.0.0.",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "\ufffd 1\ufffd 1\ufffd 1\ufffd ",
    "ancials<|vq_clip_12273|",
    "<|vq_clip_12273",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a function that calculates the sum of two numbers.",
    "<",
    "ATION<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo",
    "<|vq_clip_12273|",
    "<|vq_clip",
    "",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_122",
    "<|vq",
    "<|",
    "ion",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "\ufffd<",
    "ik",
    "ified \n\nIt seems",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "<|vq_clip_12273|>this is a",
    "et<|",
    "<|",
    " ",
    "<|vq_clip_12273|>this",
    "ary",
    "ISITION<",
    "<|vq_clip_12273|>this is",
    "<",
    "<|vq_clip",
    "<",
    "<|vq_clip_12273|>",
    "<|",
    "<",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a list of items in a table",
    " 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq_clip_122",
    "<|vq",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_",
    "<",
    "eth<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "Constraint<|",
    "<|vq_clip",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers. the code editor has a dark theme with a black background and white text. the script is written in python and the function is called \"sum\". the code editor also has a line of code that says \"print('sum')\". the script is a simple function that calculates the",
    "<|vq_clip_12273|>this is a screenshot of",
    " ",
    "\ufffd 1.0.0.",
    " 1.0.0.0.0.0.0",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "",
    "<|vq_clip_12273|>this image displays a list of files and folders in a directory",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a person named \"sara\" and the",
    "<",
    "<|vq_clip_12273|>this is",
    "<|vq",
    "<",
    " \t}\n\nIt seems like your message got a bit garbled. Could you clarify or provide more details about what you're looking for? Whether it's a specific topic or a general question, I'm here",
    "\ufffd 0\ufffd 1\ufffd 2\ufffd 3\ufffd 4\ufffd 5\ufffd 6\ufffd 7\ufffd 8\ufffd 9\ufffd 10\ufffd 11\ufffd 12",
    "<|vq_clip_12273|>",
    " ",
    "<|",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this",
    "ging",
    "/obligations<|vq_clip_12273",
    "ob<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "ed<|",
    "Layout<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a python language and is used to create a new file. the code editor has a dark background and the script is written in a light blue color. the script is used to create a new file with a python script. the code editor has a dark background and the script is",
    "ar",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer",
    "<|vq",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    "<|vq_clip_12273|>this image displays a list of items",
    " \n\nIt seems like the",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app.",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items",
    " \n\n  1. **\"The Power of Positive Thinking\"** - This book explores how a positive mindset can influence your life and help you achieve your goals. It offers practical strategies for cultivating optimism",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "  1.0.0.0.0.0.",
    "<|vq_clip_",
    "um<",
    "<|vq_clip_12273|>this is a screenshot",
    " \n\nIt seems like your message got garbled",
    " 0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this",
    ") \n\nIt seems the output is garbled due",
    "<|vq_clip_12273|>this code snippet is from a python",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j",
    " ",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd ",
    "<|vq_clip_12273|>this is a",
    " ",
    "<|vq_clip_12273|>",
    " \ufffd<|vq_clip_12273|>",
    "ation<|vq_clip_12273|>this image displays a list of items in",
    "<",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot",
    "``` \n\nThis is",
    "ian<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    "<|vq_clip_12273|>this image displays a list of",
    "<|vq_clip_12273|>",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and",
    "_MIDDLEWARE<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<",
    "in<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers and returns the result. the code is written in a dark theme with a black background and white text. the",
    "icton .. ..  ..",
    "<|vq_clip_12273|>this image displays a list of items in a",
    "<|",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform.",
    "<|vq_clip_12273|>this is a screenshot of",
    "ARY<|vq_clip_12273|>this is a screenshot of",
    " \n\n[END]",
    "<|vq_clip_12273|>this image displays a",
    "\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1",
    "",
    "<",
    "DRO<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation is",
    "<",
    "<|vq_clip_12273|",
    "\ufffd ",
    "<|vq",
    "<|",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding",
    "<|",
    "",
    "<|vq_clip_",
    "<|vq_clip_12273|>this image displays a list of items in a table format",
    "<|",
    " ",
    "<",
    "<|vq_clip_",
    "<",
    "<|vq_clip_12273",
    "ical<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    " \n\nIt seems like your message got garbled or mixed up with a lot of",
    "<",
    "<|vq_clip_12273|>this",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<",
    "<|vq_clip_12273|>",
    "matic<|vq_clip_12273|>",
    "Name<|vq_clip_122",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is",
    "",
    "<",
    "<",
    "CHANTABILITY<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<|vq_clip_12273|>",
    "ature<|vq_clip_12273|>this",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a list of ",
    "<|vq_clip_12273|>this is",
    " \n\nIt seems like your message got garbled or mixed up with",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of",
    "<|vq_clip_122",
    "lich<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"s",
    "asty<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "Text<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot",
    " \n\n```\n\nIt appears that the",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this",
    "<|vq",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a specific question about a user",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a",
    "<|",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart.",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a few lines of code. the code appears to be a function that calculates the sum of two numbers. the script is written in a dark",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of files and folders in a directory. the files",
    "n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "\u0abf",
    "\ufffd 0.0.0.0.0.0.0.0.",
    "ittable \n\nIt looks like your message got garbled or mixed up with a lot",
    "<",
    "",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the",
    " 1.0.0.0.0.0.0.0.0.0.0",
    "<|vq",
    "\u0432\u0430",
    "<|vq_clip_12273|>this is a screenshot of",
    " ",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<",
    "\n\nIt seems like the text",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the items are labeled as \"1\", \"2\",",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as",
    " 1.0.0.0.",
    " ",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "OfRows) \n\nIt seems like your message",
    " 0.0.0.0.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip",
    "<|vq_clip_",
    "<",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation is in a casual tone",
    " \n\nIt seems like your message got gar",
    "<|vq_clip_12273|>this image displays a list of files and folders in a computer",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to be added to the conversation. the user is also",
    "( 1.0) 0.0 ",
    "<|vq_clip_12273",
    "<",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two",
    "<|vq_clip_12273|>this image displays a list of files and folders in a computer's",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "\ufffd 1.0.0.0.0.0.",
    "<|vq_clip_12273|>this",
    "suspenders<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a person named \"sara\". the conversation is in a language that appears to be in",
    "\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd ",
    "ic<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers. the code is written in a dark theme with a black background. the function is called \"sum\" and it takes two arguments, \"",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    " \ufffd :// 2018 2019 2020 2021 ",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates",
    "r<|vq_clip_122",
    " 1.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<",
    "<|vq_clip_",
    " 1.0.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this is a screenshot of a",
    "ingen .. ..  ..  ..  ..  ..  ..  ..  ..",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "Name<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and",
    "<|vq_clip_12273|>this image displays a list of items in a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>",
    "ED \n\nIt seems",
    "<",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>",
    " \n\nIt",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    " \n\nIt looks",
    "With ",
    "<|vq_clip_12273|><|image_border_0|>\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. Could you clarify or provide a more",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format.",
    "an",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    ") \n\n**Note**: The above text appears to be a mix of multiple languages and unrelated content. It seems like a mistake or a glitch. If you have",
    "<",
    "<|vq_clip_12273|>",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "I \n\n``` \n\nThe assistant's answer is garbled. It seems to have produced nonsense. The user asked: \"What is the difference between a 'situation' and a 'scenario'?\" The assistant should answer that. But the assistant's answer is nonsense. So we need to correct",
    "NECTION",
    "<|vq_clip_12273|>",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1",
    " \t}\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. Could you clarify or resend your question or the information",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers.",
    "<|vq_clip_12273|",
    "<|vq_clip_12273",
    " 1.1.1.1.1.1.1.1.1.",
    "<|vq_clip",
    "<",
    "<|vq",
    "<|vq_clip",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "at 1.0.0.",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo",
    "Data",
    "ctor<|vq",
    "<|vq_clip_12273|>this image displays a list of files and folders in a directory. the files are named \"c",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the function is called \"sum\" and it takes two arguments, \"a\" and \"b\". the code editor also has a line of",
    "<|vq_clip_122",
    "ing<|vq_clip_12273|>",
    "<|vq",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains",
    "Exception<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items",
    " \n\nIt seems like your message got a bit garbled. If you have a specific question or need help with a particular topic, feel free to ask!\n\nIt looks like your message got a bit garbled. If you have a specific question or need help with a particular",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a specific question about a user named \"sud\" and the other user is responding with a message. the user is asking for a specific question about a user named \"sud",
    "<|vq_clip_12273",
    " 1.",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of",
    "<|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a",
    "<|vq_clip_12273|>this",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a database. the items are listed in a table format, with",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq_clip_12273|>this image",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "```\n\nIt seems like your message got gar",
    "<",
    "<|vq_clip_12273|>",
    " \n\nIt seems like there was a mistake in the input",
    "<|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|",
    "",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a list of 10 items that are being used in a project. the first item is a \"c\" and the second item is a \"c\". the third item is a \"c",
    "<|vq_clip_12273",
    "<|",
    "<|vq_clip_12273|>this image displays a list of items in a database. the first item is a \"c\" and the second item is a \"c\".",
    "RO",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a person with a black and white background.",
    "<|vq_clip_",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<",
    "<|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|",
    "://<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers and returns the result. the code editor has a dark theme with a black background and a green text color. the script is written in python and the function is called \"sum\". the code editor also has a line of code that",
    "<|vq_clip_12273|>this",
    " \u09b8",
    "<|vq_clip_12273",
    "<|",
    "<|vq_clip_",
    "_ .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column, with each item having a different",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_",
    "<",
    "<|vq_clip_12273|>this is a screenshot",
    "",
    "\ufffd \n\nThis is nonsense",
    "ac",
    "<|vq_clip",
    "<|vq",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot",
    "<",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_122",
    "<",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers. the code editor has a dark theme with a black background and white text. the script is written in python and the function is called \"sum\". the code editor also has a terminal window with a command prompt. the script is written in python",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot of a website's login page. the page is divided into two sections, with the left side displaying a login form and the right side showing a list of user accounts. the login form has fields for username, password",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "\ufffd<|vq_clip",
    " .. ..  .. ",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column, with each item having a unique name and a description. the",
    " \n\n",
    "i\u015fi ",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<|",
    "ic json<|vq_clip_122",
    "<|vq_clip_12273|>this image displays a list of 10 items",
    "<|vq_clip_",
    ") 1.0.0",
    "<",
    "<|vq_clip_12273|>this",
    "<",
    " \n\nIt seems like",
    "<|vq",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a person named \"sara\". the conversation is in a language that appears to be in a different",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "\n\n",
    " \n\nIt seems like your message got gar",
    "State",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "<|vq_clip_",
    "<|vq_clip_12273|>this image displays a list of items in",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "64<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a specific question about a user named \"sudhir\" and the other",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this image displays a list",
    " 1.",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code editor",
    "<",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to be added to the conversation. the",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_12273|>this image displays a list of",
    "<|vq_clip_12273|>this image displays a list of items in a table format",
    " ",
    "<|vq_clip",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the",
    "<|vq_clip_12273|>",
    " .. ..  ..  ..  ..  ..  ..  ..  ..  .. ",
    "<|vq",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays",
    " \ufffd \ufffd  \ufffd  \ufffd  \ufffd  \ufffd  \ufffd ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<",
    " ",
    "<|vq_clip_",
    "<|vq_clip_12273",
    "<",
    "\u043d\u044b\u0439<|vq_clip_",
    "<|vq_clip_12273|>",
    "\n\nIt",
    " \n\n[conversation ends]",
    "<|vq_clip_122",
    " \n\nIt seems like the text you provided is a",
    "<|",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the",
    "<|vq_clip_12273|>this image displays a list of options for a user to select from. the options include \"select all\", \"select all\", \"select all\",",
    "<|vq_clip_12273",
    "\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\n",
    "\ufffd 1\ufffd 2\ufffd 3\ufffd 4\ufffd ",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.",
    "quented<|vq_clip",
    "<|vq_clip_12273|>this image",
    "ia<|vq_clip_",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d",
    "<|vq_clip_12273|>this image displays a",
    "<|vq",
    "\n\nIt seems like your message got garbled or",
    "ton<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|>",
    "<",
    " ",
    "\u0bbe<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a",
    "<|vq_clip_12273|>this is a screenshot of a chat conversation between two users.",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip",
    "<",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|vq_clip_",
    "<|vq_clip_12273|",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text",
    "",
    "<|vq_clip",
    "> \n\nIt",
    "<",
    "<",
    "<|vq_clip",
    "<",
    "<|vq_clip_122",
    "k<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is",
    "<|vq_clip_12273|>this image displays a list of",
    "es<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a translation of a phrase in a different language. the user",
    "<|vq_clip_",
    "<|vq_clip",
    "\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. Could you clarify or resend your",
    " ",
    " .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  .. ",
    "\ufffd<|vq_clip_",
    "<|vq_clip_12273|>",
    "```",
    "<",
    "\n\nIt seems like your message got a bit garbled. If you have a specific question or need",
    "\u0d40<|vq_clip",
    " \n\n[END OF TEXT]",
    "\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers and returns the result. the code is written in a dark theme with a black background and white text. the function is named \"sum\" and it takes two arguments, \"a\" and \"b\". the code also includes a function that calculates the sum of two numbers and returns the result. the code is written in a dark theme with a black background and white text",
    "\ufffd<|vq_clip_12273|>this",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h",
    " 1.0.0.0.0.0.0.0.0.0.0.0",
    "<",
    "<",
    "\u09cd\u09af<|vq_clip_12273|>this image displays a list of items in a table format. the items include \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "ues \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of files and folders in a computer's file explorer.",
    "<|vq_clip_12273|>this image displays",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a code editor",
    "<|vq_clip_12273|",
    "<",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a",
    "",
    "<|vq_clip_12273|>this image displays",
    "\ufffd ",
    "<",
    "al<",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a response to a question about a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_12273|>this is a screenshot of",
    "<",
    "S \n\n",
    "<|vq",
    "n<",
    "<",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that takes in a list of numbers and returns the sum of the numbers. the code editor has a dark theme with a black background",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_12273|",
    "<",
    "<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of ",
    "<|vq_clip_12273|>this image displays a list of items",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers.",
    "StatusCode 1\ufffd<",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273",
    "<|vq_clip_",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>this is a screenshot of",
    "uschung<|vq_clip_12273|>this image displays a list of 10 items that are",
    "-<",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a website that provides information about the 2022-",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    " \n\n```\n\nIt seems like your message got garbled or mixed up with a lot of unrelated",
    " 1.0.0.0",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "tempt",
    "<|vq",
    "<|vq_clip_12273|>this image displays a",
    "IS<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a list",
    "er<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code editor has a dark background with a green text. the script is written in a dark theme and contains",
    "<|vq_clip_12273|>this is a screenshot of a",
    "ig<|vq_clip_12273|>this is a",
    "or",
    "ponsive<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    " \n\n```\n\nIt seems like your message got gar",
    "<|vq_clip_",
    "<|",
    " ",
    "\u0e32<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person who is a friend of the user. the user is also asking for a photo of a person",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq_clip_122",
    " \n\n```\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with a particular topic, feel free to ask!\n\nIt",
    "\u043a<|vq_clip_",
    "<|vq_clip",
    "",
    "<|",
    "ViewController<|vq_clip",
    "prise<|vq_clip_122",
    "<|vq_clip_12273|",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code editor has a dark background with a green line of code. the script is written in a dark theme and contains a function that",
    "<|vq_clip_122",
    "\ufffd<|vq_clip_12273|>this image displays a list of 10 items in a table format.",
    "<|vq_clip_12273|>this",
    "<",
    "<|vq_clip_122",
    " \n\nIt seems like your",
    "",
    "<|vq_clip_12273|>this image displays a list of items in a table format",
    "our<|vq_clip_12273|>this is a screenshot of a conversation between two",
    " ",
    " \u12e8 \u12e8 \u12e8 \u12e8 \u12e8 \u12e8 \u12e8 ",
    "<|vq_clip_12273|>this",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "",
    "<|vq_clip_12273|",
    " .. ..  ..  ..  ..  ..  ..",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this image displays a list of files and folders in a directory. the files are named \"c\" and \"c\" and are located in the \"c\" folder. the folder contains a file named \"c\" and a folder named \"c\" and \"c\". the",
    "<|vq_clip_12273|>this image displays a list",
    "<",
    "State 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    " 1.5.0.0.0",
    " 1\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0",
    "<",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of",
    "\u102c<|vq",
    "<",
    "<|vq_clip_12273|>this image displays a list of files and folders in a directory",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list",
    "<|vq_clip_",
    "<|vq",
    "ar",
    "<",
    "```\n\nIt seems",
    "<|vq_clip_12273|>this image displays a list of items in a",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items in a database. the first item is a \"c\" and the second item is a",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers.",
    " \n\nIt seems like there was a mistake in the input. Could you please",
    "urereporting<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "ffield<|vq_clip_12273|>this image displays a list of",
    "",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a new message to be sent to a user named \"sara\" and the other user is",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items include \"c\", \"c\", \"c\",",
    "<",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation appears to be in a language that is not familiar to the user.",
    "<|vq_clip_12273|>this is",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a website's login page. the page",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is",
    "s",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of",
    "<|vq_clip_12273|>this",
    "itud<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme",
    "<|",
    "<|vq_clip_12273|",
    "ievals ",
    "<",
    "<|vq_clip_12273|>this",
    "<|",
    "<|vq_clip_",
    ") \n\n",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a person named \"sara\" and the other user",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is",
    "<",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "\u0c3f\u0c02\u0c1a\u0c41<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of",
    " ",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the items are arranged in a grid, with each item having a different color and shape. the first item is a blue square with a white circle in the center, the second item",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "\u017c<|vq_clip_12273|>this image displays a list of items in a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "ed \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If",
    "<|vq_clip_12273|>",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel free",
    "<|vq_clip_12273|>",
    "s<|vq_clip_12273|>this image displays a list of items in a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a",
    "<|vq_clip_12273|>",
    "<|",
    "ers\ufffd 1\ufffd 1\ufffd ",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    " 1.0.0",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this image displays",
    "<|vq",
    "<|vq_clip_12273|",
    "<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the items are arranged in a grid, with the first item being a blue square, the second item being a green circle, the third item being a yellow triangle, and the fourth item being a purple rectangle. the items are labeled with numbers and the text \"10\" is written in a bold font. the background is a light blue color, and the items are arranged in a neat and organized manner. the image appears to be a screenshot of a website or a document.",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name",
    "<|vq_clip_12273|>\n\nIt seems like there's a mix of different languages and",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "iates 1.0.0.0.0.0.",
    "<|vq_clip_12273|>this image",
    "<|vq",
    "<",
    "<|vq_clip_122",
    "<|vq",
    "<|vq_clip_12273|>this image displays a list of items in a database. the items are listed in a table format, with each item having a unique identifier. the first item is a \"c\" with a \"c\"",
    "<",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3",
    " ",
    "<|vq_12212|>",
    "antes<|vq_clip_12273|>this is a screenshot of a conversation",
    " ",
    "ing<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "\ufffd 1\ufffd ",
    "<",
    "<|vq",
    "<",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer,",
    "",
    "<",
    "",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_122",
    "",
    "Listener<|vq_clip_",
    "\u00a0",
    "<",
    "<|vq_clip",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a person named \"sara\" and the other user is",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text",
    "ec<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items",
    "r 1.",
    "ed ",
    "<|vq_clip_12273",
    "<|",
    "<|",
    "<|vq_clip_122",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a table with various columns and rows",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app.",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot",
    "<",
    "s 1.0.0.0.",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq_clip_12273|>this image displays a list of files and folders in a directory. the files are named \"",
    " \n\nIt seems like your message got garbled or mixed up with",
    " \n\n```\n\nIt seems like your message got garbled",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|",
    "State<|vq_clip_",
    " 1",
    "<|vq_clip_12273|>this image displays a list of items in a table format.",
    "s \n\nIt seems like your message got gar",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo",
    "<",
    "<|",
    " .. ..  .. ",
    "<|",
    "<|vq_clip_12273|>this image displays a list of items",
    "<|",
    "<|",
    " \n\nIt seems like your",
    "<|vq_clip_12273",
    "orers \n\n```\n\nIt seems like your",
    "<|vq_clip_122",
    "<|vq",
    "\ufffd 1.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written",
    "ive<|vq_clip_12273|>",
    "<",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking",
    "<|",
    "<",
    "<|vq_clip_12273|",
    " \n\nIt seems like your message got",
    "",
    "<|vq_clip_12273|>this is a",
    "<",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a",
    "<|vq",
    "ine<|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    "<|vq_clip_12273|>this image displays a list of items in a table format",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is",
    "<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of items in a table",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of",
    "<",
    "<|vq_clip_12273",
    "<|",
    "<|vq_clip",
    "<|vq_clip_12273|>",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel free to clarify or ask again!\n\nIt looks like your message got mixed up with a lot of unrelated text.",
    " ",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation is in a language that appears to be in a different script, possibly a mix of english and arabic. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation is in a language that appears to be in a different script, possibly a",
    "<|vq_clip_12273|>",
    "<|",
    "<|vq_clip_12273|>this is",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<",
    "<|vq_clip_12273",
    "<",
    "<",
    "<|vq",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|",
    "<|vq_clip",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|",
    "<|vq_clip",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    "",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items include \"c\", \"c\",",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark",
    "",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is",
    "Exception<|vq_clip_12273|>this image displays a list of items in a table format.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo",
    "<|",
    "ized 1.0.0.0.0.0.0.0.0",
    "erschafts<|vq_clip",
    "<|vq_clip_12273|>this",
    "<",
    "and<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<",
    "",
    " 1.0.0.",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<",
    "<|vq_clip",
    " \n\nIt seems like your message got garbled or mixed up with a lot of",
    "<|vq_clip",
    "<|vq_clip_12273|",
    "ed \n\nIt seems like your message",
    "<|vq_clip_12273|>this image displays a list of 10 items that are used in a software program. the items are listed in a table format, with each item having a",
    "<|vq",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a",
    "<|vq_clip_12273|>this image displays a list of options for",
    "ar<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273|",
    "\ufffd<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "<|vq_clip_12273|>",
    "ization<|vq_clip_12273|",
    "<|vq_clip_12273|",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273",
    "<",
    "\ufffd<|vq_clip_12273|>this code snippet is from a python script",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform.",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this image displays a list of files and folders in a directory. the files are named \"c\" and \"",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    "<|vq",
    " \n\nIt looks like your message got garbled or mixed up",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman with a black hair. the user also mentions that the photo is not a picture of a person named \"sara\" and that the user is",
    "<",
    "<|vq_clip",
    "<|vq_clip_122",
    "<",
    "Trace \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app.",
    "<|vq_clip_12273|>this is a screenshot of",
    "<",
    "<|vq_clip_12273|>this",
    "<|",
    "<|vq_clip",
    "<",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this image displays a list of items in a database. the items are listed in a table format with columns for item name, item description, and item price. the table is",
    "```\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. Could you clarify or provide more details about what you need help with? Whether it's a specific question or a topic you'd like to discuss, I'm here to help",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    " 1.0.",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black background. the code",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation appears to be in a language that",
    "<",
    "\n\n[END OF RESPONSE]",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the items are arranged in",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "ized<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column with a header that reads \"item name\". the",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<",
    " .",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the items",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    " \n\nIt",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a",
    " ",
    "<|vq",
    "<|vq_clip_12273|>",
    "ira \n\nIt seems like there was a mistake",
    "<|vq_clip_12273|>this is a screenshot of a website that",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named",
    "Type 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "  0  ",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    "<|",
    "<|vq_clip_12273|",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a website that provides information about the 2022-2023 season of the national football league. the website is in indonesian language and has a header with the title \"2022-2023 season",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app.",
    "<|vq_clip_12273|>this is a",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a chat conversation between two users. the first user, \"sarah\", is asking for a photo of a person named \"sarah\"",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "Knife<|vq_clip_12273|>this",
    "<",
    " \n\n",
    " ",
    "ellers<|vq_clip_12273|>this image displays a list of items in a table",
    "<|vq_clip_12273|>this",
    "<|vq_clip",
    "<|vq_clip_12273|>this",
    "ATION",
    "<|",
    "<|vq_clip_122",
    "is<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the code is written in a dark background with a black text. the script appears to be a simple python script that is used to create a new file. the code editor is open to the main page of the",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    " \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "\ufe0f<|vq",
    "\u0446\u0438\u0438<|vq_clip_12273|>this is a screenshot of a website's login page. the page has a black background with a white text box in the center. the text",
    "deo<|vq_clip_122",
    "\ufffd 1.0.0.0.",
    "<|vq_clip_12273|>this",
    "ition<|vq_clip_12273|>this image displays a list of items",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "<|vq_clip_12273|",
    "<|vq_clip",
    "<|vq",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a",
    " 1.0.0.",
    "<|vq_clip_12273|>this is a screenshot of a",
    "ATION<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    "<",
    "<|vq",
    "",
    " 2019 2019 201",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"item 1\", \"item",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is",
    "\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something",
    "s<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"",
    " ",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named",
    "<|vq_clip_",
    " \n\nIt",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"c\", \"d\",",
    "<|vq_clip_12273|>this is a screenshot",
    "<",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a screenshot of a conversation about a user named",
    " \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<",
    "<|vq_clip_",
    "<|vq_clip_12273",
    "<|vq",
    " .. ",
    "\ufffd 1.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "IMED \n\nIt looks like your",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections, with the left side",
    "<",
    " ",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation appears to be in a language that is",
    "<|vq_clip_12273|>this is a screenshot of",
    "",
    "<|vq_clip",
    "<",
    " ",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column, with each item having a unique name and a description. the table appears to be a part of a larger database",
    "",
    "\ufffd 0",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections, with the left side showing a list of products and the right side showing a list of products. the left side of the page has a search bar and a filter button, while the right",
    " ",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273",
    "<|vq_clip",
    "<",
    "<|vq_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items include \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\",",
    "<|vq_clip_12273|>this is a",
    "angement<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot of a code editor",
    "<|vq_clip",
    "\ufffd 1.0.0.0.0.0.0.0",
    " 1.0.0.0.0.0",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a",
    "",
    "<|",
    "",
    "in",
    "<",
    "<|vq_clip_12273|",
    "<|",
    "<|",
    "\ufffd ",
    "<",
    "<|vq",
    "<",
    " ",
    "\u09be<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function",
    "",
    " .. ..  ..",
    "<|vq_clip_122",
    "ated<|vq_clip_12273|>this image displays a list of items in a database. the items are listed in a table format, with each item having a unique identifier. the first item is a \"c\" with a \"c\" and a \"c\" in the second column",
    "<|vq_clip_12273|>this is a screenshot of a code",
    " \n\nIt seems like your message",
    "<",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<|vq_clip_12273|>this",
    " \n\n[conversation ends",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "or<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this image displays",
    "<",
    "<|vq_clip_12273|>this is",
    "<|vq",
    "<|",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"print",
    " ",
    "<",
    "mpeg<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a translation",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    "<|vq_clip_122",
    "\u0bae\u0bbe ",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this",
    "<",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column, with each item",
    "el<|vq_clip",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the code is written in a dark theme and has a line of code that says \"if __name__ == \"__main",
    "<",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"item 1\", \"item 2\", \"item 3\", and \"item 4\". each item has a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<|vq_clip_",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    "ad<|vq_clip_12273|>",
    "k",
    " \n\n[END OF CONVERSATION]",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in",
    "<",
    "\ufffd 0.0.0.0.0",
    " \n\nIt seems",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>this image displays a list of items in a shopping",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column with a header that reads \"item",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the",
    "<",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a table",
    "<|vq_clip_",
    "<|",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this image displays a",
    "\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with a particular topic, feel",
    "<|",
    "<|vq_clip_12273|",
    "ViewController<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of",
    "\ufffd<|vq_clip_122",
    " .. ",
    "<|vq_clip_12273|>this code",
    "<|vq_clip_12273|",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>this is a screenshot",
    " \ufffd<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_12273|>this image",
    "<",
    "\u4eec<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of files and folders in a directory. the files are named \"c\", \"c\", \"c",
    "<|vq_clip_12273|>this is a screenshot of",
    "",
    "<",
    " ",
    "ientations",
    "<|vq_clip_12273|>this image displays a list of",
    "",
    "<|vq_clip_12273|>this image displays a table with",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of 10 items",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "<|vq",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_12273|",
    "<|",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this code",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a person named \"sara\". the conversation is in a language that appears to be a mix of english and hindi. the user is asking for a photo of a person named \"",
    "\ufffd<",
    "<|vq_clip_122",
    "back<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the",
    " 1.0.0.0.0.0.0.",
    "<|vq",
    "Request<|vq_clip_",
    "<|",
    "<|vq_clip_",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this image displays a list of",
    "teness<|vq_clip_12286|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person who is a friend of the user. the user is also asking for a photo of a",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|vq_clip_12273|",
    "<|vq",
    "<|vq_clip_12273|>this image displays a table",
    "<|vq_clip_12273",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<",
    "OR<|vq_clip_122",
    "<|",
    "<|vq_clip_12273|>",
    "<",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the first item is \"1. 2. 3. 4. 5. 6. 7. ",
    "able<|vq_clip_",
    "hold",
    "<|vq_clip",
    "igeria<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"c",
    " \n\n",
    "ain<|vq_clip_12273|>this is a",
    "r<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a specific question about a user",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the items are arranged in a grid, with the first item being a blue square, the",
    "<|vq_clip_12273|>this is a screenshot of a code editor",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\"",
    "<|",
    "<|vq_clip_12286|>",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is",
    "<|",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_12273|>this image displays a list of files and folders in a directory. the files are named \"c\", \"",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a",
    "",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to be added to the conversation, and the other user is responding with a message that says \"i am not sure if i can do that\". the conversation appears to be in a language that is not familiar to the user. the user is also asking for a",
    "<|",
    "<|vq_clip_12273|>",
    "\ufffd 0\ufffd 0",
    "<|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape",
    "<|vq_clip_12273|>this image displays a list of files and folders in a directory. the files are named \"c:\\users\\michael\\desktop\\c:\\users\\michael\\desktop\\c:\\users\\michael\\desktop\\c:\\users\\michael\\desktop\\c:\\users\\michael\\desktop\\c:\\users\\michael\\desktop",
    "<|vq",
    "<|",
    "able<",
    "```\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a person named \"sara\"",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this code",
    "<|",
    "<|",
    "<|vq_clip_12273",
    "ition",
    "<",
    "<",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<|vq_clip_",
    "\n\n",
    "ek<|vq_clip_12273|>this image displays a table with various columns and rows.",
    "<",
    "!!! ... \n\n**",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<|vq",
    "<|vq_clip_",
    "<|vq_clip_12273",
    "<",
    "<|vq_clip_12273|>",
    " 1.0.0.0.0.0.",
    "quences<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the first item",
    " ",
    "",
    "<",
    " 1.0.0.0.0.0.0.0.0.",
    "<|",
    "<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of",
    "<|",
    "<|vq_clip_12273|",
    " ",
    "<|vq_clip_12273|>this is a screenshot",
    " \ufffd\ufffd \ufffd\ufffd \u3420 \u3420 \u3420 \u3420 \u3420 ",
    " 1.0.",
    "s<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    "<|vq_clip_12273|>",
    "<",
    "<|",
    "<|vq_clip_12273|>this image displays a list",
    " \n\n[END OF TEXT]",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman.",
    " ",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\",",
    "<",
    "<|vq_clip",
    "<|vq_clip_12273|",
    "\u043d\u043e\u0441\u0442\u044c<|vq_clip_12273|>this image displays a list of items in",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.",
    "",
    "<|vq_clip_12273|>this image displays a list of files and folders in a computer's file explorer",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_12273|>this image displays a list of files and folders in a directory. the files are named \"file1\", \"file2\", \"file3\", and \"file4\". the folders are named \"folder1\", \"folder2\", \"folder3\", and \"folder4\". the directory is located in the \"c:\\users\\user",
    "<|vq_clip_12273|>this is a screenshot",
    "<",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq_clip_12273|",
    "<|",
    "<|vq_clip_12273|",
    " 1.0.0.0.",
    "<|vq",
    "<|vq_clip_",
    "<",
    "Variable<|vq_clip_12273|>",
    ") \n\nIt seems like your message got garbled or mixed",
    " 1.0",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<",
    "\ufffd<|vq_clip_",
    "bonate<|vq_clip_",
    "<|vq_clip_122",
    "<",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"",
    "ATION \ufffd<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black background. the",
    "* ",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "<|vq_clip",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with",
    " relevant relevant ",
    "<|",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person with a black and white background",
    "<|vq_clip_12273|>this is a screenshot of a website that provides information about the ",
    "\ufffd 0\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this image displays a list of ",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated",
    "<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of items in",
    "<|vq_clip_12273|>this is a screenshot of",
    "apsed<|vq_clip_12273|",
    " ",
    "<",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273|>this image displays",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a database. the items are listed in a table format, with each item having",
    "ed<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<",
    "<|vq_clip_12273|>this image displays a list of",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>this image displays a",
    "ed<|vq_clip_12273|>this image displays a list of items",
    "ed ",
    "<",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot",
    "nergy<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers. the code",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_12273|>",
    "<|vq_clip",
    "<|vq_clip",
    " \n\n",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items",
    "<",
    "red",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_",
    " ",
    "",
    "s<|vq",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of items. the items",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3",
    "<|vq_clip_12273|>this image displays a list of files and folders",
    "/ 1.0.0.0.0.0.",
    " \n\nIt seems",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the first item is a \"",
    "<",
    " \n\n```\n\nIt looks like your",
    "",
    "<|vq_clip_122",
    "<|vq_clip_122",
    " 1.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform.",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the",
    "<|vq_clip_12273|>this is",
    "\n\n```\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. Could you clarify what you need help",
    "<|",
    "<",
    "\ufffd 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "<|vq_clip_",
    " \n\nIt seems like your message got garbled or mixed up with a",
    "\ufffd<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot",
    " ",
    "<|vq_clip_12273|>this is a",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have",
    " ",
    " \n\n[conversation ends]",
    " \u12f0 \u12f0 \u12f0 \u12f0 ",
    "ob<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq_clip_",
    "<",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items include \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is",
    "<|",
    "<|vq_clip_12273|>this",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this image displays a list of items in a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "irection<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates",
    " ",
    "age",
    "ed<|vq_clip_",
    "<|vq_clip_12273|>this image displays a list of items",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of",
    "NullException<|vq_clip_12273|>this code snippet is from a python",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "imum<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip",
    "<|vq_clip_12273",
    " .. ",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart.",
    "<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of items in a table",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "\ufffd<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a ",
    "<|vq_clip_12273|>this image displays a list of items in",
    "<|vq_clip_",
    "<",
    "<|vq_clip_12273|>this is a screenshot of",
    "urcated<|vq_clip",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"s",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation appears to be in a language that is not familiar to the user. the user is asking for a photo of a person named \"",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot of",
    "ual \ufffd<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers and returns the result. the code",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the first user, who is a student, is",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a unique name and description. the first item is \"the 10th item\", which is a list of",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    " 1.0.0.0.0.0.0.0.",
    "anish<|vq_clip_12273|>",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd ",
    "\u00e1<|vq_clip_",
    "",
    "",
    "",
    " \n\nIt seems like there",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a person named \"s",
    "<|vq_clip_12273|>this is a screenshot of a website that provides",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"v\", \"w\", \"x\",",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in",
    "<|vq_clip_12273|>this is",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this image displays a list of items in",
    "<|vq_clip_12273",
    " .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  .. ",
    "",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line",
    "",
    "<",
    "\u09be<|vq_clip_12273|>this is",
    "us<|vq_clip_12273|>",
    " \u3400\ufffd \u3400\ufffd \u3400\ufffd \u3400\ufffd \u3400\ufffd \u3400\ufffd ",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person who is a",
    "```",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_12273|>this is",
    "oring",
    "<|vq",
    " ",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user",
    "or ..",
    "<|vq_clip_12273|>this is",
    "<",
    "<",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this image displays a list of",
    "\u0430\u0440<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a code to be used for a specific task, and the other user is responding with a code that is not available. the user is also asking for a code to be used for",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a",
    "<",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this image",
    "",
    "",
    "<|vq",
    "<|vq_clip_12273|>this is a",
    "\ufffd 0",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd ",
    "<|vq_clip_",
    "ized<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "<|vq_clip",
    "heet<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of",
    "<|vq_clip_12273|>",
    "ustomers 1",
    "<|vq_clip_12273|>this is a screenshot",
    "iric<|vq_clip_12273|",
    " \n\nIt seems like there's",
    "S<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d",
    "<|vq_clip_12273|>this is",
    "<",
    "<|vq_clip_122",
    "<|",
    "",
    "EventArgs<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a specific question about a user",
    "",
    "\u043d\u043e\u0441\u0442\u0438<|vq_clip_12273|>",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>",
    "<",
    "",
    "",
    " \ufffd<|vq_clip_12273|>this code snippet is from a python script that is used to create a new",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_",
    " .. ..  ..  ..  ..  ..  ..  ..  ..",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this image displays a list of items in",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "ions<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding",
    "",
    "<|vq_clip_12273",
    "<|",
    " ",
    "<|vq_clip_12273|>this image displays a list of items in a database. the first item is a \"c",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app.",
    "<",
    "ity<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person who is a friend",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format",
    " ",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart.",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the",
    "<|vq_clip_122",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_12273|>this image displays a list of items in a table",
    "\ufffd 0\ufffd 1\ufffd 2",
    "<",
    "<",
    "\u043d\u0438\u0439<|vq_clip_12273|>this image displays a list of",
    "",
    "<|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "\u043d\u044b\u0439 \n\nThis is nonsense. The output is garbled. The code is not correct.",
    " \ufffd<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is",
    "<",
    "uallog",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "<|",
    "<|vq_clip_12273|>",
    "<|",
    "\ufffd 1.0.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<",
    "<|",
    "<|vq_clip_12273|>this image displays a list of 10 items, each",
    "<|vq_clip_",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are",
    "I",
    "<|vq_clip_12273|>",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the code is written in a dark background with a",
    "<",
    "<|vq_clip_",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_12273|>this",
    "<|vq",
    "<|vq_clip_12273|>this image displays a table with various columns and rows. the table appears to be a database or spreadsheet",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "",
    "<|vq_clip_12273",
    "",
    "",
    "",
    "",
    "<",
    " 1\ufffd 1\ufffd 1\ufffd 1",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a code to create a new user in a database. the user is also asking for a code to create a new user in a",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark",
    "<",
    "",
    "<|vq_clip_12273|>this",
    "IRECTS<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "",
    "<",
    "\ufffd 0\ufffd 0\ufffd ",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a screenshot of a conversation between two users. the user is also asking for a screenshot of a conversation between",
    "<|vq_clip_122",
    "<|vq_clip",
    "icetexture \ufffd ",
    "",
    "",
    "<",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the",
    "ptoms<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function",
    " kotlin kotlin kotlin",
    "<|vq",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this",
    " ",
    "<|vq",
    ")",
    "<|vq_clip_12273|>",
    " .. ..  ..  ..  ..  ..  ..  ..  ..",
    "<|vq_clip_122",
    "<",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of",
    "<",
    "<|vq",
    " \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items",
    "<|vq_clip_122",
    "<|vq_clip_12273",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    " 1.0",
    "ich",
    "<|vq",
    "<|vq_clip_12273",
    "<|",
    "<",
    "<",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a",
    "<|vq_clip_12273|",
    "<|vq_clip",
    "ToUpperCase<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "es<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "<|vq_clip_",
    "<",
    "<|vq_clip_12273|>this",
    " ",
    "<",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of 10 items",
    "",
    "",
    "",
    "<|vq_clip_122",
    "ation",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the",
    "<|vq_clip",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "  1",
    "```\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text.",
    "<|vq",
    "",
    "ible<|vq_clip_12273",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is",
    "ATEGORY<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation appears to be in a language that is not familiar to the user",
    " \ufffd<|vq_clip_12273|>this image displays a list of items in a shopping cart.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<",
    " .. ..  .. ",
    "<|vq_clip_12273|>this",
    "<",
    "",
    " 1\ufffd 1\ufffd 1",
    "",
    "\ufffd ",
    "n<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"item 1",
    ")",
    "",
    "",
    "",
    "",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this image displays a list of",
    "\ufffd 0.",
    "<|vq_clip",
    " 1.0.0.0.0.0.0.0.0.0",
    "",
    "<|vq_clip_",
    "<",
    "<|vq_clip_12273|>this is a screenshot of",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a table with various columns and rows. the table appears to be a part of a larger document, possibly a report or a spreadsheet. the columns are labeled with different categories such as \"name\", \"date",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip",
    "",
    "",
    "",
    "",
    "<",
    "",
    "",
    "",
    " recruiter 4.0.0.0.0.0.0.0.0.0.",
    "",
    "",
    "",
    " ",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is",
    "",
    "",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the items are labeled as \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", and \"10\". each item has a different color and a different shape. the table appears to be a part of a larger document or presentation. the items are arranged in a grid-like pattern, with each item having a different color and shape. the table appears to be a part of a larger document or presentation.",
    "<|vq",
    "",
    "",
    "",
    "acy<|vq",
    "<|vq_clip",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "",
    "",
    "<",
    " \u0bae\u0bc2\u0b9f",
    "",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_",
    "",
    "",
    "<",
    "\u09be<|vq_clip_12273|",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "",
    "",
    "",
    "",
    "<|vq",
    "<|vq_clip_122",
    "\ufffd<|vq_clip_12273|",
    " 1.",
    "<|vq_clip_12273|>this image displays a list of items in a shopping",
    "ER 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this is a screenshot of",
    "\u0435\u043d<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_12273|>",
    "\ufffd<|vq_clip",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black background. the code is a function that calculates the sum of two numbers and returns the result. the function is called \"sum",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "",
    "File",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a person named \"sara\" and the other user",
    "<|",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    "<|vq_clip_12273|",
    " .. ..  ..",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "g",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that",
    " \n\nIt seems like your message got garbled",
    "",
    "S",
    "<|vq_clip_12273|>",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. Could you clarify or provide more details about what you need help with? Whether it's a specific question or a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says",
    "<|vq_clip_12273|>this image displays",
    "<",
    "<|vq_clip_12273|",
    "",
    "lassic<|vq_clip_12273|>this is a screenshot of a website's login page. the page has a black background with a white text box",
    "<|vq",
    "",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a",
    "ATION<|vq_clip_12273|>this is a screenshot of a conversation",
    "",
    "",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot",
    "",
    "",
    "<",
    "<|vq_clip_12273|>this is",
    "<",
    "<|vq_clip_12273|>",
    "",
    " 1.0.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new message to be sent to a user named \"sudhir\" and the other",
    "an<|vq_clip_12273|>this is a screenshot",
    " \u33c2 \u33c2 \u33c2 ",
    "\ufffd<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a",
    "<|vq_clip_12273|>this is a screenshot of a website that provides information about the 2022-2023 season of the ",
    " 1.0.0.0.0.",
    "<|vq_clip_12273|>this is a",
    "ier<|vq_clip_12273|>this is",
    "\n\nIt seems like your message got a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    " \n\n",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>",
    "\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n```\n\nThe output",
    "<|vq_clip_12273|>this image",
    "ors<|vq_clip_12273|>",
    "<",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a chat conversation between two users. the first user, \"sarah\",",
    "<|vq_clip_12273|>this image displays a",
    "exion<|vq_clip_12273|",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections, one for the product and the other",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this image displays a list of items in",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a",
    "<",
    "\ufffd 1.0.0.",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq",
    "<|vq_clip_12273|>",
    "\ufffd<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers. it has a variable named \"sum\" and a function named \"sum\". the code editor also has a line of code that says \"sum = 0\". the script",
    "<|vq_clip",
    "<|vq_clip_",
    "<|vq",
    "a<|vq_clip_12273|>this is a screenshot of a code editor",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<|vq_clip_",
    "\ufffd 1.0.0.0.0.0.0.0",
    " \n\n```\n\nIt seems like your",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the items are arranged",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking",
    "<|vq_clip_12273",
    "String) \n\n``` \n\n",
    "<|vq_clip_122",
    "<|vq",
    "<",
    "<|vq_clip_12273|>this image displays a list of files and folders",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app.",
    " \ufffd<|vq_clip_122",
    "<",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with a particular topic, feel free to clarify or ask again! I'm here to help",
    "\ufffd<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "",
    "Indicator>\n\nIt appears that the text you provided is a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a screenshot of",
    "ir<",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a code editor",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app.",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column, with each item having a unique name and",
    "thritis<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a screenshot of a conversation between two users. the user is also asking for a screenshot of a conversation between two users. the user is also asking",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman.",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a function called \"def",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the code is written in a dark background with a green text. the editor has a dark theme and a black background. the code is written in a dark",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>",
    "|vq_clip_122",
    "```\n\nIt seems like your message got garbled or mixed up with a",
    "an<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is",
    " ",
    "<|",
    "ST",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|>",
    "<",
    "",
    "",
    "s<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>",
    "at<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a code editor",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is",
    " 1.0.0.0.0.",
    "APTERS<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman",
    "<|vq_clip",
    "<|vq",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"a\", \"b\", \"c",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this image displays a list of items in a shopping",
    "able 1.0.0.0.0.0.0.",
    "\ufffd ",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot",
    " \n\nIt seems like your message got gar",
    "\ufffd 1",
    "  0  ",
    "<|",
    "re 1.0.0.0.0",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273|>",
    "<",
    "<|",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a screenshot of a conversation between two users. the user is also asking for a screenshot of a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this",
    "<|",
    "<|",
    "<|vq_clip_12273|>this image",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of",
    " \u12ed \u12ed \u12ed \u12ed \u12ed",
    "<|vq_clip_",
    "<",
    "* .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..",
    "able \n\n[END OF CONVERSATION]",
    "ments",
    "<|",
    "\ufffd 0\ufffd 1\ufffd 2\ufffd 3\ufffd 4\ufffd 5\ufffd 6\ufffd 7\ufffd 8",
    "ghextension<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq_clip_12273|>this image displays",
    "\ufffd<",
    "S<|vq_clip_12273|>this image displays a list of 10 items in a table format. the first item is \"",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for",
    "\u0440\u0430<|vq_clip_12273",
    " 1.5.0.0.0.0.0.0.0.0.0.0.0.0.",
    "",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer,",
    "<|",
    "<|",
    "<|vq",
    "<",
    "<|vq_clip",
    "<|",
    "enerate<|vq_clip_12273|>this image displays a list of items in a database. the",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_",
    "gg\u0151<|vq_clip_12273|>this is a screenshot of a code editor",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a",
    "<|vq_clip_",
    "atopics \n\n```\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with a particular",
    "<|vq_clip_12273|>this image displays a list",
    "<|",
    "",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation is in a language that appears to be a mix of english",
    "<|vq_clip_12273|>",
    "ow ",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<|",
    " \n\nIt seems like your message got gar",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"a",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of",
    "",
    "",
    "",
    "<|vq_clip_12273|>this image displays a list of",
    "",
    "<|vq_clip_",
    "",
    "",
    "itudinal<|vq_clip_12273|>this is",
    "] ",
    "<|vq_clip_12273|",
    " \u12e8 \u12e8 \u12e8 ",
    "ions<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<|vq_clip_12273|>this is a",
    "\ufffd 1.0.0.0.0",
    "<",
    "<",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the",
    "",
    " \n\nIt seems like",
    "<|vq_clip_12273|>",
    "",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "\ufffd 1\ufffd 2\ufffd ",
    "",
    "<|vq_clip_12273",
    " ",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "ed<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written",
    "<|vq_clip_12273|>this image displays a",
    "",
    "<|vq_clip_122",
    "<|vq_clip_",
    " \n\nIt seems like the text you provided is a mix of multiple languages and contains a lot of unrelated content. If you have a specific question or need assistance with a particular topic, please let me know, and I'll do my best to help!\n\nIt looks like your message got a bit",
    " ",
    "es . .  .  .  .  .  .  .  .  .",
    "p<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__main",
    "<|vq_clip_12273|>this",
    "<|vq_clip_122",
    "akken<|vq",
    " \n\nIt seems like your message got garbled",
    "",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text.",
    "<|vq_clip_12273|>this is a screenshot of a website's login page. the page is divided into two sections, with the left side displaying a login form and the right side showing a list of user accounts. the login form has fields for username, password, and email. the user accounts section has a list of user names",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "k<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    " \n\nIt seems like there was a mix-up",
    "<|vq_clip_12273|>this image displays a table",
    "",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the items are labeled as \"1\", \"2\", \"3\", \"4\", \"5\",",
    "<",
    "<|vq_clip_12273",
    "<",
    " ",
    "<|vq_clip_12273|>this image displays a list of items in a database. the items include \"c\" and \"c\" with a total of 5. the list also includes \"c\" and \"c\" with a total of 5. the items are displayed in a table format, with the \"c",
    "age \u33c4\ufffd<",
    "<|vq",
    "",
    "<|vq_clip_122",
    "\ufffd\ufffd\n\n[",
    "<|vq_clip_12273|>",
    "<|",
    "ENTION \n\nIt looks like your message got garbled or mixed up with a lot",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script",
    "<|vq_clip_122",
    "<",
    "",
    "<|vq_clip_12273",
    "",
    " 1.0.0.0.0.0.0.0.0.0.0.0",
    "",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function",
    "ViewModel<|vq_clip_12273|>",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "",
    "<|vq_clip_12273|>this",
    "\u043d<|vq_clip_12273",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    " \n\nIt seems like your message got garbled or mixed up with a",
    "<|",
    "/obligations<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip_12273|>this is a screenshot of",
    ")",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>this image displays",
    "View ",
    "<|",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "ers<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "vironmement<|vq_clip_12273|>this is",
    "<|vq_clip",
    "",
    "",
    "",
    "<|vq_clip_12273",
    "<",
    "<",
    "<|vq_clip_12273|>",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "<|vq",
    "",
    "<|vq",
    "<|vq_clip",
    "",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include",
    "",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is",
    "at",
    " ",
    "<",
    "<",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>this image displays",
    "<",
    "<|vq_clip_12273|>this image displays a table of data with various columns and rows. the table appears",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d",
    "",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of",
    "ing 0.0.0.0.",
    "<|vq_clip_12273|>this",
    "",
    "",
    "<|vq_clip",
    " 1.0.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black background. the code is a function that calculates the sum of two numbers and returns",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include",
    "i ",
    "<|vq_clip_12273|>this image displays a list of files and folders in a directory",
    "",
    "<",
    "<|vq",
    "",
    "s<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a",
    "ion",
    "<|vq_clip_",
    "<|vq_clip_12273",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays",
    " ",
    "<|vq_clip_12273|>this image displays a list of items in",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. Could you clarify or",
    "\n\nIt seems like your message got a bit garbled. Could you clarify what you need",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "an<|vq_clip_12273|>this image displays a list of",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "",
    "<|vq_clip_12273|",
    " `\n\n[conversation ends]",
    "",
    "<|vq_clip_12273|>this image displays a list of items",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    " ",
    "<|vq_clip_",
    "<|vq_clip_12273",
    "it",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "\u09a8\u09be\u09a8<|vq_clip_12273|>this",
    "Of 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "ament<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has",
    "<",
    "\ufffd<|vq_clip_12273|>this image displays a list of items in a table format.",
    "<|vq_clip_12273",
    "",
    "",
    "Manager<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"print('hello world')\". the code editor also has a line of code that says \"print('hello world')\". the script is",
    "",
    "<|vq_clip_12273|>this is a",
    "\ufffd<|vq_clip_12273|",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>",
    "<",
    "",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a website's login page. the page has a dark background with a white text box in the center.",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d",
    "",
    "",
    "<|vq_clip_12273|>this image displays a list of items in",
    "<|",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|",
    "<|vq_clip_",
    "",
    "readsheet \u12e8 \u12e8 \u12e8 \u12e8 \u12e8 \u12e8 \u12e8 \u12e8 \u12e8 \u12e8 \u12e8 \u12e8 \u12e8 \u12e8 \u12e8 \u12e8 ",
    "",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written",
    "",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this",
    "ational<",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include",
    "iffer",
    "<|vq_clip_12273|",
    " \n\nIt seems like your message got garbled or mixed up with",
    "<|vq_clip_12273|>this image displays a list of files and folders in a computer's file explorer. the list includes various files such as \"file 1\", \"file 2\", \"file 3\", and \"file 4\".",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    " ",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections",
    "<|vq_clip_",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column with a header that reads \"item name\".",
    "<|vq_clip_12273|>this is",
    "",
    "",
    "",
    "",
    "<|vq",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you",
    "<|vq_clip_12273|>",
    "<|",
    "<|vq_clip_12273|>this is",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items include \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\",",
    "able<",
    " 1.0.0.0.0.0.0.0.0.0.0.0",
    "",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "ital",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this",
    "s ",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|vq_clip_12273|>this image displays a list of 10 items, each",
    "<|vq_clip_12273|>this",
    "ave 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of",
    " ",
    "<|vq_clip_",
    "<|vq_clip",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|",
    "awn<|vq_clip_12273",
    "\u09be\u09b0<|vq_clip_12273|>",
    "<",
    "\u0435\u0439\u0441\u044b<",
    "",
    "",
    "",
    "",
    "",
    "",
    " 1.0.0.",
    "",
    "",
    "ungs<|vq",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a",
    "<",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|>this image displays a list of items in a table",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include",
    "<|vq_clip_12273|>",
    "",
    "",
    "",
    "\ufffd 0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "ilated<|",
    "\ufffd 0\ufffd 0\ufffd 0",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is",
    "\u0434<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq",
    "\ufffd 1\ufffd 1",
    " 1",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip",
    "<|",
    "",
    "ed<|vq_clip_122",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script",
    "<|vq_clip_12273",
    "<|vq_clip",
    "s<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of files and folders in a directory. the files are named \"file",
    "<|vq_clip_12273|>this is a screenshot of",
    "",
    "",
    ">",
    " 0\ufffd 1",
    "",
    "",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a website's login page. the page is in indonesian and has a form for",
    "<|vq_clip_12273|>",
    "ates<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    " 1.0.",
    "<|vq_clip_12273|>this is a screenshot of a website that provides information about the 2022 world cup",
    "",
    "",
    "<|vq_clip_122",
    "  1. **\"The Great Gatsby\" by F. Scott Fitzgerald** - This novel is a classic of American literature, known for its exploration of the American Dream and the decadence of the Jazz Age. It is often studied in high",
    "",
    "",
    "ization<|vq_clip",
    "",
    "",
    "",
    "",
    "<",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip",
    "",
    "",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|",
    " \n\n```\n\nIt seems like your",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "<|vq_clip",
    " \n\n```\n\nIt seems like your message got garbled",
    "<",
    "<",
    "<|vq_clip",
    "\u00e9<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a response to a question about a user named \"sudhir\" and the user is responding with a message",
    "<|vq_clip_12273|>",
    "adovate<|vq_clip_12273|>this",
    ")",
    "",
    "",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of a",
    " 1.0.0.0.0.0.",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the",
    " \n\nIt seems like your message got a bit garbled. Could you clarify what you need help with? Whether it's a specific question or a general topic, I'm here",
    " ",
    "",
    "",
    "<",
    "",
    "",
    "",
    "",
    " ",
    "",
    "",
    "<|vq_clip_",
    "",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need",
    "\ufffd<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    " .. ",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers.",
    "<|vq_clip_12273|>this code",
    "<|vq_clip_12273",
    "<|vq_clip",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "<|",
    "",
    "ldatabase<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "",
    "",
    " ",
    "<|vq_clip_122",
    "",
    "",
    "",
    "<|vq",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    "String",
    "",
    "",
    "",
    "",
    "",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel free to ask!\n\nIt looks like your message got a bit",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this image displays a list of items in a database. the first item is a \"c\" and the second",
    "",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\"",
    "<|",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a",
    "",
    "",
    "",
    "",
    "z<|vq",
    " .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..",
    " \n\n \n\n  1. **\"The Art of the Deal\"** - A classic that offers insights into negotiation and business strategy.\n  2.",
    "ation<|vq_clip_12273|>this image displays a list of",
    "",
    "<|vq_clip_12273|>this",
    "<|vq_clip",
    "",
    "",
    "",
    "<|vq_clip_122",
    "",
    "<|vq_clip_12273|>",
    "",
    "",
    "<|vq_clip",
    "\u0430\u043b<|vq_clip_12273|>this image displays a list of files and folders in a directory.",
    "<|vq",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo",
    "Type<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this image displays a list of items",
    "rew<",
    "",
    "i<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to be added",
    "<|vq_clip_12273",
    "",
    "",
    "ed",
    "<|vq_clip_",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with",
    "\u0bc1 .. .. ",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the function is called \"sum\" and it takes two arguments",
    "<|vq_clip_12273",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip",
    "<",
    "\ufffd 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip",
    "",
    "",
    "",
    "<|",
    " ",
    "",
    "<",
    "",
    "\ufffd ",
    "\u09ac<|",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for",
    "ics<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the",
    "",
    "",
    "",
    "<|vq_clip_12273|>this image displays",
    "<|vq",
    "",
    "",
    "",
    "<",
    "<|vq_clip_12273|",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation is",
    "<|vq_clip_12207|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a code to create a new user account. the",
    "poses<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip_12273|>this image displays a list of files",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot",
    "",
    "",
    "<",
    "<|vq_clip_122",
    "<",
    " .. ..  ..  ..  ..  ..  ..  ..  ..",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the",
    "<|vq_clip_12273|>",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>",
    " 1.0",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and",
    " ",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot",
    "s<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the",
    "",
    "<",
    "<|vq_clip_12273|>this image displays a list of items",
    " 0",
    "",
    "\ufffd<|vq_clip_12273|>this code snippet is from a python script that is used to create a new user in a database. the script is written in",
    "<|vq",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_",
    "<|",
    "\ufffd 1. 1. 1. 1. 1. 1. ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to be added to the conversation",
    "<|vq_clip_",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code editor has a dark background with a green line",
    "",
    "<|vq_clip",
    "<|vq",
    "\u043e\u043b\u044c\u043d\u044b\u0439 2.0.0.",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|",
    "<|vq_clip_",
    "<|vq_clip_122",
    " ",
    "<|vq",
    "<|vq_clip_122",
    "<|vq",
    "<|vq_clip",
    " \n\nIt seems like the text you provided is a mix of multiple languages and appears to be a random or corrupted text. It doesn't seem to be a coherent or meaningful passage. If you have a specific question or if there's a particular part of the text you'd like me to help with, please",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person who is a student and is asking for a photo of",
    "ate",
    "\u0629<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a screenshot of a conversation between two users. the user is also asking for a screenshot of a conversation between two users. the",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "\u0e32<|vq_clip_122",
    "art<|vq_clip_12273|>this is a screenshot",
    "",
    "",
    "",
    "<|vq_clip_12273",
    "y<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    " 0.0.0.0.0.0",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "<",
    "<|vq_clip_",
    " \n\nIt",
    "<|vq_clip_12273|>this code snippet is from a python script that is used to create a new user in a database. the code is written in a dark background with a green",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a",
    "",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format",
    "",
    "",
    "",
    " 1.0.0.0.0.0.0",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "an<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "\u09be<|vq_clip_12273|>this image displays a list of items in",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column with a header that reads \"item\". the",
    "zn\u00e9<|vq_clip_12273|>this is a screenshot of a website",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app.",
    "<|vq",
    "<|vq_clip_12273|>this image",
    "**Note**: The above text is a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the items are arranged in a grid, with the first item",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the",
    "<|",
    "<",
    "<|vq_clip_12273|>",
    " \n\n",
    "<|vq_clip_",
    "<",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is",
    "er<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|",
    "",
    "",
    "",
    "",
    "",
    "<|vq",
    "",
    "<|vq_clip_12273|>",
    "<",
    "",
    "",
    "VE<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "vedic \ufffd\ufffd<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|>this image displays a list of",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named",
    "<|vq_clip",
    "<|vq_clip_12273|>this is",
    "odernity<|",
    "<|vq_clip_12273|>",
    "<",
    "<",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>this is a",
    "<|",
    "<|vq_clip_12273",
    "lge<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"item",
    "<|",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape.",
    "S 1",
    "<",
    "<",
    "\ufffd 1.0.0.0.",
    "",
    "<|vq_clip_",
    "<|",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "ent \n\nIt seems like your message got garbled",
    "\ufffd 0\ufffd 0\ufffd 0",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code editor has a dark background with a green line of code. the script is written in a dark theme and contains a",
    "<|",
    "icord<|vq_clip_12273",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to be added to the conversation, and the other user is responding with a message",
    "",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with a particular",
    "culine<|vq_clip_12273",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_",
    "",
    "",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this image displays a table with various columns and rows. the table appears to be a data",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_",
    " ..'s ..'s  ..'s  ..'s  ..'s  ..'s  ..",
    "<",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme",
    "\ufffd 0\ufffd ",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a",
    ")",
    "",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a response to a question about a user",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\",",
    "<",
    "",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd ",
    "",
    "er<|vq_clip_12273|",
    "<|",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this",
    "posite<|vq_clip_",
    "",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation appears to be in a language that is not familiar to the user. the user is asking for a photo of a person named \"sara",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|>this is a screenshot",
    "",
    "",
    "itional<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_122",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and",
    "<|vq_clip_12273|>",
    "ing<",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation appears",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform",
    "<|vq_clip_12273|>this is a screenshot of a website that provides a list of 1000+ websites that are not allowed to be used for a specific purpose",
    "\u0430\u043b<|vq_clip",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|",
    "",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the",
    "",
    "",
    "",
    "<|vq_clip_12273|>",
    "<",
    "",
    "",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column with the name \"item\" and the quantity \"1\". the table also includes a column for the item name and the quantity. the items are listed in",
    "<|vq_clip_12273|>this is",
    "ir<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "ed<|vq_clip_12273|",
    "<|vq_clip_12273",
    " \n\n// \n\n//  //  //  //  //  //  // ",
    "<",
    "n<|vq_clip_12273|>",
    " .. \n\nIt seems like your message",
    "",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections, with the left side showing a list of products",
    "\u043d<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two",
    " \ufffd<|",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that",
    "ern<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the",
    "<|vq_clip_122",
    "<|",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the code is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the code is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the code is written in a dark theme and has a line of code that",
    "<|vq_clip_12273|>",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    "",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code editor has a dark background with a green text color. the script is written in a dark theme and contains",
    "<|vq_clip",
    "<|vq_clip_",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>",
    " \ufffd<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer,",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers",
    "",
    "<",
    " 1.",
    "\ufffd ",
    "abed<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is",
    "",
    " 2019\ufffd 2018\ufffd 2017\ufffd 2016\ufffd 2015\ufffd 2014\ufffd 2013\ufffd 2012\ufffd 2011",
    "",
    "",
    "ig<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of",
    "<",
    "",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers",
    "<|vq_clip_12273|>this is a screenshot of a code editor",
    "-",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"",
    "<",
    "<",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot",
    " ",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include",
    "<|vq_clip_12273|>",
    " 2019 ",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<|vq_clip_12273|>",
    "able",
    " ",
    "<",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_",
    "mented<|vq_clip_12273|>this is a screenshot of a conversation",
    "\u0c3f<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<",
    "<|vq_clip",
    "",
    "<|vq_clip_",
    "<",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>",
    "<|vq",
    "",
    "s \n\n",
    "",
    "",
    "<|vq_clip_122",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers.",
    "",
    "",
    " 1. **Data",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|vq_clip_12273",
    "<|vq_clip_122",
    "imize<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person with a black and white background. the other user is responding",
    "cript<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "shire<|vq_clip_12273|>",
    "ations<|vq_clip_12273|>",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this image",
    " 1.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text.",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script",
    "",
    "",
    "",
    "",
    "<",
    "",
    "",
    "",
    "",
    "<|vq",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person who is a friend of the user",
    " \n\nIt seems like",
    "",
    " 1.0.0.0.0.0.0.0.0.0.0.0.",
    "/",
    "<|vq",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format.",
    "",
    "",
    "",
    "",
    "",
    "ote<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column, with each item having",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a",
    "",
    "<|vq",
    "<|vq_clip_12273",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "<|vq_clip_12273|>this is",
    "<",
    "<|vq_clip_12273|>this",
    "",
    "<|",
    ") 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a new message to be sent to a user",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark",
    "",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "",
    "",
    "",
    "",
    "<|vq_clip",
    "",
    "",
    "<|vq",
    "\u00e9s<|",
    "<|vq",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a unique name and description. the items are displayed in a table format, with the",
    "<|vq_clip_12273|>this is a screenshot of",
    "ic<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "",
    "<|vq",
    "<|",
    "<",
    "reater 0\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is",
    " ",
    "<|",
    "* 1.0.0 */\n\nIt seems like your message got garbled or",
    "",
    "<|vq_clip_12273|>this is",
    "",
    "",
    " 1.0.0.0.",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\",",
    ")",
    "<",
    "age<|vq",
    "<",
    "ar<|vq_clip_12273|>",
    "\ufffd 1.0.0.",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"print('hello world')\". the code editor has a dark background with a black text editor. the script is written in a dark theme and has a line of code that says \"print('hello world')\". the code",
    " \n\n```\n\nIt seems like your message",
    "",
    "```\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you",
    "ed<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d",
    "<|vq_clip_12273|>this image displays a list of files and folders in a directory. the files are named \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\",",
    "<",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "\u0441\u0442\u0432",
    "igen<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"",
    "<|",
    "<|vq_clip_",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers. the code is written in a dark theme",
    "<|vq_clip_12273|>",
    " .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named",
    " \n\nIt seems like your message got garbled or mixed up with a",
    "\ufffd<|vq_clip_12273|>this image displays a list of files and folders in a directory.",
    "<|",
    "",
    "",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    "ViewController",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<",
    "\u043d\u043e<|vq_clip_12273|>",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other",
    "<",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has",
    "i",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black background. the code is written in a python language and has a",
    "remainder<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a few lines of code. the code",
    "<|vq_clip_12273|>this image displays a list of",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new message to be sent to a user named \"sarah\". the user is also asking for a new message to be sent to a user named \"sarah\". the user is also asking for",
    "<|",
    "<|vq_clip_12273",
    "",
    "<|vq_clip_12273|>this is a screenshot of",
    "n \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a",
    "ly",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3",
    "ViewController<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip",
    " \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a",
    "<|",
    "",
    "",
    "<|vq_clip_12273|>this image displays a list of files and folders in a directory. the files",
    "",
    " LinkedIn \ufffd ://\n\n[END OF RESPONSE]",
    "",
    "",
    "",
    "",
    "\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\nIt seems like the text you provided is a mix of various languages and characters, and it doesn't form a coherent",
    "",
    "",
    "",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\",",
    "",
    "<|vq_clip_12273|>",
    "] \n\n[END OF RESPONSE]",
    "<",
    "<|vq_clip",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "structions<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "\ufffd<|vq_clip_12273|>this image displays a list of items in a shopping cart",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black background. the code editor is displaying a python script that is used to create a new file. the script is",
    "ational \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_122",
    "<",
    "<|",
    "<",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>",
    "\ufffd 0\ufffd 0\ufffd ",
    "<",
    "ATION<|vq_clip_",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    " \n\nIt seems like your message got garbled",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip",
    "<",
    "<|vq_clip_12273|>this is",
    "ed<",
    "<|vq_clip_122",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman.",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is",
    "View>",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"c\", \"d\", \"e\", \"f",
    " ",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|",
    "<|vq",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers and returns",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    " \n\nIt seems like your",
    "s<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation is in a language",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a",
    "down<|vq_clip_12273",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "",
    "",
    "",
    "",
    "<|vq",
    "",
    "",
    "",
    "",
    "",
    "",
    " 1.0.0.0",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|",
    "",
    "<",
    "",
    "",
    "<|vq",
    "pecial \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3",
    "\ufffd 0",
    " ",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "al<|vq",
    "<",
    "<|vq_clip_12273|>",
    " \n\n",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user",
    "<|vq_clip_12273|",
    "",
    "",
    "",
    "<",
    "ualized<|vq_clip_12273|",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>",
    " \n\nIt seems like there was a",
    "<|vq_clip_12273|>this is a",
    " \ufffd<|vq_clip_",
    "<|vq_clip_12273|>this",
    "",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|>this image displays a list of 10 items",
    "<|vq_clip_",
    "<|vq_clip_12273|>this image displays a list of items in a table format.",
    "",
    "<|vq",
    "\u0bcd<|",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app.",
    "<|vq_clip_12273|>",
    "",
    " .. .. ",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<",
    "Exception<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code is displayed in a terminal window with a black background and white text. the script appears",
    "oved<|vq_clip_",
    "StreamReader> ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    " ",
    " .. ",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black background. the code editor is displaying a python script that is used to create a new user in a database. the script is written",
    "",
    "",
    "",
    "",
    "",
    "",
    " 0\ufffd 0\ufffd 0",
    "<|vq_clip",
    ".**/p",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|>",
    "<",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a",
    "",
    "",
    "",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman with a black hair. the user also mentions that the photo is not a picture of",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the items are labeled as \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", and \"",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this",
    "able<|vq_clip_12273|>this image displays a list of items in a table format",
    "<|",
    "",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the first",
    "<|vq_clip_12273|>",
    " ",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person",
    "<|vq_clip_12273|>this",
    "var<|vq_clip_12273|>this image displays a list of items in",
    "<|vq_clip",
    "<",
    "",
    "",
    "",
    "",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a",
    "",
    "<|vq_clip_12273|>this is a screenshot of",
    "",
    "\ufffd 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "",
    "<|",
    "<",
    "ebook<|vq_clip_12273|",
    "",
    "<|vq_clip_",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "\u043b\u0435\u043d\u0438\u044f<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot",
    "",
    "",
    "",
    "",
    "",
    " ..",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "<|vq",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1",
    "<|vq_clip_122",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with a particular topic, feel free to",
    "<|vq_clip_12273|>this is",
    "\ufffd 0.0",
    "ive<|vq_clip_12273|>this image displays a list of items in a table format",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a person",
    "<|vq_clip_12273|>this is a screenshot of a code editor",
    "ate<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq",
    "",
    "",
    "<|vq_clip_12273|>",
    "",
    "",
    "<|vq_clip_12273|>this is a",
    "<|",
    "or<|vq_clip_12273|>this image displays a list of items in a table format. the",
    "<|vq_clip_",
    "ional<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a",
    "<|",
    "\ufffd<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "ed) \n\n",
    "<|vq_clip_12273|>this is a screenshot of a",
    "Property",
    "tion<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    " \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "iclass \n\nIt seems like your message got",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person with a black and white background.",
    " 1.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip_122",
    "\u09bf<|vq_clip_12273|>this image displays a list of items in a database. the items include \"",
    "",
    "",
    "",
    "<|vq_clip_12273|>",
    "] .. ",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_",
    "<|",
    "ong",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    " 1.0.0.0.0.0.0.0.0.0.0.0",
    "s ",
    "",
    "",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a",
    "<|vq_clip_12273|>this image displays a list of files and folders",
    "<",
    "<|vq_clip_12273|>",
    "<|",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<",
    "<|vq_clip",
    "<|vq_clip_12273|>this is",
    "s",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"v\", \"w\",",
    "",
    "s<|vq_clip_12273|>this",
    "<|vq_clip_12273",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0",
    " ",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is",
    "ing<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a translation of a phrase",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of items in",
    "// 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to be added to the conversation. the user is also asking",
    "inary ",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273",
    "<|vq_clip_",
    "",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273",
    "```\n\nIt seems like your message",
    "<|vq_clip_12273|>",
    "ed<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in",
    "ance<|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    " \n\n[END OF CONVERSATION]",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip_12273|>this image displays a list of",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is",
    "<|vq_clip_12273|>this",
    "uallogin ",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a ",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    " \n\nIt seems like your",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "ug<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a list",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark",
    "<|vq_clip_122",
    "{|}~\n\nIt seems like your message",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the items are labeled",
    "le<|",
    "<|",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is",
    "\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"s",
    "les<|vq_clip_12273|>this image displays",
    "<|vq_clip",
    "<",
    "nce<|",
    "ViewCell \n\nIt seems like your message got garbled or mixed",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    " 2019 \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a",
    "<",
    "<|vq_clip_",
    "",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code is displayed in a black background with white text. the script is written in a python",
    "<|",
    " 1.0.0",
    "<|vq_clip_12273",
    "<|vq_clip",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"1\", \"",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "  1. **\"The Great Gatsby",
    "\ufffd 1.0.0.0.0.0.",
    "\ufffd<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections, one for the product and the other for the product's details. the product section",
    "<|vq_clip_12273|>",
    "<",
    " ",
    " \u0c2e\u0c3e \ufffd ",
    "ay",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user",
    "<|",
    "<|vq_clip_12273|>this",
    "\ufffd 0\ufffd 0",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person who is a friend of the user. the user is also asking for a photo of a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme",
    "<",
    "<|vq_clip_12286|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    " 1.0",
    "",
    "<|vq_clip",
    "<|vq_clip",
    "<|vq_clip_12273|>",
    " 1. ",
    "<|vq_clip_12273|",
    "ures<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the user is also asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation appears to",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column, with each item having a unique name and a description. the table appears to be a part of a larger database or system, as it is",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "\u043e<|vq_clip_12273|>this is a screenshot of",
    "ics<|",
    "<|",
    "<",
    "<|vq_clip_122",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    "\n\nIt seems like your",
    " witnesses 8.0.0",
    "<|vq_clip",
    "ussion<|",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the code",
    "<|vq_clip",
    "Only<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme",
    "<|vq_clip_12273|>",
    "ctor<|vq_clip_12273|>this image displays a list of items in a table format. the items include \"c\", \"c\",",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a chat conversation between two users. the user is asking for a code to be written in python, and the other user is responding with a code snippet. the code snippet is written in python and is used to",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user",
    "<|vq_clip",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the code is written in a",
    "<|vq_clip_12273|>this image displays a list of files and folders in a computer's file explorer. the files are organized",
    "<",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the first item is \"1. ",
    "",
    "<|vq_clip_12273|><|image_border_0|>\n\nIt seems like your message got garbled or",
    "<",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is",
    " ",
    "<|vq_clip_12273|>this is",
    "<|vq_clip",
    "```",
    "<|vq_clip_12273|>this image",
    " \n\nIt seems like",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "<",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot",
    "elles<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<",
    "<|vq_clip_12273|>this",
    "boards<|vq_clip_12273|>",
    "\u0131\u015f<|vq_clip",
    "<|vq_clip_",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    "where<|vq_clip",
    "<|vq_clip_12273|>this is",
    "ed<|vq_clip_12273|>",
    "<|vq_clip_12273|",
    "ar<",
    "<|vq_clip_12273|>this is a screenshot of a",
    "bed<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    "Exception<|vq_clip",
    "re<|vq_clip_12273|>",
    "<|vq_clip",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<|vq_clip",
    "ts `\n\n**Note**: The above text is a placeholder and does not represent a valid or",
    "<|vq_clip_12273",
    "<|vq_122|>",
    "<|vq_clip",
    "\u09be\u09b0",
    "<|vq_clip_12273|",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a table with various",
    "\ufffd<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this image displays a list of items in",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "hetic ",
    "> \n\nIt seems like",
    "<",
    "",
    "",
    "",
    "y<",
    "<|vq_clip_12273|>this image displays a list of items in",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this image displays a list",
    "",
    "",
    " \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "able<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    " \n\nIt seems like your message got garbled",
    "<|vq_clip_12273|>this image displays a list of ",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    "",
    "",
    "",
    "",
    "",
    "idos<|",
    "<|vq",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>",
    "ity<",
    "<",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a",
    "```\n\nIt appears that the text you provided is a mix of multiple languages and contains a large amount of unrelated content. It is not",
    "<|vq_clip_12273|>this is a",
    "ally",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column with the title \"item\" and the quantity of each item. the table also includes a column for the quantity of each",
    "<|vq_clip_12273|>this is",
    " \n\n",
    "<|vq_clip_12273",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>",
    "",
    "<|",
    "<|vq_clip_12273|>",
    "ated<|vq_clip_122",
    "<|vq_clip_",
    ") ",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column, with each item having a unique name and a description. the table appears to be a part of a larger document, possibly a report or a presentation. the items listed in the table are \"",
    "IMARY<|vq_clip_12273|",
    "preted<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman.",
    " 1",
    "",
    "",
    "",
    "",
    "<|",
    " \n\n**Note**: The text above",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip",
    "<",
    "",
    "<|vq_clip_12273|>",
    "<",
    "",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_12273|>this image displays a list of 10 items that are commonly used in a software development project. the items include \"1. 2. 3. 4. 5. 6. 7. 8. 9. 10",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a",
    "",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation appears to be",
    "<|vq_clip",
    "<",
    "ities<|vq_clip_12273|>this image displays a list",
    ") ",
    "<",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo",
    "-<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<",
    "ular 1.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    " 2019",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0",
    "<",
    "<",
    " .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the",
    "<|",
    "<|vq_clip_12273|>this code snippet is",
    " \n\nIt seems like your",
    "String<",
    "\ufffd 1.0.0.0.0.",
    "<|vq",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"s",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column with the name \"item\" and the number \"1\". the table also includes a column for \"item\" and \"item\". the items are listed in a column with the name \"",
    "<",
    "<|vq_clip_12273|>this is a screenshot of",
    "<",
    "<|vq_clip_12284|>this is",
    "<|vq_clip_",
    "<|vq_clip",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_122",
    "",
    "",
    "",
    "",
    "",
    "<|",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a",
    "",
    "",
    "",
    "",
    "",
    " witnesses<|vq_clip_12273|>this is a screenshot of a website that displays a list of products",
    "",
    "",
    "<|vq_clip_12273|>",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the items are",
    " ",
    "",
    "",
    "",
    "<",
    "",
    "",
    "",
    "",
    "<|vq",
    "",
    " \n ",
    "<|vq_clip_12273|>",
    "<|",
    "\u09be<|vq_clip_12273|>",
    "<|vq",
    "<|vq_clip_",
    "us<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the items are arranged in a grid, with each item having a different color and shape",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black background.",
    "<|",
    "<|vq_clip_12273|",
    "<|vq_clip_122",
    "<|",
    "<",
    "<|vq",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a",
    "<|vq",
    "<|",
    "<|vq_clip",
    "<|vq_clip_12273|",
    " .. ..  .. ",
    "<|vq_clip_12273|",
    "",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_122",
    "ut",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "<",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column with the name \"item\" and the number \"1\". the table also includes a column for the name \"item\" and the number \"1\". the items are listed in",
    "<",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|",
    "<|vq",
    "\ufffd 1.0.0.0.0.0.0.0.0.0",
    "```\n\n",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot",
    "h\u014d<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column with a header that reads \"item name\". the table appears to be a part of a larger database or spreadsheet. the items are listed in a column with a",
    "<|vq_clip_12273|>this is",
    "<|vq",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items",
    "",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>",
    "```",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates",
    "<|",
    "<",
    "<|vq_clip_12273|>",
    "<",
    " \n\nIt seems like your message got garbled or mixed",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is",
    "",
    "<|vq_clip_12273|>this image displays a",
    "<|vq",
    "<|vq",
    "ec",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a",
    "<|vq_clip_12273|>this image displays a list of items in a",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a",
    "Controller<|vq_clip_12273|>this is a screenshot of a website's login page. the page has a dark background with a white text box",
    " 1.0.0.0.",
    "<|vq_clip_12273|>this image",
    "",
    "<|vq_clip_12273|>this code snippet is from a python script that is used to create a new user in a database. the code is written in",
    "<",
    "<|vq_clip_12273",
    "",
    "\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections, one for the product",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a person named \"sara\" and the other",
    "",
    "",
    "",
    " \n\n",
    "",
    "",
    "",
    "",
    "sthrough<|vq_clip_",
    "",
    " 1.0.",
    "<",
    " .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  .. ",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme",
    "<",
    "<|vq_clip_12273|>this image displays a list of 10",
    "a \n\nIt seems like your message got garbled or mixed",
    "By<|",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"c\"",
    "<|vq",
    "",
    "",
    "",
    "",
    "",
    " ",
    "",
    " \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections, with the left side showing a list of products and the right side showing a list",
    "<|vq_clip_12273|>",
    " \n\nIt seems like there was a mix-up in the text. If",
    "<",
    " user\n\nIt seems like your message got garbled or mixed up with",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the first item is a \"safety\" item, followed by a \"safety\" item, a \"",
    " 2018 2019 2020 2021 ",
    "",
    "",
    " \u0bae\u0bbe",
    "<|vq_clip_122",
    "",
    "<|vq_clip_",
    "<|vq_clip_12273|>this",
    "\ufffd ",
    "<",
    "<|vq",
    " ",
    "",
    "<|vq_clip_12273|>this",
    "ions \n\n```\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If",
    "",
    "iksaan<|vq_clip_12273",
    "",
    "",
    "<|vq_clip_12273|>this",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "ort<|vq_clip_12273|>this is a screenshot of",
    "",
    "",
    "",
    "",
    "<|",
    "<|vq_clip_12273|>this image displays",
    "",
    "<|vq_clip_12273|>this image displays a list of items in a",
    "<|",
    "inally<|vq_clip_",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections, with the left side showing a list of products and the right side showing a list of products. the left side has a search bar and a filter",
    "",
    "",
    "n<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays",
    "",
    "Text",
    "l",
    "<|vq",
    "<|vq_clip_12273|>this code snippet is from a python script that is used to create a new user",
    "ve",
    "<|vq_clip_",
    "y 1.",
    "i<|vq_clip_12273|>",
    "ing<|vq_clip_12273|>this is a screenshot of a conversation",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    " 1.",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this image displays a list of items in a",
    "<|vq_clip_12273|>this image displays a list of",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code",
    " \n\nIt seems like there was a",
    "<",
    "",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_122",
    "<|vq_clip",
    "<|vq",
    "<|vq",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this image displays a",
    "",
    "i\ufffd 1.0.0",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation appears",
    "",
    "<",
    "",
    "",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated",
    "",
    "<|vq",
    "l",
    "i\ufffd ",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot",
    "<",
    "<|vq_clip_12273|>this is a screenshot",
    "Set<|vq_clip_12273|>this is",
    "",
    "<|vq",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items",
    "",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>this image displays a list of items in a database. the first item is a \"name\" field, followed by a \"description\" field. the second item is a \"name\" field, followed by a \"description\"",
    "<|vq_clip_122",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    "",
    "<|vq_clip",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products.",
    "<|vq_clip_12273|>this image displays a list",
    "",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|",
    "<|vq_clip_",
    "<|vq_clip_12273|>this image displays",
    "<|",
    "",
    "",
    "",
    "icatio<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black background. the code is written in a python language and has a function called \"def\" that is used",
    ") \n\n``` \n\nThe above is a large block of text that is not relevant. It seems the assistant responded with a huge block of nonsense. The user",
    "ations",
    "",
    "",
    "<|vq_clip_",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this image displays a list of items in a database. the items are listed in",
    " 1.0.0.0.0.0.0.0.0.0.0",
    " \n\n```\n\nIt seems like your",
    " 1.0",
    "<|vq_clip_12273",
    "ized<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code is",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code is displayed in a black background with white text. the script appears to be a part of a larger project, as it is written in a dark theme and has a",
    "<|vq",
    "",
    "",
    "<",
    "",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|>this image",
    "",
    "",
    "",
    "",
    "",
    "ience<|vq_clip_12273|>this image displays a list of",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the",
    "<|vq_clip_12273|>",
    "",
    "",
    "",
    "",
    "ar",
    "<|vq_clip_122",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"print('hello world')\". the code editor also has a line of",
    "<|vq_clip_12273|>",
    "",
    "",
    "",
    "agated \n\n[END OF TEXT]",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "",
    "",
    "",
    "",
    "ote<|vq_clip_12273|>this image displays a list of items",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "> \n\n// 1. 2",
    "<|vq",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip_122",
    "",
    "<|vq",
    "<|vq_clip_",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq_clip_122",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a",
    "<",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is",
    "ed) \n\n[END OF CONVERSATION]",
    "\ufffd\n\nIt seems like your message got garbled or mixed up with a lot of unrelated",
    "",
    "\u0bbf<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    " \n\nIt seems",
    "<|vq_clip_12273|>this is",
    "ive<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person who is a student and is asking for a photo of a person who is a student. the user is also asking for a photo of a person who is a student and is asking for a photo of a person who",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"c\", \"d",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the function is called \"sum\" and it takes two arguments, \"a\" and \"b\". the script",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3",
    "<",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum",
    "<",
    "<|vq_clip",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a few lines of code. the code appears to be a function that takes in a string",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "<|vq_clip",
    "way<|",
    "",
    "<",
    "<|vq_clip_12273|>this is",
    "<|vq_clip",
    "<|vq_clip_12273|>",
    " 1.0.0.0.0.0.0.0.0.",
    "eyond<|vq_clip_",
    " ",
    "\u0438\u0438 1.0.0.0.0.0.0.",
    "",
    "",
    "",
    "<",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the first item is a \"c\" with a \"",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items in a database.",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<|vq_clip_12273|>this image displays a list of items",
    "<|vq_12273|>",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a code editor",
    "<|vq_clip_",
    "<|",
    "<|vq_clip_12273|",
    "<|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written",
    "\u043d<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "<|",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip_12273|>this image displays a list of ",
    "(suspenders<|vq_clip_122",
    "<|",
    "s",
    " ",
    "<|vq_clip_122",
    "",
    "",
    "",
    "",
    "\n\n[",
    "<|",
    "aring<|vq_clip_12273|>this is a screenshot of",
    "ations",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip_12273",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. Could you clarify or restate your question or the topic you'd like to discuss? I'm here to help!\n\nIt looks like there was a mix-up in the text. Could you clarify what you'd like to discuss or ask about? I'm ready to help!\n\nIt seems like there was a mix-up in the text. Could you clarify what you'd like to discuss or ask about? I'm ready to help!\n\nIt looks like there was a mix-up in the text. Could you clarify what you'd like to discuss",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column, with each",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the",
    "ather \ufffd ",
    " .. ..  ..  ..  ..  ..  ..  ..  ..",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"v\", \"w\", \"x",
    "<|vq_clip_",
    "",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a single line",
    "nowledge",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "ination<|vq_clip_12273|>",
    "s<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d",
    "<|vq_clip_12273|>this is",
    "",
    "",
    "",
    "",
    "",
    "<",
    "<|vq_clip",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black background. the code is",
    "<|vq",
    "<|",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the items are arranged in a grid, with each item having a unique shape and color. the first item is a blue square with a",
    " \n\n**Note**",
    "<|vq_clip_12273",
    "ents",
    "<|",
    "\u043e\u0439",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled",
    "w",
    "aus<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\"",
    " ",
    "<|vq_clip",
    "<|vq_clip_",
    "<",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    " \u33c2\ufffd \u33c2\ufffd \u33c2\ufffd \u33c2",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column with the name \"item\" and the quantity \"1\". the table also includes",
    "<|vq_clip_",
    "",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a website that provides information about the 2022-202",
    " ",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "ivatives<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<|vq",
    " \n\nIt seems like your message got gar",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f",
    "<|",
    "",
    "",
    "",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column with a number of items and a total of 1",
    "<",
    "<|vq_clip_12273|>this is",
    "ary<|vq_clip_12273|>this code snippet is from a python",
    " ",
    "<|vq_clip",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the function is",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column, with each item having a different name and description. the first item is \"samsung s7\", followed by \"samsung s7 ",
    "<|vq_clip_12273|>this is",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "",
    "",
    "",
    "",
    "<",
    " \n\nIt seems like your message got garbled or mixed up",
    "<|",
    "<",
    "<",
    "<|vq_clip_12273|>",
    "ighboring \n\n",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart.",
    " ",
    "<|vq_clip_12273|>this image displays a list of items in a",
    "_SAMPLE<|vq",
    "<|vq_clip_12273",
    "a",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a list of",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    " 1.0.0.0.0.0.0.0",
    "",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "",
    "",
    "",
    "<",
    "<|vq_clip_12273|>this image",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip",
    "<",
    "<|vq",
    "<|vq",
    "",
    "Context",
    "<",
    "Text .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  .. ",
    "<|vq",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer,",
    " 1.0.0.0.0",
    "  1\ufffd 1",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items",
    "ation 1.0.0",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation appears to be in a language that is not familiar to the user. the user is asking for a photo of",
    "at \ufffd \ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that",
    "<|vq_clip_12273|>",
    "ro 1.0.0.0.0.0.0.0.0.0.0.0.",
    " witnesses witnesses witnesses witnesses witnesses witnesses witnesses witnesses witnesses witnesses w",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a person named \"sara\" and the",
    " ",
    " 2019 201",
    "\n\n// 1. 2. 3. 4. ",
    "or<|vq_clip_122",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person who",
    "<",
    "<|vq_clip_122",
    "ic<|vq_clip_",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "ED .. ..  ..  ..  ..  ..  ..",
    " \n\nIt",
    "\ufffd 1.0.0.0",
    "<|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    " \ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<",
    "<|vq_clip_12273|>",
    "\u03b8\u03ae\u03bc\u03b1\u03c4\u03b1 ",
    "quate<|vq_clip_12273|>",
    " \n\nIt seems like your message got gar",
    "ar<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a",
    "ational<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the code is written in a dark theme and has a line of code that says \"if",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app.",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"a\", \"b\", \"c\", \"d\", \"e\",",
    "ization<|vq",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|",
    "<|vq_clip_12273|>this image displays a list of 10 items in",
    "\ufffd 1.0.0.0.0.0.0.0.0.0",
    "",
    "",
    "",
    "\u09be<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273",
    " \n\n[END OF RESPONSE]",
    "ized<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_122",
    "<|vq",
    "",
    "",
    "",
    "<|vq_clip_",
    "<|vq",
    "<|vq_clip",
    "<|vq_clip_122",
    "<|vq_clip_12273",
    "<|",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column, with each",
    "",
    "",
    "",
    "",
    "",
    "",
    "State",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart",
    "<|vq_clip_122",
    "",
    "<|vq_clip_12273|>this image displays a list of files and folders in a directory. the files are named \"c\", \"c",
    "\ufffd<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a",
    "\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    " \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a person named \"sara\". the conversation is in a language that appears to be in a different script, possibly in a language that is not familiar to the user. the user is asking for a photo of a person named \"sara\" and the other user is",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code is displayed in a black background with white text",
    "<|vq_clip_12273|",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections, one for the product and the other for the product. the product section",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a ",
    "",
    "<|vq_clip",
    "",
    "",
    " \ufffd ",
    "",
    " .. ",
    " ",
    " ",
    "P\ufffd ",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__",
    "",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this image displays",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "\ufffd ",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme",
    "<|vq_clip_12273|>",
    " .. ..  ..  ..  ..  ..  ..",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this image",
    "it<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a website's login",
    "",
    "<",
    "<|vq_clip_12273",
    "",
    "<|vq_clip_12273|>",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the code is written in a dark background with a green line",
    "<|vq_clip_",
    "<|vq_clip_12273",
    "",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip",
    "",
    "<|vq",
    "",
    "```\n\nIt seems like there was a mistake in the previous response. Let me provide",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"s",
    "",
    "\u0443\u0447\u0435\u043d<|",
    " \ufffd\u09be<|vq_clip_12273",
    "\u043d\u0438\u043a<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation is in a language that appears to",
    "\u0633<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this image displays a list",
    "ity",
    "<|vq_clip_12273|",
    "<",
    "<|vq_clip_12273|>this image displays a list of 10 items",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d",
    "\u0c32<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot",
    "s<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to be added to the conversation, and the other user is",
    " \n\n```\n\nIt seems like your message got gar",
    "",
    "<|vq_clip_",
    "",
    "\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to be added to the conversation. the user is also asking for a",
    "<|vq_clip_12273|>this image displays a list of items in a database. the items include \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"a\", \"b\", \"c\", \"d\",",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this image displays a list of 10 items",
    "ence",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "\n\n",
    "<",
    "<|",
    "<|vq_clip_12273|>",
    "",
    "",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|",
    "<",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel free to clarify or ask again!\n\nIt looks like your message got a bit",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the items are arranged in a grid, with each item having a different color and shape",
    "\ufffd 1.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>",
    "<|vq_clip_",
    "<",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_",
    "<|vq_clip_12273",
    "<|",
    " \n\nIt seems like your",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<",
    "<|vq_clip_12273|>this image displays a list of files and folders in a computer's file explorer. the files are organized in a hierarchical structure, with the main folder being \"c:\\users\\michael\\documents\\my files\". the subfolders are \"c:\\users\\michael\\documents\\my files\\my files\". the main",
    " ",
    " \n\n \n\n  1. **\"The Art of War\" by Sun Tzu** - This ancient Chinese text is a",
    "<|vq_clip",
    "<|vq",
    "",
    "",
    "",
    "",
    "istency<|vq_clip",
    " ",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation is in a language that appears to be in a",
    "<|vq_clip_12273|>this image displays a list of files and folders in a computer's file explorer. the files are organized in a hierarchical structure, with the main folder being \"c:\\users\\michael\\",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "<|vq",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a",
    "",
    "<|vq_clip_12273|",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in python and it is used to create a new file. the script is used to create a",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    ") 1.0.0.",
    "<|vq_clip_12273|>",
    " .. \ufffd \ufffd  \ufffd  \ufffd  \ufffd  \ufffd  \ufffd  \ufffd ",
    "ate \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with a particular",
    "",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "<|vq_clip_12273|",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark",
    " 0.0.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of",
    "<",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text",
    "<|vq_clip",
    "<|vq_clip_12273",
    "",
    "",
    "<|vq_clip_12273|",
    "",
    "",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "\ufffd<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the items are labeled as \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"",
    "<",
    "<|vq_clip_12273|>this is a",
    "<",
    " \n\n```\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text",
    "",
    "CTION \n\nIt seems like there was a mix-up in the",
    "<|vq_clip_122",
    "<|",
    "<|vq",
    "<|vq_clip_12273|>this image displays a list of items in a database. the items are listed in a table format, with each item having a unique name and description. the items are organized by their respective categories, such as \"item 1\", \"item 2\", and \"item 3\". the table also includes a column for the item name, which is \"item 1\". the",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this",
    "<|",
    " .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..",
    "",
    "<|vq_clip_12273|>this image displays a list",
    " \n\nIt seems like the text you provided is a mix of multiple languages and contains",
    "<|vq_clip_",
    "",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the function is called \"sum\" and it takes two arguments, \"a\" and \"b\". the script also contains a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of",
    "red<|vq_clip_12273|>",
    " .. ..  ..  ..  ..  ..  ..  .. ",
    "<|vq_clip_122",
    "ed<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot of",
    " .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..",
    "<|vq_clip_12273|>",
    "\ufffd 1\ufffd 1\ufffd 1",
    "<|vq_clip_12273|>this is a screenshot of",
    "",
    "<|vq_clip_12273",
    "ing",
    "<|",
    " ",
    "<|vq",
    "o",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers and returns the result",
    " 1.0.0.0",
    "<|vq_clip_12273|>this is a screenshot of a",
    "ard<|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black background. the code editor is displaying a python script that is used to",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the items are arranged in a grid, with each item having a different color and shape. the items are labeled with numbers and letters, and the colors are varied. the items are arranged in a grid, with each item having a",
    "LObject<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers. it has a variable named \"sum\" and a function named \"sum\". the code editor also has a function named \"sum\" that calculates the sum of two numbers. the script",
    "<|vq",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is",
    "<|vq_clip_",
    "reciate<|vq_clip_12273|>this image",
    "<",
    " 1.0.0",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation appears",
    "<|vq_clip_12273|>",
    "ian<|",
    "<|vq_clip_12273|>this image displays a list of items",
    "<",
    "<|",
    "<|vq_clip_12273|>this image displays a list of items in",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "etion\ufffd 0\ufffd 0\ufffd 0",
    "<|vq_clip_12273|>this",
    "<|vq_clip",
    "<",
    "<",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with",
    "<|vq_clip_12273|>this image displays a list of",
    "<|vq_clip_12273|>",
    "<|",
    "<|vq_clip_",
    "\ufffd\ufffd\n\nIt seems like your",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with a particular topic, feel free to clarify",
    "",
    "",
    "",
    " 1.0",
    "ions<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is",
    "<|vq_clip_",
    " 0.0.0",
    "<|vq_clip_12273|>",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person who is a friend of the user. the user is also asking for a photo of a",
    " \n\nIt seems like there was a mix",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color",
    "<|vq_clip_12273|",
    "<",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a list of functions and variables.",
    "<|",
    "ir<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function",
    " ",
    "<|vq",
    "s \n\n```\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with a particular topic, feel free to ask!\n\nIt looks like your message got a bit mixed up. If",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "",
    "",
    "",
    "iented<",
    "har<|",
    "",
    "<|",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is",
    "<|vq_clip_12273",
    "set ",
    "\ufffd 1.0.0.0.0.0.0.0.0",
    " 2019<|",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a",
    " ",
    "",
    "<|vq_clip_12273",
    "",
    "",
    "ulacja<|",
    " .. ..  ..  ..  .. ",
    "<|vq_clip",
    "<|vq",
    "Beat \n\nIt seems like your message got garbled",
    "",
    "",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_",
    "",
    "",
    "",
    "",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a code editor",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    " \n\n```\n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app.",
    "<|vq_clip",
    "\u043d\u043e",
    "<|vq_clip_12273|>this image displays a list of 10 items that are",
    "<|vq_clip_12273|>",
    "<|",
    "ous<|vq_clip_",
    "",
    " \n\nIt looks like your message got garbled",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking",
    "<|vq_clip_12273|",
    "",
    "",
    "",
    "\u09be<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a black background. the code is a function that takes in a string and returns a string. the function is called \"get\" and it is used to retrieve a string",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this image displays a list of files and folders in a directory. the files are named \"c\" and \"c\" and are located in the \"c\" folder. the files are organized in",
    "<|vq_clip",
    " 1",
    "ighing<",
    " \ufffd<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written",
    "\ufffd<|vq_clip_12273|>",
    "",
    "",
    " \n\n ",
    "u 0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "ire<|vq_clip_12273|>",
    "",
    "",
    "",
    "<",
    "",
    "",
    "<|vq_clip",
    "",
    "",
    "<|vq_clip_12273|>",
    "",
    "",
    "",
    "",
    "<",
    "<|vq_clip_",
    "ENCES<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written",
    "View ",
    "",
    "",
    "",
    "{<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    " \n\nIt seems like your",
    "<",
    "AGE<|vq_clip_",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections, with the left side showing a list of products and the",
    "<|vq_clip_12273|",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a",
    "\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0\ufffd 0",
    "<|vq",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include",
    "<|vq_clip_12273|>",
    "<|",
    "<",
    " \n\n[END OF CONVERSATION]",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"print('hello",
    "<",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of",
    "ers",
    "<|vq_clip_12273|>this image displays a list of items in",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is",
    "Of \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific",
    "\ufffd 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>this image displays a list of items in a database",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a",
    "\u0446\u0438\u0438<|vq_clip_12273|>this image displays a list of files and folders in a directory. the files are named \"c:\\",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column with a header that reads \"item\" and \"price\". the table appears to be a part of a",
    "<|vq_clip_12273|>this image displays a list of 10 items in a table format. the first item is \"1. 1. 1. 1. 1. 1. 1",
    "<",
    "<|vq_clip_12273|>this image displays a list",
    " ",
    "<|vq_clip_",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a response to a question about a user",
    "<|vq_clip_12273|>this",
    " \n\nIt",
    "<|vq_clip_12273|>this is a screenshot",
    "way 2019\ufffd<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in",
    "<|vq_clip_12273|>this image displays a list of files and folders in a computer's file explorer. the files are organized in a hierarchical structure, with the main folder being \"c:\\users\\michael\\documents\\my files\". the subfolders are labeled \"my files\" and \"my files\". the file explorer also displays a \"my files",
    "<|",
    "<",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_122",
    " \ufffd<|vq_clip_12273",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    " 1.0.0",
    "ible \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is",
    "\ufffd 1\ufffd 1\ufffd 1\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<|vq_clip_12273|>this image displays a list of files and folders in a directory. the files are named \"",
    "<|vq",
    "er<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    " 1",
    "<|vq_clip_12273|>this image displays a list of",
    "<|vq",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation appears to be in",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of 10 items, each",
    "<",
    "<|vq_clip_12273|>this image displays a table with various columns",
    "<|vq_clip_12273|>",
    "<",
    " \n\n[END OF",
    "er<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to be added to the conversation",
    " 1.0.0.0.0.0",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this image displays a list of 10 items that are used to create a new project. the items include a \"new project\" button, a \"new project\" button",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot",
    "ared<",
    "<|vq_clip_12273|",
    "ations<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer,",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user to",
    "<|vq_clip_122",
    "re",
    " 2018\ufffd ",
    "<|vq_clip_12273|>this image displays a list of",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "<|vq_clip_12273|>",
    " \n\nIt seems like your message",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a person named \"sara\". the conversation appears to be in a language that is not familiar to the user. the user is asking for a photo of a person named \"",
    "<|vq_clip",
    "<|vq_clip",
    "<",
    "\ufeff\ufeff\ufeff\ufeff\ufeff\ufeff",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"c\", \"d\", \"e\",",
    "ian<|vq_clip_12273|>this image displays a list of 10 items, each with a different color",
    "",
    "",
    "",
    "i \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with a particular topic, feel free to ask! I'm here to help.\n\nIt looks like your message got mixed",
    "",
    "",
    "elfare<|vq_clip_12273|>",
    "<|",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items",
    "<|vq",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>this image displays",
    "Type<|vq_clip_122",
    "cored<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "<",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman.",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name",
    "<|",
    "\ufffd<|vq_clip_12273|>this",
    "upted<|vq_clip_12273",
    "at<|vq",
    "",
    "",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "<|vq_clip_12273|>this is a screenshot of a website that provides information about the 2022-2023 season of the 2022-2023 season of the 2022-2023 season of the 2022-2023 season of the 2022-202",
    "\u0107 ",
    "",
    " \n\nIt seems like",
    "<|vq_clip_12273|>this",
    "",
    "\u05d1<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<|vq_clip_12273|>this",
    "<|vq_clip_122",
    "ary<|",
    " \n\n",
    "<|vq_clip_12273|>",
    "",
    "s \n\n[END OF RESPONSE]",
    "tribution<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this image displays a list of files and folders in a computer's file explorer. the list includes various files such as \"file ",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273",
    "",
    "",
    "",
    "<|vq_clip_12273|>this image displays a list of 10 items",
    "<|vq_clip_12273|>this image displays",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "<",
    " \n\nIt looks like",
    "down<|vq_clip_12273|>",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a",
    "<|vq_clip_12273|>this is a screenshot of",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273",
    "",
    " ",
    "<|vq_clip_12273|>this",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum",
    "<|",
    "<",
    "<|",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a specific question about a user named \"sud\" and",
    " \ufffd<|vq_clip_12273|",
    "",
    "<|vq_clip",
    "",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of",
    "ning<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code",
    "<|vq_clip_12273|>this image displays a list of ",
    "<|vq_clip_12273",
    "<|vq_clip_122",
    " ",
    " \n\n```\n\nIt looks like your",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "\ufffd<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3",
    "<|vq_clip",
    " .. ..  ..  ..  ..",
    "",
    "",
    "",
    "",
    "<|",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the",
    "",
    "<|vq_clip_12273",
    "Record<|vq_clip_12273|>",
    " \n\n**Note",
    "<|vq_clip_122",
    "<|vq_clip_12273|>",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a translation of a phrase in a different language. the other",
    "",
    "",
    "",
    "<|vq_clip_12273|>",
    "",
    "",
    "<",
    "",
    ">_RESPONSE<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "",
    "<",
    "<",
    "<|vq_clip_122",
    "ance<|vq_clip_12273|>this is a screenshot of a",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    " ",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of",
    "Exception<|vq_clip_12273|>",
    "ek 1.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this image displays a list of items in a table format.",
    " \n\nIt seems like your message got",
    "ArgumentException<|vq_clip_12273|>this image",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column with a header that reads \"item 1\". the table has a header that reads \"item 1\" and",
    "",
    "<",
    "",
    "",
    "\ufffd ",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items include \"c",
    "<",
    "e<|",
    "<|vq_clip_12273|>",
    "<|",
    "<|",
    "<",
    " .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..",
    "",
    "",
    "",
    "",
    "",
    "",
    "State<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    " \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273",
    "\ufffd 1.0.0.0.0.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>this is a screenshot of a website's",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|>this image displays a list of 10 items in a",
    "<|vq_clip_12273|>this code snippet is from",
    " ",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of",
    "",
    "<|vq_clip_12273|>this image displays a",
    "",
    "",
    "",
    "",
    "",
    "",
    "\ufffd ",
    "<",
    "",
    " ",
    "",
    "",
    "",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is",
    "",
    "",
    "it 1.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|",
    "",
    "",
    "",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column with the title \"item\" and the second column has the title \"item\". the table appears to be a part of",
    "<|vq_clip_12273|>this is a",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named",
    "<|vq_clip_12273|>",
    ". \n\nThe conversation ended with a huge garbled output. The user asked: \"I want to create a new",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "",
    "<|vq_clip_122",
    "",
    "",
    "",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a",
    "<|",
    "<|vq_clip_12273|>this image displays a list of items in a table",
    "<|vq_clip_122",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "<|vq_clip_12273|>this is",
    "<|",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|vq_clip",
    "<|",
    "<",
    "<|",
    " \n\n[END OF RESPONSE]",
    " ",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "ra\u00e7\u00e3opar",
    "<|",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<",
    "ate<|vq_clip_12273|>",
    "<|vq_clip",
    "",
    " 1.0",
    "<|vq",
    "<|vq_clip_122",
    " \n\nIt looks like the text you provided is a mix of multiple",
    " \n\n[END OF RESPONSE]",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "atic<|vq",
    "<|vq_clip",
    "<|vq_clip_12273|",
    "Renderer<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the",
    " ",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person who is a friend of the user. the user is also asking for a photo of a person who is a friend",
    "<|vq_clip_12273|>this image displays a",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"s",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this is a screenshot of a chat conversation between two users. the user is asking for a photo of a person named \"s",
    "<",
    " \n\nIt seems the output got garbled. Let's just provide the final answer. The answer is the",
    " 1\ufffd 1",
    "<",
    "<",
    "<",
    "\ufffd<|vq_clip_12273|>this code snippet is from a",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "<|vq_clip_12273",
    "<|vq",
    " \n\nIt seems like your message",
    "<|vq_clip",
    "NCE \n\nIt seems like your message got garbled or mixed up with a lot of",
    "<|vq_clip_",
    "<|vq_clip_12273|>this image displays",
    "s 1.0.0.0.0.0.0.0.0.0.0.0",
    " \t}\n\nIt seems like your message",
    "<|vq_clip_12273",
    "<",
    "<|vq_clip_12273|>this image displays a list of",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    "s ",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is",
    "\ufffd<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with",
    "<|vq_clip_12273|>this image",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "<",
    "Table<|vq",
    "<|vq_clip_12273|>this is",
    "\n\n",
    " 1.0.0.0.0.",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>this",
    "or",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "gences<|vq",
    " 2018\ufffd 2019\ufffd 2020\ufffd 2021\ufffd 2022\ufffd 2023\ufffd 2024\ufffd 2025\ufffd 2026\ufffd 2027\ufffd ",
    "> \n\nIt seems like your message",
    "",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code editor has a",
    "<|vq_clip_12273|>this image displays a list of items in a",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>",
    "at<|vq",
    "ed<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark",
    "\ufffd 1.0.0.0.",
    " ",
    "ificat \n\nIt seems like your message",
    "<|vq_clip_12273|>this image displays",
    "<|vq_clip_12273|>this is a screenshot of a code editor with",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the",
    "<|vq_clip",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person",
    "<|vq_clip_12273|>this image displays a list of",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a response to a question",
    " 1.0.0",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of",
    "<|vq_clip",
    "ators<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column, with each",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a response to a question about a user named \"sarah\" who is asking for a",
    "<|vq_clip_12273|>this image displays a list of items in a database. the first item is a \"c",
    "' \n\nIt seems like there was a mix-up in the text",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation appears to be in a",
    "\u09bf<|vq_clip_12273|>this is a screenshot of",
    "<|",
    "<|vq",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this",
    "<|vq_clip_",
    "",
    "s<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<",
    " ",
    "acurriculars<|vq_clip_122",
    "=\n```\n\nIt seems",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this image displays a list of items in a database. the items are listed in a table format, with each item having a unique identifier. the first item is a \"c\" with a \"c\" and \"c\" in the second column",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging",
    "<",
    "<",
    "<|vq_clip_12273|>",
    "<|",
    " \n\n[conversation ends]",
    "<|vq_clip_122",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>",
    "<",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel free to ask!\n\nIt looks like your message got a bit mixed up. If",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"print('hello world')\". the code editor has a black background and a white text editor. the script is written in a",
    "<|vq_clip_12273|>",
    "<|vq_clip",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person",
    "<|vq_clip_12273|>",
    "\ufffd<|vq_clip",
    "<|vq_clip_122",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation is in a language that appears to be a mix of english and hindi. the user is asking",
    "<|vq_clip_12273|>",
    "S \n\n[END OF RESPONSE]",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    "<",
    "<|vq_clip_12273",
    "<|vq_clip_122",
    "<|vq_clip_12273|",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip",
    " 1.0.0.0.0.",
    "\u0b3f<|vq",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>",
    "",
    " 2018\ufffd 2019\ufffd 2020",
    "abis<|",
    "<",
    "<|",
    " 1.0.",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the",
    "n \n\nIt seems like your message",
    "<|",
    "<",
    "s] \ufffd<",
    "<|vq_clip_12273",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation appears to be in a language that is not familiar to the user. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the conversation appears to be",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this image displays a list of items in",
    "<",
    "<|vq_clip_12273|>",
    "s<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "Listener<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>",
    "ANK",
    "<|",
    "\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1\ufffd 1",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code is displayed in a black background with white text. the script appears to be a part of a larger",
    "<|",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>",
    " 1.0.0.0.0.0.0.0.0.0",
    "<|vq_clip_12273|>this is a screenshot",
    "\ufffd 1.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>",
    "<",
    " \n\n[conversation ends]",
    "ant \n\n```\n\nIt looks",
    " \n\nIt looks like",
    "<",
    "",
    "<|vq_clip_12273|>this is a screenshot of a",
    ">\n\nIt seems like your message got a bit garbled. If you have a specific",
    "ular",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is",
    "<|vq",
    " .. \n\nIt seems like your message got garbled or mixed up with a lot",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a code to be added to a website, and the other user is responding with a code that says \"i am not sure if i can do it\". the user also mentions that they are not sure if they",
    "<|vq_clip_12273|>this is",
    "or<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "-",
    "<|vq_clip_12273",
    "<|vq_clip_122",
    "```\n\nIt seems like your message got a bit",
    "<|vq_clip",
    "<|vq",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo",
    "<",
    "",
    "View ",
    "ynomial<|vq_clip_12273|>this is a screenshot of",
    "<|vq_clip",
    "<|",
    "|vq_clip_12273|",
    "<|vq_clip",
    "<|vq_clip_122",
    ") \n\nIt seems like your message got",
    "<|vq_clip_",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person who is a friend of the user. the user is also asking for a",
    "<|vq_clip_12273",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo",
    "<|vq_clip_12273|>",
    "<",
    "<|vq",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"a\", \"",
    "<|vq_clip_122",
    "\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\nIt seems like your message got garbled",
    "<|vq_clip_12273|>",
    " relevant ",
    "<|vq_clip_",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script.",
    " \ufffd<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark",
    "",
    " 1.0.0.0",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function",
    "SE \n\nIt seems",
    "```\n\nIt seems like the text you provided is a mix of multiple languages and contains a lot of unrelated content. If you have a specific question or need assistance with a particular topic, please let me know, and I'll do my",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a woman. the user also mentions that the photo is",
    "<|vq_clip_122",
    "<|vq_clip",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d",
    "<|vq_clip_12273|>this is a screenshot of a code editor",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python",
    "<|vq_clip",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>this is",
    "<|vq_clip_12273|>",
    "<|vq",
    " \n \n\n",
    "<|",
    "<|vq_clip_",
    "<|",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a specific question about a user",
    "<|vq_clip_12273|>this is",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    " ",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a new user",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<",
    "",
    "<|vq_clip_12273|>this is a screenshot of",
    "",
    "ED ",
    "<|vq_clip_12273|>this is a screenshot of a code",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u",
    "<|",
    "m<|vq_clip_122",
    "<|vq_clip",
    "<|vq_clip_12273|>",
    "<",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this image displays a list of files and folders in a computer's file explorer. the files are organized in",
    "<|",
    "",
    "<",
    "<",
    "<|vq",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip",
    "<|vq_clip_12273|>",
    "",
    "he 1.0.0.0",
    "<|vq_clip_122",
    "<|vq_clip_",
    "<|",
    "<|vq_clip_122",
    "<|vq",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled as \"s\", \"t\", \"u\",",
    " \n\n```\n\nIt seems like",
    "ia<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3",
    "line<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a",
    "ar<|vq_clip_12273|>",
    " ",
    "",
    "<|",
    "<|vq_clip_12273|>this image displays a list of items in a",
    "<|vq_clip_12273|>",
    "ation<|vq_clip_12273|",
    "",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this",
    "ates",
    "s<|vq_clip_",
    "<|vq",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a",
    " 1.0.0.0.0.0.0.0.0.0.0.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is",
    "<",
    "\ufffd 1.0.0.0.0.0",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3",
    "ar<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3d printer, a 3",
    " \n\nIt seems like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel free to ask!\n\nIt looks like your message got a bit mixed up. If you have a specific question or need help with something, just let me",
    "<",
    "<|",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are listed in a column with a header that reads \"item\". the table appears",
    "<|vq_clip_12273|>this is a",
    " witnesses<|",
    "<",
    "\t<|vq_clip_12273|>this image displays a list of 10 items in a table format. the items are",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    " \n\n[END OF CONVERSATION]",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273",
    " \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<",
    "Name) \n\nIt seems like your",
    "ances<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"if __name__ == \"__main__\":\". the code",
    "<|vq_clip_122",
    " \t}\n\nIt seems like your message got garbled or mixed up with a lot of unrelated",
    " ",
    "<|vq_clip_12273|>this is a screenshot",
    "<|vq_clip_12273|>this is a screenshot of a",
    "<|vq_clip_122",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is",
    " 1.0.",
    " ",
    "<|vq_clip_12273|>",
    "<|vq_clip_122",
    "<|vq_clip_122",
    "<",
    "",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a",
    "\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd ",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is a function that calculates the sum of two numbers. the code is written in a dark theme with a black background. the function is called \"sum\" and it takes two arguments, \"",
    "<|vq_clip_12273|>",
    "",
    "<|",
    "",
    "",
    "```\n\nIt seems like your message got garbled",
    "",
    "",
    "",
    "",
    "",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>this image displays a list of items in a shopping cart. the items include a 3d printer, a 3d printer, a 3d",
    "<|vq_clip",
    "<|",
    "",
    " \ufffd \ufffd  \ufffd  \ufffd  \ufffd  \ufffd  \ufffd  \ufffd  \ufffd  \ufffd ",
    "",
    "",
    "<|vq_clip_12273",
    "<|vq_clip_12273|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a specific question about a user named \"sud\" and the user is responding with a question about the user. the",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the items are labeled",
    "<|vq_clip_12273|>this",
    "<|vq_clip_12273|>",
    "\u043a\u0438<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named",
    "\ufffd ",
    "<",
    "\u0259<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging platform. the user is asking for a photo of a person named \"sara\" and the other user is responding with a",
    "<|vq_clip_12273|>this",
    "",
    "",
    "",
    "a .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  .. ",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on",
    "<|vq_clip_12273|>this image displays a list of 10",
    "= ",
    "<|vq_clip_",
    "<",
    "<|vq_clip_12273|>this image displays a list of items in a",
    "ative<|vq",
    "<|vq_clip_",
    "<|vq_clip_",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking",
    "<|vq_clip_12273|>this image displays a list of",
    " \ufffd<|vq_clip_12273|>this is a screenshot of a conversation between two",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user",
    "Reader<|vq_clip_12273",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with",
    "<|",
    "<|vq_clip_12273|>this is a screenshot of a conversation",
    "<|vq_clip_12273",
    "<|vq_clip_12273",
    " \n\nIt seems like your message got garbled or mixed up",
    "s",
    "<|vq_clip_12273|>this is a screenshot of a conversation between",
    " 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.",
    " `\n\n**Note**: The above text is",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code is displayed in a black background with a white text. the script is written in a dark theme and contains a function that calculates the sum of two numbers. the code is displayed in a black background with a white text.",
    "ollow",
    " 1.0.0.0.0.0.0.0.",
    "<",
    "<|vq_clip_12273",
    "<|vq_clip_12273|>",
    "<"
  ],
  "errors": [
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    ""
  ],
  "request_timestamps": [
    1759956973.3692365,
    1759956973.4098263,
    1759956973.5960832,
    1759956973.7354903,
    1759956973.7651248,
    1759956973.7650955,
    1759956973.790456,
    1759956973.7995458,
    1759956973.9392362,
    1759956974.008566,
    1759956974.1544487,
    1759956974.1982121,
    1759956974.2357614,
    1759956974.2357247,
    1759956974.2609332,
    1759956974.2701602,
    1759956974.3365262,
    1759956974.34417,
    1759956974.3911216,
    1759956974.4364502,
    1759956974.4923265,
    1759956974.5132754,
    1759956974.7721713,
    1759956974.818231,
    1759956974.9829345,
    1759956974.9881442,
    1759956975.0531454,
    1759956975.154573,
    1759956975.272679,
    1759956975.2986293,
    1759956975.328792,
    1759956975.3617315,
    1759956975.364729,
    1759956975.3683321,
    1759956975.6342819,
    1759956975.86939,
    1759956975.9339576,
    1759956975.9339147,
    1759956975.952833,
    1759956975.9902093,
    1759956976.1450348,
    1759956976.1721382,
    1759956976.2068896,
    1759956976.2839284,
    1759956976.4065819,
    1759956976.554753,
    1759956976.6027951,
    1759956976.6365447,
    1759956976.9543428,
    1759956977.0067136,
    1759956977.3923562,
    1759956977.4081812,
    1759956977.4209695,
    1759956977.5434482,
    1759956977.628035,
    1759956977.745836,
    1759956977.80604,
    1759956977.8396182,
    1759956977.9136808,
    1759956977.9687197,
    1759956977.992602,
    1759956978.0563886,
    1759956978.0905921,
    1759956978.109181,
    1759956978.2059286,
    1759956978.2091973,
    1759956978.3149016,
    1759956978.3613243,
    1759956978.3699174,
    1759956978.3805985,
    1759956978.421159,
    1759956978.4987752,
    1759956978.5469942,
    1759956978.5713587,
    1759956978.581375,
    1759956978.6577058,
    1759956978.7565784,
    1759956978.8071647,
    1759956978.9464676,
    1759956978.951206,
    1759956978.9786968,
    1759956979.1253479,
    1759956979.1313388,
    1759956979.1911585,
    1759956979.2486558,
    1759956979.3114414,
    1759956979.3284488,
    1759956979.3284845,
    1759956979.3486338,
    1759956979.4227636,
    1759956979.4584074,
    1759956979.4868002,
    1759956979.5019243,
    1759956979.5528843,
    1759956979.6604033,
    1759956979.6880662,
    1759956979.761835,
    1759956979.7891304,
    1759956979.9112866,
    1759956979.9180157,
    1759956979.9180434,
    1759956979.9403458,
    1759956980.011138,
    1759956980.0557659,
    1759956980.062938,
    1759956980.0777795,
    1759956980.2921817,
    1759956980.3158433,
    1759956980.4279752,
    1759956980.5193932,
    1759956980.5711298,
    1759956980.8236413,
    1759956980.9929686,
    1759956981.0499482,
    1759956981.1042633,
    1759956981.199449,
    1759956981.2324622,
    1759956981.2532434,
    1759956981.5418591,
    1759956981.5570886,
    1759956981.6605299,
    1759956981.6605675,
    1759956981.7428567,
    1759956981.898024,
    1759956981.9118433,
    1759956981.938262,
    1759956981.9609504,
    1759956982.0168426,
    1759956982.0355313,
    1759956982.137993,
    1759956982.174217,
    1759956982.1742604,
    1759956982.3262932,
    1759956982.3496926,
    1759956982.5276556,
    1759956982.5369022,
    1759956982.7041492,
    1759956982.745054,
    1759956982.8010585,
    1759956982.829878,
    1759956982.8740902,
    1759956982.889186,
    1759956982.9656303,
    1759956982.9806106,
    1759956983.0087066,
    1759956983.0677087,
    1759956983.111452,
    1759956983.1166608,
    1759956983.311751,
    1759956983.3223486,
    1759956983.3667963,
    1759956983.437367,
    1759956983.484311,
    1759956983.5039911,
    1759956983.5532494,
    1759956983.6145372,
    1759956983.6724236,
    1759956983.7317877,
    1759956983.8274736,
    1759956983.847471,
    1759956983.893081,
    1759956983.954181,
    1759956984.0574925,
    1759956984.0981734,
    1759956984.1417696,
    1759956984.1672838,
    1759956984.2441971,
    1759956984.2730148,
    1759956984.373084,
    1759956984.3778791,
    1759956984.395819,
    1759956984.4467347,
    1759956984.4915438,
    1759956984.4982102,
    1759956984.5476246,
    1759956984.602608,
    1759956984.6234524,
    1759956984.802745,
    1759956984.876411,
    1759956985.0067775,
    1759956985.045241,
    1759956985.0825658,
    1759956985.1118019,
    1759956985.1265607,
    1759956985.1884103,
    1759956985.200672,
    1759956985.2212257,
    1759956985.2467387,
    1759956985.2643595,
    1759956985.3041432,
    1759956985.3277144,
    1759956985.4904761,
    1759956985.556023,
    1759956985.6153662,
    1759956985.812922,
    1759956985.83023,
    1759956985.882498,
    1759956985.933764,
    1759956985.9461992,
    1759956985.9773753,
    1759956986.0766175,
    1759956986.1818,
    1759956986.1817105,
    1759956986.181783,
    1759956986.1991289,
    1759956986.3217728,
    1759956986.351911,
    1759956986.5364172,
    1759956986.6455467,
    1759956986.7427025,
    1759956986.797233,
    1759956986.8844862,
    1759956987.0228784,
    1759956987.0306969,
    1759956987.0745914,
    1759956987.1304846,
    1759956987.2822924,
    1759956987.2823646,
    1759956987.2823508,
    1759956987.3221803,
    1759956987.330841,
    1759956987.394546,
    1759956987.4596994,
    1759956987.467124,
    1759956987.4966486,
    1759956987.552082,
    1759956987.564536,
    1759956987.6211483,
    1759956987.6841385,
    1759956987.7672727,
    1759956987.8878524,
    1759956987.919525,
    1759956988.1350517,
    1759956988.1777575,
    1759956988.2286978,
    1759956988.2682087,
    1759956988.2742443,
    1759956988.2982266,
    1759956988.3734934,
    1759956988.4707758,
    1759956988.5067716,
    1759956988.5427024,
    1759956988.5697148,
    1759956988.5823853,
    1759956988.6009686,
    1759956988.6307254,
    1759956988.635279,
    1759956988.667913,
    1759956989.02329,
    1759956989.1611962,
    1759956989.2411401,
    1759956989.2583601,
    1759956989.3089645,
    1759956989.355274,
    1759956989.4327614,
    1759956989.5237186,
    1759956989.5883768,
    1759956989.591682,
    1759956989.7764359,
    1759956989.8343575,
    1759956989.843106,
    1759956989.9240677,
    1759956990.145928,
    1759956990.2064078,
    1759956990.2480898,
    1759956990.2481344,
    1759956990.323909,
    1759956990.3295314,
    1759956990.3664732,
    1759956990.4719803,
    1759956990.5008576,
    1759956990.500834,
    1759956990.5472188,
    1759956990.8256078,
    1759956990.8446121,
    1759956990.8446536,
    1759956990.8825338,
    1759956990.922897,
    1759956990.954561,
    1759956991.0096722,
    1759956991.2755423,
    1759956991.3326633,
    1759956991.4829192,
    1759956991.4873574,
    1759956991.4929905,
    1759956991.5643356,
    1759956991.5689821,
    1759956991.6297953,
    1759956991.6913083,
    1759956991.742315,
    1759956991.7778187,
    1759956991.8407671,
    1759956991.8514829,
    1759956992.081771,
    1759956992.1105468,
    1759956992.1105835,
    1759956992.2108977,
    1759956992.2109432,
    1759956992.2412171,
    1759956992.2725396,
    1759956992.313809,
    1759956992.350888,
    1759956992.3704712,
    1759956992.4665837,
    1759956992.5757446,
    1759956992.6025715,
    1759956992.7599247,
    1759956992.7803805,
    1759956992.814378,
    1759956992.827413,
    1759956992.8404272,
    1759956992.8614006,
    1759956992.8711257,
    1759956992.9160998,
    1759956993.1090808,
    1759956993.1230145,
    1759956993.1788516,
    1759956993.2781053,
    1759956993.2850783,
    1759956993.351801,
    1759956993.4690707,
    1759956993.5565844,
    1759956993.6367323,
    1759956993.664611,
    1759956993.7268882,
    1759956993.7759926,
    1759956993.7910678,
    1759956993.9120378,
    1759956994.0644937,
    1759956994.1149824,
    1759956994.3016026,
    1759956994.656529,
    1759956994.7037044,
    1759956994.726605,
    1759956994.7538419,
    1759956994.9082859,
    1759956995.0091925,
    1759956995.1645947,
    1759956995.3354294,
    1759956995.357215,
    1759956995.4303384,
    1759956995.5182889,
    1759956995.523154,
    1759956995.655957,
    1759956995.6914148,
    1759956995.728337,
    1759956995.7740107,
    1759956995.8066902,
    1759956995.8421705,
    1759956995.8874092,
    1759956995.9060588,
    1759956995.9727643,
    1759956996.0157688,
    1759956996.1754017,
    1759956996.3392808,
    1759956996.3497236,
    1759956996.454914,
    1759956996.595164,
    1759956996.6014576,
    1759956996.6325169,
    1759956996.6492229,
    1759956996.6531148,
    1759956996.7046869,
    1759956996.7407033,
    1759956996.8074255,
    1759956996.8199258,
    1759956996.8403888,
    1759956996.8957596,
    1759956996.9247248,
    1759956996.928518,
    1759956996.9774938,
    1759956997.1037095,
    1759956997.2028427,
    1759956997.213327,
    1759956997.2469258,
    1759956997.310895,
    1759956997.4450862,
    1759956997.4451535,
    1759956997.4451692,
    1759956997.4558847,
    1759956997.7768462,
    1759956997.8161175,
    1759956998.1400602,
    1759956998.1773062,
    1759956998.2883506,
    1759956998.3415282,
    1759956998.4349267,
    1759956998.5150151,
    1759956998.5406938,
    1759956998.5726237,
    1759956998.601942,
    1759956998.6104133,
    1759956998.6411903,
    1759956998.6645257,
    1759956998.6682875,
    1759956998.7092412,
    1759956998.7737992,
    1759956998.8604112,
    1759956998.8679602,
    1759956998.8679993,
    1759956998.908229,
    1759956998.9385333,
    1759956998.984008,
    1759956999.0305035,
    1759956999.1066425,
    1759956999.2226348,
    1759956999.3222418,
    1759956999.3907416,
    1759956999.416936,
    1759956999.4513144,
    1759956999.4666958,
    1759956999.4905605,
    1759956999.5097795,
    1759956999.5341802,
    1759956999.654843,
    1759956999.6987073,
    1759956999.7419875,
    1759956999.7480338,
    1759956999.8305721,
    1759956999.8901672,
    1759956999.9192407,
    1759956999.945694,
    1759957000.114637,
    1759957000.2284439,
    1759957000.2374,
    1759957000.3501997,
    1759957000.3657944,
    1759957000.5107958,
    1759957000.586814,
    1759957000.7252576,
    1759957000.760863,
    1759957000.8018658,
    1759957000.8018334,
    1759957000.8410914,
    1759957000.8803475,
    1759957000.9097366,
    1759957000.9673977,
    1759957001.0934994,
    1759957001.14742,
    1759957001.1630702,
    1759957001.2122555,
    1759957001.3320982,
    1759957001.4575396,
    1759957001.4682407,
    1759957001.536697,
    1759957001.5794697,
    1759957001.5863564,
    1759957001.6155624,
    1759957001.6352954,
    1759957001.6495526,
    1759957001.6692781,
    1759957001.6746156,
    1759957001.6797953,
    1759957001.6946416,
    1759957001.7371974,
    1759957001.884525,
    1759957002.0368557,
    1759957002.0995162,
    1759957002.1239617,
    1759957002.152572,
    1759957002.1670728,
    1759957002.2131298,
    1759957002.263583,
    1759957002.312879,
    1759957002.3437686,
    1759957002.4223478,
    1759957002.42778,
    1759957002.4490952,
    1759957002.5494463,
    1759957002.6408784,
    1759957002.7440176,
    1759957002.7482963,
    1759957002.7810912,
    1759957002.9159718,
    1759957002.919308,
    1759957003.0541394,
    1759957003.0744271,
    1759957003.1739314,
    1759957003.1812503,
    1759957003.254417,
    1759957003.285377,
    1759957003.4887137,
    1759957003.510849,
    1759957003.558135,
    1759957003.613364,
    1759957003.6502461,
    1759957003.7222288,
    1759957003.827927,
    1759957003.8775322,
    1759957004.0164063,
    1759957004.0644872,
    1759957004.1413193,
    1759957004.1478293,
    1759957004.2171164,
    1759957004.3787413,
    1759957004.430878,
    1759957004.4955728,
    1759957004.5659697,
    1759957004.6048412,
    1759957004.6259956,
    1759957004.7995868,
    1759957004.8459158,
    1759957004.8815372,
    1759957004.919648,
    1759957004.9696884,
    1759957004.9888067,
    1759957004.988765,
    1759957005.065196,
    1759957005.0706522,
    1759957005.1335058,
    1759957005.136952,
    1759957005.2451038,
    1759957005.3261242,
    1759957005.3261716,
    1759957005.371067,
    1759957005.5222452,
    1759957005.7227664,
    1759957005.7396216,
    1759957005.8871634,
    1759957005.9150257,
    1759957006.038811,
    1759957006.0481257,
    1759957006.1758728,
    1759957006.2660775,
    1759957006.3293648,
    1759957006.4184222,
    1759957006.4242885,
    1759957006.4592745,
    1759957006.520383,
    1759957006.8223667,
    1759957006.847811,
    1759957006.878674,
    1759957006.8840091,
    1759957006.890253,
    1759957006.985248,
    1759957007.0146575,
    1759957007.1121027,
    1759957007.158539,
    1759957007.1701043,
    1759957007.2049477,
    1759957007.261368,
    1759957007.3310661,
    1759957007.4092984,
    1759957007.429017,
    1759957007.4586606,
    1759957007.6117465,
    1759957007.6758907,
    1759957007.8605072,
    1759957007.993908,
    1759957008.1066978,
    1759957008.1067426,
    1759957008.124621,
    1759957008.1425066,
    1759957008.1722224,
    1759957008.404442,
    1759957008.4593682,
    1759957008.5329251,
    1759957008.6021929,
    1759957008.6151793,
    1759957008.6479585,
    1759957008.6985724,
    1759957008.7357876,
    1759957008.8459902,
    1759957008.9927745,
    1759957009.1653056,
    1759957009.251327,
    1759957009.3842688,
    1759957009.445353,
    1759957009.4495192,
    1759957009.467544,
    1759957009.6088428,
    1759957009.9679968,
    1759957010.0192142,
    1759957010.0967278,
    1759957010.105464,
    1759957010.1173446,
    1759957010.154878,
    1759957010.1837044,
    1759957010.2591395,
    1759957010.4751527,
    1759957010.4925923,
    1759957010.517104,
    1759957010.6028948,
    1759957010.6904604,
    1759957010.723013,
    1759957010.730186,
    1759957010.9293628,
    1759957011.0330458,
    1759957011.0424407,
    1759957011.0750442,
    1759957011.1837041,
    1759957011.2581162,
    1759957011.2615557,
    1759957011.3291821,
    1759957011.5160043,
    1759957011.5632634,
    1759957011.6819701,
    1759957011.7922554,
    1759957011.8296914,
    1759957011.975496,
    1759957012.0808938,
    1759957012.0957007,
    1759957012.1039855,
    1759957012.153972,
    1759957012.1899526,
    1759957012.2098918,
    1759957012.2463036,
    1759957012.2902427,
    1759957012.4228065,
    1759957012.7151587,
    1759957012.8401723,
    1759957012.8476403,
    1759957012.9500277,
    1759957013.1752772,
    1759957013.221931,
    1759957013.2575717,
    1759957013.2662709,
    1759957013.2899501,
    1759957013.3419263,
    1759957013.4072323,
    1759957013.4628623,
    1759957013.5165293,
    1759957013.548949,
    1759957013.58931,
    1759957013.745679,
    1759957013.7457252,
    1759957013.832638,
    1759957013.8556483,
    1759957013.9829865,
    1759957014.0081642,
    1759957014.0254076,
    1759957014.0305119,
    1759957014.0665338,
    1759957014.119529,
    1759957014.141724,
    1759957014.1499734,
    1759957014.173388,
    1759957014.4281719,
    1759957014.4528482,
    1759957014.527189,
    1759957014.549767,
    1759957014.5595453,
    1759957014.5990531,
    1759957014.718304,
    1759957014.7260916,
    1759957014.7784655,
    1759957014.8247945,
    1759957014.8278267,
    1759957014.844634,
    1759957014.8663077,
    1759957015.0139637,
    1759957015.0484867,
    1759957015.0535903,
    1759957015.0878468,
    1759957015.1133258,
    1759957015.1394405,
    1759957015.28933,
    1759957015.3636568,
    1759957015.3987017,
    1759957015.6855702,
    1759957015.6855373,
    1759957015.7386048,
    1759957015.7549567,
    1759957015.8052402,
    1759957015.8386402,
    1759957015.886063,
    1759957016.0476246,
    1759957016.2217994,
    1759957016.276551,
    1759957016.3502283,
    1759957016.5724514,
    1759957016.6477315,
    1759957016.7157006,
    1759957016.7460659,
    1759957016.8243186,
    1759957016.8275478,
    1759957016.9431365,
    1759957016.9922626,
    1759957017.0012608,
    1759957017.0378706,
    1759957017.0784838,
    1759957017.240071,
    1759957017.2634377,
    1759957017.3212438,
    1759957017.426547,
    1759957017.433579,
    1759957017.4784632,
    1759957017.5366964,
    1759957017.5408158,
    1759957017.5981228,
    1759957017.6481354,
    1759957017.7321794,
    1759957017.826663,
    1759957017.9042952,
    1759957017.9042425,
    1759957017.9291346,
    1759957017.9291003,
    1759957017.9907422,
    1759957018.1512012,
    1759957018.217315,
    1759957018.2951279,
    1759957018.4676588,
    1759957018.5197282,
    1759957018.5256615,
    1759957018.6288698,
    1759957018.7260258,
    1759957018.9229176,
    1759957018.980806,
    1759957018.984685,
    1759957019.0200582,
    1759957019.0360403,
    1759957019.1269364,
    1759957019.161883,
    1759957019.1885037,
    1759957019.3798835,
    1759957019.49864,
    1759957019.5380158,
    1759957019.708397,
    1759957019.7183063,
    1759957019.756379,
    1759957019.849829,
    1759957019.9039164,
    1759957019.9306405,
    1759957020.0929167,
    1759957020.13914,
    1759957020.1452858,
    1759957020.1810238,
    1759957020.2248592,
    1759957020.329712,
    1759957020.3297336,
    1759957020.342676,
    1759957020.3426895,
    1759957020.342623,
    1759957020.351956,
    1759957020.439569,
    1759957020.4432423,
    1759957020.5317788,
    1759957020.5486026,
    1759957020.5595822,
    1759957020.6407666,
    1759957020.7897751,
    1759957020.7898269,
    1759957020.8050075,
    1759957020.8049707,
    1759957020.8860435,
    1759957020.9084983,
    1759957020.978584,
    1759957021.0781353,
    1759957021.106807,
    1759957021.1539273,
    1759957021.1982696,
    1759957021.3585732,
    1759957021.363719,
    1759957021.4086206,
    1759957021.5419924,
    1759957021.5884924,
    1759957021.6189604,
    1759957021.6889782,
    1759957021.7037704,
    1759957021.7081103,
    1759957021.7403975,
    1759957021.7979946,
    1759957022.0266764,
    1759957022.0881662,
    1759957022.1014273,
    1759957022.105158,
    1759957022.2382543,
    1759957022.3099132,
    1759957022.35844,
    1759957022.3920918,
    1759957022.3952687,
    1759957022.5076954,
    1759957022.5150661,
    1759957022.52868,
    1759957022.5659401,
    1759957022.5953326,
    1759957022.595377,
    1759957022.6319246,
    1759957022.6465409,
    1759957022.6700468,
    1759957022.9306176,
    1759957022.9988406,
    1759957023.0308743,
    1759957023.1710024,
    1759957023.17644,
    1759957023.3506024,
    1759957023.3506448,
    1759957023.4933498,
    1759957023.58439,
    1759957023.6011846,
    1759957023.7060027,
    1759957023.7504115,
    1759957023.7869813,
    1759957023.8485389,
    1759957023.9348497,
    1759957024.0057554,
    1759957024.148007,
    1759957024.1615188,
    1759957024.2030652,
    1759957024.2527685,
    1759957024.3318982,
    1759957024.371978,
    1759957024.544144,
    1759957024.5483525,
    1759957024.6637294,
    1759957024.6768465,
    1759957024.7125134,
    1759957024.810354,
    1759957024.857579,
    1759957024.8819304,
    1759957024.9962718,
    1759957025.1405919,
    1759957025.3717442,
    1759957025.3717072,
    1759957025.384706,
    1759957025.3847432,
    1759957025.422915,
    1759957025.5323105,
    1759957025.5483847,
    1759957025.5922701,
    1759957025.7386734,
    1759957025.7821102,
    1759957025.8100922,
    1759957025.8499866,
    1759957025.9732456,
    1759957026.0390668,
    1759957026.1177032,
    1759957026.132596,
    1759957026.3490222,
    1759957026.541155,
    1759957026.5944397,
    1759957026.7056653,
    1759957026.7161329,
    1759957026.785,
    1759957026.79358,
    1759957026.9256136,
    1759957027.0980012,
    1759957027.098014,
    1759957027.0979502,
    1759957027.1043515,
    1759957027.1743295,
    1759957027.187481,
    1759957027.2027047,
    1759957027.3496647,
    1759957027.3691468,
    1759957027.3790708,
    1759957027.379057,
    1759957027.3789907,
    1759957027.389577,
    1759957027.4378452,
    1759957027.4960172,
    1759957027.509781,
    1759957027.5227218,
    1759957027.6159537,
    1759957027.6678574,
    1759957027.7255762,
    1759957027.8474667,
    1759957027.9149325,
    1759957027.9386919,
    1759957027.9985688,
    1759957028.0333765,
    1759957028.0334103,
    1759957028.100347,
    1759957028.1034362,
    1759957028.3585355,
    1759957028.423739,
    1759957028.4421806,
    1759957028.533172,
    1759957028.5331311,
    1759957028.7103996,
    1759957028.9182668,
    1759957029.1222744,
    1759957029.1367564,
    1759957029.1532698,
    1759957029.1674373,
    1759957029.2286131,
    1759957029.2662807,
    1759957029.3310895,
    1759957029.3364985,
    1759957029.3677645,
    1759957029.4619377,
    1759957029.4692996,
    1759957029.4962168,
    1759957029.567026,
    1759957029.726799,
    1759957029.8456392,
    1759957029.9499533,
    1759957029.9945025,
    1759957030.036988,
    1759957030.1456249,
    1759957030.1597848,
    1759957030.2112327,
    1759957030.245218,
    1759957030.2955647,
    1759957030.5598414,
    1759957030.6796393,
    1759957030.7517302,
    1759957030.7681026,
    1759957030.9400756,
    1759957031.0210037,
    1759957031.219646,
    1759957031.233151,
    1759957031.421528,
    1759957031.444433,
    1759957031.453731,
    1759957031.5176573,
    1759957031.6747875,
    1759957031.6824455,
    1759957031.7933583,
    1759957031.881616,
    1759957031.9739573,
    1759957032.0020235,
    1759957032.0478003,
    1759957032.191916,
    1759957032.3866587,
    1759957032.422917,
    1759957032.4852216,
    1759957032.5108995,
    1759957032.516619,
    1759957032.5165777,
    1759957032.7221186,
    1759957032.7852333,
    1759957032.798122,
    1759957032.849749,
    1759957032.8601122,
    1759957032.874313,
    1759957032.9140785,
    1759957033.0578578,
    1759957033.132004,
    1759957033.255945,
    1759957033.2767425,
    1759957033.4839392,
    1759957033.5074694,
    1759957033.5396147,
    1759957033.6451683,
    1759957033.6562936,
    1759957033.7131412,
    1759957033.7552204,
    1759957033.8022685,
    1759957033.8067973,
    1759957034.1355178,
    1759957034.17312,
    1759957034.2620158,
    1759957034.2796361,
    1759957034.4812937,
    1759957034.5096164,
    1759957034.5174725,
    1759957034.5601525,
    1759957034.5729816,
    1759957034.617495,
    1759957034.8138826,
    1759957034.9117022,
    1759957034.95883,
    1759957035.0029004,
    1759957035.0028396,
    1759957035.0376368,
    1759957035.0565107,
    1759957035.1013703,
    1759957035.2873895,
    1759957035.4233904,
    1759957035.5860806,
    1759957035.5924633,
    1759957035.6136851,
    1759957035.8016102,
    1759957035.8378649,
    1759957035.868034,
    1759957035.9761443,
    1759957036.1070635,
    1759957036.1199226,
    1759957036.1198525,
    1759957036.1199062,
    1759957036.227908,
    1759957036.3552809,
    1759957036.3657339,
    1759957036.479839,
    1759957036.504398,
    1759957036.5582688,
    1759957036.675531,
    1759957036.6994953,
    1759957036.738986,
    1759957036.7450094,
    1759957036.8180141,
    1759957036.8725333,
    1759957036.8724947,
    1759957036.8842437,
    1759957037.2428322,
    1759957037.2891092,
    1759957037.301651,
    1759957037.493022,
    1759957037.5018544,
    1759957037.5914543,
    1759957037.8218467,
    1759957037.8250365,
    1759957037.852631,
    1759957038.0483367,
    1759957038.1139753,
    1759957038.1434739,
    1759957038.3524795,
    1759957038.3591065,
    1759957038.4129539,
    1759957038.4446876,
    1759957038.5274787,
    1759957038.579203,
    1759957038.583545,
    1759957038.6255682,
    1759957038.629045,
    1759957038.6335523,
    1759957038.6508052,
    1759957038.677569,
    1759957038.7513404,
    1759957038.788765,
    1759957038.8329823,
    1759957038.8473318,
    1759957038.9503398,
    1759957038.959208,
    1759957039.0271828,
    1759957039.095327,
    1759957039.1041715,
    1759957039.1979156,
    1759957039.3039007,
    1759957039.325311,
    1759957039.4117403,
    1759957039.4640417,
    1759957039.4966362,
    1759957039.503356,
    1759957039.6157823,
    1759957039.7198315,
    1759957039.8226414,
    1759957039.8529742,
    1759957039.9221869,
    1759957039.994398,
    1759957040.0430677,
    1759957040.047562,
    1759957040.0744236,
    1759957040.3726425,
    1759957040.4310408,
    1759957040.478894,
    1759957040.535125,
    1759957040.5546792,
    1759957040.5857234,
    1759957040.7110846,
    1759957040.7501504,
    1759957040.7592437,
    1759957040.7592816,
    1759957040.800013,
    1759957040.83832,
    1759957040.9214854,
    1759957041.060672,
    1759957041.067779,
    1759957041.0884347,
    1759957041.1212435,
    1759957041.1572926,
    1759957041.1689954,
    1759957041.2944133,
    1759957041.2985165,
    1759957041.3887367,
    1759957041.3888304,
    1759957041.396331,
    1759957041.5288289,
    1759957041.5964804,
    1759957041.6034362,
    1759957041.7375681,
    1759957041.7414896,
    1759957041.8279295,
    1759957042.1215923,
    1759957042.129249,
    1759957042.1399713,
    1759957042.179728,
    1759957042.2188275,
    1759957042.2478044,
    1759957042.3107464,
    1759957042.3195846,
    1759957042.3453465,
    1759957042.385035,
    1759957042.3936968,
    1759957042.6457467,
    1759957042.7795517,
    1759957042.8001928,
    1759957042.8940825,
    1759957042.9396756,
    1759957043.0003726,
    1759957043.0067172,
    1759957043.028121,
    1759957043.0424511,
    1759957043.0636344,
    1759957043.114528,
    1759957043.1223683,
    1759957043.270233,
    1759957043.3122542,
    1759957043.414597,
    1759957043.5330856,
    1759957043.5638747,
    1759957043.5768402,
    1759957043.5768704,
    1759957043.6008046,
    1759957043.6007612,
    1759957043.6625936,
    1759957043.7316833,
    1759957043.7991636,
    1759957043.8718576,
    1759957043.9605348,
    1759957043.9604907,
    1759957043.982459,
    1759957044.011435,
    1759957044.0440197,
    1759957044.135115,
    1759957044.2734954,
    1759957044.465514,
    1759957044.5714493,
    1759957044.5888095,
    1759957044.8077962,
    1759957044.8395028,
    1759957044.8920233,
    1759957044.925808,
    1759957044.9722238,
    1759957044.972161,
    1759957044.9753547,
    1759957044.9963567,
    1759957045.0758953,
    1759957045.2039495,
    1759957045.2447362,
    1759957045.281614,
    1759957045.3080757,
    1759957045.3873067,
    1759957045.4853427,
    1759957045.4914386,
    1759957045.556065,
    1759957045.6410382,
    1759957045.8320377,
    1759957045.8456795,
    1759957046.0204697,
    1759957046.116052,
    1759957046.1437793,
    1759957046.1522133,
    1759957046.193909,
    1759957046.198367,
    1759957046.2885816,
    1759957046.4004276,
    1759957046.6498332,
    1759957046.7073362,
    1759957046.8061368,
    1759957046.8334942,
    1759957046.859603,
    1759957046.8697014,
    1759957046.9532459,
    1759957046.9743075,
    1759957046.9818573,
    1759957046.9934244,
    1759957047.066903,
    1759957047.165338,
    1759957047.3897789,
    1759957047.3979928,
    1759957047.4608412,
    1759957047.5166044,
    1759957047.5726047,
    1759957047.6152055,
    1759957047.6151602,
    1759957047.6847575,
    1759957047.8935199,
    1759957047.9577277,
    1759957048.0938027,
    1759957048.2032452,
    1759957048.316134,
    1759957048.3942957,
    1759957048.4152372,
    1759957048.4207203,
    1759957048.495485,
    1759957048.5140107,
    1759957048.5589046,
    1759957048.698959,
    1759957048.7677608,
    1759957048.8626208,
    1759957048.9073043,
    1759957048.9157314,
    1759957048.940292,
    1759957048.9865496,
    1759957048.9907887,
    1759957049.0218723,
    1759957049.0218253,
    1759957049.0314963,
    1759957049.0864787,
    1759957049.1049485,
    1759957049.1242385,
    1759957049.2663217,
    1759957049.2854629,
    1759957049.3006883,
    1759957049.7928452,
    1759957049.8635225,
    1759957049.9341195,
    1759957049.9411259,
    1759957049.9673772,
    1759957049.9984934,
    1759957050.0822792,
    1759957050.086394,
    1759957050.0922172,
    1759957050.206643,
    1759957050.354335,
    1759957050.4129326,
    1759957050.5545075,
    1759957050.6427195,
    1759957050.760346,
    1759957050.7801716,
    1759957050.7873278,
    1759957050.7997003,
    1759957050.9948053,
    1759957051.0463123,
    1759957051.204773,
    1759957051.2048173,
    1759957051.3338602,
    1759957051.3338144,
    1759957051.351929,
    1759957051.5322976,
    1759957051.590312,
    1759957051.6656005,
    1759957051.7329712,
    1759957051.9249363,
    1759957051.9248881,
    1759957051.932649,
    1759957051.9916575,
    1759957052.073689,
    1759957052.0737228,
    1759957052.2089999,
    1759957052.2619808,
    1759957052.2775877,
    1759957052.3084574,
    1759957052.443529,
    1759957052.4839535,
    1759957052.5101745,
    1759957052.563214,
    1759957052.670386,
    1759957052.6704547,
    1759957052.6704423,
    1759957052.908303,
    1759957052.9267502,
    1759957052.9396203,
    1759957052.9706388,
    1759957053.0974112,
    1759957053.2198114,
    1759957053.3118165,
    1759957053.4304044,
    1759957053.4658673,
    1759957053.6089573,
    1759957053.6820722,
    1759957053.8771205,
    1759957053.9413013,
    1759957053.946379,
    1759957054.020907,
    1759957054.0209332,
    1759957054.0906675,
    1759957054.0906172,
    1759957054.0949419,
    1759957054.239249,
    1759957054.3802667,
    1759957054.5425243,
    1759957054.5424583,
    1759957054.542511,
    1759957054.642966,
    1759957054.6830359,
    1759957054.7213364,
    1759957054.8559198,
    1759957055.1333387,
    1759957055.1837895,
    1759957055.4374504,
    1759957055.4432583,
    1759957055.5023623,
    1759957055.5556748,
    1759957055.6307702,
    1759957055.6407156,
    1759957055.8551311,
    1759957055.9114428,
    1759957055.935093,
    1759957056.0259457,
    1759957056.172279,
    1759957056.200695,
    1759957056.2477536,
    1759957056.3241029,
    1759957056.680577,
    1759957056.712247,
    1759957056.7435443,
    1759957056.8877919,
    1759957056.9165921,
    1759957056.9314072,
    1759957056.982238,
    1759957056.9870477,
    1759957056.9968402,
    1759957057.0050194,
    1759957057.0313933,
    1759957057.0504458,
    1759957057.1940763,
    1759957057.2075818,
    1759957057.2641203,
    1759957057.3316114,
    1759957057.387014,
    1759957057.3949769,
    1759957057.412032,
    1759957057.4218524,
    1759957057.460628,
    1759957057.483514,
    1759957057.5541902,
    1759957057.6058753,
    1759957057.612798,
    1759957057.6127641,
    1759957057.6541,
    1759957057.8232195,
    1759957057.8270552,
    1759957057.903495,
    1759957058.0171032,
    1759957058.194973,
    1759957058.207061,
    1759957058.2144086,
    1759957058.2313082,
    1759957058.5758238,
    1759957058.6457396,
    1759957058.6667113,
    1759957058.716231,
    1759957058.7392883,
    1759957058.7450173,
    1759957058.8661609,
    1759957058.8933682,
    1759957058.9358203,
    1759957058.9718366,
    1759957059.0550911,
    1759957059.1240735,
    1759957059.1717792,
    1759957059.1766386,
    1759957059.2119608,
    1759957059.2256467,
    1759957059.2502732,
    1759957059.2742064,
    1759957059.335737,
    1759957059.3700354,
    1759957059.4115825,
    1759957059.4522784,
    1759957059.5109482,
    1759957059.5938997,
    1759957059.6425643,
    1759957059.6697032,
    1759957059.7179797,
    1759957059.7495613,
    1759957059.8423617,
    1759957059.8734958,
    1759957059.9189773,
    1759957059.926293,
    1759957060.0423865,
    1759957060.2738452,
    1759957060.2874312,
    1759957060.3170683,
    1759957060.461746,
    1759957060.4780343,
    1759957060.5637338,
    1759957060.670426,
    1759957060.7892213,
    1759957060.828052,
    1759957060.840131,
    1759957060.8940442,
    1759957061.0756643,
    1759957061.1068668,
    1759957061.1340995,
    1759957061.2142606,
    1759957061.255405,
    1759957061.2965982,
    1759957061.4048662,
    1759957061.526259,
    1759957061.5763106,
    1759957061.5954583,
    1759957061.665899,
    1759957061.6965692,
    1759957061.8222618,
    1759957061.8268344,
    1759957061.912987,
    1759957061.9180903,
    1759957061.9676185,
    1759957062.0918932,
    1759957062.112963,
    1759957062.1539147,
    1759957062.1538696,
    1759957062.1611567,
    1759957062.1652186,
    1759957062.181003,
    1759957062.1960876,
    1759957062.4889486,
    1759957062.5993276,
    1759957062.6908038,
    1759957062.735289,
    1759957062.7405162,
    1759957062.8056724,
    1759957062.9204006,
    1759957062.955178,
    1759957062.982667,
    1759957063.1422954,
    1759957063.1896636,
    1759957063.2979743,
    1759957063.4062104,
    1759957063.6169078,
    1759957063.629746,
    1759957063.664691,
    1759957063.6874642,
    1759957063.6970365,
    1759957063.7511609,
    1759957063.7643754,
    1759957063.764328,
    1759957063.7799208,
    1759957063.8399153,
    1759957063.8471134,
    1759957063.9109063,
    1759957063.928894,
    1759957063.997896,
    1759957064.0350502,
    1759957064.0912473,
    1759957064.1531634,
    1759957064.2271624,
    1759957064.242745,
    1759957064.2426991,
    1759957064.3325903,
    1759957064.3528514,
    1759957064.4594445,
    1759957064.6586175,
    1759957064.7756073,
    1759957064.789366,
    1759957064.8372452,
    1759957064.9537373,
    1759957064.955046,
    1759957064.997529,
    1759957065.032759,
    1759957065.3782227,
    1759957065.3826406,
    1759957065.4167461,
    1759957065.4241598,
    1759957065.4692388,
    1759957065.5350554,
    1759957065.5501196,
    1759957065.5501585,
    1759957065.66524,
    1759957065.877788,
    1759957065.9538684,
    1759957066.0356412,
    1759957066.057258,
    1759957066.1009388,
    1759957066.156107,
    1759957066.245221,
    1759957066.3202777,
    1759957066.3413455,
    1759957066.3972566,
    1759957066.5948074,
    1759957066.722255,
    1759957066.7762706,
    1759957066.8040164,
    1759957066.8843272,
    1759957066.960371,
    1759957067.0528855,
    1759957067.1871922,
    1759957067.2256982,
    1759957067.2479074,
    1759957067.3338726,
    1759957067.4276018,
    1759957067.439383,
    1759957067.5128155,
    1759957067.5653677,
    1759957067.5730605,
    1759957067.6275487,
    1759957067.6814606,
    1759957067.7061837,
    1759957067.7288268,
    1759957067.7342,
    1759957067.7512252,
    1759957067.790915,
    1759957067.8306952,
    1759957067.9848533,
    1759957068.0746791,
    1759957068.2494946,
    1759957068.5127683,
    1759957068.5171974,
    1759957068.6334784,
    1759957068.7361147,
    1759957068.834888,
    1759957068.9335222,
    1759957069.1546576,
    1759957069.165615,
    1759957069.3036926,
    1759957069.4569106,
    1759957069.4929516,
    1759957069.556171,
    1759957069.606973,
    1759957069.6330628,
    1759957069.6961498,
    1759957069.747397,
    1759957069.8137896,
    1759957069.9514108,
    1759957070.1070688,
    1759957070.2403135,
    1759957070.2687132,
    1759957070.3536391,
    1759957070.5151145,
    1759957070.6201105,
    1759957070.658769,
    1759957070.7670028,
    1759957071.114738,
    1759957071.1932654,
    1759957071.261248,
    1759957071.3020473,
    1759957071.3137221,
    1759957071.3339543,
    1759957071.3401577,
    1759957071.377101,
    1759957071.5216007,
    1759957071.9162805,
    1759957071.9490578,
    1759957072.0697553,
    1759957072.0917037,
    1759957072.1249034,
    1759957072.2116563,
    1759957072.2232428,
    1759957072.2865946,
    1759957072.3196576,
    1759957072.4033828,
    1759957072.412008,
    1759957072.5081575,
    1759957072.5153456,
    1759957072.7211263,
    1759957072.7892938,
    1759957072.8273728,
    1759957073.0416708,
    1759957073.1863177,
    1759957073.1863575,
    1759957073.2642608,
    1759957073.3982434,
    1759957073.414106,
    1759957073.525711,
    1759957073.5575757,
    1759957073.6842146,
    1759957073.8038285,
    1759957073.884818,
    1759957073.8884363,
    1759957073.9524186,
    1759957074.0556214,
    1759957074.0749073,
    1759957074.0836213,
    1759957074.1357763,
    1759957074.2733243,
    1759957074.4341834,
    1759957074.5334783,
    1759957074.5880733,
    1759957074.5993574,
    1759957074.5993986,
    1759957074.697285,
    1759957074.730399,
    1759957074.737149,
    1759957074.794612,
    1759957074.9503775,
    1759957074.9916523,
    1759957075.0179791,
    1759957075.040044,
    1759957075.0540671,
    1759957075.1576018,
    1759957075.2291095,
    1759957075.26622,
    1759957075.4952705,
    1759957075.6219423,
    1759957075.7097938,
    1759957075.8212264,
    1759957075.8476746,
    1759957075.8802824,
    1759957076.0038764,
    1759957076.0319417,
    1759957076.1594136,
    1759957076.1810467,
    1759957076.29182,
    1759957076.2912073,
    1759957076.2969756,
    1759957076.3381517,
    1759957076.5055196,
    1759957076.7088656,
    1759957076.7403889,
    1759957076.794315,
    1759957076.8026743,
    1759957076.8227484,
    1759957076.883084,
    1759957076.9986587,
    1759957077.1018322,
    1759957077.1058714,
    1759957077.1611366,
    1759957077.172265,
    1759957077.2665923,
    1759957077.2760153,
    1759957077.2759993,
    1759957077.2759428,
    1759957077.3513548,
    1759957077.351301,
    1759957077.4113846,
    1759957077.4206364,
    1759957077.4338305,
    1759957077.4407113,
    1759957077.5208778,
    1759957077.527987,
    1759957077.5593958,
    1759957077.5965023,
    1759957077.615967,
    1759957077.6210754,
    1759957077.7948923,
    1759957077.8329036,
    1759957077.8328714,
    1759957077.924274,
    1759957077.9531069,
    1759957078.2132676,
    1759957078.2672582,
    1759957078.2966738,
    1759957078.3049958,
    1759957078.4785638,
    1759957078.5284076,
    1759957078.5441284,
    1759957078.607786,
    1759957078.692979,
    1759957078.8854039,
    1759957078.9309263,
    1759957078.9692695,
    1759957078.9731584,
    1759957079.0149906,
    1759957079.0406237,
    1759957079.2286656,
    1759957079.277715,
    1759957079.4989657,
    1759957079.6275744,
    1759957079.715497,
    1759957079.75196,
    1759957079.7843957,
    1759957079.7976904,
    1759957079.8600104,
    1759957079.95492,
    1759957080.0325198,
    1759957080.0687547,
    1759957080.1261125,
    1759957080.1957412,
    1759957080.2622528,
    1759957080.2890282,
    1759957080.3601553,
    1759957080.36807,
    1759957080.4174926,
    1759957080.4436321,
    1759957080.5083313,
    1759957080.5662336,
    1759957080.5799267,
    1759957080.7224066,
    1759957080.7224731,
    1759957080.722488,
    1759957080.7548232,
    1759957080.754792,
    1759957080.912994,
    1759957080.919347,
    1759957080.929171,
    1759957080.9874384,
    1759957081.1060104,
    1759957081.1161683,
    1759957081.1630228,
    1759957081.3110816,
    1759957081.3251882,
    1759957081.3539777,
    1759957081.3812408,
    1759957081.4338791,
    1759957081.4926615,
    1759957081.538486,
    1759957081.7120063,
    1759957081.7345781,
    1759957081.9092355,
    1759957081.9692352,
    1759957082.0620959,
    1759957082.1170738,
    1759957082.3049433,
    1759957082.3288436,
    1759957082.367554,
    1759957082.407405,
    1759957082.5494103,
    1759957082.573713,
    1759957082.584402,
    1759957082.6442564,
    1759957082.7640786,
    1759957082.8930085,
    1759957082.9286191,
    1759957082.9678388,
    1759957083.2188725,
    1759957083.4888222,
    1759957083.509578,
    1759957083.5181377,
    1759957083.5303164,
    1759957083.5647137,
    1759957083.5805032,
    1759957083.6800961,
    1759957083.8973637,
    1759957083.9667737,
    1759957084.002807,
    1759957084.0308628,
    1759957084.0836725,
    1759957084.1587296,
    1759957084.1695437,
    1759957084.185774,
    1759957084.3102512,
    1759957084.4320114,
    1759957084.5031953,
    1759957084.5779014,
    1759957084.6918643,
    1759957084.7225344,
    1759957084.8431768,
    1759957085.0263572,
    1759957085.050869,
    1759957085.0819035,
    1759957085.1621277,
    1759957085.168807,
    1759957085.2452867,
    1759957085.277489,
    1759957085.3239849,
    1759957085.3239343,
    1759957085.3771677,
    1759957085.4780548,
    1759957085.6522493,
    1759957085.8440297,
    1759957085.9255729,
    1759957086.0758293,
    1759957086.0792634,
    1759957086.134893,
    1759957086.2082348,
    1759957086.2375915,
    1759957086.2375433,
    1759957086.2504532,
    1759957086.2614193,
    1759957086.344154,
    1759957086.3533525,
    1759957086.3533921,
    1759957086.3692362,
    1759957086.570696,
    1759957086.6088185,
    1759957086.643362,
    1759957086.6689224,
    1759957086.7025428,
    1759957086.851681,
    1759957086.8796039,
    1759957086.9018357,
    1759957087.018616,
    1759957087.0221338,
    1759957087.0481963,
    1759957087.0539172,
    1759957087.1385603,
    1759957087.1386092,
    1759957087.2097294,
    1759957087.2222955,
    1759957087.3603878,
    1759957087.8805618,
    1759957088.0629234,
    1759957088.1263723,
    1759957088.1826692,
    1759957088.2059233,
    1759957088.2263072,
    1759957088.2899415,
    1759957088.294072,
    1759957088.5163229,
    1759957088.6864748,
    1759957088.7667518,
    1759957088.8212965,
    1759957088.855326,
    1759957088.8609772,
    1759957088.9125898,
    1759957088.9259126,
    1759957088.9626567,
    1759957089.0041358,
    1759957089.0326188,
    1759957089.1114733,
    1759957089.1396012,
    1759957089.1552522,
    1759957089.261426,
    1759957089.3237932,
    1759957089.3859625,
    1759957089.5631196,
    1759957089.5674758,
    1759957089.5714896,
    1759957089.591072,
    1759957089.6728537,
    1759957089.7599692,
    1759957089.835095,
    1759957089.8455138,
    1759957089.9607277,
    1759957090.0362947,
    1759957090.2923377,
    1759957090.2922435,
    1759957090.2923574,
    1759957090.3119557,
    1759957090.3527067,
    1759957090.4179606,
    1759957090.485962,
    1759957090.5054178,
    1759957090.6441007,
    1759957090.6625242,
    1759957090.849676,
    1759957090.9247184,
    1759957091.0188587,
    1759957091.1001225,
    1759957091.106404,
    1759957091.133983,
    1759957091.2786975,
    1759957091.4230914,
    1759957091.5824559,
    1759957091.605893,
    1759957091.6405697,
    1759957091.896244,
    1759957092.0222259,
    1759957092.1008446,
    1759957092.1249616,
    1759957092.184354,
    1759957092.2333343,
    1759957092.2932186,
    1759957092.482183,
    1759957092.4918509,
    1759957092.5044117,
    1759957092.6885273,
    1759957092.7355678,
    1759957092.8121336,
    1759957092.8794053,
    1759957092.8824048,
    1759957092.895759,
    1759957092.9014642,
    1759957092.9273183,
    1759957093.0715957,
    1759957093.1477487,
    1759957093.1535742,
    1759957093.2560818,
    1759957093.2617228,
    1759957093.2944834,
    1759957093.3534045,
    1759957093.392242,
    1759957093.5125055,
    1759957093.5724723,
    1759957093.65039,
    1759957093.7122793,
    1759957093.7239347,
    1759957093.7642796,
    1759957093.7830873,
    1759957093.794238,
    1759957093.9707425,
    1759957094.1157844,
    1759957094.2029817,
    1759957094.237847,
    1759957094.3227122,
    1759957094.4443896,
    1759957094.476823,
    1759957094.5826902,
    1759957094.684124,
    1759957094.6915116,
    1759957094.7353559,
    1759957094.7985232,
    1759957094.8154917,
    1759957094.9184067,
    1759957094.929245,
    1759957094.9292872,
    1759957094.9560657,
    1759957095.04979,
    1759957095.136211,
    1759957095.165092,
    1759957095.2036414,
    1759957095.2279809,
    1759957095.2929814,
    1759957095.468151,
    1759957095.499694,
    1759957095.5198534,
    1759957095.5466433,
    1759957095.5785928,
    1759957095.608015,
    1759957095.6080523,
    1759957095.659296,
    1759957095.680248,
    1759957095.686355,
    1759957095.7193418,
    1759957095.722857,
    1759957095.7616482,
    1759957095.8258505,
    1759957095.907805,
    1759957095.925998,
    1759957095.9654067,
    1759957095.9991794,
    1759957096.1339843,
    1759957096.1424446,
    1759957096.4530256,
    1759957096.453056,
    1759957096.524203,
    1759957096.5432675,
    1759957096.5482054,
    1759957096.922981,
    1759957097.024461,
    1759957097.1021686,
    1759957097.1134949,
    1759957097.194437,
    1759957097.2081556,
    1759957097.3065128,
    1759957097.3631408,
    1759957097.3631902,
    1759957097.4061885,
    1759957097.4259067,
    1759957097.4877508,
    1759957097.5090032,
    1759957097.509047,
    1759957097.628088,
    1759957097.7246082,
    1759957097.8083754,
    1759957097.851972,
    1759957098.00121,
    1759957098.0338762,
    1759957098.0594618,
    1759957098.1115136,
    1759957098.1222205,
    1759957098.1820853,
    1759957098.2773921,
    1759957098.2948468,
    1759957098.339664,
    1759957098.588681,
    1759957098.6685154,
    1759957098.6780548,
    1759957098.7664926,
    1759957098.7838886,
    1759957098.9983943,
    1759957099.0489962,
    1759957099.0833178,
    1759957099.091787,
    1759957099.1979828,
    1759957099.2206874,
    1759957099.2587688,
    1759957099.2894723,
    1759957099.3192372,
    1759957099.3439453,
    1759957099.5058594,
    1759957099.601414,
    1759957099.636353,
    1759957099.703687,
    1759957099.8068757,
    1759957099.899055,
    1759957099.9834054,
    1759957100.058487,
    1759957100.1242,
    1759957100.2141795,
    1759957100.2350094,
    1759957100.2808373,
    1759957100.29309,
    1759957100.3524938,
    1759957100.4459453,
    1759957100.4935098,
    1759957100.4990458,
    1759957100.5252686,
    1759957100.5424645,
    1759957100.6338096,
    1759957100.6947236,
    1759957100.7422223,
    1759957100.8099694,
    1759957100.8225327,
    1759957101.0438447,
    1759957101.1079288,
    1759957101.2087178,
    1759957101.2392168,
    1759957101.2976968,
    1759957101.3423648,
    1759957101.5172746,
    1759957101.5770864,
    1759957101.6884458,
    1759957101.7452402,
    1759957101.8771696,
    1759957101.9120677,
    1759957101.925075,
    1759957101.9394712,
    1759957102.0116498,
    1759957102.073955,
    1759957102.17695,
    1759957102.1888547,
    1759957102.2206037,
    1759957102.3656943,
    1759957102.529513,
    1759957102.6868682,
    1759957102.8408465,
    1759957102.8619711,
    1759957102.951619,
    1759957102.959203,
    1759957103.1049633,
    1759957103.1126888,
    1759957103.160052,
    1759957103.1976542,
    1759957103.2487013,
    1759957103.3477175,
    1759957103.4544098,
    1759957103.4619162,
    1759957103.4820344,
    1759957103.6589425,
    1759957103.6589026,
    1759957103.7566228,
    1759957103.784439,
    1759957103.7989435,
    1759957104.0084295,
    1759957104.066257,
    1759957104.1397405,
    1759957104.1881373,
    1759957104.2394025,
    1759957104.2678251,
    1759957104.3841476,
    1759957104.4554029,
    1759957104.5006642,
    1759957104.5007114,
    1759957104.5981276,
    1759957104.743072,
    1759957104.7481117,
    1759957104.8509855,
    1759957104.8584168,
    1759957104.9801228,
    1759957105.0275395,
    1759957105.0275872,
    1759957105.0420253,
    1759957105.1393785,
    1759957105.1852303,
    1759957105.192864,
    1759957105.215934,
    1759957105.219739,
    1759957105.2408636,
    1759957105.299447,
    1759957105.2993894,
    1759957105.2994084,
    1759957105.3423848,
    1759957105.4799283,
    1759957105.5097122,
    1759957105.5434809,
    1759957105.5657938,
    1759957105.726519,
    1759957105.7397213,
    1759957105.7396846,
    1759957105.7594855,
    1759957105.8480172,
    1759957105.9249063,
    1759957105.9706812,
    1759957105.9831083,
    1759957106.0236974,
    1759957106.050788,
    1759957106.1518428,
    1759957106.2344897,
    1759957106.3796983,
    1759957106.448504,
    1759957106.6257746,
    1759957106.730524,
    1759957106.7347887,
    1759957106.8151534,
    1759957106.8762012,
    1759957106.966352,
    1759957106.9762025,
    1759957107.054582,
    1759957107.1041386,
    1759957107.126862,
    1759957107.159479,
    1759957107.2390344,
    1759957107.3638546,
    1759957107.3794177,
    1759957107.4421642,
    1759957107.4506934,
    1759957107.474257,
    1759957107.5066228,
    1759957107.554923,
    1759957107.56583,
    1759957107.5992358,
    1759957107.7085986,
    1759957107.737979,
    1759957107.8507216,
    1759957107.8506892,
    1759957107.8567977,
    1759957107.9485922,
    1759957107.967545,
    1759957108.1092749,
    1759957108.138434,
    1759957108.2402062,
    1759957108.2522655,
    1759957108.3312247,
    1759957108.3808591,
    1759957108.4201088,
    1759957108.5718343,
    1759957108.5767813,
    1759957108.6620986,
    1759957108.7491596,
    1759957108.8931339,
    1759957109.0856812,
    1759957109.1047907,
    1759957109.1632352,
    1759957109.1883452,
    1759957109.3112528,
    1759957109.31808,
    1759957109.3181007,
    1759957109.325953,
    1759957109.4918547,
    1759957109.508939,
    1759957109.5142949,
    1759957109.521537,
    1759957109.536021,
    1759957109.626805,
    1759957109.6267414,
    1759957109.6267917,
    1759957109.6594176,
    1759957109.7979763,
    1759957109.9894195,
    1759957109.9995642,
    1759957110.0074058,
    1759957110.0919182,
    1759957110.141488,
    1759957110.1491427,
    1759957110.447412,
    1759957110.521915,
    1759957110.7083366,
    1759957110.789166,
    1759957110.850042,
    1759957110.9179778,
    1759957110.997331,
    1759957111.0848908,
    1759957111.1060848,
    1759957111.1451886,
    1759957111.2758813,
    1759957111.5012786,
    1759957111.589561,
    1759957111.667529,
    1759957111.8428204,
    1759957111.9159417,
    1759957112.043589,
    1759957112.05948,
    1759957112.0988922,
    1759957112.1557705,
    1759957112.1731384,
    1759957112.2380009,
    1759957112.3293722,
    1759957112.3936048,
    1759957112.4535322,
    1759957112.460764,
    1759957112.5134337,
    1759957112.5351796,
    1759957112.5398529,
    1759957112.7281265,
    1759957112.7346692,
    1759957112.7346303,
    1759957112.8929863,
    1759957112.9002702,
    1759957112.900307,
    1759957112.982669,
    1759957112.982698,
    1759957113.0995462,
    1759957113.1461866,
    1759957113.2622523,
    1759957113.3325381,
    1759957113.368435,
    1759957113.4296556,
    1759957113.474954,
    1759957113.5263183,
    1759957113.5316281,
    1759957113.6272066,
    1759957113.6673067,
    1759957113.7151914,
    1759957113.7559135,
    1759957113.7840607,
    1759957113.8431263,
    1759957114.015121,
    1759957114.0288146,
    1759957114.1334236,
    1759957114.139731,
    1759957114.1938014,
    1759957114.2481406,
    1759957114.3459637,
    1759957114.6615787,
    1759957114.670394,
    1759957114.6704657,
    1759957114.6704507,
    1759957114.7216454,
    1759957114.8823996,
    1759957114.9496548,
    1759957114.994044,
    1759957115.0521255,
    1759957115.0984948,
    1759957115.1838255,
    1759957115.4425635,
    1759957115.5188303,
    1759957115.5187776,
    1759957115.5483937,
    1759957115.5674357,
    1759957115.5718484,
    1759957115.599305,
    1759957115.6044588,
    1759957115.647647,
    1759957115.7127955,
    1759957115.7199469,
    1759957115.7754178,
    1759957115.8925765,
    1759957115.9386024,
    1759957116.0147665,
    1759957116.0289943,
    1759957116.0676215,
    1759957116.0795476,
    1759957116.1443002,
    1759957116.3019478,
    1759957116.387392,
    1759957116.3947058,
    1759957116.585062,
    1759957116.6010764,
    1759957116.6207504,
    1759957116.669679,
    1759957116.7836974,
    1759957116.804272,
    1759957117.0956495,
    1759957117.1082509,
    1759957117.3668144,
    1759957117.3839238,
    1759957117.410687,
    1759957117.4327455,
    1759957117.4764743,
    1759957117.5637462,
    1759957117.5963361,
    1759957117.5963163,
    1759957117.6100953,
    1759957117.66306,
    1759957117.6658792,
    1759957117.829326,
    1759957117.8292806,
    1759957117.852869,
    1759957117.961824,
    1759957117.9702876,
    1759957117.9781303,
    1759957118.047056,
    1759957118.183788,
    1759957118.1989775,
    1759957118.1989598,
    1759957118.2915874,
    1759957118.2989452,
    1759957118.407164,
    1759957118.545981,
    1759957118.620466,
    1759957118.6737306,
    1759957118.690144,
    1759957118.8024557,
    1759957118.9173605,
    1759957118.9269376,
    1759957119.047962,
    1759957119.323706,
    1759957119.3237212,
    1759957119.360034,
    1759957119.3803885,
    1759957119.462788,
    1759957119.4781058,
    1759957119.5513678,
    1759957119.5905807,
    1759957119.7179725,
    1759957119.728423,
    1759957119.7780564,
    1759957119.7822833,
    1759957119.9004757,
    1759957120.042538,
    1759957120.0514822,
    1759957120.2393618,
    1759957120.247685,
    1759957120.293573,
    1759957120.415184,
    1759957120.491462,
    1759957120.515887,
    1759957120.5451052,
    1759957120.5534554,
    1759957120.6159942,
    1759957120.7765958,
    1759957120.798774,
    1759957120.8146005,
    1759957120.873119,
    1759957121.056605,
    1759957121.0809028,
    1759957121.0922103,
    1759957121.383404,
    1759957121.4309645,
    1759957121.435843,
    1759957121.4607866,
    1759957121.6362736,
    1759957121.878061,
    1759957121.9652092,
    1759957122.0596693,
    1759957122.071682,
    1759957122.0724664,
    1759957122.0849707,
    1759957122.0993767,
    1759957122.1188982,
    1759957122.2135947,
    1759957122.219081,
    1759957122.3050857,
    1759957122.3088043,
    1759957122.4333107,
    1759957122.443442,
    1759957122.5170755,
    1759957122.5268285,
    1759957122.5924447,
    1759957122.600416,
    1759957122.6678784,
    1759957122.720635,
    1759957122.7502651,
    1759957122.870052,
    1759957122.9231253,
    1759957122.9649298,
    1759957123.0220637,
    1759957123.1162686,
    1759957123.1381686,
    1759957123.3323593,
    1759957123.4837124,
    1759957123.4910789,
    1759957123.5550897,
    1759957123.655149,
    1759957123.6861904,
    1759957123.7215264,
    1759957123.735111,
    1759957123.8425622,
    1759957123.8474529,
    1759957123.990844,
    1759957124.1354973,
    1759957124.2558048,
    1759957124.2594352,
    1759957124.2777917,
    1759957124.2900949,
    1759957124.29532,
    1759957124.3669133,
    1759957124.3927717,
    1759957124.4695206,
    1759957124.4740803,
    1759957124.506427,
    1759957124.5651727,
    1759957124.6197262,
    1759957124.8873932,
    1759957124.927035,
    1759957124.9590364,
    1759957124.9793072,
    1759957125.054849,
    1759957125.09242,
    1759957125.098571,
    1759957125.1199908,
    1759957125.2231402,
    1759957125.4051423,
    1759957125.5719526,
    1759957125.7819793,
    1759957125.789024,
    1759957125.8415542,
    1759957125.9684489,
    1759957126.0893474,
    1759957126.1085184,
    1759957126.209297,
    1759957126.3648539,
    1759957126.3993773,
    1759957126.4057562,
    1759957126.4678497,
    1759957126.4762704,
    1759957126.5043952,
    1759957126.6482103,
    1759957126.655718,
    1759957126.786236,
    1759957126.922189,
    1759957126.931802,
    1759957126.942919,
    1759957126.9743462,
    1759957126.9743056,
    1759957127.1044116,
    1759957127.1287978,
    1759957127.223763,
    1759957127.2987795,
    1759957127.3054326,
    1759957127.3246136,
    1759957127.4856734,
    1759957127.5282269,
    1759957127.528168,
    1759957127.551748,
    1759957127.5517044,
    1759957127.5649602,
    1759957127.6620057,
    1759957127.6620524,
    1759957127.716161,
    1759957127.7161162,
    1759957127.781398,
    1759957127.8016133,
    1759957127.8329685,
    1759957127.9270976,
    1759957127.967831,
    1759957127.9904335,
    1759957128.1026719,
    1759957128.107404,
    1759957128.2361197,
    1759957128.2400942,
    1759957128.25259,
    1759957128.408219,
    1759957128.5291886,
    1759957128.5292306,
    1759957128.5691473,
    1759957128.619602,
    1759957128.7754247,
    1759957128.7856646,
    1759957128.785625,
    1759957128.8137543,
    1759957129.029008,
    1759957129.029028,
    1759957129.0406582,
    1759957129.0650342,
    1759957129.199454,
    1759957129.2658489,
    1759957129.3200996,
    1759957129.3360305,
    1759957129.4133623,
    1759957129.4399288,
    1759957129.5378978,
    1759957129.635303,
    1759957129.6631129,
    1759957129.667573,
    1759957129.6808133,
    1759957129.6900523,
    1759957129.7132306,
    1759957130.074241,
    1759957130.116254,
    1759957130.143735,
    1759957130.2962265,
    1759957130.4027512,
    1759957130.4028008,
    1759957130.4135532,
    1759957130.5823083,
    1759957130.6150715,
    1759957130.6349537,
    1759957130.634909,
    1759957130.6783378,
    1759957130.803023,
    1759957130.876432,
    1759957130.8816411,
    1759957130.9351127,
    1759957131.0911248,
    1759957131.1337316,
    1759957131.2038412,
    1759957131.2641225,
    1759957131.2954612,
    1759957131.3871446,
    1759957131.4214826,
    1759957131.5277781,
    1759957131.6946344,
    1759957131.7983856,
    1759957131.8562431,
    1759957131.8956022,
    1759957132.088946,
    1759957132.1417644,
    1759957132.1776838,
    1759957132.2702935,
    1759957132.3463368,
    1759957132.3753722,
    1759957132.427949,
    1759957132.5001993,
    1759957132.8095188,
    1759957132.8378892,
    1759957132.8917422,
    1759957132.9698935,
    1759957133.0473049,
    1759957133.0713418,
    1759957133.1130352,
    1759957133.1170394,
    1759957133.1679015,
    1759957133.1828303,
    1759957133.2257965,
    1759957133.4554665,
    1759957133.5578427,
    1759957133.6521566,
    1759957133.74073,
    1759957133.8866463,
    1759957134.0043478,
    1759957134.0886922,
    1759957134.1609678,
    1759957134.2514572,
    1759957134.2624342,
    1759957134.3409774,
    1759957134.3984365,
    1759957134.4739974,
    1759957134.5672088,
    1759957134.7323868,
    1759957134.7926073,
    1759957134.8298862,
    1759957134.8401108,
    1759957134.990368,
    1759957135.008381,
    1759957135.0138843,
    1759957135.050529,
    1759957135.257258,
    1759957135.3510444,
    1759957135.4321268,
    1759957135.49391,
    1759957135.5264945,
    1759957135.5437355,
    1759957135.6261227,
    1759957135.726213,
    1759957135.7262568,
    1759957135.8098218,
    1759957135.8984983,
    1759957135.9066818,
    1759957136.034286,
    1759957136.0915942,
    1759957136.0915446,
    1759957136.1312885,
    1759957136.1929886,
    1759957136.2767851,
    1759957136.3482113,
    1759957136.3627694,
    1759957136.5111258,
    1759957136.5191348,
    1759957136.5578532,
    1759957136.568224,
    1759957136.6395702,
    1759957136.6396158,
    1759957136.731807,
    1759957136.7398264,
    1759957136.7936864,
    1759957136.8013344,
    1759957136.8479548,
    1759957137.0964909,
    1759957137.1968782,
    1759957137.322019,
    1759957137.4508042,
    1759957137.696111,
    1759957137.7703729,
    1759957137.814115,
    1759957137.8450305,
    1759957137.8932116,
    1759957137.9309757,
    1759957137.9568636,
    1759957137.9988892,
    1759957138.084589,
    1759957138.174633,
    1759957138.2299364,
    1759957138.2348356,
    1759957138.2405703,
    1759957138.2930987,
    1759957138.4492104,
    1759957138.4590316,
    1759957138.4657984,
    1759957138.5924091,
    1759957138.6499927,
    1759957138.658412,
    1759957138.726191,
    1759957138.741468,
    1759957138.7456553,
    1759957138.8032382,
    1759957138.9062445,
    1759957138.9124851,
    1759957138.922911,
    1759957138.9913557,
    1759957139.01081,
    1759957139.1086917,
    1759957139.1321704,
    1759957139.146842,
    1759957139.3488169,
    1759957139.449742,
    1759957139.501579,
    1759957139.5091722,
    1759957139.5626297,
    1759957139.7018526,
    1759957139.736899,
    1759957139.7412326,
    1759957139.7513692,
    1759957139.7825186,
    1759957139.9033806,
    1759957139.9446015,
    1759957139.9781525,
    1759957139.9871316,
    1759957140.043488,
    1759957140.0655613,
    1759957140.0920224,
    1759957140.195456,
    1759957140.2033124,
    1759957140.233646,
    1759957140.346365,
    1759957140.5205178,
    1759957140.5483425,
    1759957140.6381366,
    1759957140.6475534,
    1759957140.658282,
    1759957140.7373204,
    1759957140.8105593,
    1759957140.8346217,
    1759957140.8437936,
    1759957140.9055882,
    1759957140.914429,
    1759957140.9503145,
    1759957140.9933662,
    1759957141.0041761,
    1759957141.0182433,
    1759957141.1750329,
    1759957141.2866485,
    1759957141.286693,
    1759957141.2943728,
    1759957141.3501697,
    1759957141.378723,
    1759957141.4467504,
    1759957141.4829826,
    1759957141.626278,
    1759957141.6490383,
    1759957141.6755288,
    1759957141.6907027,
    1759957141.7069652,
    1759957141.8296785,
    1759957142.0478551,
    1759957142.0741324,
    1759957142.184562,
    1759957142.1954057,
    1759957142.2212925,
    1759957142.393787,
    1759957142.5088596,
    1759957142.5343254,
    1759957142.5587766,
    1759957142.6546118,
    1759957142.671226,
    1759957142.6742873,
    1759957142.6867054,
    1759957142.7888644,
    1759957142.8117342,
    1759957142.8117797,
    1759957142.8186593,
    1759957142.8929036,
    1759957142.9183867,
    1759957142.9183588,
    1759957142.9356303,
    1759957142.9356673,
    1759957142.9391854,
    1759957142.9887738,
    1759957143.0518398,
    1759957143.1430755,
    1759957143.2183917,
    1759957143.4214737,
    1759957143.4394972,
    1759957143.5073311,
    1759957143.679599,
    1759957143.916643,
    1759957143.9513562,
    1759957144.0450935,
    1759957144.0953982,
    1759957144.190005,
    1759957144.2105796,
    1759957144.2406995,
    1759957144.289509,
    1759957144.3786125,
    1759957144.3951592,
    1759957144.4655375,
    1759957144.524926,
    1759957144.5341938,
    1759957144.5377195,
    1759957144.9674098,
    1759957145.079124,
    1759957145.1947086,
    1759957145.2370186,
    1759957145.2759702,
    1759957145.2833285,
    1759957145.3279903,
    1759957145.5032775,
    1759957145.5240195,
    1759957145.533255,
    1759957145.6830878,
    1759957145.6986144,
    1759957145.8605506,
    1759957145.865373,
    1759957145.8715434,
    1759957145.9119017,
    1759957145.9697309,
    1759957146.1314874,
    1759957146.1434457,
    1759957146.1986284,
    1759957146.2481515,
    1759957146.3392136,
    1759957146.3707173,
    1759957146.4548833,
    1759957146.4744222,
    1759957146.548547,
    1759957146.606279,
    1759957146.6663592,
    1759957146.745217,
    1759957146.783535,
    1759957146.8224175,
    1759957146.8325868,
    1759957146.864874,
    1759957146.8988554,
    1759957146.9563336,
    1759957146.9984202,
    1759957147.0264323,
    1759957147.082953,
    1759957147.1305897,
    1759957147.1983728,
    1759957147.207045,
    1759957147.2479112,
    1759957147.3695624,
    1759957147.4230814,
    1759957147.4836986,
    1759957147.5689383,
    1759957147.5835812,
    1759957147.6466923,
    1759957147.6914978,
    1759957147.7389784,
    1759957147.7741566,
    1759957148.0120256,
    1759957148.076588,
    1759957148.1619258,
    1759957148.1826375,
    1759957148.2184882,
    1759957148.2316449,
    1759957148.4302917,
    1759957148.5460856,
    1759957148.5747576,
    1759957148.6031785,
    1759957148.772672,
    1759957148.8355997,
    1759957148.862156,
    1759957148.9699652,
    1759957149.0138767,
    1759957149.0189075,
    1759957149.018858,
    1759957149.0594618,
    1759957149.2888038,
    1759957149.3070126,
    1759957149.3507898,
    1759957149.5019608,
    1759957149.5519495,
    1759957149.5613143,
    1759957149.6999073,
    1759957149.720375,
    1759957149.88499,
    1759957149.9129865,
    1759957149.9598126,
    1759957150.0481677,
    1759957150.0695944,
    1759957150.2370923,
    1759957150.2809696,
    1759957150.3197541,
    1759957150.4486897,
    1759957150.5303454,
    1759957150.5501533,
    1759957150.861554,
    1759957150.904595,
    1759957150.9230227,
    1759957150.9483776,
    1759957150.9992576,
    1759957151.107121,
    1759957151.1316786,
    1759957151.150813,
    1759957151.2493107,
    1759957151.3240678,
    1759957151.4076657,
    1759957151.4248793,
    1759957151.4492807,
    1759957151.5842621,
    1759957151.6192825,
    1759957151.6412406,
    1759957151.6547058,
    1759957151.674024,
    1759957151.6939805,
    1759957151.7424095,
    1759957151.773703,
    1759957151.9448755,
    1759957152.0992825,
    1759957152.1531339,
    1759957152.2843187,
    1759957152.4474776,
    1759957152.4659877,
    1759957152.5031264,
    1759957152.629183,
    1759957152.6508875,
    1759957152.7355893,
    1759957152.7441576,
    1759957152.778259,
    1759957152.8082662,
    1759957152.8539,
    1759957152.9386263,
    1759957152.9883776,
    1759957153.026939,
    1759957153.0613122,
    1759957153.099494,
    1759957153.1549764,
    1759957153.1607912,
    1759957153.1687677,
    1759957153.1887782,
    1759957153.7401073,
    1759957153.8167713,
    1759957153.8342488,
    1759957154.0153039,
    1759957154.0723028,
    1759957154.1756775,
    1759957154.3057895,
    1759957154.3796656,
    1759957154.4168737,
    1759957154.4793103,
    1759957154.914089,
    1759957155.1465018,
    1759957155.1705801,
    1759957155.2316887,
    1759957155.285296,
    1759957155.2982125,
    1759957155.3034167,
    1759957155.3911328,
    1759957155.4155087,
    1759957155.535215,
    1759957155.5942683,
    1759957155.6025643,
    1759957155.655627,
    1759957155.7873797,
    1759957155.8346255,
    1759957155.969476,
    1759957156.1578875,
    1759957156.2798154,
    1759957156.3568223,
    1759957156.479658,
    1759957156.4880786,
    1759957156.4924357,
    1759957156.5008166,
    1759957156.5374157,
    1759957156.578923,
    1759957156.5905726,
    1759957156.6112819,
    1759957156.6292396,
    1759957156.6715903,
    1759957156.6853318,
    1759957156.70155,
    1759957156.8680406,
    1759957156.978668,
    1759957157.0123656,
    1759957157.0382893,
    1759957157.1659088,
    1759957157.1965432,
    1759957157.2285485,
    1759957157.3094873,
    1759957157.39323,
    1759957157.4008193,
    1759957157.400779,
    1759957157.484106,
    1759957157.502599,
    1759957157.5025537,
    1759957157.5391068,
    1759957157.750596,
    1759957157.7505794,
    1759957157.7797594,
    1759957157.7797744,
    1759957157.7796998,
    1759957157.8096154,
    1759957157.8096466,
    1759957157.8769755,
    1759957157.9193122,
    1759957157.9413931,
    1759957157.9750981,
    1759957157.9818993,
    1759957158.0866687,
    1759957158.1652687,
    1759957158.1786346,
    1759957158.2406473,
    1759957158.2454085,
    1759957158.2796502,
    1759957158.441158,
    1759957158.4599216,
    1759957158.475369,
    1759957158.4955323,
    1759957158.5441318,
    1759957158.5560825,
    1759957158.585614,
    1759957158.6115391,
    1759957158.633054,
    1759957158.7180195,
    1759957158.7580657,
    1759957158.9249105,
    1759957158.9798708,
    1759957158.985573,
    1759957159.074697,
    1759957159.1447537,
    1759957159.1630096,
    1759957159.174137,
    1759957159.1846313,
    1759957159.2854233,
    1759957159.3575377,
    1759957159.3686206,
    1759957159.382665,
    1759957159.3926334,
    1759957159.4176738,
    1759957159.5365264,
    1759957159.5709352,
    1759957159.576368,
    1759957159.709658,
    1759957159.8349268,
    1759957159.9265776,
    1759957160.035301,
    1759957160.0693407,
    1759957160.081178,
    1759957160.1122186,
    1759957160.1801603,
    1759957160.2061303,
    1759957160.508472,
    1759957160.6118963,
    1759957160.6245837,
    1759957160.6787174,
    1759957160.8474066,
    1759957160.9240828,
    1759957161.04395,
    1759957161.1873326,
    1759957161.2646368,
    1759957161.2691455,
    1759957161.440443,
    1759957161.4404044,
    1759957161.6296217,
    1759957161.708433,
    1759957161.7184482,
    1759957161.8705137,
    1759957161.9453378,
    1759957161.9967685,
    1759957162.0187736,
    1759957162.0556483,
    1759957162.05941,
    1759957162.151111,
    1759957162.1690037,
    1759957162.2839494,
    1759957162.3529456,
    1759957162.6987114,
    1759957162.708851,
    1759957162.8744857,
    1759957162.8744621,
    1759957162.9684522,
    1759957163.0161612,
    1759957163.0795882,
    1759957163.0876496,
    1759957163.1642537,
    1759957163.1687994,
    1759957163.1729622,
    1759957163.2662773,
    1759957163.335651,
    1759957163.442851,
    1759957163.4586482,
    1759957163.557679,
    1759957163.7859645,
    1759957163.9399965,
    1759957163.9456844,
    1759957164.116424,
    1759957164.1164026,
    1759957164.1239748,
    1759957164.1627162,
    1759957164.2273383,
    1759957164.317516,
    1759957164.3335273,
    1759957164.3844063,
    1759957164.396744,
    1759957164.4866843,
    1759957164.5171285,
    1759957164.5279543,
    1759957164.6023562,
    1759957164.712951,
    1759957164.81028,
    1759957165.0376377,
    1759957165.0536702,
    1759957165.4308019,
    1759957165.4475133,
    1759957165.4535131,
    1759957165.6827881,
    1759957165.695587,
    1759957165.7716968,
    1759957165.897215,
    1759957165.9443138,
    1759957165.9519925,
    1759957165.9550402,
    1759957165.973487,
    1759957166.0080452,
    1759957166.0510046,
    1759957166.1174474,
    1759957166.1439877,
    1759957166.1760073,
    1759957166.2747362,
    1759957166.3934367,
    1759957166.4090896,
    1759957166.426199,
    1759957166.4597442,
    1759957166.4851892,
    1759957166.625985,
    1759957166.6520576,
    1759957166.6706455,
    1759957166.758675,
    1759957166.7706573,
    1759957166.855106,
    1759957166.9085135,
    1759957166.993038,
    1759957167.1441967,
    1759957167.2725482,
    1759957167.2977295,
    1759957167.3708043,
    1759957167.4184487,
    1759957167.4656866,
    1759957167.5377636,
    1759957167.5448341,
    1759957167.573624,
    1759957167.6916785,
    1759957167.738822,
    1759957167.8350875,
    1759957167.8832068,
    1759957167.9591115,
    1759957168.1162002,
    1759957168.2432833,
    1759957168.3071804,
    1759957168.3311293,
    1759957168.4825282,
    1759957168.5528457,
    1759957168.5919087,
    1759957168.6021101,
    1759957168.700598,
    1759957168.787697,
    1759957168.9829278,
    1759957169.069557,
    1759957169.1334283,
    1759957169.1938658,
    1759957169.1998067,
    1759957169.2249022,
    1759957169.2682061,
    1759957169.338928,
    1759957169.360904,
    1759957169.4329875,
    1759957169.4329412,
    1759957169.45883,
    1759957169.5148382,
    1759957169.5344214,
    1759957169.5828073,
    1759957169.726267,
    1759957169.9226406,
    1759957169.9754684,
    1759957170.041424,
    1759957170.0505679,
    1759957170.0506036,
    1759957170.1462233,
    1759957170.294897,
    1759957170.339819,
    1759957170.3571548,
    1759957170.5378373,
    1759957170.5441594,
    1759957170.67577,
    1759957170.7136505,
    1759957170.9568799,
    1759957170.9855754,
    1759957171.3346193,
    1759957171.3483596,
    1759957171.373756,
    1759957171.45293,
    1759957171.590835,
    1759957171.6129422,
    1759957171.8942661,
    1759957171.9170516,
    1759957172.1750295,
    1759957172.3219721,
    1759957172.334026,
    1759957172.3857965,
    1759957172.5103037,
    1759957172.6526914,
    1759957172.673731,
    1759957172.881119,
    1759957172.884791,
    1759957172.9658947,
    1759957172.9723341,
    1759957172.9939153,
    1759957173.1083236,
    1759957173.181951,
    1759957173.2218175,
    1759957173.231887,
    1759957173.3144422,
    1759957173.33261,
    1759957173.452266,
    1759957173.514382,
    1759957173.6167839,
    1759957173.692455,
    1759957173.713439,
    1759957173.8611186,
    1759957173.9065413,
    1759957174.000416,
    1759957174.0421724,
    1759957174.110372,
    1759957174.1156101,
    1759957174.2872024,
    1759957174.2907193,
    1759957174.2955647,
    1759957174.342839,
    1759957174.47188,
    1759957174.4796586,
    1759957174.535562,
    1759957174.6166816,
    1759957174.6359048,
    1759957174.6799378,
    1759957174.7165153,
    1759957174.7762055,
    1759957174.8913543,
    1759957175.0149727,
    1759957175.2669632,
    1759957175.2840924,
    1759957175.4546058,
    1759957175.5519974,
    1759957175.5855303,
    1759957175.6006756,
    1759957175.6469069,
    1759957175.684006,
    1759957175.7097907,
    1759957175.7255094,
    1759957175.7383986,
    1759957175.8258777,
    1759957175.8521016,
    1759957175.8879101,
    1759957176.0417898,
    1759957176.0520065,
    1759957176.1853235,
    1759957176.3968205,
    1759957176.5906782,
    1759957176.5906365,
    1759957176.8925648,
    1759957176.8971865,
    1759957176.9715703,
    1759957177.0998235,
    1759957177.1404502,
    1759957177.2347786,
    1759957177.2425244,
    1759957177.2471566,
    1759957177.4316113,
    1759957177.4401793,
    1759957177.440141,
    1759957177.473824,
    1759957177.5072234,
    1759957177.574779,
    1759957177.6962996,
    1759957177.77384,
    1759957177.8327491,
    1759957177.875173,
    1759957177.941881,
    1759957178.0291796,
    1759957178.0797305,
    1759957178.4172897,
    1759957178.4324334,
    1759957178.4407167,
    1759957178.5687683,
    1759957178.5979943,
    1759957178.7660553,
    1759957178.801447,
    1759957178.81823,
    1759957178.8423388,
    1759957178.8596578,
    1759957178.8701909,
    1759957178.881136,
    1759957178.9890933,
    1759957179.140678,
    1759957179.1821826,
    1759957179.2384508,
    1759957179.2485616,
    1759957179.2690492,
    1759957179.2690933,
    1759957179.520421,
    1759957179.6069086,
    1759957179.6410203,
    1759957179.6590312,
    1759957180.0082777,
    1759957180.0120943,
    1759957180.0717654,
    1759957180.09826,
    1759957180.1595094,
    1759957180.3289003,
    1759957180.4514394,
    1759957180.515764,
    1759957180.7220442,
    1759957180.8188233,
    1759957180.934243,
    1759957180.9704406,
    1759957180.9887805,
    1759957181.0683577,
    1759957181.1470487,
    1759957181.158502,
    1759957181.158518,
    1759957181.1955473,
    1759957181.2878866,
    1759957181.3643525,
    1759957181.5539544,
    1759957181.6136975,
    1759957181.6254086,
    1759957181.6732266,
    1759957181.723358,
    1759957181.7234046,
    1759957181.767552,
    1759957181.7802863,
    1759957181.8214977,
    1759957181.928982,
    1759957182.032386,
    1759957182.0759907,
    1759957182.1052155,
    1759957182.1493387,
    1759957182.2415657,
    1759957182.3498328,
    1759957182.3754225,
    1759957182.4560595,
    1759957182.5025942,
    1759957182.5119696,
    1759957182.5405688,
    1759957182.5473704,
    1759957182.573098,
    1759957182.7228205,
    1759957182.8084624,
    1759957182.8409166,
    1759957182.8595507,
    1759957182.8805792,
    1759957182.9168692,
    1759957182.9204934,
    1759957182.9424233,
    1759957183.017293,
    1759957183.017255,
    1759957183.0344217,
    1759957183.0817022,
    1759957183.0817456,
    1759957183.1753037,
    1759957183.221877,
    1759957183.310782,
    1759957183.3601162,
    1759957183.4483976,
    1759957183.580114,
    1759957183.596365,
    1759957183.603586,
    1759957183.63443,
    1759957183.6533659,
    1759957183.7316608,
    1759957183.7317078,
    1759957183.7582233,
    1759957183.7581801,
    1759957183.765496,
    1759957183.8045099,
    1759957183.969461,
    1759957183.9990048,
    1759957184.0454197,
    1759957184.0805237,
    1759957184.1682363,
    1759957184.2269053,
    1759957184.2760093,
    1759957184.2903042,
    1759957184.3390512,
    1759957184.5839179,
    1759957184.5839672,
    1759957184.5900254,
    1759957184.590062,
    1759957184.7143826,
    1759957184.9401288,
    1759957185.0968387,
    1759957185.0967932,
    1759957185.14761,
    1759957185.164772,
    1759957185.2164152,
    1759957185.2270193,
    1759957185.4034793,
    1759957185.6290607,
    1759957185.652071,
    1759957185.6628072,
    1759957185.6627645,
    1759957185.6661336,
    1759957185.7545733,
    1759957185.824518,
    1759957185.8883345,
    1759957185.8995094,
    1759957185.8995526,
    1759957185.903201,
    1759957185.9460351,
    1759957185.9599962,
    1759957185.9804213,
    1759957186.0609384,
    1759957186.0870516,
    1759957186.1987445,
    1759957186.297829,
    1759957186.3435204,
    1759957186.3812757,
    1759957186.3813045,
    1759957186.4076176,
    1759957186.432371,
    1759957186.575389,
    1759957186.6348693,
    1759957186.7060254,
    1759957186.7060726,
    1759957186.7576258,
    1759957186.7892485,
    1759957186.7953212,
    1759957186.888878,
    1759957187.0287626,
    1759957187.062378,
    1759957187.062423,
    1759957187.074412,
    1759957187.0744517,
    1759957187.104429,
    1759957187.2427056,
    1759957187.281276,
    1759957187.319723,
    1759957187.3383517,
    1759957187.4303765,
    1759957187.4903455,
    1759957187.5458746,
    1759957187.5723147,
    1759957187.8568413,
    1759957187.8605225,
    1759957188.0252335,
    1759957188.0448837,
    1759957188.0658572,
    1759957188.0952017,
    1759957188.2216713,
    1759957188.2584317,
    1759957188.2834508,
    1759957188.3454666,
    1759957188.38534,
    1759957188.476403,
    1759957188.476449,
    1759957188.5505865,
    1759957188.575656,
    1759957188.6047347,
    1759957188.8026426,
    1759957188.9817693,
    1759957189.0030458,
    1759957189.0783622,
    1759957189.0843444,
    1759957189.1234632,
    1759957189.1729906,
    1759957189.3732553,
    1759957189.4735696,
    1759957189.4854717,
    1759957189.4855092,
    1759957189.7085724,
    1759957189.7241135,
    1759957189.7618814,
    1759957189.7944427,
    1759957189.7981625,
    1759957189.962071,
    1759957189.9684043,
    1759957189.9875672,
    1759957190.0986962,
    1759957190.121179,
    1759957190.272326,
    1759957190.3303714,
    1759957190.3629308,
    1759957190.3672295,
    1759957190.3962252,
    1759957190.4158175,
    1759957190.464788,
    1759957190.5586607,
    1759957190.585852,
    1759957190.6025677,
    1759957190.6111054,
    1759957190.6452863,
    1759957190.7411575,
    1759957190.8774104,
    1759957190.8897448,
    1759957190.910651,
    1759957190.9547036,
    1759957190.972469,
    1759957191.268974,
    1759957191.2756891,
    1759957191.3370864,
    1759957191.4237912,
    1759957191.4459445,
    1759957191.5177884,
    1759957191.6196024,
    1759957191.709021,
    1759957191.7583055,
    1759957191.8288784,
    1759957191.901279,
    1759957191.9067578,
    1759957192.0747902,
    1759957192.1723835,
    1759957192.2647493,
    1759957192.4334488,
    1759957192.4901621,
    1759957192.5080597,
    1759957192.5080254,
    1759957192.6123424,
    1759957192.6257997,
    1759957192.625771,
    1759957192.6415746,
    1759957192.646531,
    1759957192.6871288,
    1759957192.7100961,
    1759957192.7584572,
    1759957192.777685,
    1759957192.8826115,
    1759957192.8825674,
    1759957192.89196,
    1759957192.8927865,
    1759957192.9019656,
    1759957192.9565158,
    1759957193.0727077,
    1759957193.0984864,
    1759957193.1646407,
    1759957193.1759977,
    1759957193.2693565,
    1759957193.3490224,
    1759957193.3642404,
    1759957193.6385524,
    1759957193.6561553,
    1759957193.6562166,
    1759957193.6974642,
    1759957193.7061806,
    1759957193.7061408,
    1759957193.7161708,
    1759957193.7368827,
    1759957193.7856696,
    1759957193.8754706,
    1759957193.903692,
    1759957194.1021864,
    1759957194.1106148,
    1759957194.1659815,
    1759957194.2708771,
    1759957194.2970312,
    1759957194.3373926,
    1759957194.4041734,
    1759957194.4100838,
    1759957194.539748,
    1759957194.5697832,
    1759957194.704936,
    1759957194.7308316,
    1759957194.7526605,
    1759957194.7951474,
    1759957194.8137991,
    1759957194.8138454,
    1759957194.8214254,
    1759957194.8408146,
    1759957194.8589263,
    1759957194.8938694,
    1759957194.928481,
    1759957194.9285235,
    1759957194.9919121,
    1759957195.045062,
    1759957195.1925743,
    1759957195.215092,
    1759957195.215134,
    1759957195.2328942,
    1759957195.2466695,
    1759957195.327225,
    1759957195.510272,
    1759957195.5177023,
    1759957195.5839777,
    1759957195.729782,
    1759957195.7558517,
    1759957195.80026,
    1759957195.830411,
    1759957195.850489,
    1759957195.874233,
    1759957196.017714,
    1759957196.032782,
    1759957196.0328193,
    1759957196.1237197,
    1759957196.2050607,
    1759957196.2526493,
    1759957196.3838131,
    1759957196.4039214,
    1759957196.415536,
    1759957196.4348862,
    1759957196.5915592,
    1759957196.7751763,
    1759957196.8518066,
    1759957196.8640246,
    1759957196.8731868,
    1759957196.9098053,
    1759957196.9234145,
    1759957196.9298086,
    1759957196.9545925,
    1759957197.0205069,
    1759957197.072277,
    1759957197.0909705,
    1759957197.1288505,
    1759957197.1419697,
    1759957197.2058897,
    1759957197.2433202,
    1759957197.2560952,
    1759957197.3179555,
    1759957197.322276,
    1759957197.4501383,
    1759957197.5537927,
    1759957197.594073,
    1759957197.6728337,
    1759957198.3178024,
    1759957198.395228,
    1759957198.4474478,
    1759957198.5178175,
    1759957198.5344706,
    1759957198.5345013,
    1759957198.6119664,
    1759957198.612013,
    1759957198.6970577,
    1759957198.8060505,
    1759957199.0752532,
    1759957199.2933586,
    1759957199.3268042,
    1759957199.334031,
    1759957199.5295048,
    1759957199.5392485,
    1759957199.5985003,
    1759957199.6260304,
    1759957199.6643174,
    1759957199.6745398,
    1759957199.9049032,
    1759957199.9295974,
    1759957199.9295657,
    1759957199.929615,
    1759957199.9296308,
    1759957199.9296448,
    1759957199.962328,
    1759957199.976519,
    1759957200.0949547,
    1759957200.154898,
    1759957200.160388,
    1759957200.1983125,
    1759957200.198359,
    1759957200.237929,
    1759957200.2724528,
    1759957200.4737644,
    1759957200.7011912,
    1759957200.762825,
    1759957200.8028922,
    1759957200.857054,
    1759957200.908983,
    1759957200.9660852,
    1759957201.0399404,
    1759957201.1340897,
    1759957201.1763103,
    1759957201.1803327,
    1759957201.2909608,
    1759957201.3219144,
    1759957201.3219461,
    1759957201.3261602,
    1759957201.3872762,
    1759957201.4154587,
    1759957201.4848175,
    1759957201.543576,
    1759957201.577984,
    1759957201.6042545,
    1759957201.714695,
    1759957201.8924422,
    1759957201.9037652,
    1759957202.1318128,
    1759957202.1696837,
    1759957202.173991,
    1759957202.2042427,
    1759957202.2334485,
    1759957202.3741758,
    1759957202.4682224,
    1759957202.490688,
    1759957202.5421333,
    1759957202.5645058,
    1759957202.5644898,
    1759957202.5862927,
    1759957202.697665,
    1759957202.7195053,
    1759957202.7313578,
    1759957202.731322,
    1759957202.820715,
    1759957202.9341898,
    1759957202.9595342,
    1759957203.1713514,
    1759957203.2295709,
    1759957203.2544196,
    1759957203.4263847,
    1759957203.4798896,
    1759957203.6018434,
    1759957203.668509,
    1759957203.7045054,
    1759957203.7608953,
    1759957203.766425,
    1759957203.822086,
    1759957203.834646,
    1759957203.8813472,
    1759957203.9867828,
    1759957203.9868112,
    1759957204.2405095,
    1759957204.2494779,
    1759957204.24944,
    1759957204.3626232,
    1759957204.515173,
    1759957204.5814435,
    1759957204.587971,
    1759957204.5971875,
    1759957204.7056012,
    1759957204.7349524,
    1759957204.7631185,
    1759957204.8661332,
    1759957204.9159355,
    1759957205.0173872,
    1759957205.029317,
    1759957205.0508242,
    1759957205.0508704,
    1759957205.0508392,
    1759957205.0852494,
    1759957205.158631,
    1759957205.1778843,
    1759957205.1819544,
    1759957205.2259898,
    1759957205.2259445,
    1759957205.2478156,
    1759957205.4433057,
    1759957205.4491816,
    1759957205.5329103,
    1759957205.624488,
    1759957205.7679439,
    1759957205.8585193,
    1759957205.9175246,
    1759957206.1157563,
    1759957206.1301858,
    1759957206.20205,
    1759957206.2099652,
    1759957206.235305,
    1759957206.4406798,
    1759957206.5182683,
    1759957206.531442,
    1759957206.560357,
    1759957206.6694555,
    1759957206.782196,
    1759957206.7930584,
    1759957206.8093643,
    1759957207.13108,
    1759957207.1310492,
    1759957207.140453,
    1759957207.1728294,
    1759957207.313973,
    1759957207.330956,
    1759957207.5248585,
    1759957207.5683372,
    1759957207.5753264,
    1759957207.686385,
    1759957207.71235,
    1759957207.7663352,
    1759957207.8086715,
    1759957207.912071,
    1759957207.9240844,
    1759957208.107694,
    1759957208.1272707,
    1759957208.1591756,
    1759957208.1901505,
    1759957208.2824423,
    1759957208.313028,
    1759957208.3685608,
    1759957208.4283373,
    1759957208.4399197,
    1759957208.5207565,
    1759957208.6255167,
    1759957208.687241,
    1759957208.7641776,
    1759957208.7979488,
    1759957208.822833,
    1759957208.988051,
    1759957209.0165308,
    1759957209.0165167,
    1759957209.0164561,
    1759957209.0436409,
    1759957209.0539887,
    1759957209.0539455,
    1759957209.0589607,
    1759957209.0914307,
    1759957209.102285,
    1759957209.2671516,
    1759957209.2756205,
    1759957209.275606,
    1759957209.3490639,
    1759957209.4310856,
    1759957209.504837,
    1759957209.5731444,
    1759957209.6216853,
    1759957209.6823452,
    1759957209.7332404,
    1759957209.7336233,
    1759957209.7379754,
    1759957209.7655828,
    1759957209.8002486,
    1759957209.9116378,
    1759957210.0856056,
    1759957210.0906265,
    1759957210.185899,
    1759957210.3200922,
    1759957210.3245373,
    1759957210.569314,
    1759957210.6005337,
    1759957210.6965802,
    1759957210.7107792,
    1759957210.771199,
    1759957210.8074574,
    1759957210.8430247,
    1759957211.1117861,
    1759957211.1223238,
    1759957211.182204,
    1759957211.2504697,
    1759957211.3346035,
    1759957211.5299842,
    1759957211.600871,
    1759957211.8030055,
    1759957211.8321674,
    1759957211.8443317,
    1759957212.0239878,
    1759957212.100078,
    1759957212.157204,
    1759957212.229293,
    1759957212.2714498,
    1759957212.2907884,
    1759957212.4264925,
    1759957212.54025,
    1759957212.5816104,
    1759957212.6801248,
    1759957212.9123847,
    1759957212.9283214,
    1759957213.0014124,
    1759957213.1489396,
    1759957213.2571373,
    1759957213.355325,
    1759957213.3671198,
    1759957213.3839362,
    1759957213.3893812,
    1759957213.4465575,
    1759957213.4842227,
    1759957213.4998462,
    1759957213.5081978,
    1759957213.525196,
    1759957213.5252423,
    1759957213.5734603,
    1759957213.5806408,
    1759957213.6617296,
    1759957213.697514,
    1759957213.7421598,
    1759957213.7838042,
    1759957213.873167,
    1759957213.9309964,
    1759957214.0145733,
    1759957214.0201175,
    1759957214.0284805,
    1759957214.1267784,
    1759957214.3262832,
    1759957214.3572445,
    1759957214.4319637,
    1759957214.4612007,
    1759957214.4644065,
    1759957214.5114026,
    1759957214.6184049,
    1759957214.6840415,
    1759957214.7407503,
    1759957214.7975998,
    1759957214.823988,
    1759957214.8240325,
    1759957214.8544366,
    1759957214.9175742,
    1759957215.0728872,
    1759957215.1634169,
    1759957215.1993272,
    1759957215.2515905,
    1759957215.2728453,
    1759957215.3471358,
    1759957215.3629558,
    1759957215.4397764,
    1759957215.4858513,
    1759957215.5012338,
    1759957215.5390856,
    1759957215.570417,
    1759957215.59688,
    1759957215.6135604,
    1759957215.72337,
    1759957215.7592764,
    1759957215.9172652,
    1759957216.068367,
    1759957216.1470456,
    1759957216.1470916,
    1759957216.188343,
    1759957216.409555,
    1759957216.5070384,
    1759957216.5176194,
    1759957216.5255656,
    1759957216.6649764,
    1759957216.7595317,
    1759957216.8789191,
    1759957216.913421,
    1759957216.9134645,
    1759957216.9184868,
    1759957216.979402,
    1759957216.979446,
    1759957217.0115154,
    1759957217.1187842,
    1759957217.1187387,
    1759957217.118768,
    1759957217.1360173,
    1759957217.2674918,
    1759957217.310007,
    1759957217.4112923,
    1759957217.4517424,
    1759957217.5218515,
    1759957217.5833359,
    1759957217.6716063,
    1759957217.7382827,
    1759957217.8854744,
    1759957217.896226,
    1759957217.9353988,
    1759957217.9562924,
    1759957217.9629734,
    1759957217.9998324,
    1759957218.044228,
    1759957218.044248,
    1759957218.2370248,
    1759957218.4097357,
    1759957218.4255276,
    1759957218.4254901,
    1759957218.4581945,
    1759957218.4643977,
    1759957218.4692328,
    1759957218.5524879,
    1759957218.5759997,
    1759957218.646689,
    1759957218.7270007,
    1759957218.7513604,
    1759957218.7648427,
    1759957218.7879357,
    1759957218.8062668,
    1759957218.818112,
    1759957218.8463182,
    1759957218.9534457,
    1759957219.0239515,
    1759957219.0650725,
    1759957219.1359766,
    1759957219.2154703,
    1759957219.2643142,
    1759957219.2876985,
    1759957219.2982857,
    1759957219.3040807,
    1759957219.4166477,
    1759957219.6151671,
    1759957219.6333168,
    1759957219.637643,
    1759957219.6537745,
    1759957219.6731849,
    1759957219.8547223,
    1759957219.8606074,
    1759957219.8801713,
    1759957219.9148192,
    1759957220.0495548,
    1759957220.3534255,
    1759957220.4144683,
    1759957220.5121357,
    1759957220.532358,
    1759957220.6183412,
    1759957220.6317186,
    1759957220.6513956,
    1759957220.755955,
    1759957220.7559128,
    1759957220.8137522,
    1759957220.8393757,
    1759957221.0173419,
    1759957221.0264404,
    1759957221.031965,
    1759957221.0578187,
    1759957221.1121,
    1759957221.1847153,
    1759957221.1994648,
    1759957221.2751334,
    1759957221.3155313,
    1759957221.334142,
    1759957221.3724036,
    1759957221.4237158,
    1759957221.4878886,
    1759957221.550361,
    1759957221.6250343,
    1759957221.631961,
    1759957221.6319466,
    1759957221.643392,
    1759957221.7830029,
    1759957221.906187,
    1759957221.9381802,
    1759957221.9560242,
    1759957222.034321,
    1759957222.04747,
    1759957222.2324808,
    1759957222.264553,
    1759957222.37772,
    1759957222.3916137,
    1759957222.4579237,
    1759957222.5278494,
    1759957222.7665846,
    1759957222.775034,
    1759957222.8158295,
    1759957222.9316108,
    1759957222.9441285,
    1759957223.0880492,
    1759957223.0955374,
    1759957223.2646976,
    1759957223.3069127,
    1759957223.358847,
    1759957223.5170274,
    1759957223.5169833,
    1759957223.545979,
    1759957223.5631125,
    1759957223.68765,
    1759957223.6943626,
    1759957223.6969159,
    1759957223.7275379,
    1759957223.7394469,
    1759957223.7433739,
    1759957223.979193,
    1759957224.0084753,
    1759957224.0103686,
    1759957224.0332546,
    1759957224.033236,
    1759957224.0808797,
    1759957224.1081142,
    1759957224.1483538,
    1759957224.1899674,
    1759957224.2017994,
    1759957224.2384636,
    1759957224.3683445,
    1759957224.3683913,
    1759957224.3827302,
    1759957224.4116406,
    1759957224.4812868,
    1759957224.6230361,
    1759957224.6851778,
    1759957224.7686472,
    1759957224.9036486,
    1759957224.9130204,
    1759957225.1532457,
    1759957225.2050807,
    1759957225.2113724,
    1759957225.2660084,
    1759957225.5056314,
    1759957225.5659046,
    1759957225.620644,
    1759957225.6308572,
    1759957225.665984,
    1759957225.7457,
    1759957225.7881277,
    1759957225.788069,
    1759957225.788039,
    1759957225.8220947,
    1759957225.9242082,
    1759957225.9342422,
    1759957225.9771993,
    1759957226.0036564,
    1759957226.1596181,
    1759957226.204114,
    1759957226.2183075,
    1759957226.332283,
    1759957226.3613026,
    1759957226.4477825,
    1759957226.523504,
    1759957226.52346,
    1759957226.6438005,
    1759957226.7115889,
    1759957226.7251742,
    1759957226.7333415,
    1759957226.797445,
    1759957226.843987,
    1759957226.8752673,
    1759957226.979099,
    1759957227.0782678,
    1759957227.0859954,
    1759957227.183552,
    1759957227.1835966,
    1759957227.3184106,
    1759957227.3293517,
    1759957227.3360546,
    1759957227.419623,
    1759957227.681663,
    1759957227.8835256,
    1759957227.9603481,
    1759957228.1199162,
    1759957228.315521,
    1759957228.321549,
    1759957228.3667026,
    1759957228.400362,
    1759957228.400393,
    1759957228.4152882,
    1759957228.4208434,
    1759957228.4366255,
    1759957228.5078213,
    1759957228.5077934,
    1759957228.5743296,
    1759957228.6275454,
    1759957228.6465027,
    1759957228.746311,
    1759957228.8244798,
    1759957228.84765,
    1759957228.863007,
    1759957228.8777304,
    1759957228.8967123,
    1759957228.9331176,
    1759957229.053611,
    1759957229.053598,
    1759957229.2946095,
    1759957229.3176463,
    1759957229.4074285,
    1759957229.4327042,
    1759957229.497285,
    1759957229.532869,
    1759957229.5506418,
    1759957229.6715167,
    1759957229.688158,
    1759957229.7195733,
    1759957229.8057659,
    1759957229.9066873,
    1759957230.2086449,
    1759957230.24124,
    1759957230.3096306,
    1759957230.35429,
    1759957230.719593,
    1759957230.7196388,
    1759957230.7907171,
    1759957230.8462057,
    1759957230.9498692,
    1759957230.9499133,
    1759957230.9726136,
    1759957230.9926932,
    1759957231.122102,
    1759957231.14982,
    1759957231.1629002,
    1759957231.2189949,
    1759957231.3968875,
    1759957231.4338953,
    1759957231.5355172,
    1759957231.5597396,
    1759957231.5792797,
    1759957231.6413262,
    1759957231.669909,
    1759957231.694886,
    1759957231.7343266,
    1759957231.7754946,
    1759957231.945375,
    1759957231.9769552,
    1759957232.146139,
    1759957232.1501088,
    1759957232.1893523,
    1759957232.2143867,
    1759957232.2183247,
    1759957232.2410038,
    1759957232.2901945,
    1759957232.3433707,
    1759957232.3764572,
    1759957232.532992,
    1759957232.640909,
    1759957232.6463983,
    1759957232.7350485,
    1759957232.741154,
    1759957232.7734702,
    1759957232.781999,
    1759957232.7819622,
    1759957232.932581,
    1759957233.0166695,
    1759957233.021777,
    1759957233.0217392,
    1759957233.160272,
    1759957233.1785522,
    1759957233.2352166,
    1759957233.235171,
    1759957233.3032653,
    1759957233.3225179,
    1759957233.402954,
    1759957233.4369466,
    1759957233.492344,
    1759957233.568152,
    1759957233.6247077,
    1759957233.6395175,
    1759957233.6957777,
    1759957233.8652506,
    1759957233.8726377,
    1759957233.8813586,
    1759957233.9067981,
    1759957233.9142127,
    1759957233.9448895,
    1759957234.0431843,
    1759957234.052164,
    1759957234.173474,
    1759957234.1735232,
    1759957234.3678162,
    1759957234.3933637,
    1759957234.4826467,
    1759957234.6559966,
    1759957234.728003,
    1759957234.773425,
    1759957234.8075812,
    1759957234.8124087,
    1759957234.8923466,
    1759957234.9852395,
    1759957235.019101,
    1759957235.052675,
    1759957235.0573344,
    1759957235.1502013,
    1759957235.2364948,
    1759957235.2503352,
    1759957235.2751923,
    1759957235.3122816,
    1759957235.3722348,
    1759957235.4336548,
    1759957235.480908,
    1759957235.5044672,
    1759957235.5515566,
    1759957235.6408582,
    1759957235.675917,
    1759957235.739592,
    1759957235.7573605,
    1759957235.8105738,
    1759957235.841008,
    1759957235.8794756,
    1759957235.9671195,
    1759957235.9806643,
    1759957235.98072,
    1759957235.9807332,
    1759957236.0015507,
    1759957236.0245073,
    1759957236.0689085,
    1759957236.0814855,
    1759957236.227672,
    1759957236.2728586,
    1759957236.2916994,
    1759957236.370604,
    1759957236.4392903,
    1759957236.4442108,
    1759957236.4650197,
    1759957236.5817394,
    1759957236.6523504,
    1759957236.679158,
    1759957236.7724679,
    1759957236.8313892,
    1759957236.8628864,
    1759957236.8742745,
    1759957237.0452592,
    1759957237.0999434,
    1759957237.240028,
    1759957237.3015912,
    1759957237.3524554,
    1759957237.3950827,
    1759957237.3998957,
    1759957237.4112384,
    1759957237.505089,
    1759957237.505134,
    1759957237.5433643,
    1759957237.5717158,
    1759957237.732939,
    1759957237.9181726,
    1759957238.010984,
    1759957238.0594032,
    1759957238.2095242,
    1759957238.2220786,
    1759957238.2466614,
    1759957238.3289266,
    1759957238.3765848,
    1759957238.4045284,
    1759957238.4115672,
    1759957238.4772458,
    1759957238.4827816,
    1759957238.6872346,
    1759957238.761181,
    1759957238.761226,
    1759957238.7698665,
    1759957238.821241,
    1759957238.8212867,
    1759957238.9778376,
    1759957239.027512,
    1759957239.103389,
    1759957239.2130198,
    1759957239.2341397,
    1759957239.2409706,
    1759957239.3052716,
    1759957239.462288,
    1759957239.5039058,
    1759957239.722777,
    1759957239.7285528,
    1759957239.7400537,
    1759957239.7730327,
    1759957240.0463123,
    1759957240.0501893,
    1759957240.1450164,
    1759957240.2286646,
    1759957240.2837036,
    1759957240.3411143,
    1759957240.4545505,
    1759957240.70963,
    1759957240.7654886,
    1759957240.7654512,
    1759957240.846899,
    1759957240.9015589,
    1759957240.9965909,
    1759957241.1365964,
    1759957241.2801473,
    1759957241.3293574,
    1759957241.5790045,
    1759957241.7009459,
    1759957241.7065792,
    1759957241.728825,
    1759957241.7900555,
    1759957241.8281026,
    1759957241.871095,
    1759957241.9476552,
    1759957241.9863667,
    1759957242.018947,
    1759957242.0651321,
    1759957242.097527,
    1759957242.1061378,
    1759957242.1682026,
    1759957242.2282538,
    1759957242.2515671,
    1759957242.267975,
    1759957242.4076777,
    1759957242.4788504,
    1759957242.5155034,
    1759957242.5894222,
    1759957242.6275718,
    1759957242.7621295,
    1759957242.7857704,
    1759957242.8885324,
    1759957242.8921664,
    1759957242.9117,
    1759957242.955681,
    1759957242.9682,
    1759957242.9682326,
    1759957243.182728,
    1759957243.2431633,
    1759957243.27479,
    1759957243.325463,
    1759957243.346153,
    1759957243.3769174,
    1759957243.3889513,
    1759957243.4887605,
    1759957243.50694,
    1759957243.5448542,
    1759957243.5753934,
    1759957243.5845046,
    1759957243.8058765,
    1759957243.8470514,
    1759957243.8542144,
    1759957244.025339,
    1759957244.063298,
    1759957244.164978,
    1759957244.172959,
    1759957244.1729214,
    1759957244.2438018,
    1759957244.2779434,
    1759957244.3165705,
    1759957244.4735389,
    1759957244.506557,
    1759957244.665497,
    1759957244.8543499,
    1759957244.980056,
    1759957245.0604646,
    1759957245.351203,
    1759957245.3655589,
    1759957245.365589,
    1759957245.3813443,
    1759957245.3923452,
    1759957245.7027612,
    1759957245.805793,
    1759957245.83044,
    1759957245.9211748,
    1759957245.9643655,
    1759957246.0148864,
    1759957246.0200658,
    1759957246.149853,
    1759957246.2566402,
    1759957246.2877324,
    1759957246.3673015,
    1759957246.4351313,
    1759957246.4900925,
    1759957246.5319529,
    1759957246.5894897,
    1759957246.5973895,
    1759957246.695718,
    1759957246.8396645,
    1759957246.9317074,
    1759957247.0022666,
    1759957247.0686178,
    1759957247.096374,
    1759957247.1452143,
    1759957247.163627,
    1759957247.2341883,
    1759957247.2624893,
    1759957247.2952685,
    1759957247.4912415,
    1759957247.503645,
    1759957247.5553417,
    1759957247.6804187,
    1759957247.6917121,
    1759957247.7187045,
    1759957247.7615101,
    1759957247.775913,
    1759957247.8342288,
    1759957247.894926,
    1759957247.9395363,
    1759957248.1444476,
    1759957248.2419176,
    1759957248.3176432,
    1759957248.5702474,
    1759957248.731545,
    1759957248.918051,
    1759957249.1649694,
    1759957249.2251809,
    1759957249.24299,
    1759957249.3960311,
    1759957249.396085,
    1759957249.4172134,
    1759957249.506926,
    1759957249.5418146,
    1759957249.5902438,
    1759957249.5965564,
    1759957249.6630168,
    1759957249.6765864,
    1759957249.7113602,
    1759957249.8939636,
    1759957249.9027114,
    1759957249.9241323,
    1759957250.3113825,
    1759957250.3322475,
    1759957250.3667104,
    1759957250.4130373,
    1759957250.4387445,
    1759957250.472619,
    1759957250.5121312,
    1759957250.5317779,
    1759957250.5358472,
    1759957250.5735674,
    1759957250.5949464,
    1759957250.630465,
    1759957250.650801,
    1759957250.6644528,
    1759957250.7180183,
    1759957250.763738,
    1759957250.8990855,
    1759957251.0300596,
    1759957251.1501913,
    1759957251.270967,
    1759957251.339417,
    1759957251.3539586,
    1759957251.3539178,
    1759957251.4339514,
    1759957251.583532,
    1759957251.588095,
    1759957251.6161423,
    1759957251.7516794,
    1759957251.799492,
    1759957251.815457,
    1759957251.850194,
    1759957251.8746645,
    1759957251.8746936,
    1759957252.1041048,
    1759957252.1270766,
    1759957252.2161813,
    1759957252.229711,
    1759957252.2536914,
    1759957252.338108,
    1759957252.408945,
    1759957252.4447513,
    1759957252.4447093,
    1759957252.5939693,
    1759957252.6514254,
    1759957252.8151407,
    1759957252.931302,
    1759957252.9372642,
    1759957253.228614,
    1759957253.2781086,
    1759957253.284739,
    1759957253.3969753,
    1759957253.4106467,
    1759957253.6098473,
    1759957253.671601,
    1759957253.8951905,
    1759957253.9058862,
    1759957253.9319394,
    1759957253.9367995,
    1759957253.9495678,
    1759957254.0537574,
    1759957254.2687016,
    1759957254.2814755,
    1759957254.3310244,
    1759957254.3478994,
    1759957254.3727112,
    1759957254.4021196,
    1759957254.4644268,
    1759957254.4807005,
    1759957254.573756,
    1759957254.7064626,
    1759957254.7450125,
    1759957254.9033449,
    1759957255.0424144,
    1759957255.12754,
    1759957255.1709354,
    1759957255.1911306,
    1759957255.2730272,
    1759957255.3025413,
    1759957255.42619,
    1759957255.5838487,
    1759957255.587389,
    1759957255.634645,
    1759957255.7684026,
    1759957255.8623269,
    1759957255.9334064,
    1759957256.0122154,
    1759957256.0671828,
    1759957256.0856166,
    1759957256.1429873,
    1759957256.1429338,
    1759957256.1499789,
    1759957256.2580628,
    1759957256.3541393,
    1759957256.4225814,
    1759957256.5135171,
    1759957256.522938,
    1759957256.620535,
    1759957256.6657124,
    1759957256.7438462,
    1759957256.8128955,
    1759957256.8401747,
    1759957256.8462992,
    1759957256.8784544,
    1759957256.9204848,
    1759957256.9293575,
    1759957256.9767165,
    1759957256.9806423,
    1759957257.062173,
    1759957257.1118288,
    1759957257.1579564,
    1759957257.1744077,
    1759957257.2030249,
    1759957257.2346065,
    1759957257.3209922,
    1759957257.4593778,
    1759957257.4726565,
    1759957257.5001068,
    1759957257.513888,
    1759957257.989921,
    1759957257.9959528,
    1759957258.0063226,
    1759957258.1522493,
    1759957258.2760422,
    1759957258.6900826,
    1759957258.8396997,
    1759957258.953548,
    1759957259.145753,
    1759957259.2399957,
    1759957259.2493212,
    1759957259.275437,
    1759957259.328444,
    1759957259.338311,
    1759957259.3429546,
    1759957259.4096742,
    1759957259.4801245,
    1759957259.533376,
    1759957259.5334218,
    1759957259.5862906,
    1759957259.8490486,
    1759957259.857541,
    1759957259.8575022,
    1759957259.9030457,
    1759957259.9404664,
    1759957260.218857,
    1759957260.3061802,
    1759957260.4738264,
    1759957260.5170586,
    1759957260.5342062,
    1759957260.5587597,
    1759957260.5588,
    1759957260.6118317,
    1759957260.906853,
    1759957260.9173157,
    1759957260.9173532,
    1759957260.970876,
    1759957261.0143127,
    1759957261.2183366,
    1759957261.2733173,
    1759957261.3355074,
    1759957261.3581958,
    1759957261.4696016,
    1759957261.4778652,
    1759957261.7266204,
    1759957261.885141,
    1759957261.946736,
    1759957261.9516616,
    1759957262.0050626,
    1759957262.0736356,
    1759957262.198689,
    1759957262.1987362,
    1759957262.2536688,
    1759957262.259053,
    1759957262.2780395,
    1759957262.3927808,
    1759957262.40142,
    1759957262.4196093,
    1759957262.5046465,
    1759957262.5300941,
    1759957262.5300462,
    1759957262.5583596,
    1759957262.5847368,
    1759957262.7321548,
    1759957262.7957556,
    1759957262.816424,
    1759957262.8529503,
    1759957262.8846617,
    1759957262.9127643,
    1759957262.9300365,
    1759957262.9349048,
    1759957262.9989624,
    1759957263.0663316,
    1759957263.0714996,
    1759957263.0848043,
    1759957263.1241136,
    1759957263.1611772,
    1759957263.1720417,
    1759957263.1720037,
    1759957263.2575667,
    1759957263.4673345,
    1759957263.4975276,
    1759957263.581125,
    1759957263.6582327,
    1759957263.6730468,
    1759957263.9637818,
    1759957263.9716353,
    1759957264.0638359,
    1759957264.0680163,
    1759957264.0724761,
    1759957264.1757872,
    1759957264.2337105,
    1759957264.3474202,
    1759957264.3565238,
    1759957264.4783087,
    1759957264.4888875,
    1759957264.518893,
    1759957264.5915163,
    1759957264.6147804,
    1759957264.6147943,
    1759957264.640711,
    1759957264.6604927,
    1759957264.66053,
    1759957264.6972597,
    1759957264.7212772,
    1759957264.7437885,
    1759957264.7674227,
    1759957264.771717,
    1759957264.8520694,
    1759957264.974891,
    1759957264.9982579,
    1759957265.329687,
    1759957265.4163306,
    1759957265.5057726,
    1759957265.5120127,
    1759957265.6017358,
    1759957265.6074598,
    1759957265.6306908,
    1759957265.7097676,
    1759957265.787381,
    1759957265.9153047,
    1759957265.9259334,
    1759957265.9351225,
    1759957266.0337586,
    1759957266.2020397,
    1759957266.216057,
    1759957266.2797346,
    1759957266.3616426,
    1759957266.4476173,
    1759957266.4898825,
    1759957266.7131639,
    1759957266.7745805,
    1759957266.7746253,
    1759957266.7816863,
    1759957266.9060836,
    1759957267.023441,
    1759957267.1414344,
    1759957267.2094753,
    1759957267.2243984,
    1759957267.4074886,
    1759957267.4121506,
    1759957267.5054328,
    1759957267.7358227,
    1759957267.7405653,
    1759957267.9211755,
    1759957267.995916,
    1759957268.063273,
    1759957268.073328,
    1759957268.086096,
    1759957268.0961456,
    1759957268.1847608,
    1759957268.2118695,
    1759957268.2435837,
    1759957268.2904754,
    1759957268.4503248,
    1759957268.4743304,
    1759957268.5218973,
    1759957268.6540923,
    1759957268.8139665,
    1759957268.8587692,
    1759957268.873802,
    1759957268.8907712,
    1759957269.010121,
    1759957269.1938002,
    1759957269.2066047,
    1759957269.2947237,
    1759957269.3081272,
    1759957269.3080885,
    1759957269.332596,
    1759957269.3467824,
    1759957269.3468258,
    1759957269.437288,
    1759957269.4570634,
    1759957269.4638174,
    1759957269.5230095,
    1759957269.626937,
    1759957269.733217,
    1759957269.7795253,
    1759957269.828204,
    1759957269.9310021,
    1759957270.0009365,
    1759957270.0428438,
    1759957270.1367357,
    1759957270.2546568,
    1759957270.2831516,
    1759957270.3948712,
    1759957270.4039223,
    1759957270.475654,
    1759957270.543494,
    1759957270.552482,
    1759957270.5524495,
    1759957270.5599387,
    1759957270.6028,
    1759957270.6170678,
    1759957270.7018006,
    1759957270.7069812,
    1759957270.724948,
    1759957270.9544468,
    1759957270.9610837,
    1759957270.9610434,
    1759957270.9703376,
    1759957270.994052,
    1759957271.0198898,
    1759957271.2485533,
    1759957271.3046167,
    1759957271.3176885,
    1759957271.3177245,
    1759957271.4106042,
    1759957271.420143,
    1759957271.4405503,
    1759957271.44681,
    1759957271.481343,
    1759957271.5653205,
    1759957271.5971203,
    1759957271.664053,
    1759957271.6991534,
    1759957271.7229347,
    1759957271.8602493,
    1759957272.0801744,
    1759957272.1194491,
    1759957272.3592649,
    1759957272.4968581,
    1759957272.6848488,
    1759957272.7263174,
    1759957272.827356,
    1759957272.8334692,
    1759957272.8890283,
    1759957272.912741,
    1759957273.02668,
    1759957273.0265996,
    1759957273.0266972,
    1759957273.0267115,
    1759957273.065904,
    1759957273.0659344,
    1759957273.1426425,
    1759957273.154731,
    1759957273.309737,
    1759957273.3135169,
    1759957273.3544672,
    1759957273.5025504,
    1759957273.528442,
    1759957273.5575104,
    1759957273.5574486,
    1759957273.5575283,
    1759957273.5692444,
    1759957273.5692081,
    1759957273.6581988,
    1759957273.7084396,
    1759957273.7982259,
    1759957273.8269742,
    1759957273.849436,
    1759957273.8926506,
    1759957273.9416883,
    1759957274.0031009,
    1759957274.0492249,
    1759957274.0856209,
    1759957274.1931267,
    1759957274.3335025,
    1759957274.3651912,
    1759957274.4349759,
    1759957274.4598446,
    1759957274.7161093,
    1759957274.716088,
    1759957274.7411618,
    1759957274.753376,
    1759957274.7716842,
    1759957274.9643214,
    1759957275.1051826,
    1759957275.1051528,
    1759957275.136228,
    1759957275.1888273,
    1759957275.2148795,
    1759957275.2672958,
    1759957275.2744997,
    1759957275.3955853,
    1759957275.4064434,
    1759957275.4064043,
    1759957275.4479904,
    1759957275.4961388,
    1759957275.676039,
    1759957275.776093,
    1759957275.8678398,
    1759957276.0203762,
    1759957276.0393653,
    1759957276.0393195,
    1759957276.0446403,
    1759957276.0584538,
    1759957276.2850134,
    1759957276.4449627,
    1759957276.4805105,
    1759957276.5207627,
    1759957276.5705562,
    1759957276.6194253,
    1759957276.6861026,
    1759957276.962083,
    1759957276.9741364,
    1759957276.996407,
    1759957277.133609,
    1759957277.2104173,
    1759957277.2259233,
    1759957277.2532609,
    1759957277.2930758,
    1759957277.4668694,
    1759957277.5131097,
    1759957277.5699694,
    1759957277.5754218,
    1759957277.5976477,
    1759957277.8268507,
    1759957277.840964,
    1759957277.989599,
    1759957278.1107264,
    1759957278.197337,
    1759957278.2012465,
    1759957278.2493587,
    1759957278.3918371,
    1759957278.4375565,
    1759957278.446174,
    1759957278.576198,
    1759957278.6214683,
    1759957278.8529353,
    1759957278.9412098,
    1759957279.0594146,
    1759957279.075537,
    1759957279.1869895,
    1759957279.2009385,
    1759957279.2509866,
    1759957279.3612697,
    1759957279.3732784,
    1759957279.3924055,
    1759957279.417358,
    1759957279.4274857,
    1759957279.4983144,
    1759957279.5049345,
    1759957279.6381097,
    1759957279.6604726,
    1759957280.1104596,
    1759957280.1134672,
    1759957280.2857633,
    1759957280.395263,
    1759957280.5690823,
    1759957280.6419349,
    1759957280.652845,
    1759957280.6528082,
    1759957280.7632031,
    1759957280.7710688,
    1759957280.9524608,
    1759957280.9674861,
    1759957280.9898298,
    1759957281.0292459,
    1759957281.07814,
    1759957281.140634,
    1759957281.2467566,
    1759957281.2553244,
    1759957281.255361,
    1759957281.3261502,
    1759957281.3566256,
    1759957281.4893203,
    1759957281.53389,
    1759957281.573633,
    1759957281.6316986,
    1759957281.6375082,
    1759957281.6928413,
    1759957281.7078235,
    1759957281.707781,
    1759957281.761695,
    1759957281.793118,
    1759957281.7930672,
    1759957281.881448,
    1759957281.8933022,
    1759957281.9007325,
    1759957281.9156141,
    1759957282.2229338,
    1759957282.422268,
    1759957282.4396641,
    1759957282.48694,
    1759957282.5636916,
    1759957282.574362,
    1759957282.6520066,
    1759957282.6758416,
    1759957282.690638,
    1759957282.9467545,
    1759957283.1822317,
    1759957283.394027,
    1759957283.4319975,
    1759957283.499209,
    1759957283.6213412,
    1759957283.621301,
    1759957283.7311602,
    1759957283.8951626,
    1759957283.9317842,
    1759957284.0905583,
    1759957284.1433284,
    1759957284.2462015,
    1759957284.2557929,
    1759957284.323098,
    1759957284.327206,
    1759957284.3795676,
    1759957284.379614,
    1759957284.390669,
    1759957284.4690921,
    1759957284.496992,
    1759957284.5228336,
    1759957284.5628855,
    1759957284.5738099,
    1759957284.6990561,
    1759957284.726075,
    1759957284.8321545,
    1759957284.8576329,
    1759957284.8783834,
    1759957284.9748337,
    1759957285.07384,
    1759957285.126493,
    1759957285.249353,
    1759957285.2597692,
    1759957285.3219144,
    1759957285.4407086,
    1759957285.476099,
    1759957285.527045,
    1759957285.7800455,
    1759957285.7852151,
    1759957285.8188717,
    1759957286.015406,
    1759957286.0419536,
    1759957286.3208625,
    1759957286.3208146,
    1759957286.382132,
    1759957286.4156039,
    1759957286.437338,
    1759957286.4721463,
    1759957286.5254564,
    1759957286.6168818,
    1759957286.6370533,
    1759957286.6751034,
    1759957286.7145498,
    1759957286.8259037,
    1759957286.9715574,
    1759957286.9862556,
    1759957287.0054984,
    1759957287.0558355,
    1759957287.1014435,
    1759957287.141738,
    1759957287.1785498,
    1759957287.2006578,
    1759957287.3665342,
    1759957287.4020476,
    1759957287.4238498,
    1759957287.4280806,
    1759957287.4934835,
    1759957287.498782,
    1759957287.5193708,
    1759957287.6525428,
    1759957287.8530693,
    1759957287.8712122,
    1759957287.878719,
    1759957287.8787637,
    1759957287.8953297,
    1759957288.0452752,
    1759957288.0550425,
    1759957288.110419,
    1759957288.1189399,
    1759957288.2219763,
    1759957288.29025,
    1759957288.3296926,
    1759957288.3296468,
    1759957288.3358142,
    1759957288.3357751,
    1759957288.3549962,
    1759957288.5607677,
    1759957288.5671353,
    1759957288.60898,
    1759957288.6125443,
    1759957288.6723928,
    1759957289.1006374,
    1759957289.1570675,
    1759957289.1872365,
    1759957289.3379476,
    1759957289.3419192,
    1759957289.422896,
    1759957289.4435906,
    1759957289.536713,
    1759957289.625598,
    1759957289.825659,
    1759957289.8636193,
    1759957289.874142,
    1759957289.8977585,
    1759957289.925507,
    1759957289.9516523,
    1759957290.0675871,
    1759957290.0874035,
    1759957290.1017253,
    1759957290.2612357,
    1759957290.448682,
    1759957290.5045848,
    1759957290.548056,
    1759957290.6256254,
    1759957290.6774044,
    1759957290.7120788,
    1759957290.8875396,
    1759957290.9251513,
    1759957290.973007,
    1759957290.983264,
    1759957291.077998,
    1759957291.1864655,
    1759957291.194821,
    1759957291.5016887,
    1759957291.5069957,
    1759957291.5759587,
    1759957291.6239395,
    1759957291.6622512,
    1759957291.6872005,
    1759957291.7590714,
    1759957291.7855883,
    1759957291.7966943,
    1759957291.7966285,
    1759957291.7967067,
    1759957291.934769,
    1759957291.9471514,
    1759957291.9471865,
    1759957291.968887,
    1759957292.1700282,
    1759957292.2084954,
    1759957292.3697615,
    1759957292.5273528,
    1759957292.5341668,
    1759957292.557653,
    1759957292.6635835,
    1759957292.8364425,
    1759957292.9548652,
    1759957292.9741423,
    1759957293.047804,
    1759957293.0537193,
    1759957293.1465945,
    1759957293.1742613,
    1759957293.207068,
    1759957293.2475655,
    1759957293.3616326,
    1759957293.594621,
    1759957293.6888783,
    1759957293.7000792,
    1759957293.7000427,
    1759957293.7638786,
    1759957293.80451,
    1759957293.8291945,
    1759957293.8871577,
    1759957293.9375522,
    1759957294.1351035,
    1759957294.232778,
    1759957294.3301165,
    1759957294.3301604,
    1759957294.3356147,
    1759957294.4144747,
    1759957294.4715288,
    1759957294.4799771,
    1759957294.5712998,
    1759957294.5852022,
    1759957294.6682444,
    1759957294.7329068,
    1759957294.825382,
    1759957294.8342772,
    1759957294.8603969,
    1759957294.9594738,
    1759957294.9792094,
    1759957295.00535,
    1759957295.029325,
    1759957295.029337,
    1759957295.0987413,
    1759957295.3465178,
    1759957295.4411929,
    1759957295.507638,
    1759957295.6392043,
    1759957295.8348277,
    1759957295.9664514,
    1759957296.344501,
    1759957296.3513472,
    1759957296.3513062,
    1759957296.4482744,
    1759957296.5317678,
    1759957296.7054985,
    1759957296.8354275,
    1759957296.8824458,
    1759957297.0033083,
    1759957297.1714578,
    1759957297.2128062,
    1759957297.2646623,
    1759957297.285368,
    1759957297.3328571,
    1759957297.3370862,
    1759957297.464311,
    1759957297.6093373,
    1759957297.907061,
    1759957298.0103893,
    1759957298.2031987,
    1759957298.207297,
    1759957298.2388616,
    1759957298.2841165,
    1759957298.313967,
    1759957298.4634883,
    1759957298.567199,
    1759957298.6010494,
    1759957298.6171505,
    1759957298.6397078,
    1759957298.7140677,
    1759957298.7581284,
    1759957298.789772,
    1759957298.843516,
    1759957298.8846354,
    1759957299.3198004,
    1759957299.5323052,
    1759957299.61722,
    1759957299.6977634,
    1759957299.7591074,
    1759957299.7796237,
    1759957299.8816578,
    1759957299.9549415,
    1759957299.9644382,
    1759957299.9643993,
    1759957300.0086195,
    1759957300.059295,
    1759957300.0623145,
    1759957300.208445,
    1759957300.2084112,
    1759957300.273848,
    1759957300.38834,
    1759957300.5165517,
    1759957300.5535822,
    1759957300.566111,
    1759957300.6108046,
    1759957300.614847,
    1759957300.6233554,
    1759957300.7361488,
    1759957300.7577677,
    1759957300.9370055,
    1759957300.943659,
    1759957301.060614,
    1759957301.3385217,
    1759957301.344105,
    1759957301.5215557,
    1759957301.890912,
    1759957301.8909533,
    1759957301.9603477,
    1759957302.037403,
    1759957302.040679,
    1759957302.2022371,
    1759957302.21568,
    1759957302.3471334,
    1759957302.47024,
    1759957302.4772255,
    1759957302.5158045,
    1759957302.541531,
    1759957302.699689,
    1759957302.7479947,
    1759957302.9513826,
    1759957303.1021922,
    1759957303.1086633,
    1759957303.1087077,
    1759957303.1162128,
    1759957303.2429996,
    1759957303.2691567,
    1759957303.3401663,
    1759957303.4029298,
    1759957303.4995663,
    1759957303.5556617,
    1759957303.5646362,
    1759957303.605042,
    1759957303.6115205,
    1759957303.622836,
    1759957303.6467986,
    1759957303.6997755,
    1759957303.7612674,
    1759957304.0576816,
    1759957304.1143672,
    1759957304.1256342,
    1759957304.2493303,
    1759957304.5576725,
    1759957304.6249611,
    1759957304.6607654,
    1759957304.6680143,
    1759957304.6874292,
    1759957304.728632,
    1759957304.7662961,
    1759957304.774101,
    1759957304.7849927,
    1759957304.9449854,
    1759957305.0508015,
    1759957305.0888438,
    1759957305.1004996,
    1759957305.1296933,
    1759957305.1491408,
    1759957305.2469652,
    1759957305.26119,
    1759957305.2660718,
    1759957305.3346386,
    1759957305.3708277,
    1759957305.3809133,
    1759957305.380877,
    1759957305.4102178,
    1759957305.4431589,
    1759957305.5191,
    1759957305.5504515,
    1759957305.6137357,
    1759957305.6475167,
    1759957305.6628609,
    1759957305.758187,
    1759957305.786222,
    1759957305.8597376,
    1759957306.1063364,
    1759957306.2362704,
    1759957306.2363045,
    1759957306.257583,
    1759957306.257618,
    1759957306.4115071,
    1759957306.609785,
    1759957306.6429684,
    1759957306.7722447,
    1759957307.0803046,
    1759957307.1755214,
    1759957307.1864119,
    1759957307.1941862,
    1759957307.4230435,
    1759957307.429187,
    1759957307.6516364,
    1759957307.6861656,
    1759957307.8198726,
    1759957307.9863467,
    1759957308.0369718,
    1759957308.097639,
    1759957308.4193618,
    1759957308.4942522,
    1759957308.6038334,
    1759957308.9560022,
    1759957309.0382087,
    1759957309.072459,
    1759957309.0872195,
    1759957309.1278446,
    1759957309.2023776,
    1759957309.4194095,
    1759957309.4600108,
    1759957309.498848,
    1759957309.5121734,
    1759957309.549945,
    1759957309.6516535,
    1759957309.667218,
    1759957309.7359617,
    1759957309.9205022,
    1759957309.9633477,
    1759957310.0183272,
    1759957310.0183454,
    1759957310.0182605,
    1759957310.0309143,
    1759957310.0308788,
    1759957310.0804248,
    1759957310.176321,
    1759957310.2021813,
    1759957310.2270365,
    1759957310.282007,
    1759957310.3242126,
    1759957310.399606,
    1759957310.487481,
    1759957310.63776,
    1759957310.6546972,
    1759957310.7791228,
    1759957310.8553488,
    1759957310.955859,
    1759957310.9669487,
    1759957311.0127976,
    1759957311.1159034,
    1759957311.1927109,
    1759957311.267843,
    1759957311.3300815,
    1759957311.4833074,
    1759957311.5224833,
    1759957311.5412688,
    1759957311.5966003,
    1759957311.6712465,
    1759957311.7419448,
    1759957311.7418804,
    1759957311.8051345,
    1759957311.825705,
    1759957311.8661551,
    1759957312.0161114,
    1759957312.0218046,
    1759957312.266234,
    1759957312.2718668,
    1759957312.4075687,
    1759957312.4742036,
    1759957312.5773888,
    1759957312.667243,
    1759957312.8970363,
    1759957313.0478182,
    1759957313.3177586,
    1759957313.401342,
    1759957313.5777192,
    1759957313.606752,
    1759957313.6154785,
    1759957313.6351266,
    1759957313.6815124,
    1759957313.6867325,
    1759957313.7413173,
    1759957313.8515224,
    1759957313.8515525,
    1759957313.8975875,
    1759957313.924055,
    1759957314.0761058,
    1759957314.2029624,
    1759957314.2295814,
    1759957314.3135855,
    1759957314.3933396,
    1759957314.5561237,
    1759957314.6520064,
    1759957314.674359,
    1759957314.7109652,
    1759957314.7485275,
    1759957314.8127234,
    1759957315.0632436,
    1759957315.0896783,
    1759957315.1430984,
    1759957315.2853525,
    1759957315.5039973,
    1759957315.538351,
    1759957315.552753,
    1759957315.9069579,
    1759957316.0777533,
    1759957316.087764,
    1759957316.311171,
    1759957316.6090093,
    1759957317.0098603,
    1759957317.505509,
    1759957317.6206982,
    1759957317.7688205,
    1759957317.8042252,
    1759957317.840688,
    1759957318.2024179,
    1759957318.2342558,
    1759957318.3406825,
    1759957318.4118614,
    1759957318.6207824,
    1759957318.7307358,
    1759957319.0214396,
    1759957319.2140563,
    1759957319.2531238,
    1759957319.3259954,
    1759957319.4047763,
    1759957319.4102602,
    1759957319.8384693,
    1759957319.8586743,
    1759957320.2179024,
    1759957320.2524369,
    1759957320.2524836,
    1759957320.3935683,
    1759957320.431065,
    1759957320.4927957,
    1759957320.499685,
    1759957320.6180944,
    1759957320.6557047,
    1759957320.684102,
    1759957320.847253,
    1759957320.8721964,
    1759957320.9746823,
    1759957320.9824593,
    1759957321.0128953,
    1759957321.0710053,
    1759957321.1283114,
    1759957321.1438537,
    1759957321.175484,
    1759957321.2049172,
    1759957321.3255978,
    1759957321.4445179,
    1759957321.4871376,
    1759957321.591258,
    1759957321.6166637,
    1759957321.6955104,
    1759957321.7170553,
    1759957321.7422588,
    1759957321.934951,
    1759957322.0380225,
    1759957322.0776534,
    1759957322.1035862,
    1759957322.2450542,
    1759957322.2700095,
    1759957322.3163316,
    1759957322.5394871,
    1759957322.5758092,
    1759957322.6272972,
    1759957322.6376345,
    1759957322.8012495,
    1759957322.8012962,
    1759957322.8758278,
    1759957322.9503694,
    1759957323.0961432,
    1759957323.1917284,
    1759957323.3718429,
    1759957323.5613992,
    1759957323.5656323,
    1759957323.6270561,
    1759957323.6937628,
    1759957323.7205865,
    1759957323.7615352,
    1759957323.8019636,
    1759957324.00746,
    1759957324.0312488,
    1759957324.0787463,
    1759957324.145203,
    1759957324.2475443,
    1759957324.2678466,
    1759957324.3268588,
    1759957324.3405302,
    1759957324.3516326,
    1759957324.388587,
    1759957324.4591854,
    1759957324.4790053,
    1759957324.5434988,
    1759957324.5511932,
    1759957324.7328565,
    1759957324.7974277,
    1759957324.9053319,
    1759957325.2297134,
    1759957325.296893,
    1759957325.3528585,
    1759957325.3595417,
    1759957325.36399,
    1759957325.3793492,
    1759957325.4439337,
    1759957325.5031164,
    1759957325.596276,
    1759957325.6676874,
    1759957325.8199024,
    1759957325.8582282,
    1759957325.895495,
    1759957325.9885428,
    1759957325.988602,
    1759957325.996715,
    1759957326.0337667,
    1759957326.1986268,
    1759957326.2274053,
    1759957326.2365513,
    1759957326.4360433,
    1759957326.4607494,
    1759957326.5897858,
    1759957326.706746,
    1759957326.7974558,
    1759957327.048374,
    1759957327.2032015,
    1759957327.2735841,
    1759957327.2815778,
    1759957327.3869965,
    1759957327.3946378,
    1759957327.4831352,
    1759957327.5194924,
    1759957327.5289207,
    1759957327.5387857,
    1759957327.6878035,
    1759957327.769176,
    1759957327.845822,
    1759957327.8458714,
    1759957327.8653286,
    1759957327.8776212,
    1759957327.9040701,
    1759957327.9279485,
    1759957327.9711428,
    1759957328.03493,
    1759957328.0536213,
    1759957328.095371,
    1759957328.1738005,
    1759957328.1840339,
    1759957328.3053186,
    1759957328.3151135,
    1759957328.3151433,
    1759957328.5529854,
    1759957328.5910962,
    1759957328.8250494,
    1759957328.8475983,
    1759957328.9282215,
    1759957328.9664035,
    1759957329.132943,
    1759957329.1458788,
    1759957329.1458392,
    1759957329.2074685,
    1759957329.2234802,
    1759957329.2382398,
    1759957329.3259227,
    1759957329.4332836,
    1759957329.4437134,
    1759957329.4906166,
    1759957329.4906592,
    1759957329.582862,
    1759957330.1107774,
    1759957330.2541032,
    1759957330.3880534,
    1759957330.4273763,
    1759957330.4617898,
    1759957330.4765875,
    1759957330.4960594,
    1759957330.5671632,
    1759957330.6739235,
    1759957330.6903865,
    1759957330.7679346,
    1759957330.8653111,
    1759957330.9205487,
    1759957331.0446384,
    1759957331.0672548,
    1759957331.1097457,
    1759957331.3360474,
    1759957331.3984604,
    1759957331.4125178,
    1759957331.509879,
    1759957331.5579755,
    1759957331.57138,
    1759957331.6452408,
    1759957331.680651,
    1759957331.7858484,
    1759957331.786614,
    1759957331.7966685,
    1759957331.8718615,
    1759957331.9780307,
    1759957332.091191,
    1759957332.1756496,
    1759957332.199505,
    1759957332.2076457,
    1759957332.3739934,
    1759957332.3872716,
    1759957332.444536,
    1759957332.518817,
    1759957332.5381615,
    1759957332.5381172,
    1759957332.5603044,
    1759957332.6543112,
    1759957332.726264,
    1759957332.7950857,
    1759957333.0110924,
    1759957333.071972,
    1759957333.13756,
    1759957333.253584,
    1759957333.2658787,
    1759957333.2934756,
    1759957333.3855548,
    1759957333.4093308,
    1759957333.442786,
    1759957333.5241494,
    1759957333.6870944,
    1759957333.7311535,
    1759957333.750685,
    1759957334.010637,
    1759957334.0306726,
    1759957334.0669594,
    1759957334.1483965,
    1759957334.154231,
    1759957334.1735842,
    1759957334.1775153,
    1759957334.2524915,
    1759957334.3338182,
    1759957334.333774,
    1759957334.3400397,
    1759957334.4050705,
    1759957334.4653094,
    1759957334.5963187,
    1759957334.6479027,
    1759957334.6809576,
    1759957334.6955383,
    1759957334.8107662,
    1759957334.868028,
    1759957335.1081486,
    1759957335.1260905,
    1759957335.2891967,
    1759957335.3929958,
    1759957335.3961549,
    1759957335.531602,
    1759957335.531643,
    1759957335.5715978,
    1759957335.5716498,
    1759957335.5816467,
    1759957335.5816834,
    1759957335.6788225,
    1759957335.7219558,
    1759957335.7655292,
    1759957335.8105764,
    1759957335.8225589,
    1759957335.822519,
    1759957336.1662529,
    1759957336.4012556,
    1759957336.4942613,
    1759957336.7511737,
    1759957336.7781541,
    1759957336.8304508,
    1759957336.8753576,
    1759957336.9332523,
    1759957337.0145185,
    1759957337.0309873,
    1759957337.0985796,
    1759957337.1397228,
    1759957337.1637754,
    1759957337.1680765,
    1759957337.1968873,
    1759957337.608291,
    1759957337.7469258,
    1759957337.7469552,
    1759957338.1312025,
    1759957338.139026,
    1759957338.1826866,
    1759957338.2739913,
    1759957338.319406,
    1759957338.3587205,
    1759957338.3724704,
    1759957338.4008543,
    1759957338.4634228,
    1759957338.6493437,
    1759957338.704712,
    1759957338.7979324,
    1759957338.8114436,
    1759957338.846286,
    1759957338.8952684,
    1759957338.9143143,
    1759957338.9673228,
    1759957339.003121,
    1759957339.0640543,
    1759957339.150387,
    1759957339.2959027,
    1759957339.4011824,
    1759957339.4133193,
    1759957339.4434154,
    1759957339.5166392,
    1759957339.598923,
    1759957339.637874,
    1759957339.9656389,
    1759957340.2511232,
    1759957340.3308878,
    1759957340.330844,
    1759957340.4644094,
    1759957340.5830507,
    1759957340.5881546,
    1759957340.6158607,
    1759957340.7528872,
    1759957340.8714144,
    1759957340.9345531,
    1759957340.9499156,
    1759957341.0176907,
    1759957341.1245754,
    1759957341.2171597,
    1759957341.3154244,
    1759957341.3379555,
    1759957341.3610728,
    1759957341.455611,
    1759957341.4653013,
    1759957341.5092714,
    1759957341.5228815,
    1759957341.6920419,
    1759957341.9001167,
    1759957342.0348804,
    1759957342.0455768,
    1759957342.0696342,
    1759957342.3072875,
    1759957342.4341683,
    1759957342.584139,
    1759957342.6966853,
    1759957342.7845955,
    1759957342.889212,
    1759957343.0005836,
    1759957343.0113492,
    1759957343.0465019,
    1759957343.0694478,
    1759957343.1211774,
    1759957343.1465454,
    1759957343.315968,
    1759957343.327507,
    1759957343.3347788,
    1759957343.4019465,
    1759957343.495051,
    1759957343.5146027,
    1759957343.5146317,
    1759957343.8326805,
    1759957343.8496535,
    1759957343.849622,
    1759957343.958922,
    1759957343.963427,
    1759957344.2106142,
    1759957344.2884994,
    1759957344.2981765,
    1759957344.3586526,
    1759957344.8292286,
    1759957344.9454014,
    1759957344.9816716,
    1759957345.2299974,
    1759957345.3146172,
    1759957345.429415,
    1759957345.4410818,
    1759957345.563121,
    1759957345.6116326,
    1759957345.7820756,
    1759957345.918554,
    1759957346.0131204,
    1759957346.0166407,
    1759957346.063782,
    1759957346.2271419,
    1759957346.2536242,
    1759957346.2807534,
    1759957346.3526976,
    1759957346.359732,
    1759957346.536342,
    1759957346.5598097,
    1759957346.6059616,
    1759957346.7443163,
    1759957346.913685,
    1759957346.9917817,
    1759957347.058868,
    1759957347.06746,
    1759957347.1223319,
    1759957347.220735,
    1759957347.3147728,
    1759957347.3720067,
    1759957347.6599183,
    1759957347.8130004,
    1759957347.8335416,
    1759957347.8608413,
    1759957347.8877668,
    1759957347.9645357,
    1759957348.1489186,
    1759957348.148967,
    1759957348.1533673,
    1759957348.3941796,
    1759957348.4367716,
    1759957348.6279182,
    1759957348.6307333,
    1759957348.6793969,
    1759957348.7950017,
    1759957348.841938,
    1759957348.8505163,
    1759957348.952261,
    1759957349.014116,
    1759957349.0204778,
    1759957349.0494337,
    1759957349.1734724,
    1759957349.31884,
    1759957349.4182858,
    1759957349.556663,
    1759957349.7842684,
    1759957349.8904905,
    1759957349.9723122,
    1759957350.0236182,
    1759957350.0786119,
    1759957350.1243536,
    1759957350.1496668,
    1759957350.1496222,
    1759957350.162627,
    1759957350.206828,
    1759957350.2365758,
    1759957350.2365596,
    1759957350.4015067,
    1759957350.5032916,
    1759957350.7282112,
    1759957350.7546563,
    1759957350.9106846,
    1759957350.927209,
    1759957351.0630238,
    1759957351.2360713,
    1759957351.2580247,
    1759957351.3453283,
    1759957351.3984303,
    1759957351.6510992,
    1759957351.664623,
    1759957351.815927,
    1759957351.8210185,
    1759957351.8426878,
    1759957351.8858354,
    1759957352.015556,
    1759957352.087977,
    1759957352.1272256,
    1759957352.264471,
    1759957352.3907263,
    1759957352.4733627,
    1759957352.4987884,
    1759957352.592076,
    1759957352.6869814,
    1759957352.7657824,
    1759957352.8999748,
    1759957353.0761156,
    1759957353.1562,
    1759957353.1762872,
    1759957353.2801418,
    1759957353.2944663,
    1759957353.3086433,
    1759957353.3354,
    1759957353.38244,
    1759957353.3864884,
    1759957353.5431225,
    1759957353.6097574,
    1759957353.7062216,
    1759957353.7115667,
    1759957353.7359722,
    1759957353.7980878,
    1759957353.952989,
    1759957353.9611733,
    1759957354.0148869,
    1759957354.1975732,
    1759957354.3145623,
    1759957354.3293667,
    1759957354.337767,
    1759957354.4269652,
    1759957354.5469337,
    1759957354.5940177,
    1759957354.7494466,
    1759957354.7494159,
    1759957354.7539713,
    1759957354.8001611,
    1759957354.9364696,
    1759957354.9761431,
    1759957354.995029,
    1759957355.0009084,
    1759957355.0363202,
    1759957355.1225767,
    1759957355.1514702,
    1759957355.1794481,
    1759957355.4083865,
    1759957355.4191792,
    1759957355.4524994,
    1759957355.6019728,
    1759957355.6428988,
    1759957355.7606688,
    1759957355.7728488,
    1759957355.8867543,
    1759957355.9074829,
    1759957355.9501865,
    1759957355.9501517,
    1759957356.2355714,
    1759957356.4219248,
    1759957356.460806,
    1759957356.4807143,
    1759957356.6027236,
    1759957356.6148226,
    1759957356.669841,
    1759957356.8773599,
    1759957356.947304,
    1759957356.963678,
    1759957357.1562424,
    1759957357.1872761,
    1759957357.3137934,
    1759957357.4585958,
    1759957357.7618625,
    1759957357.7698078,
    1759957357.8343806,
    1759957357.8477685,
    1759957357.9428914,
    1759957357.9521003,
    1759957358.0945218,
    1759957358.145351,
    1759957358.1600952,
    1759957358.245664,
    1759957358.2556217,
    1759957358.260632,
    1759957358.3745992,
    1759957358.3983846,
    1759957358.551105,
    1759957358.5915048,
    1759957358.6074834,
    1759957358.6618032,
    1759957358.6776662,
    1759957358.8592095,
    1759957358.8780222,
    1759957358.9563632,
    1759957358.9609404,
    1759957359.0684628,
    1759957359.0891297,
    1759957359.2313309,
    1759957359.2685258,
    1759957359.3138897,
    1759957359.4693696,
    1759957359.55176,
    1759957359.5783362,
    1759957359.7293465,
    1759957359.8024254,
    1759957359.9854994,
    1759957360.3068829,
    1759957360.3883514,
    1759957360.3942564,
    1759957360.5124633,
    1759957360.5379443,
    1759957360.5943148,
    1759957360.6349506,
    1759957360.719994,
    1759957360.7545657,
    1759957361.0071123,
    1759957361.151062,
    1759957361.156416,
    1759957361.4289677,
    1759957361.4851315,
    1759957361.5744472,
    1759957361.8854256,
    1759957361.8963854,
    1759957361.8964007,
    1759957361.896329,
    1759957361.9567115,
    1759957362.0000055,
    1759957362.083504,
    1759957362.1710212,
    1759957362.2162223,
    1759957362.2776213,
    1759957362.3210425,
    1759957362.3368814,
    1759957362.483624,
    1759957362.6065657,
    1759957362.6403267,
    1759957362.6631715,
    1759957362.7408476,
    1759957362.7408051,
    1759957362.8593848,
    1759957363.1912942,
    1759957363.3598075,
    1759957363.4854739,
    1759957363.5708556,
    1759957363.6350656,
    1759957363.7064724,
    1759957363.7689419,
    1759957363.8948383,
    1759957363.9000285,
    1759957363.9559011,
    1759957364.016008,
    1759957364.0208583,
    1759957364.1631143,
    1759957364.1815562,
    1759957364.2109764,
    1759957364.4199593,
    1759957364.8468869,
    1759957364.8514104,
    1759957365.051356,
    1759957365.1162686,
    1759957365.1505668,
    1759957365.1899219,
    1759957365.459271,
    1759957365.7211933,
    1759957365.8107183,
    1759957365.9885967,
    1759957365.9921126,
    1759957366.135211,
    1759957366.3940613,
    1759957366.4807396,
    1759957366.5396712,
    1759957366.5809808,
    1759957366.6751838,
    1759957366.7199495,
    1759957366.8137581,
    1759957366.9318085,
    1759957367.131272,
    1759957367.1886022,
    1759957367.224043,
    1759957367.5428216,
    1759957367.5910451,
    1759957367.612027,
    1759957367.7183096,
    1759957367.7319372,
    1759957367.7856286,
    1759957367.8170156,
    1759957367.8567512,
    1759957368.0564153,
    1759957368.3195279,
    1759957368.3195431,
    1759957368.4297905,
    1759957368.4448779,
    1759957368.5073624,
    1759957368.557589,
    1759957368.8384762,
    1759957368.8826773,
    1759957368.898192,
    1759957369.0146792,
    1759957369.1410618,
    1759957369.1410177,
    1759957369.145498,
    1759957369.2434294,
    1759957369.2730396,
    1759957369.3907595,
    1759957369.4876697,
    1759957369.619861,
    1759957369.6686227,
    1759957369.7966208,
    1759957369.9339688,
    1759957369.9540553,
    1759957369.9845154,
    1759957369.9950135,
    1759957370.1196098,
    1759957370.2170882,
    1759957370.5387428,
    1759957370.6069715,
    1759957370.770813,
    1759957370.8703325,
    1759957370.9815516,
    1759957371.079905,
    1759957371.1854599,
    1759957371.190546,
    1759957371.2722194,
    1759957371.2877479,
    1759957371.3167336,
    1759957371.33201,
    1759957371.4526513,
    1759957371.6187782,
    1759957371.682,
    1759957371.6872573,
    1759957371.7983708,
    1759957371.9000533,
    1759957371.9366014,
    1759957371.9544585,
    1759957372.0433846,
    1759957372.0848894,
    1759957372.1240427,
    1759957372.148218,
    1759957372.1686683,
    1759957372.2398555,
    1759957372.2564158,
    1759957372.2667391,
    1759957372.2804449,
    1759957372.4054074,
    1759957372.4473846,
    1759957372.4596004,
    1759957372.638901,
    1759957372.8048816,
    1759957373.0057971,
    1759957373.046471,
    1759957373.072533,
    1759957373.1162431,
    1759957373.211999,
    1759957373.2180023,
    1759957373.2642105,
    1759957373.3755352,
    1759957373.4064517,
    1759957373.5225003,
    1759957373.522537,
    1759957373.5800712,
    1759957373.718716,
    1759957373.7971947,
    1759957373.8153782,
    1759957373.8711126,
    1759957373.8906639,
    1759957373.894567,
    1759957373.9528854,
    1759957374.032784,
    1759957374.0680945,
    1759957374.1145444,
    1759957374.4513128,
    1759957374.47917,
    1759957374.5409229,
    1759957374.6406531,
    1759957374.6579978,
    1759957374.7069466,
    1759957374.728339,
    1759957374.7367678,
    1759957375.0335157,
    1759957375.0470126,
    1759957375.1260097,
    1759957375.2562225,
    1759957375.2694724,
    1759957375.4768016,
    1759957375.535274,
    1759957375.6269271,
    1759957375.6316862,
    1759957375.7003284,
    1759957375.7638228,
    1759957375.87544,
    1759957375.8754716,
    1759957376.0444915,
    1759957376.3599524,
    1759957376.3880064,
    1759957376.4794862,
    1759957376.551186,
    1759957376.7296908,
    1759957376.8478565,
    1759957376.8624394,
    1759957376.9279947,
    1759957377.0268636,
    1759957377.0424228,
    1759957377.0796158,
    1759957377.0836217,
    1759957377.1492062,
    1759957377.1834278,
    1759957377.2691512,
    1759957377.274473,
    1759957377.3210907,
    1759957377.3565638,
    1759957377.371162,
    1759957377.3831737,
    1759957377.410448,
    1759957377.4725077,
    1759957377.5189042,
    1759957377.8026352,
    1759957377.8084145,
    1759957377.863917,
    1759957377.9845693,
    1759957378.042563,
    1759957378.0426078,
    1759957378.1738362,
    1759957378.1869454,
    1759957378.2559152,
    1759957378.266264,
    1759957378.3573272,
    1759957378.4077218,
    1759957378.407767,
    1759957378.4435773,
    1759957378.7962756,
    1759957378.916665,
    1759957378.9816713,
    1759957379.0770967,
    1759957379.0922184,
    1759957379.1200025,
    1759957379.2334933,
    1759957379.4567335,
    1759957379.5073016,
    1759957379.5579696,
    1759957379.5694633,
    1759957379.6165168,
    1759957379.6243572,
    1759957379.6977243,
    1759957379.7034426,
    1759957379.7635117,
    1759957379.8251219,
    1759957379.8393202,
    1759957379.9512134,
    1759957380.3651388,
    1759957380.4284594,
    1759957380.552793,
    1759957380.5892093,
    1759957380.6921227,
    1759957380.696242,
    1759957380.8342786,
    1759957380.8696556,
    1759957380.9147658,
    1759957380.9377017,
    1759957381.0746503,
    1759957381.125291,
    1759957381.143451,
    1759957381.372384,
    1759957381.4012835,
    1759957381.426504,
    1759957381.4623787,
    1759957381.462338,
    1759957381.6390264,
    1759957381.6580634,
    1759957381.6967666,
    1759957381.7053251,
    1759957381.7450264,
    1759957381.7519429,
    1759957381.781179,
    1759957381.816119,
    1759957382.0301538,
    1759957382.030193,
    1759957382.0435157,
    1759957382.189772,
    1759957382.5349517,
    1759957382.6443493,
    1759957382.6894505,
    1759957382.8908226,
    1759957382.890903,
    1759957382.8908863,
    1759957383.0024261,
    1759957383.1459167,
    1759957383.4106207,
    1759957383.507904,
    1759957383.7847593,
    1759957383.9209461,
    1759957383.9542422,
    1759957384.0098474,
    1759957384.0523002,
    1759957384.052259,
    1759957384.1096847,
    1759957384.117424,
    1759957384.3044527,
    1759957384.3113801,
    1759957384.3113453,
    1759957384.4183624,
    1759957384.4991198,
    1759957384.5111296,
    1759957384.7225158,
    1759957384.8591316,
    1759957384.8674324,
    1759957385.1421123,
    1759957385.2156718,
    1759957385.2533777,
    1759957385.797452,
    1759957385.8289282,
    1759957386.0060487,
    1759957386.1766276,
    1759957386.2237072,
    1759957386.3335276,
    1759957386.4830213,
    1759957386.6031864,
    1759957386.632237,
    1759957386.7815642,
    1759957386.9479935,
    1759957386.9719138,
    1759957387.1865926,
    1759957387.2465086,
    1759957387.2957802,
    1759957387.5041702,
    1759957387.5137532,
    1759957387.5848658,
    1759957387.6569924,
    1759957387.9070065,
    1759957388.018865,
    1759957388.0560493,
    1759957388.207138,
    1759957388.3419116,
    1759957388.3469489,
    1759957388.5149527,
    1759957388.7211502,
    1759957388.7309105,
    1759957388.7376404,
    1759957388.8289664,
    1759957389.0293152,
    1759957389.0293598,
    1759957389.126189,
    1759957389.286954,
    1759957389.3382144,
    1759957389.3894517,
    1759957389.524163,
    1759957389.539592,
    1759957389.6280875,
    1759957389.6894178,
    1759957389.7440624,
    1759957389.7586896,
    1759957389.9887831,
    1759957390.025846,
    1759957390.194127,
    1759957390.2043982,
    1759957390.2233603,
    1759957390.2444272,
    1759957390.2877839,
    1759957390.2923355,
    1759957390.531378,
    1759957390.5544868,
    1759957390.709902,
    1759957390.865906,
    1759957390.9176605,
    1759957390.932556,
    1759957390.9478366,
    1759957390.9690046,
    1759957391.0672665,
    1759957391.2124333,
    1759957391.3740304,
    1759957391.4308026,
    1759957391.54304,
    1759957391.6410263,
    1759957391.661641,
    1759957391.7114444,
    1759957391.7733607,
    1759957391.7958076,
    1759957391.8235471,
    1759957391.9337282,
    1759957392.0013177,
    1759957392.0416648,
    1759957392.0515306,
    1759957392.1351302,
    1759957392.3071346,
    1759957392.3677387,
    1759957392.3989382,
    1759957392.5605376,
    1759957392.5606105,
    1759957392.560629,
    1759957392.5811536,
    1759957392.6184008,
    1759957392.6719272,
    1759957392.7453744,
    1759957392.8369052,
    1759957393.0396545,
    1759957393.3512614,
    1759957393.490499,
    1759957393.651317,
    1759957393.7032337,
    1759957393.7268047,
    1759957393.843761,
    1759957393.8779294,
    1759957393.9824033,
    1759957394.0440824,
    1759957394.0818,
    1759957394.1836944,
    1759957394.1836753,
    1759957394.2363114,
    1759957394.257104,
    1759957394.3510096,
    1759957394.5351396,
    1759957394.5741243,
    1759957394.5902777,
    1759957394.5962174,
    1759957394.6806228,
    1759957394.779706,
    1759957394.8624883,
    1759957394.8669803,
    1759957394.9022193,
    1759957394.9187853,
    1759957395.0541523,
    1759957395.0851057,
    1759957395.252772,
    1759957395.2693226,
    1759957395.4079049,
    1759957395.501784,
    1759957395.5915163,
    1759957395.6845767,
    1759957395.7207935,
    1759957395.863467,
    1759957395.8842049,
    1759957396.019118,
    1759957396.228285,
    1759957396.2761972,
    1759957396.328866,
    1759957396.6153076,
    1759957396.6198444,
    1759957396.6854954,
    1759957396.9131725,
    1759957397.0526912,
    1759957397.1325064,
    1759957397.2252214,
    1759957397.232447,
    1759957397.2389207,
    1759957397.3145308,
    1759957397.3511589,
    1759957397.4338923,
    1759957397.5276446,
    1759957397.5311368,
    1759957397.5523076,
    1759957397.8169272,
    1759957397.9484725,
    1759957398.1277835,
    1759957398.3053658,
    1759957398.3053255,
    1759957398.3255432,
    1759957398.6045663,
    1759957398.6975918,
    1759957399.0361001,
    1759957399.3187394,
    1759957399.3353014,
    1759957399.5395029,
    1759957399.5673227,
    1759957399.730253,
    1759957399.7342696,
    1759957399.743085,
    1759957399.7558243,
    1759957399.9070818,
    1759957399.9070358,
    1759957399.926808,
    1759957399.9739516,
    1759957400.0158153,
    1759957400.1166265,
    1759957400.3359187,
    1759957400.4596329,
    1759957400.5957077,
    1759957400.7146938,
    1759957400.7529645,
    1759957400.774331,
    1759957400.7847471,
    1759957400.9218378,
    1759957400.9446526,
    1759957401.1078057,
    1759957401.1174285,
    1759957401.1570578,
    1759957401.2519827,
    1759957401.2615144,
    1759957401.3411958,
    1759957401.3411486,
    1759957401.3567896,
    1759957401.4930823,
    1759957401.6701674,
    1759957401.6701255,
    1759957401.8048358,
    1759957401.9668443,
    1759957401.9860268,
    1759957402.0172055,
    1759957402.162167,
    1759957402.1747024,
    1759957402.2105238,
    1759957402.2866893,
    1759957402.4288204,
    1759957402.4287806,
    1759957402.5426235,
    1759957402.5637145,
    1759957402.6432505,
    1759957402.7764318,
    1759957402.785819,
    1759957402.8093522,
    1759957402.999716,
    1759957403.037143,
    1759957403.0510764,
    1759957403.0955648,
    1759957403.1039326,
    1759957403.302981,
    1759957403.3660088,
    1759957403.4737768,
    1759957403.6046996,
    1759957403.6378703,
    1759957403.641659,
    1759957403.6485806,
    1759957403.7176208,
    1759957403.7822938,
    1759957403.7956457,
    1759957404.0130544,
    1759957404.1077259,
    1759957404.1384923,
    1759957404.368229,
    1759957404.4085965,
    1759957404.4370432,
    1759957404.4938207,
    1759957404.557199,
    1759957404.5678976,
    1759957404.5883675,
    1759957404.957903,
    1759957405.0336294,
    1759957405.1951103,
    1759957405.1950893,
    1759957405.2736228,
    1759957405.344757,
    1759957405.3599772,
    1759957405.4592843,
    1759957405.5485542,
    1759957405.6440792,
    1759957405.6837904,
    1759957405.6970887,
    1759957405.7469919,
    1759957405.7919698,
    1759957405.8413827,
    1759957405.9450252,
    1759957406.0602894,
    1759957406.098656,
    1759957406.3277252,
    1759957406.3368616,
    1759957406.3731458,
    1759957406.4169545,
    1759957406.4664826,
    1759957406.4800172,
    1759957406.5769947,
    1759957406.5947325,
    1759957406.6657112,
    1759957406.7873077,
    1759957406.8118937,
    1759957406.909233,
    1759957407.0011911,
    1759957407.1423492,
    1759957407.3438258,
    1759957407.3495748,
    1759957407.4968457,
    1759957407.6059258,
    1759957407.6787028,
    1759957407.7039626,
    1759957407.8890324,
    1759957407.9247885,
    1759957408.0251696,
    1759957408.1745124,
    1759957408.2094245,
    1759957408.2094665,
    1759957408.298438,
    1759957408.3780434,
    1759957408.383713,
    1759957408.4016163,
    1759957408.4503646,
    1759957408.472491,
    1759957408.668542,
    1759957408.7530608,
    1759957408.7808142,
    1759957408.8606884,
    1759957409.0410986,
    1759957409.3020866,
    1759957409.3624055,
    1759957409.3978965,
    1759957409.5457995,
    1759957409.549564,
    1759957409.6018536,
    1759957409.6788826,
    1759957409.8187845,
    1759957409.8921242,
    1759957409.9471772,
    1759957409.9812078,
    1759957410.0228174,
    1759957410.0654182,
    1759957410.1452444,
    1759957410.1941838,
    1759957410.3317616,
    1759957410.375236,
    1759957410.4213276,
    1759957410.427489,
    1759957410.498913,
    1759957410.5151005,
    1759957410.5834725,
    1759957410.591036,
    1759957410.7317271,
    1759957410.935985,
    1759957410.9988818,
    1759957411.0612674,
    1759957411.1830728,
    1759957411.250385,
    1759957411.320435,
    1759957411.3413687,
    1759957411.3838573,
    1759957411.4311583,
    1759957411.431127,
    1759957411.7671695,
    1759957411.879848,
    1759957411.8940427,
    1759957411.9922986,
    1759957412.0015516,
    1759957412.1090643,
    1759957412.1286001,
    1759957412.179543,
    1759957412.2177398,
    1759957412.285527,
    1759957412.2854784,
    1759957412.2978256,
    1759957412.4709232,
    1759957412.662528,
    1759957412.997501,
    1759957413.0541604,
    1759957413.209077,
    1759957413.4234583,
    1759957413.762409,
    1759957413.8626368,
    1759957413.883467,
    1759957413.9728057,
    1759957413.979423,
    1759957413.999521,
    1759957414.0626247,
    1759957414.0711627,
    1759957414.1610157,
    1759957414.1746933,
    1759957414.2437856,
    1759957414.2626603,
    1759957414.268141,
    1759957414.2887623,
    1759957414.2925951,
    1759957414.308627,
    1759957414.419758,
    1759957414.8201149,
    1759957414.8650942,
    1759957414.8977203,
    1759957414.928752,
    1759957414.9501288,
    1759957414.9897287,
    1759957415.0006173,
    1759957415.181714,
    1759957415.2349284,
    1759957415.2349455,
    1759957415.267959,
    1759957415.3382015,
    1759957415.3721967,
    1759957415.5899937,
    1759957415.638479,
    1759957415.6748288,
    1759957415.865786,
    1759957416.0089955,
    1759957416.425334,
    1759957416.4680872,
    1759957416.6213984,
    1759957416.7511327,
    1759957416.9026854,
    1759957417.0352852,
    1759957417.0680788,
    1759957417.2475781,
    1759957417.3038611,
    1759957417.3273907,
    1759957417.3828752,
    1759957417.420442,
    1759957417.4994557,
    1759957417.6818423,
    1759957418.1007965,
    1759957418.3252275,
    1759957418.4186845,
    1759957418.4360297,
    1759957418.5788429,
    1759957418.6938188,
    1759957418.6938648,
    1759957418.7048166,
    1759957418.71973,
    1759957418.9800303,
    1759957419.1612525,
    1759957419.2850263,
    1759957419.319179,
    1759957419.3507845,
    1759957419.3588815,
    1759957419.3688607,
    1759957419.487755,
    1759957419.6794643,
    1759957419.6795092,
    1759957419.739356,
    1759957419.7698681,
    1759957419.82211,
    1759957420.0371573,
    1759957420.2072082,
    1759957420.3350446,
    1759957420.4409146,
    1759957420.4561422,
    1759957420.466336,
    1759957420.5488567,
    1759957420.5632856,
    1759957420.8010502,
    1759957420.8068807,
    1759957420.9180613,
    1759957421.0738354,
    1759957421.1433132,
    1759957421.272823,
    1759957421.3424025,
    1759957421.8862355,
    1759957421.9124622,
    1759957422.0532684,
    1759957422.2166393,
    1759957422.2959182,
    1759957422.3369741,
    1759957422.3869085,
    1759957422.5663588,
    1759957422.7091355,
    1759957422.7432747,
    1759957422.8042738,
    1759957423.250299,
    1759957423.250344,
    1759957423.4689233,
    1759957423.5107315,
    1759957423.554596,
    1759957423.5975378,
    1759957423.7243161,
    1759957423.7776103,
    1759957423.7942297,
    1759957423.8189957,
    1759957423.845462,
    1759957423.938241,
    1759957424.150424,
    1759957424.2345085,
    1759957424.2641456,
    1759957424.4960642,
    1759957424.5320694,
    1759957424.578927,
    1759957424.6360621,
    1759957424.692242,
    1759957424.788788,
    1759957424.9411845,
    1759957425.1394668,
    1759957425.2486901,
    1759957425.2773156,
    1759957425.288231,
    1759957425.3412585,
    1759957425.360241,
    1759957425.3602,
    1759957425.3658056,
    1759957425.4418101,
    1759957425.544592,
    1759957425.5825703,
    1759957425.7581985,
    1759957425.7954865,
    1759957425.818092,
    1759957425.8431916,
    1759957426.0620887,
    1759957426.1301801,
    1759957426.1687193,
    1759957426.1765704,
    1759957426.2345698,
    1759957426.3535328,
    1759957426.384425,
    1759957426.4702306,
    1759957426.5437496,
    1759957426.6314414,
    1759957426.748409,
    1759957427.046883,
    1759957427.0649178,
    1759957427.0711946,
    1759957427.2272997,
    1759957427.2511952,
    1759957427.3992934,
    1759957427.403362,
    1759957427.4073722,
    1759957427.5481472,
    1759957427.6053982,
    1759957427.695898,
    1759957427.7230952,
    1759957427.837933,
    1759957428.0664706,
    1759957428.0773237,
    1759957428.0934904,
    1759957428.194656,
    1759957428.256642,
    1759957428.3518953,
    1759957428.661964,
    1759957428.7668288,
    1759957428.769734,
    1759957428.9750938,
    1759957429.0124094,
    1759957429.0192962,
    1759957429.1125565,
    1759957429.2610912,
    1759957429.3630073,
    1759957429.384226,
    1759957429.396029,
    1759957429.4492173,
    1759957429.4491713,
    1759957429.5696502,
    1759957429.5789537,
    1759957429.5789165,
    1759957429.6366687,
    1759957429.7233636,
    1759957429.8687997,
    1759957430.0100684,
    1759957430.0546842,
    1759957430.0788143,
    1759957430.0828032,
    1759957430.1984928,
    1759957430.2269022,
    1759957430.3992088,
    1759957430.4234037,
    1759957430.5438175,
    1759957430.5990791,
    1759957430.6073864,
    1759957430.7780094,
    1759957430.7823753,
    1759957430.831255,
    1759957430.9504926,
    1759957431.0052626,
    1759957431.0432522,
    1759957431.1627967,
    1759957431.2235105,
    1759957431.2234643,
    1759957431.3837304,
    1759957431.4248424,
    1759957431.5928504,
    1759957431.6223168,
    1759957431.7855437,
    1759957431.9072597,
    1759957432.020091,
    1759957432.061683,
    1759957432.1138182,
    1759957432.1138635,
    1759957432.4295037,
    1759957432.441178,
    1759957432.4411628,
    1759957432.4873993,
    1759957432.4929643,
    1759957432.5419912,
    1759957432.599796,
    1759957432.6507034,
    1759957432.7440586,
    1759957432.750016,
    1759957432.8444493,
    1759957432.8625498,
    1759957432.9308927,
    1759957432.9375415,
    1759957432.937578,
    1759957433.0198584,
    1759957433.0867193,
    1759957433.1073534,
    1759957433.1950252,
    1759957433.2195096,
    1759957433.2733548,
    1759957433.2782311,
    1759957433.3622215,
    1759957433.382952,
    1759957433.469114,
    1759957433.4724863,
    1759957433.638834,
    1759957433.6516724,
    1759957433.7382808,
    1759957433.8137536,
    1759957433.9385092,
    1759957434.0243168,
    1759957434.0335932,
    1759957434.0371819,
    1759957434.2356517,
    1759957434.312686,
    1759957434.362881,
    1759957434.3951473,
    1759957434.5173929,
    1759957434.5395768,
    1759957434.664876,
    1759957434.8293304,
    1759957434.891831,
    1759957435.0698617,
    1759957435.0763397,
    1759957435.0803251,
    1759957435.1625288,
    1759957435.2409787,
    1759957435.28629,
    1759957435.3857105,
    1759957435.4171176,
    1759957435.4774466,
    1759957435.7368991,
    1759957435.7446077,
    1759957435.7724912,
    1759957435.7855656,
    1759957435.8212457,
    1759957435.8343115,
    1759957435.9097178,
    1759957435.9608436,
    1759957435.983039,
    1759957436.0408292,
    1759957436.1539443,
    1759957436.1657665,
    1759957436.3247693,
    1759957436.4101112,
    1759957436.410069,
    1759957436.499253,
    1759957436.5507927,
    1759957436.6089687,
    1759957436.6559572,
    1759957436.7227707,
    1759957436.811281,
    1759957436.9762144,
    1759957436.9940357,
    1759957437.0068603,
    1759957437.1598,
    1759957437.2403407,
    1759957437.604675,
    1759957437.6163566,
    1759957437.6768022,
    1759957437.820967,
    1759957437.85444,
    1759957437.9059768,
    1759957437.9710567,
    1759957438.264564,
    1759957438.464098,
    1759957438.4758132,
    1759957438.4809713,
    1759957438.620518,
    1759957438.6467445,
    1759957438.7866652,
    1759957438.8043122,
    1759957438.8571522,
    1759957438.944417,
    1759957438.9668825,
    1759957439.0069296,
    1759957439.0194092,
    1759957439.1073236,
    1759957439.1784492,
    1759957439.2705119,
    1759957439.319526,
    1759957439.4666739,
    1759957439.5199108,
    1759957439.5727015,
    1759957439.6934328,
    1759957439.7109528,
    1759957439.7990456,
    1759957439.9764524,
    1759957439.9950051,
    1759957440.0277383,
    1759957440.0936897,
    1759957440.1016653,
    1759957440.133672,
    1759957440.187933,
    1759957440.2485824,
    1759957440.3672433,
    1759957440.4211602,
    1759957440.4312725,
    1759957440.443385,
    1759957440.585231,
    1759957440.6748006,
    1759957440.7092202,
    1759957440.7486854,
    1759957440.8528574,
    1759957440.866895,
    1759957440.9213789,
    1759957441.01056,
    1759957441.0877273,
    1759957441.0876787,
    1759957441.1050174,
    1759957441.1234128,
    1759957441.2180636,
    1759957441.318278,
    1759957441.5398214,
    1759957441.6101153,
    1759957441.7850597,
    1759957441.8049078,
    1759957441.8743768,
    1759957441.933204,
    1759957442.0423243,
    1759957442.2155457,
    1759957442.2529724,
    1759957442.2580361,
    1759957442.3374584,
    1759957442.3663344,
    1759957442.592388,
    1759957442.6055639,
    1759957442.7112982,
    1759957442.7201798,
    1759957442.7395532,
    1759957442.7584078,
    1759957442.8480365,
    1759957442.8549147,
    1759957442.8925993,
    1759957442.9897017,
    1759957442.9948156,
    1759957443.0355496,
    1759957443.0513797,
    1759957443.2393918,
    1759957443.3021953,
    1759957443.3125927,
    1759957443.6003053,
    1759957443.6426578,
    1759957443.748173,
    1759957443.7907503,
    1759957443.9325683,
    1759957443.9993923,
    1759957444.0389018,
    1759957444.060945,
    1759957444.2232428,
    1759957444.4097335,
    1759957444.4869215,
    1759957444.5060601,
    1759957444.776902,
    1759957444.8118753,
    1759957444.9002492,
    1759957444.9442677,
    1759957444.9835854,
    1759957445.129389,
    1759957445.1893127,
    1759957445.254767,
    1759957445.2701359,
    1759957445.32898,
    1759957445.4369411,
    1759957445.463765,
    1759957445.5318773,
    1759957445.6321497,
    1759957445.6899467,
    1759957445.8154733,
    1759957445.8389962,
    1759957446.0344594,
    1759957446.2239313,
    1759957446.2314923,
    1759957446.300983,
    1759957446.3248906,
    1759957446.3249352,
    1759957446.5581388,
    1759957446.6000226,
    1759957446.6671503,
    1759957446.6772285,
    1759957446.6995096,
    1759957446.7153354,
    1759957447.0874453,
    1759957447.099251,
    1759957447.2929215,
    1759957447.5886312,
    1759957447.6276364,
    1759957447.627687,
    1759957447.6524656,
    1759957447.7943985,
    1759957447.9031107,
    1759957447.9582992,
    1759957448.0097969,
    1759957448.0375693,
    1759957448.1051238,
    1759957448.1490774,
    1759957448.4085937,
    1759957448.9055886,
    1759957448.9148834,
    1759957449.0162606,
    1759957449.1752346,
    1759957449.319975,
    1759957449.3717756,
    1759957449.399598,
    1759957449.4527152,
    1759957449.5037503,
    1759957449.5770843,
    1759957449.58914,
    1759957449.597661,
    1759957449.6931686,
    1759957449.7924833,
    1759957450.0506914,
    1759957450.1203544,
    1759957450.1706643,
    1759957450.1764657,
    1759957450.2009826,
    1759957450.2471278,
    1759957450.3358572,
    1759957450.3819432,
    1759957450.3875177,
    1759957450.392386,
    1759957450.485021,
    1759957450.49524,
    1759957450.5834699,
    1759957450.6989942,
    1759957450.7028508,
    1759957450.7096772,
    1759957450.8117085,
    1759957450.8213065,
    1759957450.8660996,
    1759957450.8720808,
    1759957450.903325,
    1759957451.00485,
    1759957451.0521076,
    1759957451.0813935,
    1759957451.225332,
    1759957451.225287,
    1759957451.2447824,
    1759957451.2859821,
    1759957451.3913856,
    1759957451.479068,
    1759957451.5115433,
    1759957451.571659,
    1759957451.594363,
    1759957451.6200976,
    1759957451.6228335,
    1759957451.7806914,
    1759957451.9634726,
    1759957452.3651235,
    1759957452.8446553,
    1759957453.0677361,
    1759957453.2376845,
    1759957453.4184408,
    1759957454.0264919,
    1759957454.0524335,
    1759957454.1118605,
    1759957454.479942,
    1759957454.58901,
    1759957454.924789,
    1759957455.2013323,
    1759957455.2255852,
    1759957455.2334054,
    1759957455.2462895,
    1759957455.2546268,
    1759957455.2831738,
    1759957455.3053029,
    1759957455.5476477,
    1759957455.567404,
    1759957455.5733564,
    1759957455.6434917,
    1759957455.8697896,
    1759957455.9002128,
    1759957455.9628136,
    1759957456.2534287,
    1759957456.2687075,
    1759957456.2985055,
    1759957456.3732924,
    1759957456.4069436,
    1759957456.4196563,
    1759957456.4421036,
    1759957456.5174055,
    1759957456.935263,
    1759957456.9882276,
    1759957456.996001,
    1759957457.1261973,
    1759957457.1322465,
    1759957457.2122538,
    1759957457.2615073,
    1759957457.3482046,
    1759957457.4734464,
    1759957457.4777513,
    1759957457.6486278,
    1759957457.7462137,
    1759957457.78805,
    1759957457.8258212,
    1759957457.8995852,
    1759957457.9642498,
    1759957458.0240502,
    1759957458.03035,
    1759957458.2025974,
    1759957458.2462928,
    1759957458.2670937,
    1759957458.585084,
    1759957458.6648083,
    1759957458.9362147,
    1759957458.9715378,
    1759957458.9759026,
    1759957458.9869726,
    1759957459.263684,
    1759957459.296261,
    1759957459.3619177,
    1759957459.4528549,
    1759957459.4950411,
    1759957459.8438048,
    1759957459.8438554,
    1759957459.8524852,
    1759957459.8524468,
    1759957459.8640013,
    1759957459.893756,
    1759957459.9611387,
    1759957459.9992988,
    1759957460.0129807,
    1759957460.0853205,
    1759957460.1084068,
    1759957460.2206886,
    1759957460.229211,
    1759957460.3186963,
    1759957460.384704,
    1759957460.4534838,
    1759957460.5928051,
    1759957460.7867124,
    1759957461.1274498,
    1759957461.5210452,
    1759957461.521146,
    1759957461.5211308,
    1759957461.5211139,
    1759957461.7949364,
    1759957461.8025095,
    1759957461.8939345,
    1759957461.9637122,
    1759957462.0338101,
    1759957462.0453973,
    1759957462.0911992,
    1759957462.360958,
    1759957462.4647596,
    1759957462.8587067,
    1759957462.9389215,
    1759957462.9896457,
    1759957463.077858,
    1759957463.1126804,
    1759957463.1740146,
    1759957463.218105,
    1759957463.3449485,
    1759957463.4066694,
    1759957463.7427447,
    1759957463.801728,
    1759957463.933884,
    1759957463.9877486,
    1759957463.9877014,
    1759957464.0941133,
    1759957464.1696386,
    1759957464.2070155,
    1759957464.4088073,
    1759957464.5398047,
    1759957464.9033005,
    1759957465.2134178,
    1759957465.2161434,
    1759957465.2778597,
    1759957465.4684803,
    1759957465.5457857,
    1759957465.6729994,
    1759957465.8575602,
    1759957466.0100064,
    1759957466.0700612,
    1759957466.408848,
    1759957466.433036,
    1759957466.6861794,
    1759957466.7170458,
    1759957466.7423558,
    1759957466.7476006,
    1759957466.858736,
    1759957466.8766594,
    1759957467.2833498,
    1759957467.3791687,
    1759957467.4405124,
    1759957467.4579582,
    1759957467.7214904,
    1759957467.7590623,
    1759957467.7884426,
    1759957467.8211043,
    1759957467.8898437,
    1759957468.1317546,
    1759957468.2678554,
    1759957468.2983074,
    1759957468.4833622,
    1759957468.8959262,
    1759957469.0614452,
    1759957469.139983,
    1759957469.329479,
    1759957469.5011187,
    1759957469.6197138,
    1759957469.6635666,
    1759957469.9506514,
    1759957470.043725,
    1759957470.1548662,
    1759957470.1638198,
    1759957470.1947446,
    1759957470.1946986,
    1759957470.2924762,
    1759957470.3496182,
    1759957470.4759097,
    1759957470.6264422,
    1759957470.6394076,
    1759957471.087183,
    1759957471.2198524,
    1759957471.2197986,
    1759957471.2683156,
    1759957471.3968399,
    1759957471.4346545,
    1759957471.6711605,
    1759957471.6908848,
    1759957471.7694974,
    1759957471.7756405,
    1759957471.904745,
    1759957471.9174752,
    1759957472.0076754,
    1759957472.0965347,
    1759957472.1749072,
    1759957472.2859125,
    1759957472.3012664,
    1759957472.4242473,
    1759957472.5117803,
    1759957472.5168908,
    1759957472.5700526,
    1759957472.701941,
    1759957472.7116919,
    1759957472.8253849,
    1759957472.914028,
    1759957473.1034904,
    1759957473.2423503,
    1759957473.5586474,
    1759957473.739287,
    1759957473.7889254,
    1759957474.3377595,
    1759957474.360266,
    1759957474.456697,
    1759957474.7632048,
    1759957474.7775776,
    1759957474.863289,
    1759957474.8726747,
    1759957474.8935802,
    1759957475.0457687,
    1759957475.444239,
    1759957475.5754333,
    1759957475.9067998,
    1759957476.04178,
    1759957476.0700023,
    1759957476.2648547,
    1759957476.2687027,
    1759957476.4196541,
    1759957476.4298553,
    1759957476.4660256,
    1759957476.4776824,
    1759957476.6814055,
    1759957476.6858444,
    1759957476.7077868,
    1759957476.7169797,
    1759957476.7390945,
    1759957477.13178,
    1759957477.1437533,
    1759957477.1926146,
    1759957477.7244778,
    1759957477.8873742,
    1759957477.9058187,
    1759957477.9737606,
    1759957478.1356027,
    1759957478.1730738,
    1759957478.1980772,
    1759957478.447715,
    1759957478.48192,
    1759957478.4866562,
    1759957478.5327199,
    1759957478.61092,
    1759957478.6324346,
    1759957478.7160876,
    1759957478.7345946,
    1759957478.8990004,
    1759957478.9472787,
    1759957479.007025,
    1759957479.4809458,
    1759957479.502492,
    1759957479.5423396,
    1759957479.6576636,
    1759957479.6639123,
    1759957479.6936927,
    1759957479.712484,
    1759957479.740154,
    1759957479.924946,
    1759957479.9806173,
    1759957480.0394545,
    1759957480.1451244,
    1759957480.1545615,
    1759957480.1651726,
    1759957480.2768242,
    1759957480.292501,
    1759957480.432588,
    1759957480.4325433,
    1759957480.447329,
    1759957480.5188396,
    1759957480.6377435,
    1759957480.9113386,
    1759957480.936779,
    1759957481.0130005,
    1759957481.0201359,
    1759957481.187926,
    1759957481.2225482,
    1759957481.3547359,
    1759957481.364419,
    1759957481.393663,
    1759957481.4664578,
    1759957481.5427015,
    1759957481.5784914,
    1759957481.6605928,
    1759957481.6924822,
    1759957481.743235,
    1759957481.7558587,
    1759957481.7721062,
    1759957481.8692098,
    1759957481.891552,
    1759957481.9180825,
    1759957482.0535035,
    1759957482.1580198,
    1759957482.34006,
    1759957482.3790016,
    1759957482.5572379,
    1759957482.5609362,
    1759957482.7192497,
    1759957482.786876,
    1759957482.9225965,
    1759957482.9290562,
    1759957482.9439397,
    1759957483.064101,
    1759957483.1307259,
    1759957483.4448018,
    1759957483.4448216,
    1759957483.4613326,
    1759957483.5276842,
    1759957483.5375373,
    1759957483.5638573,
    1759957483.5833812,
    1759957483.6297746,
    1759957483.6618567,
    1759957483.85896,
    1759957483.8759499,
    1759957483.9421053,
    1759957484.1230946,
    1759957484.3142054,
    1759957484.3570983,
    1759957484.3736231,
    1759957484.3789613,
    1759957484.4017358,
    1759957484.5913484,
    1759957484.6140506,
    1759957484.965913,
    1759957485.0857282,
    1759957485.2083495,
    1759957485.2675703,
    1759957485.32129,
    1759957485.4484832,
    1759957485.4551911,
    1759957485.5108905,
    1759957485.6769934,
    1759957485.683316,
    1759957485.699743,
    1759957486.134876,
    1759957486.1388419,
    1759957486.1647031,
    1759957486.1919024,
    1759957486.3107631,
    1759957486.3291879,
    1759957486.5566132,
    1759957486.6712418,
    1759957486.774337,
    1759957486.7742882,
    1759957486.888622,
    1759957486.9409041,
    1759957487.063557,
    1759957487.1868029,
    1759957487.2590587,
    1759957487.2926848,
    1759957487.3493593,
    1759957487.356266,
    1759957487.4275897,
    1759957487.4824638,
    1759957487.6197038,
    1759957487.8114915,
    1759957487.8445146,
    1759957487.859818,
    1759957487.9729311,
    1759957488.052684,
    1759957488.0583234,
    1759957488.0923314,
    1759957488.2491686,
    1759957488.2660575,
    1759957488.351462,
    1759957488.3787658,
    1759957488.5724392,
    1759957488.5767481,
    1759957488.620736,
    1759957488.7232525,
    1759957488.7292516,
    1759957488.9725895,
    1759957489.0713649,
    1759957489.185904,
    1759957489.2137475,
    1759957489.2957575,
    1759957489.335431,
    1759957489.4847362,
    1759957489.5339015,
    1759957489.5709589,
    1759957489.5790348,
    1759957489.5877125,
    1759957489.587753,
    1759957489.7224984,
    1759957489.8662283,
    1759957489.915883,
    1759957490.0570016,
    1759957490.1445348,
    1759957490.201735,
    1759957490.2171764,
    1759957490.2588277,
    1759957490.3090634,
    1759957490.3808322,
    1759957490.5061865,
    1759957490.6925309,
    1759957490.8632517,
    1759957490.8879244,
    1759957490.8878818,
    1759957490.9164646,
    1759957490.9164321,
    1759957490.9164846,
    1759957490.9793522,
    1759957491.0221777,
    1759957491.2889547,
    1759957491.4089692,
    1759957491.5368226,
    1759957491.5672405,
    1759957491.5954416,
    1759957491.8083515,
    1759957491.8623917,
    1759957491.871936,
    1759957492.101896,
    1759957492.101939,
    1759957492.216965,
    1759957492.257119,
    1759957492.381395,
    1759957492.4342408,
    1759957492.4454627,
    1759957492.4684439,
    1759957492.511527,
    1759957492.5185206,
    1759957492.6482399,
    1759957492.697933,
    1759957492.8073852,
    1759957492.8752296,
    1759957492.9179082,
    1759957492.9287126,
    1759957492.9494863,
    1759957493.0084147,
    1759957493.0367088,
    1759957493.0397584,
    1759957493.179182,
    1759957493.3016856,
    1759957493.3561995,
    1759957493.4010475,
    1759957493.4447727,
    1759957493.5986538,
    1759957493.669499,
    1759957493.7084827,
    1759957493.7270067,
    1759957494.002708,
    1759957494.0614362,
    1759957494.1455574,
    1759957494.2032812,
    1759957494.4509223,
    1759957494.604258,
    1759957494.7094028,
    1759957494.7252045,
    1759957494.73638,
    1759957494.7541895,
    1759957494.8096118,
    1759957494.8220644,
    1759957494.8221016,
    1759957494.9613712,
    1759957495.003192,
    1759957495.0177965,
    1759957495.095441,
    1759957495.0953925,
    1759957495.117381,
    1759957495.1174104,
    1759957495.1736448,
    1759957495.2067497,
    1759957495.283028,
    1759957495.4366088,
    1759957495.444343,
    1759957495.488087,
    1759957495.4980285,
    1759957495.52933,
    1759957495.6581743,
    1759957496.0068743,
    1759957496.0926132,
    1759957496.106619,
    1759957496.1123745,
    1759957496.116285,
    1759957496.1335807,
    1759957496.3816688,
    1759957496.5183852,
    1759957496.7602632,
    1759957496.8122115,
    1759957496.8521986,
    1759957496.9476037,
    1759957497.0331788,
    1759957497.15856,
    1759957497.341683,
    1759957497.3763363,
    1759957497.5776837,
    1759957497.5822968,
    1759957497.6851707,
    1759957497.8230503,
    1759957497.8960845,
    1759957498.1343186,
    1759957498.2956047,
    1759957498.3170094,
    1759957498.628031,
    1759957498.7267444,
    1759957498.8186347,
    1759957498.8514707,
    1759957498.8568134,
    1759957498.8921328,
    1759957498.9405167,
    1759957498.9457755,
    1759957499.0531301,
    1759957499.074305,
    1759957499.0983267,
    1759957499.1206384,
    1759957499.1351793,
    1759957499.175058,
    1759957499.1800833,
    1759957499.187222,
    1759957499.3171008,
    1759957499.425428,
    1759957499.535513,
    1759957499.6065013,
    1759957499.8395176,
    1759957499.8558948,
    1759957500.003347,
    1759957500.0602918,
    1759957500.0981677,
    1759957500.5221972,
    1759957500.531141,
    1759957500.5311038,
    1759957500.9964428,
    1759957501.1718974,
    1759957501.2295275,
    1759957501.350626,
    1759957501.3951132,
    1759957501.468638,
    1759957501.6055777,
    1759957501.6099432,
    1759957501.6653697,
    1759957501.7667577,
    1759957501.7816818,
    1759957501.9658852,
    1759957502.0580566,
    1759957502.0713465,
    1759957502.134975,
    1759957502.1726294,
    1759957502.2282178,
    1759957502.283254,
    1759957502.2965462,
    1759957502.4179318,
    1759957502.5368195,
    1759957502.602996,
    1759957502.6745298,
    1759957502.7800925,
    1759957502.9479237,
    1759957502.9965832,
    1759957503.070468,
    1759957503.0914316,
    1759957503.1052794,
    1759957503.1576707,
    1759957503.172683,
    1759957503.3151283,
    1759957503.3151002,
    1759957503.328963,
    1759957503.373325,
    1759957503.427751,
    1759957503.5494583,
    1759957503.6256988,
    1759957503.6585047,
    1759957503.6841183,
    1759957503.75989,
    1759957503.7639968,
    1759957503.9784725,
    1759957503.9911325,
    1759957504.0099995,
    1759957504.1553257,
    1759957504.311673,
    1759957504.3985064,
    1759957504.4183598,
    1759957504.5806892,
    1759957504.6564057,
    1759957504.6922283,
    1759957504.750557,
    1759957504.868851,
    1759957504.9626906,
    1759957504.9627373,
    1759957504.9682717,
    1759957504.987345,
    1759957505.2010837,
    1759957505.3255758,
    1759957505.3615642,
    1759957505.507269,
    1759957505.7295165,
    1759957505.8613374,
    1759957505.8791814,
    1759957506.0051966,
    1759957506.0120072,
    1759957506.0222306,
    1759957506.1439934,
    1759957506.196521,
    1759957506.2777994,
    1759957506.3598907,
    1759957506.3957407,
    1759957506.3957732,
    1759957506.480213,
    1759957506.5214708,
    1759957506.7252793,
    1759957506.7252316,
    1759957506.7318442,
    1759957506.8460526,
    1759957506.8814266,
    1759957506.8888645,
    1759957507.00695,
    1759957507.1184022,
    1759957507.1701133,
    1759957507.2741766,
    1759957507.2997403,
    1759957507.3344295,
    1759957507.3393972,
    1759957507.4814487,
    1759957507.5993865,
    1759957507.6093025,
    1759957507.6985767,
    1759957507.8149724,
    1759957507.8638268,
    1759957507.9210432,
    1759957507.9614687,
    1759957507.9772356,
    1759957508.0532365,
    1759957508.1073706,
    1759957508.165882,
    1759957508.2585828,
    1759957508.2642715,
    1759957508.3278632,
    1759957508.4397438,
    1759957508.4704843,
    1759957508.492277,
    1759957508.5604057,
    1759957508.6536171,
    1759957508.6728394,
    1759957508.6977558,
    1759957508.7751253,
    1759957508.9424994,
    1759957508.954825,
    1759957509.0631304,
    1759957509.0700357,
    1759957509.2339647,
    1759957509.3874166,
    1759957509.4135337,
    1759957509.429661,
    1759957509.5147598,
    1759957509.6853476,
    1759957509.819717,
    1759957509.9672558,
    1759957510.0021667,
    1759957510.0150564,
    1759957510.2778828,
    1759957510.3451526,
    1759957510.3724241,
    1759957510.4214509,
    1759957510.4824116,
    1759957510.482368,
    1759957510.675512,
    1759957510.8602335,
    1759957510.86025,
    1759957510.8601775,
    1759957511.187692,
    1759957511.1957052,
    1759957511.2172773,
    1759957511.2577405,
    1759957511.2635186,
    1759957511.307228,
    1759957511.3292227,
    1759957511.4563143,
    1759957511.4624102,
    1759957511.4710572,
    1759957511.478692,
    1759957511.5666084,
    1759957511.733676,
    1759957511.7899282,
    1759957511.8372626,
    1759957511.9856389,
    1759957512.141894,
    1759957512.2570703,
    1759957512.2773676,
    1759957512.3919988,
    1759957512.4704883,
    1759957512.5023599,
    1759957512.5910554,
    1759957512.7395835,
    1759957512.7560477,
    1759957512.7588134,
    1759957512.7805345,
    1759957512.7910454,
    1759957512.803439,
    1759957512.836677,
    1759957513.1339178,
    1759957513.2042737,
    1759957513.3913007,
    1759957513.4622421,
    1759957513.4712427,
    1759957513.6826344,
    1759957513.8831582,
    1759957513.9488358,
    1759957514.0040948,
    1759957514.0099,
    1759957514.1832547,
    1759957514.18976,
    1759957514.4205177,
    1759957514.4666412,
    1759957514.4830177,
    1759957514.4870248,
    1759957514.6102812,
    1759957514.6437616,
    1759957514.6733944,
    1759957514.6734471,
    1759957514.7152047,
    1759957514.7151756,
    1759957514.7850347,
    1759957514.7894175,
    1759957514.8939755,
    1759957514.9105587,
    1759957514.9648752,
    1759957514.9696379,
    1759957515.0135088,
    1759957515.0480704,
    1759957515.0565321,
    1759957515.1029847,
    1759957515.2213604,
    1759957515.261025,
    1759957515.264433,
    1759957515.2709758,
    1759957515.3020568,
    1759957515.3398452,
    1759957515.7244756,
    1759957515.7324207,
    1759957515.7957559,
    1759957515.8015342,
    1759957515.8398979,
    1759957515.9165006,
    1759957515.9673624,
    1759957516.1468172,
    1759957516.1762915,
    1759957516.190922,
    1759957516.2416766,
    1759957516.2777421,
    1759957516.6036477,
    1759957516.6105464,
    1759957516.6105835,
    1759957516.7093275,
    1759957516.7989597,
    1759957516.848129,
    1759957516.8784463,
    1759957517.0117452,
    1759957517.0504594,
    1759957517.2034698,
    1759957517.254214,
    1759957517.3233492,
    1759957517.4796753,
    1759957517.603267,
    1759957517.6032214,
    1759957517.7707763,
    1759957517.8505564,
    1759957517.8575132,
    1759957517.9716547,
    1759957518.0824702,
    1759957518.174765,
    1759957518.2545784,
    1759957518.5581343,
    1759957518.6010647,
    1759957518.669058,
    1759957518.818725,
    1759957518.8327422,
    1759957519.0150506,
    1759957519.076199,
    1759957519.2106173,
    1759957519.2235434,
    1759957519.3413465,
    1759957519.459902,
    1759957519.4655445,
    1759957519.472061,
    1759957519.5495484,
    1759957519.7447567,
    1759957519.7797022,
    1759957519.955372,
    1759957519.974607,
    1759957520.2824516,
    1759957520.2898324,
    1759957520.2898695,
    1759957520.5476375,
    1759957520.622814,
    1759957520.7318373,
    1759957520.8292453,
    1759957520.8601952,
    1759957520.8602476,
    1759957520.8765292,
    1759957520.9520464,
    1759957520.9922035,
    1759957521.1525934,
    1759957521.2054749,
    1759957521.2089646,
    1759957521.5030034,
    1759957521.771517,
    1759957521.9110503,
    1759957522.0620165,
    1759957522.1321023,
    1759957522.167646,
    1759957522.2253,
    1759957522.8828382,
    1759957523.0740743,
    1759957523.1077094,
    1759957523.128383,
    1759957523.1499617,
    1759957523.157304,
    1759957523.1707702,
    1759957523.198882,
    1759957523.2071006,
    1759957523.2192237,
    1759957523.2995348,
    1759957523.3062356,
    1759957523.5426564,
    1759957523.6052766,
    1759957523.636381,
    1759957523.7009892,
    1759957523.7123096,
    1759957523.8228369,
    1759957523.8228831,
    1759957523.8707504,
    1759957523.9899065,
    1759957524.1581995,
    1759957524.227515,
    1759957524.3070107,
    1759957524.3906949,
    1759957524.3967977,
    1759957524.4543104,
    1759957524.5620847,
    1759957524.6432688,
    1759957524.650639,
    1759957524.7378263,
    1759957524.7377777,
    1759957524.750387,
    1759957524.8571942,
    1759957524.9390812,
    1759957524.9480612,
    1759957524.9991698,
    1759957525.0867188,
    1759957525.2313213,
    1759957525.2361007,
    1759957525.2749767,
    1759957525.3531516,
    1759957525.5302446,
    1759957525.7466044,
    1759957525.8354554,
    1759957525.9502554,
    1759957526.0424247,
    1759957526.1225867,
    1759957526.157537,
    1759957526.221181,
    1759957526.2645364,
    1759957526.2796848,
    1759957526.3694541,
    1759957526.4102898,
    1759957526.5101578,
    1759957526.5277107,
    1759957526.5276718,
    1759957526.5885785,
    1759957526.7311227,
    1759957526.785875,
    1759957526.7912226,
    1759957526.9598918,
    1759957526.9814591,
    1759957527.6277535,
    1759957527.643932,
    1759957527.7445009,
    1759957527.7957404,
    1759957527.8106537,
    1759957527.8914163,
    1759957528.051998,
    1759957528.1280072,
    1759957528.1390617,
    1759957528.208243,
    1759957528.2630076,
    1759957528.2733095,
    1759957528.2891922,
    1759957528.3141484,
    1759957528.3457618,
    1759957528.3579063,
    1759957528.399284,
    1759957528.4517703,
    1759957528.4992228,
    1759957528.6774585,
    1759957528.698,
    1759957528.7047052,
    1759957528.7238688,
    1759957528.7603955,
    1759957528.7905686,
    1759957528.936894,
    1759957529.0126915,
    1759957529.089907,
    1759957529.1586657,
    1759957529.1993704,
    1759957529.2195628,
    1759957529.383667,
    1759957529.401931,
    1759957529.4185762,
    1759957529.4303067,
    1759957529.4348817,
    1759957529.4929676,
    1759957529.5216174,
    1759957529.6415324,
    1759957529.6469154,
    1759957529.82356,
    1759957529.8952847,
    1759957530.0228608,
    1759957530.0808702,
    1759957530.199877,
    1759957530.2768285,
    1759957530.3211873,
    1759957530.343613,
    1759957530.3911178,
    1759957530.3981311,
    1759957530.4774735,
    1759957530.7773972,
    1759957530.9537747,
    1759957531.034645,
    1759957531.2578576,
    1759957531.2648964,
    1759957531.4603553,
    1759957531.5181386,
    1759957531.532846,
    1759957531.5383048,
    1759957531.5679376,
    1759957531.6793442,
    1759957531.6837301,
    1759957531.7106006,
    1759957531.7214053,
    1759957531.826934,
    1759957531.9771554,
    1759957532.0171244,
    1759957532.0251067,
    1759957532.1800518,
    1759957532.2690766,
    1759957532.3032367,
    1759957532.3416095,
    1759957532.3476615,
    1759957532.373156,
    1759957532.4096205,
    1759957532.7484102,
    1759957532.7699614,
    1759957532.777215,
    1759957532.8290663,
    1759957532.8814838,
    1759957532.909591,
    1759957533.068667,
    1759957533.2438018,
    1759957533.2522264,
    1759957533.3718793,
    1759957533.4055326,
    1759957533.4105248,
    1759957533.4484327,
    1759957533.5618005,
    1759957533.5719726,
    1759957533.7039368,
    1759957533.710863,
    1759957533.8925917,
    1759957533.8997629,
    1759957533.9934955,
    1759957534.1740618,
    1759957534.2047746,
    1759957534.2481647,
    1759957534.268825,
    1759957534.3809571,
    1759957534.7558563,
    1759957534.827075,
    1759957534.8308568,
    1759957534.9713576,
    1759957535.084544,
    1759957535.1373177,
    1759957535.1675055,
    1759957535.3335717,
    1759957535.3813655,
    1759957535.5074902,
    1759957535.7320979,
    1759957535.761278,
    1759957535.8140476,
    1759957535.82324,
    1759957535.8791447,
    1759957535.885966,
    1759957535.9634428,
    1759957536.0206985,
    1759957536.075771,
    1759957536.1228836,
    1759957536.1663122,
    1759957536.184746,
    1759957536.4606805,
    1759957536.4664447,
    1759957536.5194554,
    1759957536.601715,
    1759957536.6354134,
    1759957536.8822334,
    1759957536.9953027,
    1759957537.0766149,
    1759957537.1334567,
    1759957537.3240287,
    1759957537.43236,
    1759957537.5672731,
    1759957537.6315792,
    1759957537.7927709,
    1759957537.7968059,
    1759957537.9583125,
    1759957537.9939733,
    1759957538.090659,
    1759957538.1470196,
    1759957538.592733,
    1759957538.5976455,
    1759957538.6425476,
    1759957538.648613,
    1759957538.7204201,
    1759957538.730676,
    1759957538.7931247,
    1759957538.8083274,
    1759957538.8307528,
    1759957539.0127382,
    1759957539.070081,
    1759957539.2607565,
    1759957539.2863853,
    1759957539.3032105,
    1759957539.3475938,
    1759957539.4383667,
    1759957539.4946454,
    1759957539.70286,
    1759957539.8936563,
    1759957540.1837535,
    1759957540.2225046,
    1759957540.2587886,
    1759957540.3119614,
    1759957540.449328,
    1759957540.4547489,
    1759957540.536553,
    1759957540.5405269,
    1759957541.0709445,
    1759957541.1345413,
    1759957541.9341714,
    1759957541.9519827,
    1759957542.0151994,
    1759957542.0487666,
    1759957542.063408,
    1759957542.0673454,
    1759957542.1903095,
    1759957542.233014,
    1759957542.3652067,
    1759957542.4003305,
    1759957542.4066038,
    1759957542.4066424,
    1759957542.802761,
    1759957543.255351,
    1759957543.2953,
    1759957543.3054087,
    1759957543.6296546,
    1759957543.6617897,
    1759957543.9836166,
    1759957544.005699,
    1759957544.405282,
    1759957544.4335265,
    1759957544.5270622,
    1759957544.6307015,
    1759957544.7308388,
    1759957545.0001159,
    1759957545.056177,
    1759957545.1261904,
    1759957545.281683,
    1759957545.5481088,
    1759957545.774081,
    1759957545.9502394,
    1759957545.9963508,
    1759957546.061985,
    1759957546.1236064,
    1759957546.182556,
    1759957546.2078698,
    1759957546.2430427,
    1759957546.252285,
    1759957546.320656,
    1759957546.3445852,
    1759957546.357475,
    1759957546.4466827,
    1759957546.5191712,
    1759957546.5234988,
    1759957546.5794306,
    1759957546.7098753,
    1759957546.7099109,
    1759957546.8127472,
    1759957547.060115,
    1759957547.1697433,
    1759957547.1905022,
    1759957547.2033238,
    1759957547.222566,
    1759957547.226403,
    1759957547.2973514,
    1759957547.4733741,
    1759957547.4846866,
    1759957547.4847722,
    1759957547.4847558,
    1759957547.5029125,
    1759957547.5818462,
    1759957547.9056594,
    1759957547.935737,
    1759957547.9410896,
    1759957548.0100758,
    1759957548.1129582,
    1759957548.1440625,
    1759957548.15439,
    1759957548.1745617,
    1759957548.238268,
    1759957548.2383127,
    1759957548.2544763,
    1759957548.3421507,
    1759957548.446823,
    1759957548.8268557,
    1759957548.9236047,
    1759957548.9340994,
    1759957549.0922444,
    1759957549.1471267,
    1759957549.1843843,
    1759957549.2041736,
    1759957549.2042396,
    1759957549.2136133,
    1759957549.3447325,
    1759957549.3862433,
    1759957549.4256594,
    1759957549.5102913,
    1759957549.581586,
    1759957549.9171512,
    1759957549.9806206,
    1759957550.1055243,
    1759957550.1489718,
    1759957550.2263145,
    1759957550.313028,
    1759957550.3465927,
    1759957550.352069,
    1759957550.3833032,
    1759957550.5131435,
    1759957550.5734599,
    1759957550.7030885,
    1759957550.7879226,
    1759957550.833306,
    1759957550.865981,
    1759957550.8727953,
    1759957550.9286191,
    1759957551.1571085,
    1759957551.1635158,
    1759957551.1815803,
    1759957551.287957,
    1759957551.3603997,
    1759957551.498829,
    1759957551.5429068,
    1759957551.5821257,
    1759957551.6245768,
    1759957551.773574,
    1759957551.9050798,
    1759957551.9152431,
    1759957552.0684893,
    1759957552.1387064,
    1759957552.2124333,
    1759957552.2833393,
    1759957552.3534048,
    1759957552.4899647,
    1759957552.5078344,
    1759957552.5942183,
    1759957552.607458,
    1759957552.718693,
    1759957552.7301536,
    1759957552.7519166,
    1759957552.7864738,
    1759957552.8183184,
    1759957552.8710263,
    1759957552.9891858,
    1759957552.9950147,
    1759957552.9949741,
    1759957553.0354123,
    1759957553.0507243,
    1759957553.0655012,
    1759957553.0953016,
    1759957553.2451067,
    1759957553.2509456,
    1759957553.2959006,
    1759957553.295942,
    1759957553.578623,
    1759957553.7256181,
    1759957553.752485,
    1759957553.8898735,
    1759957553.902484,
    1759957553.986117,
    1759957554.0025492,
    1759957554.0259733,
    1759957554.039223,
    1759957554.0597558,
    1759957554.0980272,
    1759957554.1034398,
    1759957554.1034782,
    1759957554.1595294,
    1759957554.2181723,
    1759957554.288145,
    1759957554.3853736,
    1759957554.4593773,
    1759957554.4641702,
    1759957554.500857,
    1759957554.5416205,
    1759957554.778101,
    1759957554.8002846,
    1759957554.8983204,
    1759957554.9370072,
    1759957555.0412602,
    1759957555.07146,
    1759957555.2182298,
    1759957555.2253704,
    1759957555.3107202,
    1759957555.310774,
    1759957555.3107862,
    1759957555.3893015,
    1759957555.395608,
    1759957555.4358723,
    1759957555.561993,
    1759957555.5903928,
    1759957555.643827,
    1759957555.643846,
    1759957555.6790488,
    1759957555.707709,
    1759957555.7406943,
    1759957555.9368923,
    1759957555.9451976,
    1759957555.988032,
    1759957556.0756311,
    1759957556.138245,
    1759957556.1867335,
    1759957556.243122,
    1759957556.2736535,
    1759957556.3439033,
    1759957556.4576952,
    1759957556.4657133,
    1759957556.5258102,
    1759957556.5377467,
    1759957556.5878778,
    1759957556.5947142,
    1759957556.6516898,
    1759957556.6604433,
    1759957556.740779,
    1759957556.7500947,
    1759957556.7501311,
    1759957556.7640116,
    1759957556.8243484,
    1759957556.8381515,
    1759957557.0748882,
    1759957557.3732836,
    1759957557.4072556,
    1759957557.440878,
    1759957557.5245037,
    1759957557.6113942,
    1759957557.7389352,
    1759957557.8326366,
    1759957558.0091054,
    1759957558.1175857,
    1759957558.1833842,
    1759957558.2118983,
    1759957558.2235866,
    1759957558.436496,
    1759957558.601692,
    1759957558.6137297,
    1759957558.6374173,
    1759957558.6938932,
    1759957558.7006786,
    1759957558.8270636,
    1759957558.8443036,
    1759957558.89854,
    1759957558.943774,
    1759957558.9451256,
    1759957558.9981334,
    1759957559.0390344,
    1759957559.085423,
    1759957559.1530218,
    1759957559.1880243,
    1759957559.2674062,
    1759957559.353693,
    1759957559.364306,
    1759957559.4196086,
    1759957559.4242256,
    1759957559.4522357,
    1759957559.4639506,
    1759957559.5729303,
    1759957559.6486206,
    1759957559.8168979,
    1759957559.871251,
    1759957559.9326181,
    1759957559.9704907,
    1759957560.0172195,
    1759957560.0171723,
    1759957560.1038716,
    1759957560.1795278,
    1759957560.2723317,
    1759957560.3238063,
    1759957560.4368389,
    1759957560.5644763,
    1759957560.729464,
    1759957560.7449143,
    1759957560.7994812,
    1759957560.8135772,
    1759957561.004214,
    1759957561.067516,
    1759957561.0881534,
    1759957561.223552,
    1759957561.3083122,
    1759957561.374882,
    1759957561.3946192,
    1759957561.4779234,
    1759957561.4914715,
    1759957561.4996586,
    1759957561.5741105,
    1759957561.630555,
    1759957561.7189088,
    1759957561.72467,
    1759957561.769272,
    1759957561.7734084,
    1759957561.8129575,
    1759957561.8442974,
    1759957561.905003,
    1759957561.92037,
    1759957562.033801,
    1759957562.0390337,
    1759957562.0820785,
    1759957562.307145,
    1759957562.30719,
    1759957562.322604,
    1759957562.3226383,
    1759957562.334324,
    1759957562.3342855,
    1759957562.367213,
    1759957562.3833666,
    1759957562.4371912,
    1759957562.471822,
    1759957562.5305245,
    1759957562.5305703,
    1759957562.578312,
    1759957562.658576,
    1759957562.6662545,
    1759957562.7063613,
    1759957562.7117877,
    1759957562.8014514,
    1759957562.8386114,
    1759957562.9131937,
    1759957562.9966238,
    1759957562.9965765,
    1759957563.0004368,
    1759957563.1128948,
    1759957563.1128795,
    1759957563.1181722,
    1759957563.249828,
    1759957563.271283,
    1759957563.377982,
    1759957563.4603965,
    1759957563.5823302,
    1759957563.6520019,
    1759957563.669023,
    1759957563.70835,
    1759957563.7795925,
    1759957563.8032107,
    1759957563.881212,
    1759957563.9013755,
    1759957563.9703588,
    1759957564.00215,
    1759957564.0951226,
    1759957564.2789574,
    1759957564.3064187,
    1759957564.3375027,
    1759957564.412728,
    1759957564.4738395,
    1759957564.710975,
    1759957564.8362014,
    1759957565.0018125,
    1759957565.021945,
    1759957565.068824,
    1759957565.158297,
    1759957565.1877372,
    1759957565.1876876,
    1759957565.1985521,
    1759957565.2046063,
    1759957565.2253237,
    1759957565.3248866,
    1759957565.3680608,
    1759957565.708206,
    1759957566.0294101,
    1759957566.112348,
    1759957566.266739,
    1759957566.30186,
    1759957566.46116,
    1759957566.6241496,
    1759957566.8750298,
    1759957566.944884,
    1759957566.9954362,
    1759957567.1115031,
    1759957567.133826,
    1759957567.200252,
    1759957567.3434863,
    1759957567.3477132,
    1759957567.4173467,
    1759957567.5505779,
    1759957567.5815032,
    1759957567.6792762,
    1759957567.6982358,
    1759957567.9625533,
    1759957568.1017725,
    1759957568.215925,
    1759957568.2337418,
    1759957568.310576,
    1759957568.344391,
    1759957568.5104127,
    1759957568.549264,
    1759957568.9811988,
    1759957569.0783334,
    1759957569.1270347,
    1759957569.2077408,
    1759957569.2629163,
    1759957569.3310356,
    1759957569.3508441,
    1759957569.4316804,
    1759957569.4397166,
    1759957569.5889244,
    1759957569.63776,
    1759957569.7746797,
    1759957569.8277307,
    1759957570.016222,
    1759957570.1839867,
    1759957570.266353,
    1759957570.277767,
    1759957570.293654,
    1759957570.3719203,
    1759957570.3775897,
    1759957570.427101,
    1759957570.43272,
    1759957570.4426646,
    1759957570.4505615,
    1759957570.7214959,
    1759957570.7341447,
    1759957570.755474,
    1759957570.8867414,
    1759957570.9630034,
    1759957571.0355146,
    1759957571.1715465,
    1759957571.2270002,
    1759957571.5095465,
    1759957571.5243163,
    1759957571.5561278,
    1759957571.6156478,
    1759957571.662318,
    1759957571.7664244,
    1759957571.8242016,
    1759957571.8926013,
    1759957571.9368484,
    1759957571.9589386,
    1759957571.9905248,
    1759957572.0051906,
    1759957572.0399654,
    1759957572.227163,
    1759957572.2510786,
    1759957572.2995892,
    1759957572.3659143,
    1759957572.4187498,
    1759957572.456763,
    1759957572.499024,
    1759957572.5030832,
    1759957572.5247269,
    1759957572.5986786,
    1759957572.6104906,
    1759957572.732113,
    1759957572.741355,
    1759957572.8331554,
    1759957572.8746278,
    1759957573.0105927,
    1759957573.026743,
    1759957573.082974,
    1759957573.1157975,
    1759957573.28094,
    1759957573.3042204,
    1759957573.3695133,
    1759957573.5509555,
    1759957573.587208,
    1759957573.6659179,
    1759957573.880794,
    1759957573.9109268,
    1759957573.9912317,
    1759957574.1249993,
    1759957574.2359564,
    1759957574.4521418,
    1759957574.8393626,
    1759957574.839408,
    1759957574.8751545,
    1759957574.9077215,
    1759957575.074232,
    1759957575.2960224,
    1759957575.3015175,
    1759957575.338672,
    1759957575.3465762,
    1759957575.4467363,
    1759957575.5179443,
    1759957575.6114974,
    1759957575.6951785,
    1759957575.7666905,
    1759957575.8111086,
    1759957575.8268492,
    1759957575.9838574,
    1759957576.167215,
    1759957576.2510803,
    1759957576.2705715,
    1759957576.4182315,
    1759957576.4555697,
    1759957576.5656986,
    1759957576.5874903,
    1759957576.7136936,
    1759957576.7174146,
    1759957576.87762,
    1759957577.0970888,
    1759957577.117599,
    1759957577.1377702,
    1759957577.1451995,
    1759957577.1804464,
    1759957577.3370593,
    1759957577.3370159,
    1759957577.4044611,
    1759957577.4212687,
    1759957577.4908738,
    1759957577.5182986,
    1759957577.580629,
    1759957577.6170263,
    1759957577.6585193,
    1759957577.6645882,
    1759957577.7576659,
    1759957577.902109,
    1759957578.0827177,
    1759957578.1877754,
    1759957578.2499268,
    1759957578.3158162,
    1759957578.3221593,
    1759957578.4028323,
    1759957578.550741
  ],
  "mean_ttft_ms": 53808.36351956842,
  "median_ttft_ms": 65220.28509399934,
  "std_ttft_ms": 24661.258152768718,
  "p99_ttft_ms": 82776.4832347004,
  "mean_tpot_ms": 135.24325519732596,
  "median_tpot_ms": 134.90172021812407,
  "std_tpot_ms": 8.84986358639789,
  "p99_tpot_ms": 152.16357203811944,
  "mean_itl_ms": 135.6371947639867,
  "median_itl_ms": 133.5142754996923,
  "std_itl_ms": 21.622560809688938,
  "p99_itl_ms": 181.67916358983345
}