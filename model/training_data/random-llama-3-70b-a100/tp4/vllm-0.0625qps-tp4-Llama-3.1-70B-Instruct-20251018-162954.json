{"date": "20251018-162954", "backend": "vllm", "model_id": "meta-llama/Llama-3.1-70B-Instruct", "tokenizer_id": "meta-llama/Llama-3.1-70B-Instruct", "num_prompts": 19, "tensor_parallel_size": 4, "request_rate": 0.0625, "burstiness": 1.0, "max_concurrency": null, "duration": 405.7886023210003, "completed": 18, "total_input_tokens": 116308, "total_output_tokens": 154, "request_throughput": 0.04435807190503849, "request_goodput:": null, "output_throughput": 0.3795079485208848, "total_token_throughput": 287.0016539002551, "input_lens": [13911, 3103, 5864, 16384, 15588, 681, 5682, 1691, 22106, 3138, 2341, 9894, 4615, 2284, 3255, 2884, 10337, 11837, 2819], "output_lens": [2, 6, 7, 13, 2, 71, 1, 1, 0, 1, 4, 10, 4, 2, 1, 17, 2, 3, 7], "ttfts": [0.10277220599982684, 0.24198174200000722, 0.38320444199962367, 2.0742299709995677, 1.8203644070003975, 0.08171070800017333, 0.37541306799994345, 0.1457786500000111, 0.0, 0.23132071700001688, 0.1794379820003087, 0.6998642150001615, 0.3553634500003682, 0.17806511099979616, 0.204722096000296, 0.23026005400015492, 0.7842946480000137, 1.3562637329996505, 0.21158388700041542], "itls": [[0.028190770000037446], [0.030281733999800053, 0.03068621600004917, 0.029210761999820534, 0.028615075000288925, 0.02886609100005444], [0.02819541600001685, 0.028849791000084224, 0.02888223099989773, 0.028780944000118325, 0.02886629099975835, 0.029005270000197925], [0.027733212999919488, 0.029413047000161896, 0.029338718999952107, 0.029501631000130146, 0.029807179999806976, 0.029076991000238195, 0.029561933999957546, 0.029398058999959176, 0.02944103899972106, 0.02948685299998033, 0.029600035000385105, 0.029610924999815325], [0.02832665400001133], [0.029709465999985696, 0.03030885100042724, 0.030342312999891874, 0.030368281999926694, 0.030479418000140868, 0.030386694999833708, 0.03024912000000768, 0.030563023000013345, 0.029785488000015903, 0.028361390000100073, 0.028402315999755956, 0.02837666799996441, 0.028611095000087516, 0.028351291000035417, 0.02840506099983031, 0.028352884000014456, 0.028515056000287586, 0.028267355000025418, 0.02846561499973177, 0.028358935000142083, 0.02856904600002963, 0.028304845000093337, 0.028396956000051432, 0.028482895999786706, 0.028380526000091777, 0.028502693000064028, 0.028501580000011018, 0.028248469999653025, 0.02844244100015203, 0.028412184999979218, 0.028423575000033452, 0.028549139000006107, 0.02826925899989874, 0.028371808999963832, 0.028476474999934, 0.028564717000335804, 0.028202484999837907, 0.02840265700024247, 0.02847118399995452, 0.028476773999955185, 0.028371840000090742, 0.028435808999802248, 0.028372670999942784, 0.028470352000113053, 0.028355218999877252, 0.02846759700014445, 0.02832052499979909, 0.03127160000030926, 0.025546556999870518, 0.028401533999840467, 0.02845970299995315, 0.028421130999959132, 0.028442130000257748, 0.028366029000153503, 0.02856761299972277, 0.028310777000115195, 0.02835665099973994, 0.028363744000216684, 0.02858995499991579, 0.028244263000033243, 0.028504526000233454, 0.02840619299968239, 0.028383481000219035, 0.028402095999808807, 0.02839412999992419, 0.028382390000388114, 0.028463078999720892, 0.0284010240002317, 0.028515105999758816, 0.028521768000246084], [], [], [], [], [0.02995578199988813, 0.03075321799997255, 0.03088777700031642], [0.028200140000080864, 0.029148266999982297, 0.029121947000021464, 0.02890851099982683, 0.029034183000021585, 0.02920893000009528, 0.028881490000003396, 0.029034894999767857, 0.029223587000160478], [0.02912018100005298, 0.028806297999835806, 0.02895565600010741], [0.030354626999724132], [], [0.029380688999935956, 0.4309869650001019, 0.24383341900011146, 0.028974331999961578, 0.02902932500001043, 0.028639179000037984, 0.02872365599978366, 0.028627427000174066, 0.028699660999791377, 0.028709238999908848, 0.02860148800027673, 0.028732462999869313, 0.028742179999881046, 0.02873188100011248, 0.02869105599984323, 0.028931623000062245], [0.028603881999970326], [0.028193742999974347, 0.02942827100014256], [0.030300179999812826, 0.030626097000094887, 0.03053358399984063, 0.02879303500003516, 0.028650928999923053, 0.028777615000308288]], "generated_texts": ["\ufffd.", "\ufffd_MAPPING\ufffd_", "\ufffd_LISTING\ufffd_LIST", "ventually\t\t\ufffd_HPPROPERTY\ufffd_HPP", "", "\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_", "\t", "", "", "", "\u0435\u0440\u0435\u043c\u0435\u043d", "stry\ufffd_id\ufffd_id\ufffd_id", "witcher\ufffd_", "<|", "", "es\t\t<|reserved_special_token_96|>I apologize, but it", "\ufffd_", "\ufffd.scal", "\ufffd_\ufffd_\ufffd_"], "errors": ["", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 360, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 388, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", ""], "request_timestamps": [1760804588.9087114, 1760804598.2220755, 1760804660.555289, 1760804667.712802, 1760804678.215249, 1760804696.864664, 1760804730.8940382, 1760804770.9886217, 1760804788.2439365, 1760804820.3259566, 1760804831.7354093, 1760804871.4965417, 1760804912.1744902, 1760804913.5676327, 1760804918.7788374, 1760804918.9486637, 1760804948.535996, 1760804965.2018971], "mean_ttft_ms": 536.479504833374, "median_ttft_ms": 236.65122950001205, "std_ttft_ms": 584.4357853828088, "p99_ttft_ms": 2031.0728251197086, "mean_tpot_ms": 31.858626074002764, "median_tpot_ms": 28.967094166622097, "std_tpot_ms": 9.873607925503498, "p99_tpot_ms": 62.5873083224895, "mean_itl_ms": 33.42561622059079, "median_itl_ms": 28.61308500018822, "std_itl_ms": 38.84032897636069, "p99_itl_ms": 169.4367823501819}