Epoch 1/500: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:09<00:00,  2.52it/s, loss=1.7895]
Epoch 2/500: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:10<00:00,  2.22it/s, loss=1.7737]
Epoch 3/500: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:09<00:00,  2.49it/s, loss=1.6773]
Epoch 4/500: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:09<00:00,  2.50it/s, loss=1.6239]
Epoch 5/500:  25%|████████████████████████████████████                                                                                                            | 6/24 [00:02<00:07,  2.32it/s, loss=1.6099]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/Users/grantwilkins/powertrace-sim/model/train_entry.py", line 97, in <module>
    result = train_classifiers(
             ^^^^^^^^^^^^^^^^^^
  File "/Users/grantwilkins/powertrace-sim/model/classifiers/train.py", line 110, in train_classifiers
    loss.backward()
  File "/Users/grantwilkins/anaconda3/envs/ml-inference/lib/python3.12/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/Users/grantwilkins/anaconda3/envs/ml-inference/lib/python3.12/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/Users/grantwilkins/anaconda3/envs/ml-inference/lib/python3.12/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/grantwilkins/anaconda3/envs/ml-inference/lib/python3.12/site-packages/wandb/integration/torch/wandb_torch.py", line 276, in <lambda>
    handle = var.register_hook(lambda grad: _callback(grad, log_track))

KeyboardInterrupt
