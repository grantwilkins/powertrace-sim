Performance Report for meta-llama/Llama-3.1-70B-Instruct
================================

Test Parameters:
- Poisson arrival rate: 0.25
- Tensor parallel size: 8
- Time window: 600.0s

Test Summary:
- Total requests: 140
- Total input tokens: 17887
- Total output tokens: 50104
- Avg tokens per request: 485.65

Latency Metrics:
- Average E2E latency: 11.52s
- P50 latency: 7.37s
- P90 latency: 23.30s
- P99 latency: 55.95s

Throughput Metrics:
- Average prefill throughput: 3745.03 tokens/s
- Average decode throughput: 55.36 tokens/s
- Max prefill throughput: 25303.62 tokens/s
- Max decode throughput: 199.71 tokens/s
- Aggregate prefill throughput: 3745.03 tokens/s
- Aggregate decode throughput: 55.36 tokens/s

Batch Metrics:
- Average batch size: 3.06
- Max batch size: 7.0
- Batch size P50: 3.00
- Batch size P90: 5.00

Throughput Analysis by Batch Size:
- Batch size (0.0, 1.0]: Prefill=2013.31 tokens/s, Decode=30.49 tokens/s, Requests=15
- Batch size (1.0, 2.0]: Prefill=3444.49 tokens/s, Decode=46.89 tokens/s, Requests=35
- Batch size (2.0, 4.0]: Prefill=3740.69 tokens/s, Decode=61.43 tokens/s, Requests=61
- Batch size (4.0, 8.0]: Prefill=5500.91 tokens/s, Decode=73.33 tokens/s, Requests=25

Token Distribution:
- Average input tokens: 127.76
- Average output tokens: 357.89
- Max input tokens: 1051
- Max output tokens: 2175
