{"date": "20251009-173811", "backend": "vllm", "model_id": "openai/gpt-oss-120b", "tokenizer_id": "openai/gpt-oss-120b", "num_prompts": 19, "tensor_parallel_size": 2, "request_rate": 0.0625, "burstiness": 1.0, "max_concurrency": null, "duration": 345.32123188100013, "completed": 18, "total_input_tokens": 116308, "total_output_tokens": 178, "request_throughput": 0.052125378743589426, "request_goodput:": null, "output_throughput": 0.5154620786866065, "total_token_throughput": 337.32649268476433, "input_lens": [13911, 3103, 5864, 16384, 15588, 681, 5682, 1691, 22106, 3138, 2341, 9894, 4615, 2284, 3255, 2884, 10337, 11837, 2819], "output_lens": [2, 6, 7, 13, 9, 71, 1, 3, 0, 16, 4, 10, 4, 2, 1, 17, 2, 3, 7], "ttfts": [0.05159988900049939, 0.05914567600029841, 0.10242850499980705, 0.30935724200026016, 0.2822753480004394, 0.03266622399951302, 0.09615585800020199, 0.044266994999816234, 0.0, 0.06486079299975245, 0.04885360500065872, 0.14103075399998488, 0.08154636499966728, 0.046988598999632814, 0.06431356899975071, 0.056740007000371406, 0.14329412699953537, 0.22040809100053593, 0.054171935000340454], "itls": [[0.0021471509999173577], [0.0024973199997475604, 0.003977078000389156, 0.004182458999821392, 0.004148566999901959, 0.004501489999711339], [0.0024214450004365062, 0.0037443740002345294, 0.004100977999769384, 0.004268767000212392, 0.004240470999320678, 0.004632079000657541], [0.001339524000286474, 0.004188558999885572, 0.004210192999380524, 0.004271996000170475, 0.004316710999773932, 0.0043364040002416004, 0.004291715000363183, 0.004425455999808037, 0.004276794999896083, 0.004277134999938426, 0.004381950000606594, 0.004761035999763408], [0.0012734470001305453, 0.004028927000035765, 0.004311687999688729, 0.004245971999807807, 0.004324670000642072, 0.004429798999808554, 0.004243962000145984, 0.004863090000071679], [0.003021593999619654, 0.003958232000513817, 0.0041981069998655585, 0.004163351999523002, 0.004187014000308409, 0.004157053000199085, 0.004159479000009014, 0.00432113799979561, 0.004080751999936183, 0.004245371999786585, 0.004174815000624221, 0.0041486519994577975, 0.00427542200031894, 0.004135256999688863, 0.004206706999866583, 0.004169714000454405, 0.004189895999843429, 0.0042016629995487165, 0.004157841000051121, 0.0042538269999568, 0.004081242000211205, 0.004286133000277914, 0.004169345000264002, 0.004214877999402233, 0.004116916000384663, 0.004152403000261984, 0.004183007999927213, 0.004166191999502189, 0.004266832000212162, 0.004142247000345378, 0.004200458999548573, 0.004223464000460808, 0.004112788999918848, 0.004121121999560273, 0.004122758000448812, 0.004188315999272163, 0.004132865999963542, 0.004123150000850728, 0.00406705199930002, 0.0041723809999894, 0.00412009699994087, 0.00416088200017839, 0.004157461000431795, 0.004107923999981722, 0.004225709999445826, 0.0041210540002794005, 0.004265687999577494, 0.003932837000320433, 0.004162530000030529, 0.004060811000272224, 0.004212613000163401, 0.00408067199987272, 0.0042417149998073, 0.00411388500015164, 0.004141174999858777, 0.004070625000167638, 0.004186639999716135, 0.004078584000126284, 0.004202379999696859, 0.004086924000148429, 0.004107036999812408, 0.004097962000741973, 0.004172097999799007, 0.004164070000115316, 0.004043304999868269, 0.004115708999961498, 0.00410963600006653, 0.00410176799960027, 0.004101597000044421, 0.004364395000266086], [], [0.003454269000030763, 0.004375874000288604], [], [0.0023885870004960452, 0.004004585000075167, 0.004204249999929743, 0.0042845389998547034, 0.004094513000381994, 0.004207854999549454, 0.0041665440003271215, 0.004245834999892395, 0.004100696000023163, 0.004235203999996884, 0.004205985000226065, 0.004278933999557921, 0.00404000599974097, 0.004268902000148955, 0.004555743999844708], [0.002747563000411901, 0.004050454000207537, 0.004388031999951636], [0.0015674199994464288, 0.0039016270002321107, 0.005388463000599586, 0.0032300759994541295, 0.004201652000119793, 0.0042483329998503905, 0.004252601999723993, 0.00522731900036888, 0.003791580999859434], [0.0024806510000416893, 0.0040750599991952186, 0.004533780000201659], [0.003030464000403299], [], [0.0026785529998960556, 0.0037670289993911865, 0.004167828999925405, 0.0041307960000267485, 0.004218426000079489, 0.004302209000343282, 0.004108205000193266, 0.004238290000103007, 0.004208519999338023, 0.004202155000712082, 0.004223311999339785, 0.004276818000107596, 0.0041275630001109676, 0.004232878999573586, 0.004219716000079643, 0.004430900999977894], [0.0021488809998118086], [0.0015585749997626408, 0.004411149000588921], [0.0027434660005383193, 0.003661619000013161, 0.004094189999705122, 0.004208037000353215, 0.00415032299952145, 0.004410731000461965]], "generated_texts": ["<|", "<|vq_lbr_audio", "\n\n```\n\nIt looks like the", "<|vq_12471|>\n\nIt looks like your", "<|vq_lbr_userWhat is the", "<|vq_lbr_image_12457|>\n\nIt looks like the text you posted is a mix of different languages and possibly some random characters or symbols. It seems to be a garbled or corrupted text that doesn't form a coherent message or request. If you have a specific question or need assistance with something, please provide a clear and concise", "<", "<|vq", "", "\ufffd\n\nIt seems like the text you provided is a mix of different languages and characters", "<|vq_l", "<|vq_lbr\n\nIt looks like your", "<|vq_l", "<|", "<", "<|vq_lbr_audio_124437|>\n\nIt looks like the", "<|", "<|vq", "<|vq_lbr_124"], "errors": ["", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", ""], "request_timestamps": [1760031146.619857, 1760031165.290152, 1760031199.3212163, 1760031239.4438639, 1760031243.3681183, 1760031256.6636229, 1760031288.7608886, 1760031300.14158, 1760031380.6121705, 1760031381.9965067, 1760031387.2251108, 1760031387.3603864, 1760031416.9334116, 1760031433.614156, 1760031463.101065, 1760031468.043633, 1760031476.164823, 1760031489.0330703], "mean_ttft_ms": 105.56131011117031, "median_ttft_ms": 64.58718099975158, "std_ttft_ms": 81.12850313899158, "p99_ttft_ms": 304.7533200202906, "mean_tpot_ms": 3.6027343371569507, "median_tpot_ms": 3.8896545833419323, "std_tpot_ms": 0.6411019678675953, "p99_tpot_ms": 4.132847661158507, "mean_itl_ms": 4.016037518755411, "median_itl_ms": 4.168587000094703, "std_itl_ms": 0.6259001027374999, "p99_itl_ms": 5.0124238901935305}