{"date": "20251009-192618", "backend": "vllm", "model_id": "openai/gpt-oss-120b", "tokenizer_id": "openai/gpt-oss-120b", "num_prompts": 4800, "tensor_parallel_size": 2, "request_rate": 16.0, "burstiness": 1.0, "max_concurrency": null, "duration": 424.4345186360006, "completed": 3270, "total_input_tokens": 12926136, "total_output_tokens": 37830, "request_throughput": 7.704368651514854, "request_goodput:": null, "output_throughput": 89.13035660147001, "total_token_throughput": 30544.08967880869, "input_lens": [13911, 3103, 5864, 16384, 15588, 681, 5682, 1691, 1783, 44747, 2341, 9894, 4615, 2284, 3255, 2884, 10337, 1594, 2819, 780, 120, 4100, 5171, 883, 16384, 403, 2101, 1626, 19661, 10059, 2369, 3028, 752, 12441, 1362, 2373, 13166, 7499, 1304, 1432, 11736, 419, 305, 16384, 1140, 1234, 503, 4699, 12455, 1581, 746, 3058, 1139, 545, 1937, 3200, 2149, 2786, 994, 1340, 953, 1345, 816, 299, 2428, 1284, 332, 3324, 736, 22083, 4455, 2302, 6997, 513, 3110, 940, 20654, 1057, 1418, 2125, 12419, 5382, 3335, 368, 10270, 16082, 7307, 1639, 615, 17406, 1282, 7667, 2512, 40861, 2957, 4346, 2021, 14249, 2297, 3109, 15858, 453, 493, 5804, 12500, 16384, 1267, 878, 16384, 10183, 15588, 5413, 774, 16335, 1488, 4830, 5664, 1684, 3926, 5510, 3023, 596, 2774, 8595, 930, 1694, 1238, 15278, 4186, 3128, 856, 3616, 951, 2069, 10181, 4205, 3767, 1589, 3089, 600, 387, 3240, 2400, 4017, 16384, 5647, 732, 6827, 469, 1202, 12595, 13156, 880, 805, 1793, 963, 6900, 609, 565, 1234, 1155, 16384, 5678, 2200, 519, 5058, 664, 365, 7382, 2831, 5502, 10149, 5128, 976, 640, 4229, 825, 935, 1210, 2036, 1353, 440, 984, 173, 3974, 343, 592, 2116, 885, 10908, 481, 2680, 10969, 552, 3553, 11460, 4670, 4943, 16384, 8692, 1331, 1535, 6698, 4108, 4040, 337, 1945, 887, 2718, 1793, 5438, 2832, 4745, 1196, 707, 1272, 1961, 3032, 16384, 1907, 698, 1365, 1199, 3393, 366, 2142, 2373, 2579, 1035, 1538, 417, 1161, 1099, 3157, 560, 4718, 10341, 205, 3193, 4207, 991, 1290, 1726, 1440, 1422, 316, 7097, 6552, 816, 398, 3544, 23992, 2335, 1406, 4275, 4290, 899, 436, 350, 3910, 540, 1144, 1036, 1885, 237, 2459, 3555, 2202, 1419, 2224, 3099, 18849, 16384, 3068, 974, 1299, 3439, 1758, 214, 16384, 1769, 6137, 10684, 10829, 2737, 3903, 632, 7572, 4267, 8366, 1001, 1177, 16384, 622, 15488, 6978, 2224, 3794, 1287, 3002, 474, 12381, 1754, 945, 4158, 1203, 460, 454, 4286, 1676, 1724, 6538, 578, 894, 1308, 2216, 1907, 1457, 1867, 1775, 905, 29789, 2702, 749, 559, 1417, 1680, 16384, 920, 5639, 4545, 540, 4677, 543, 11513, 3893, 289, 3281, 941, 12400, 6472, 1213, 937, 525, 1230, 1467, 1337, 2374, 3775, 2935, 862, 410, 8964, 935, 975, 1126, 263, 1181, 1178, 3953, 4308, 2006, 5569, 12847, 1964, 2385, 1620, 1294, 1488, 577, 2720, 21960, 5043, 1518, 2110, 3439, 4054, 355, 1591, 5261, 308, 3059, 167, 648, 2084, 322, 675, 395, 12245, 2393, 3729, 1564, 1354, 337, 1449, 864, 13141, 25401, 10029, 5104, 1034, 585, 4643, 2956, 285, 2954, 4895, 2132, 1630, 821, 406, 4819, 1422, 1545, 13440, 4242, 3004, 31033, 10635, 13247, 5555, 3791, 199, 2289, 1731, 2215, 5638, 98, 1068, 35572, 1195, 420, 5197, 2709, 686, 2825, 4933, 2009, 4820, 2177, 1293, 558, 1817, 2474, 5236, 1760, 3304, 691, 844, 1769, 626, 4925, 3325, 2716, 2900, 16384, 1193, 177, 2487, 17724, 1130, 680, 1232, 2439, 1149, 16384, 694, 835, 161, 2634, 217, 1103, 1475, 915, 13531, 5966, 14050, 756, 6915, 3448, 19902, 6200, 735, 1252, 5160, 107, 10558, 3671, 1900, 2546, 643, 11586, 6703, 8331, 16384, 1842, 11775, 1134, 652, 1834, 3044, 1924, 6674, 1544, 1363, 1054, 33862, 356, 546, 8362, 5349, 9067, 33673, 229, 966, 2424, 3458, 14522, 2731, 15683, 1564, 731, 314, 751, 2607, 751, 14936, 9448, 147, 5169, 170, 3107, 7687, 2145, 488, 1049, 1498, 1635, 1598, 15374, 2527, 528, 1531, 10615, 12027, 1226, 6542, 119, 7328, 997, 2393, 2221, 5634, 1488, 947, 8330, 148, 2043, 453, 864, 16384, 1902, 2476, 281, 896, 2480, 2951, 3938, 2017, 3567, 11923, 267, 2081, 35875, 3823, 1339, 823, 583, 1729, 6949, 233, 21937, 570, 4738, 1086, 1190, 11328, 3261, 1297, 70, 3632, 3238, 1569, 606, 2942, 3032, 28183, 1574, 718, 1641, 363, 3162, 17085, 21308, 425, 1044, 36636, 321, 2268, 1316, 293, 476, 3887, 5351, 1728, 3118, 17086, 2871, 8222, 380, 21054, 1312, 1561, 1432, 1322, 518, 2444, 12557, 1878, 1995, 938, 1755, 3336, 1329, 1212, 3113, 727, 2637, 4926, 8919, 1809, 8994, 6234, 667, 523, 1428, 6197, 1845, 1032, 11020, 2739, 155, 2832, 3540, 2561, 3276, 1855, 468, 1329, 706, 716, 498, 3287, 2225, 1220, 978, 1947, 6549, 220, 24843, 1096, 10601, 235, 732, 2543, 3079, 711, 6116, 24624, 3089, 1042, 6883, 4586, 5188, 970, 88, 16384, 339, 1921, 16384, 2874, 5676, 382, 282, 1112, 6633, 1365, 833, 2484, 6569, 407, 527, 839, 6661, 2587, 16384, 5597, 14246, 8035, 2521, 920, 4221, 928, 1451, 8608, 1787, 825, 1198, 6148, 1088, 1305, 1139, 10322, 1307, 343, 753, 716, 7845, 4885, 3812, 1146, 814, 1143, 628, 16384, 25299, 3716, 486, 1781, 673, 547, 570, 13773, 1726, 860, 3682, 2021, 4411, 268, 2790, 4674, 13023, 11548, 12910, 1965, 4932, 4178, 917, 2087, 14016, 1216, 2676, 4426, 2053, 4411, 593, 1786, 2041, 15283, 1578, 1154, 2045, 727, 2470, 1337, 278, 1873, 1409, 10172, 1855, 10283, 3545, 3917, 456, 3376, 2352, 3575, 3180, 447, 1909, 868, 1891, 744, 8465, 15105, 743, 2169, 611, 1252, 801, 9436, 4742, 1875, 1299, 11624, 3120, 3455, 1941, 311, 19142, 26628, 4062, 6081, 968, 12642, 13486, 958, 11079, 782, 2049, 1973, 2023, 795, 1042, 958, 2863, 2872, 16384, 9028, 1140, 2856, 10953, 2066, 12336, 2114, 5187, 785, 1396, 3352, 2814, 2600, 1330, 5824, 16384, 3124, 1615, 4588, 1104, 875, 2071, 116, 561, 1362, 450, 641, 1235, 327, 1278, 1108, 2054, 7112, 2415, 2045, 2229, 2566, 653, 1761, 2806, 442, 5178, 6565, 997, 1532, 760, 4312, 621, 1564, 776, 2113, 277, 8596, 691, 35221, 1581, 864, 752, 5597, 1120, 2692, 827, 980, 14998, 5560, 1647, 418, 16384, 778, 366, 16384, 1281, 400, 942, 2993, 2463, 11654, 14838, 1125, 542, 5748, 8621, 813, 427, 6207, 210, 518, 5791, 1880, 1494, 2945, 1689, 478, 12690, 13601, 2504, 2099, 16384, 1474, 1501, 2983, 10081, 11522, 1503, 11769, 438, 1417, 792, 660, 12704, 835, 1113, 2988, 8329, 3392, 16384, 1840, 2656, 2705, 9687, 3491, 1758, 704, 2614, 9334, 1272, 3575, 2619, 5166, 824, 16384, 17400, 1336, 5607, 2769, 4979, 1157, 1840, 2025, 11228, 4270, 4799, 969, 5800, 2560, 9210, 16384, 1425, 1278, 772, 1706, 1312, 2967, 18257, 1342, 6444, 712, 29451, 1278, 4432, 9170, 1431, 3245, 2432, 23381, 2604, 2746, 3146, 1606, 2216, 12232, 1347, 3683, 5333, 1255, 2242, 2567, 2493, 3622, 270, 1892, 2599, 664, 12599, 2386, 11156, 837, 736, 2557, 11302, 34818, 2223, 6107, 4320, 10053, 597, 13141, 836, 632, 605, 6829, 1129, 872, 2324, 1591, 947, 4579, 6450, 10170, 4645, 3111, 283, 12533, 2785, 16149, 6812, 9669, 3166, 3226, 1033, 2072, 780, 905, 747, 1683, 6335, 16384, 36752, 453, 8034, 1435, 966, 2517, 510, 2552, 1813, 2226, 3039, 11665, 2034, 32667, 3155, 642, 414, 1867, 413, 2200, 5611, 3896, 630, 14684, 2867, 1285, 21252, 3852, 674, 1285, 828, 634, 778, 4209, 2115, 759, 1549, 329, 13110, 16384, 1809, 4468, 1859, 2930, 4144, 592, 1931, 11009, 832, 1071, 1424, 2686, 3559, 8055, 3461, 1866, 7983, 4335, 385, 16384, 14001, 1660, 3028, 8576, 1653, 4462, 6734, 654, 1030, 5505, 3317, 5520, 1727, 1454, 24065, 566, 2104, 4949, 3584, 1735, 1481, 2537, 2177, 9367, 2347, 391, 492, 10621, 550, 4632, 1487, 1657, 1724, 7658, 1616, 1926, 13008, 2508, 3583, 2599, 9299, 2123, 2776, 12250, 363, 1210, 9592, 5595, 10217, 4993, 2863, 14918, 10775, 2601, 2379, 2470, 559, 4664, 1731, 14825, 1838, 33049, 2620, 1004, 5951, 16245, 1965, 1435, 1352, 249, 1643, 2633, 6375, 5744, 1263, 1473, 6879, 1651, 1140, 9244, 6256, 2039, 1039, 218, 3822, 745, 230, 11422, 4075, 570, 525, 5208, 760, 8314, 3936, 3605, 3118, 2466, 5263, 1212, 2196, 4569, 3711, 536, 1152, 2638, 1275, 14074, 1296, 1671, 4658, 2874, 1703, 869, 2784, 38515, 3384, 848, 13500, 406, 350, 5748, 2561, 1091, 596, 16384, 2272, 3596, 2834, 3223, 3619, 4472, 12919, 1449, 294, 846, 2692, 6307, 3862, 22706, 497, 94, 7093, 1045, 1220, 2309, 425, 1359, 16384, 3483, 2966, 350, 16384, 417, 16384, 195, 9375, 11847, 806, 3180, 3649, 816, 405, 468, 3623, 1819, 1074, 10958, 3494, 870, 533, 3553, 1106, 2228, 11315, 3472, 773, 2384, 700, 11723, 1077, 2509, 2803, 2380, 14185, 407, 1214, 2839, 1717, 697, 11958, 1284, 1193, 3512, 1395, 3877, 1038, 1507, 12229, 845, 3974, 816, 1125, 1843, 479, 1397, 913, 1303, 1870, 828, 1568, 8429, 1942, 7042, 10255, 4682, 17709, 2242, 2315, 1018, 808, 387, 10360, 685, 8785, 1194, 773, 3963, 20598, 3734, 1385, 3389, 688, 4986, 3417, 726, 16384, 3619, 16384, 11617, 1623, 1269, 1282, 266, 929, 2621, 10705, 854, 5272, 503, 1048, 1207, 13366, 3304, 5759, 4665, 2610, 12200, 11468, 1139, 4685, 273, 3141, 1174, 31169, 6273, 2394, 5290, 10108, 3065, 7245, 1395, 1980, 1124, 6293, 11433, 1143, 2368, 21190, 1913, 703, 2310, 36665, 4654, 1257, 1192, 14824, 445, 22652, 1178, 1123, 18855, 4357, 16384, 1583, 1750, 392, 1386, 903, 1219, 293, 12415, 420, 91, 540, 1028, 564, 6688, 1717, 2054, 21258, 2736, 5863, 589, 1094, 4157, 122, 440, 3467, 1178, 5595, 4866, 534, 3125, 7494, 13054, 681, 5257, 16524, 3629, 4391, 74, 5266, 14602, 3230, 2470, 4298, 2898, 4092, 2001, 859, 661, 666, 441, 617, 13868, 4580, 1004, 1300, 2261, 971, 10584, 4700, 12074, 2891, 5298, 1481, 2733, 1421, 1936, 1397, 14398, 2418, 3726, 2347, 3458, 887, 531, 3161, 4258, 2110, 11294, 5423, 16384, 1602, 11321, 885, 1072, 3373, 186, 8521, 11505, 1523, 609, 1762, 2027, 1747, 2901, 1044, 745, 3652, 2227, 2482, 6405, 17731, 779, 7966, 391, 473, 4913, 2596, 2243, 1806, 2068, 1805, 8874, 1289, 1673, 14384, 2059, 16384, 15375, 8992, 323, 2366, 349, 5058, 526, 2730, 20037, 558, 336, 1138, 13557, 19485, 5480, 1876, 5241, 267, 1282, 5677, 1669, 11999, 1244, 12464, 2771, 2097, 4053, 3816, 2524, 10957, 11701, 2713, 985, 2356, 11459, 984, 574, 5981, 29191, 2220, 1901, 2179, 5092, 793, 656, 2193, 341, 16332, 15573, 4597, 1976, 7799, 636, 1412, 3967, 10899, 43842, 122, 688, 3377, 14330, 16384, 5537, 19578, 584, 1922, 2605, 6908, 5267, 6224, 723, 9446, 437, 1108, 3209, 1694, 660, 809, 363, 3587, 7995, 1789, 1286, 395, 5456, 16384, 18697, 620, 946, 16598, 2565, 11797, 6059, 3570, 15444, 583, 22696, 10969, 1866, 22456, 12855, 4949, 471, 9474, 2373, 1575, 3252, 2540, 1368, 1513, 768, 4113, 1112, 697, 2398, 11357, 1894, 1023, 3115, 16384, 404, 3042, 2503, 18236, 5943, 10265, 313, 4852, 797, 705, 34433, 733, 9349, 2891, 2838, 2801, 329, 283, 2532, 27766, 2188, 809, 2040, 1825, 697, 6095, 297, 3818, 3049, 6067, 661, 2233, 16384, 4139, 2231, 3615, 2196, 16384, 5895, 1818, 2637, 1300, 7561, 425, 341, 9942, 16384, 3344, 2262, 4117, 980, 2412, 2085, 3980, 24140, 1143, 5061, 950, 670, 16384, 2083, 1057, 310, 4457, 4311, 1438, 594, 1944, 796, 708, 1783, 628, 2621, 3900, 793, 443, 11130, 710, 966, 2525, 3863, 1507, 3317, 1285, 686, 9594, 15679, 12907, 2335, 15014, 2955, 1182, 3337, 22309, 677, 743, 4828, 262, 3883, 332, 193, 39421, 16384, 1610, 2197, 21347, 5583, 432, 15121, 2446, 1372, 26359, 8166, 10439, 10168, 1977, 276, 826, 2471, 8325, 6011, 3854, 815, 14491, 27199, 11041, 1634, 5355, 2015, 5300, 6728, 3104, 777, 32981, 14309, 15448, 333, 1722, 1050, 10483, 16474, 6811, 2028, 262, 1343, 3904, 347, 2005, 624, 12518, 2057, 2444, 10790, 2697, 4913, 17444, 9650, 9980, 1246, 990, 320, 10045, 1339, 11836, 379, 15362, 5800, 13545, 863, 406, 16384, 41401, 478, 825, 852, 1485, 4953, 1439, 724, 404, 2046, 2093, 10764, 2212, 1792, 629, 1427, 1233, 1329, 695, 3612, 1708, 1602, 303, 3439, 12719, 793, 5938, 445, 1950, 1482, 469, 2461, 13001, 2152, 1200, 13201, 2244, 2060, 1251, 9548, 3301, 1117, 1774, 884, 1023, 987, 573, 4698, 1450, 3675, 956, 1869, 914, 4410, 1520, 894, 328, 2706, 916, 1963, 1163, 5707, 3635, 3267, 1014, 11437, 13178, 799, 2415, 325, 9306, 20133, 4726, 300, 14433, 1349, 3641, 2358, 1508, 12763, 326, 2775, 5440, 1933, 1754, 1707, 14333, 2083, 3512, 2154, 1481, 1165, 1469, 7970, 10492, 2088, 1393, 9910, 2123, 10233, 193, 31225, 2719, 9224, 14801, 1684, 2148, 1158, 7617, 1376, 16384, 6371, 5686, 3696, 620, 1243, 3751, 4210, 19183, 1194, 775, 5141, 820, 5222, 7477, 3300, 1348, 2090, 3838, 36553, 16384, 672, 663, 682, 1044, 181, 999, 973, 2178, 3163, 510, 5377, 14508, 30053, 11291, 2487, 16384, 6829, 357, 2039, 6372, 16526, 1918, 8076, 915, 2037, 2852, 1384, 1954, 4686, 3216, 820, 593, 838, 2000, 1675, 800, 1034, 375, 3164, 1912, 499, 2062, 8750, 885, 8490, 1399, 2483, 12697, 9336, 2378, 569, 472, 370, 303, 12303, 696, 1828, 921, 855, 1177, 4332, 5552, 3005, 672, 4056, 4263, 2702, 1028, 4357, 3181, 64, 4059, 243, 4146, 1686, 7427, 1793, 42768, 1699, 6411, 10586, 1762, 4527, 18915, 1985, 8979, 11054, 3923, 16156, 10369, 7342, 4406, 524, 2332, 881, 1677, 2602, 2230, 1184, 8105, 309, 4461, 258, 3043, 753, 5250, 16215, 2624, 651, 972, 2509, 3796, 16384, 2553, 5846, 360, 462, 1351, 535, 10250, 1272, 9139, 10254, 2094, 3470, 1878, 32131, 3400, 1744, 3482, 13307, 4377, 2859, 2292, 655, 645, 2851, 11250, 860, 8181, 13097, 319, 11959, 1583, 1965, 1763, 6559, 340, 3300, 706, 3743, 10906, 1997, 3015, 3135, 829, 10538, 13057, 4324, 34873, 1202, 1003, 13120, 9469, 1863, 351, 88, 606, 1730, 9327, 975, 3481, 8379, 2301, 1708, 473, 532, 11390, 1601, 2286, 1896, 4148, 842, 1381, 16087, 829, 1465, 1044, 3259, 6152, 1155, 1243, 1470, 27665, 885, 1321, 147, 437, 1765, 5364, 2764, 596, 428, 2421, 22349, 6454, 2143, 341, 690, 900, 853, 388, 31024, 941, 913, 6910, 2242, 670, 1382, 22738, 1436, 5234, 2637, 16384, 3021, 16786, 4869, 6554, 6658, 599, 1698, 6939, 313, 1153, 415, 716, 656, 7907, 1543, 773, 23556, 2335, 1973, 27585, 3463, 413, 1000, 6483, 1009, 13467, 596, 3751, 774, 1140, 6690, 1737, 4889, 3363, 4579, 752, 1565, 3186, 785, 15537, 849, 12039, 660, 189, 14423, 1595, 1220, 1605, 9526, 691, 4219, 1253, 1036, 3728, 5925, 1135, 857, 552, 11921, 1061, 261, 9423, 442, 4709, 2444, 2742, 1050, 2987, 319, 3815, 11077, 5283, 10159, 676, 1625, 3413, 1777, 1161, 27590, 7190, 1547, 13596, 117, 712, 27598, 1167, 2881, 6094, 3488, 1007, 374, 3687, 264, 4098, 1624, 548, 2740, 1991, 1919, 1821, 3169, 11047, 3450, 6083, 22182, 11852, 3745, 1098, 599, 2505, 474, 684, 2599, 1023, 715, 1923, 2164, 1593, 1319, 5115, 2912, 1562, 16384, 2473, 6941, 1078, 446, 836, 1488, 10319, 8690, 1751, 3319, 1898, 1240, 2083, 13166, 858, 4645, 646, 1205, 2006, 2861, 10213, 1891, 789, 4084, 1338, 2598, 1758, 235, 3495, 3796, 5537, 14479, 536, 3526, 3134, 1260, 3092, 19030, 522, 2619, 727, 975, 283, 1187, 1597, 3658, 2000, 366, 5158, 1753, 3419, 5782, 10188, 16384, 1845, 2813, 610, 6423, 542, 274, 4981, 23483, 4700, 3130, 332, 100, 598, 2034, 521, 974, 401, 2408, 2208, 1176, 9290, 10378, 3721, 275, 592, 3127, 1000, 1169, 5371, 3505, 8480, 1246, 9070, 1086, 10398, 2244, 775, 332, 1434, 1507, 5132, 1769, 1241, 6533, 1560, 1060, 3759, 1165, 4124, 1036, 1563, 2362, 1324, 30694, 4900, 3139, 3391, 993, 5105, 14619, 6032, 13695, 1652, 4011, 1022, 1558, 16384, 16384, 7816, 5610, 651, 3511, 1346, 623, 1141, 2269, 1094, 1090, 4775, 2341, 2583, 2259, 950, 442, 2811, 1143, 218, 1297, 600, 4309, 3546, 3451, 961, 4468, 2840, 1273, 1213, 5334, 1186, 2790, 12076, 16322, 12459, 5382, 381, 936, 1093, 12313, 925, 3055, 2232, 714, 3041, 3096, 502, 7670, 201, 1043, 5820, 537, 2937, 480, 1803, 39503, 790, 366, 1284, 1265, 952, 4806, 753, 4015, 11994, 2328, 777, 505, 915, 4337, 2371, 5599, 4662, 2332, 3363, 15379, 9482, 1432, 5935, 3806, 6974, 4182, 684, 336, 15683, 27404, 851, 19954, 639, 7299, 158, 165, 3018, 1825, 1178, 1434, 3607, 1267, 11191, 720, 5309, 1121, 435, 2235, 3482, 11424, 2539, 967, 3365, 4446, 12426, 1902, 40353, 1850, 2631, 649, 563, 796, 4049, 2656, 6274, 1627, 567, 7037, 1957, 8199, 13226, 16384, 1569, 5381, 5326, 1085, 1652, 400, 363, 2296, 4780, 4031, 2904, 5163, 1044, 1480, 4497, 3217, 1585, 8543, 48055, 20334, 24110, 4905, 2003, 498, 3517, 6609, 4506, 3948, 254, 742, 3395, 1881, 3550, 496, 1867, 433, 232, 2766, 5048, 12650, 1926, 358, 6043, 1903, 16384, 5633, 220, 4585, 10359, 866, 1516, 1801, 3094, 648, 563, 3868, 1969, 2420, 178, 1644, 750, 725, 5508, 598, 15404, 1388, 3279, 755, 7766, 9846, 757, 1526, 848, 312, 2788, 4478, 16384, 744, 8689, 20770, 2484, 3875, 5221, 16384, 3379, 13386, 770, 2795, 6164, 2615, 847, 2203, 1733, 20696, 321, 3662, 3846, 31715, 1989, 274, 1956, 16651, 775, 224, 367, 2822, 3011, 5297, 1880, 383, 812, 4918, 2332, 4083, 3223, 1594, 11368, 15410, 21164, 1734, 3297, 2553, 186, 4085, 14809, 846, 9891, 1506, 2759, 6485, 905, 7838, 11242, 763, 1040, 4138, 1373, 14501, 1574, 843, 16257, 1369, 2159, 1279, 3220, 1632, 2857, 115, 2223, 3150, 1604, 4172, 4502, 8388, 2242, 243, 161, 343, 1916, 1680, 2707, 1004, 888, 3679, 4111, 16283, 1915, 3117, 12255, 567, 905, 516, 1144, 4883, 3644, 10167, 3510, 2196, 1160, 425, 1648, 4221, 185, 17781, 16384, 4187, 15361, 888, 947, 1823, 11651, 3334, 765, 7291, 1448, 12927, 1071, 662, 10482, 16832, 6255, 2380, 673, 1146, 216, 731, 1642, 3065, 1375, 1876, 1292, 4564, 743, 5020, 16384, 3361, 1119, 10911, 26178, 578, 699, 555, 489, 633, 4764, 6717, 928, 2510, 4605, 2231, 698, 396, 6072, 3448, 3769, 590, 2587, 3991, 2822, 880, 6084, 372, 5550, 6562, 11266, 1370, 665, 4785, 925, 2097, 1409, 740, 2844, 432, 3833, 689, 297, 13813, 3212, 3769, 4915, 150, 661, 2246, 10624, 4732, 16179, 1121, 2702, 595, 1280, 889, 994, 1296, 2004, 2047, 3632, 36979, 10800, 1124, 1425, 1219, 3429, 5177, 8114, 830, 44878, 430, 3012, 6574, 1695, 6502, 571, 751, 1720, 6151, 1262, 1213, 21559, 2497, 7874, 4318, 4299, 1591, 1075, 4208, 1929, 1650, 5367, 1607, 795, 5432, 2183, 638, 587, 2219, 16384, 1297, 1380, 10680, 1876, 406, 354, 7702, 4158, 4957, 1875, 898, 1573, 10626, 15081, 3705, 499, 1385, 1596, 934, 176, 19131, 870, 8589, 1371, 1101, 2209, 6366, 1075, 6101, 9743, 5939, 11957, 8282, 20100, 11669, 2512, 1246, 165, 466, 1220, 1313, 1689, 664, 25961, 1731, 1622, 821, 883, 710, 1291, 779, 7989, 2604, 685, 1467, 545, 6083, 9160, 7920, 567, 1807, 1284, 3707, 659, 950, 1268, 2365, 4287, 1391, 4147, 4935, 1580, 507, 550, 3831, 1183, 303, 3921, 2304, 425, 7312, 5015, 2327, 491, 427, 1425, 303, 3120, 423, 2395, 1455, 4371, 712, 2700, 430, 4793, 1760, 3447, 467, 3459, 2798, 2981, 2818, 1615, 7827, 1683, 886, 1873, 702, 1199, 1644, 1316, 2488, 16384, 3744, 6499, 21570, 20898, 34097, 5106, 188, 641, 10149, 1561, 16384, 14945, 964, 12700, 1373, 476, 3338, 2385, 2841, 16167, 736, 33731, 526, 1828, 11528, 3735, 1761, 2635, 527, 1295, 2194, 2229, 371, 2865, 2716, 11977, 2007, 390, 392, 12720, 958, 35309, 5031, 1650, 90, 1693, 1177, 1543, 5376, 351, 2613, 11241, 1003, 3359, 5784, 2518, 21263, 915, 4528, 12233, 841, 547, 488, 42737, 1854, 16384, 3681, 3240, 2798, 5997, 690, 16384, 1789, 921, 2787, 6644, 659, 3727, 908, 1144, 1166, 4628, 589, 2469, 1369, 786, 525, 532, 331, 5354, 1531, 2379, 7302, 522, 709, 2644, 268, 1057, 722, 2871, 20538, 16384, 5606, 781, 1304, 1363, 16384, 379, 2499, 201, 17732, 16331, 1274, 6734, 1858, 1255, 1515, 1047, 40348, 462, 10482, 1296, 2760, 761, 6827, 1478, 1807, 12944, 3088, 14656, 768, 1207, 571, 13787, 2143, 4339, 10777, 817, 2559, 1392, 601, 1737, 16384, 16384, 2330, 13531, 1900, 1884, 11279, 694, 20480, 2249, 2029, 1056, 1045, 1664, 437, 1018, 1313, 505, 1389, 797, 7776, 1528, 1622, 3199, 3687, 295, 1320, 735, 1703, 1107, 2375, 679, 1070, 1042, 6573, 2995, 2998, 1458, 1308, 3703, 4699, 2031, 7015, 27484, 320, 3208, 1906, 3062, 6819, 10410, 336, 6746, 666, 939, 2502, 939, 346, 2074, 15727, 3857, 1145, 937, 1586, 6357, 5424, 600, 16384, 1396, 562, 5308, 1342, 16384, 5075, 1605, 11303, 5084, 517, 5309, 1132, 1823, 2308, 759, 460, 2994, 433, 117, 796, 2876, 1484, 8053, 2445, 29901, 1232, 411, 6597, 437, 726, 1675, 2003, 382, 737, 2674, 6923, 2933, 1942, 358, 1013, 3546, 6561, 5315, 17069, 7518, 16384, 1039, 863, 10618, 2588, 2260, 14735, 972, 640, 849, 7867, 411, 3458, 1081, 1354, 4524, 5056, 2913, 254, 11249, 8444, 2209, 2020, 14495, 5664, 1934, 1448, 11492, 7295, 6272, 338, 3331, 5169, 381, 1991, 282, 2304, 202, 943, 1020, 10899, 9864, 3601, 1287, 715, 1536, 644, 5827, 16384, 6364, 2878, 1665, 1279, 13627, 1060, 11127, 575, 13355, 303, 2380, 497, 12475, 12707, 3608, 13874, 600, 2290, 15074, 2017, 10582, 260, 911, 287, 4981, 4718, 762, 3926, 1059, 12008, 3008, 1226, 3165, 312, 2273, 1922, 210, 272, 258, 3151, 2290, 2700, 464, 6994, 5890, 16775, 7285, 1516, 283, 331, 14679, 1782, 5267, 1813, 2682, 16384, 9288, 1241, 3018, 3442, 4617, 2160, 1161, 1990, 14632, 12729, 7822, 1597, 3200, 12696, 7424, 6334, 3734, 5210, 17909, 7269, 3584, 2361, 1058, 354, 1937, 884, 2134, 7006, 2416, 1265, 781, 414, 8656, 283, 714, 156, 1411, 1371, 1280, 1864, 40702, 731, 22046, 37589, 5423, 795, 11778, 10568, 2576, 596, 2198, 2104, 10309, 681, 374, 27290, 1975, 19806, 6182, 394, 6073, 882, 1293, 805, 2205, 245, 1069, 26600, 8025, 2358, 4294, 2011, 630, 5420, 788, 1120, 2441, 5653, 1601, 10525, 1065, 4155, 2006, 10952, 2529, 253, 6615, 1826, 1087, 11947, 1387, 3866, 858, 796, 14641, 840, 1050, 305, 12003, 3095, 2595, 5840, 463, 1101, 1806, 363, 8455, 1958, 1400, 2591, 873, 2099, 16384, 3886, 12520, 1352, 874, 13775, 456, 157, 4468, 4045, 5000, 17762, 16384, 1815, 1086, 73, 1897, 4989, 2013, 6881, 16384, 13398, 7741, 349, 6213, 2142, 1566, 1669, 1682, 1422, 2486, 1649, 560, 3161, 1023, 6328, 1925, 2297, 209, 501, 5617, 891, 1112, 1471, 41718, 3015, 8444, 1488, 2526, 531, 7301, 2251, 2097, 2899, 9813, 1578, 12448, 783, 3179, 16384, 1165, 2616, 5246, 1716, 383, 625, 3785, 5327, 4736, 7052, 2162, 2512, 375, 2832, 3920, 1052, 4057, 271, 4565, 2780, 16384, 9455, 10484, 4910, 4069, 544, 1382, 14904, 402, 1217, 419, 9858, 1072, 10926, 1267, 1147, 8154, 5612, 100, 3282, 3866, 2516, 969, 2061, 1289, 17482, 1599, 1008, 2392, 4830, 10037, 1086, 2892, 6481, 11555, 7542, 3608, 658, 444, 1599, 424, 842, 1657, 1173, 16947, 22875, 2577, 5979, 1093, 4439, 16384, 1806, 4090, 2481, 5805, 301, 624, 2339, 16614, 2306, 320, 807, 833, 3065, 864, 944, 6589, 8680, 1268, 3188, 252, 2485, 19741, 3566, 2233, 1303, 980, 1640, 362, 11748, 3716, 1785, 1010, 1849, 4805, 6078, 739, 684, 16384, 6976, 4356, 1715, 5521, 492, 10774, 1921, 4769, 4067, 15165, 23517, 7659, 6180, 284, 310, 705, 747, 583, 2695, 1199, 7530, 9878, 1936, 12731, 2052, 1238, 2145, 5649, 338, 1588, 2771, 2979, 1332, 3420, 2755, 1042, 16384, 3240, 1388, 40611, 6200, 2235, 16384, 1237, 509, 1938, 2422, 194, 1422, 1332, 1331, 998, 455, 4600, 1051, 648, 866, 1188, 2251, 4167, 700, 1179, 454, 64, 2371, 10636, 3548, 10820, 2221, 548, 1746, 1248, 18625, 3121, 16384, 12481, 1845, 15499, 5161, 980, 11585, 409, 824, 2598, 1266, 13795, 4075, 1312, 1190, 2454, 625, 3847, 440, 3965, 1667, 3152, 655, 10761, 16384, 1208, 2833, 10468, 4618, 3213, 655, 15399, 2119, 1200, 1956, 2505, 949, 3440, 15435, 658, 1192, 1892, 7005, 541, 10139, 184, 1231, 4222, 16335, 2959, 1031, 4346, 2501, 241, 517, 10541, 2848, 440, 4924, 6422, 1238, 4119, 64, 26062, 7278, 579, 2725, 1377, 46375, 1252, 461, 15985, 1420, 2242, 658, 638, 3145, 3565, 5248, 6728, 1585, 1225, 4543, 991, 5213, 3016, 7119, 4177, 626, 771, 4472, 16281, 466, 2049, 2723, 373, 3381, 1803, 199, 11895, 773, 487, 3172, 3689, 4491, 1306, 1974, 894, 472, 6548, 1784, 1635, 221, 1642, 790, 1649, 1570, 1222, 5612, 3267, 6904, 465, 978, 1911, 1277, 1831, 544, 908, 13381, 750, 4288, 1578, 10470, 1037, 2277, 526, 16384, 1641, 4977, 3148, 1051, 462, 2372, 1083, 14177, 4090, 2177, 33276, 2356, 15677, 9280, 7284, 572, 3483, 964, 878, 1987, 13662, 6398, 3888, 11236, 16384, 5224, 150, 3100, 1167, 3136, 3104, 727, 14890, 2489, 5627, 8835, 887, 732, 6864, 9247, 439, 16384, 1542, 4276, 3717, 686, 772, 201, 563, 15412, 2088, 9012, 1939, 2900, 13908, 10657, 1307, 399, 1245, 2141, 766, 2975, 13609, 3960, 825, 724, 14065, 2062, 18324, 596, 1319, 4231, 11183, 900, 826, 1948, 373, 1933, 1860, 4434, 10832, 3739, 4517, 2116, 1345, 222, 753, 12018, 326, 2610, 1285, 649, 1191, 4454, 5292, 237, 1695, 11587, 1504, 2252, 385, 1178, 14937, 839, 409, 2355, 4757, 7429, 1130, 2552, 3636, 4081, 1094, 13147, 938, 11610, 1950, 1047, 985, 47871, 1222, 11770, 4303, 14053, 1015, 3420, 1774, 418, 713, 1609, 1061, 4562, 861, 689, 657, 3125, 3400, 317, 3961, 5151, 311, 934, 9621, 6043, 2053, 3468, 16384, 3474, 521, 8968, 766, 5962, 4112, 5315, 10883, 398, 1850, 16384, 10722, 2428, 648, 2247, 732, 397, 10269, 27915, 853, 3085, 1147, 14150, 1932, 11325, 817, 3923, 15185, 2692, 6975, 295, 4349, 2066, 4635, 5189, 167, 1226, 956, 2362, 236, 602, 6015, 2427, 603, 1512, 6688, 264, 1583, 1552, 2454, 15033, 16340, 3674, 1047, 7972, 777, 3228, 11255, 6535, 4876, 171, 1788, 1047, 8581, 5037, 2663, 4788, 11411, 4014, 2218, 313, 2917, 4349, 7426, 3569, 6047, 297, 1325, 15019, 1390, 1811, 1058, 4490, 671, 2293, 2165, 2340, 17537, 9312, 10576, 410, 4824, 1990, 1796, 1798, 3087, 1884, 853, 419, 2790, 376, 6847, 699, 784, 678, 446, 854, 1462, 12638, 135, 909, 5280, 477, 1837, 9639, 466, 1233, 882, 5330, 3328, 3941, 16384, 11997, 1791, 1600, 405, 303, 1892, 478, 3975, 12427, 1052, 362, 16384, 11128, 915, 2359, 8564, 720, 16272, 642, 1644, 325, 122, 6069, 11663, 296, 328, 7043, 1693, 9648, 4024, 1857, 2070, 1085, 2225, 1868, 5020, 1669, 10225, 5501, 2437, 471, 1674, 245, 529, 4462, 25013, 1991, 1432, 885, 1136, 5777, 3375, 442, 2486, 2330, 12253, 289, 37264, 11290, 588, 16384, 546, 2063, 3697, 5266, 4388, 1201, 5456, 871, 1109, 10613, 10514, 1554, 750, 7560, 497, 15093, 676, 41629, 5537, 4738, 2564, 2110, 324, 846, 4434, 4145, 637, 13731, 2636, 13711, 1261, 1127, 723, 665, 3018, 920, 6517, 1002, 10801, 3163, 2655, 563, 2869, 2100, 4004, 1139, 403, 2704, 2330, 2613, 6040, 710, 145, 3369, 3122, 1182, 2410, 13210, 196, 310, 2093, 9145, 1301, 4891, 23014, 1879, 4799, 27472, 1101, 771, 1804, 7334, 355, 5142, 2729, 688, 1958, 1596, 704, 19726, 501, 204, 2359, 6303, 12048, 588, 16384, 10710, 9564, 10741, 1076, 236, 2465, 1295, 2387, 797, 4188, 2914, 567, 1899, 2732, 16384, 2220, 710, 1411, 13835, 1725, 263, 1387, 10095, 1500, 16384, 799, 9717, 7162, 4238, 2005, 4104, 1218, 1095, 877, 2700, 1586, 1535, 10759, 920, 4486, 1125, 346, 416, 1163, 3994, 4047, 1533, 3945, 25368, 1498, 5116, 7381, 6109, 1425, 3731, 192, 2476, 2972, 2361, 1564, 8393, 1803, 1713, 1532, 6232, 1448, 798, 1772, 13075, 1435, 3933, 1471, 1473, 1078, 524, 12552, 4404, 11314, 3248, 813, 4537, 3292, 9303, 16384, 7601, 1297, 1677, 11322, 1143, 1712, 4014, 6487, 2553, 82, 2902, 1417, 682, 2051, 6853, 576, 11486, 34084, 5583, 22675, 1515, 1311, 1998, 1866, 1409, 1643, 1583, 2681, 324, 3412, 12926, 6501, 705, 6304, 16384, 1530, 13249, 16384, 6206, 11001, 598, 2589, 3075, 3717, 4762, 2372, 471, 11401, 3031, 546, 4604, 3671, 3607, 33519, 41514, 3745, 838, 366, 859, 147, 1500, 12311, 529, 1096, 11032, 2248, 10817, 1630, 10690, 177, 4456, 6705, 1371, 1420, 4887, 888, 845, 2832, 1025, 3913, 726, 10513, 4113, 2148, 16505, 624, 744, 413, 8729, 28850, 6487, 13534, 8410, 3276, 1271, 4556, 2520, 1500, 1133, 6549, 10149, 1476, 1235, 4306, 993, 3881, 13502, 10235, 2052, 16384, 1325, 2333, 709, 922, 438, 16384, 3747, 1899, 624, 268, 2606, 1703, 3470, 4279, 6084, 1907, 3960, 1276, 783, 1377, 4655, 3893, 1970, 2848, 11710, 275, 502, 1969, 4317, 10160, 5395, 73, 153, 1070, 16384, 1998, 169, 1344, 3941, 5758, 3352, 1541, 4216, 7108, 1085, 1744, 1720, 306, 501, 155, 2192, 1440, 1376, 1923, 3537, 953, 7266, 346, 1968, 1793, 20411, 1159, 6474, 1544, 1786, 1695, 4306, 5107, 1027, 424, 679, 2396, 1961, 2333, 899, 4794, 1645, 11025, 2370, 19499, 2340, 2305, 2565, 626, 10774, 10067, 10031, 1086, 5786, 2602, 2231, 711, 7528, 3168, 1809, 7541, 2202, 26297, 6114, 1388, 8903, 2136, 16384, 2185, 1831, 2215, 14187, 10984, 2757, 27540, 1161, 4742, 1085, 552, 708, 1198, 1742, 6364, 1058, 7456, 329, 16384, 348, 2484, 1572, 842, 23229, 6392, 1653, 7557, 15901, 620, 1831, 1118, 3315, 1288, 1841, 605, 16612, 1351, 616, 16384, 422, 3491, 184, 2805, 2457, 1513, 445, 777, 822, 549, 704, 9687, 3072, 8637, 673, 1243, 10698, 539, 1450, 1258, 14116, 2250, 1492, 3312, 2058, 605, 1002, 9310, 8384, 2651, 6132, 12174, 1229, 2447, 2548, 804, 3265, 567, 2236, 1486, 3205, 450, 1126, 15858, 1722, 2153, 956, 2100, 3034, 1184, 1518, 1663, 21096, 6929, 956, 4849, 4841, 2644, 6567, 2228, 2249, 1650, 1484, 1585, 258, 3867, 1401, 397, 5810, 683, 5143, 883, 5737, 16136, 20776, 1509, 5724, 2718, 2724, 5470, 839, 487, 911, 8663, 862, 369, 33484, 1137, 1219, 431, 3581, 3732, 1090, 10366, 249, 11601, 16384, 3117, 3901, 2347, 2935, 1546, 2761, 827, 510, 2258, 2226, 549, 1089, 1359, 4391, 2379, 21745, 346, 2690, 3576, 16384, 3264, 5522, 5580, 272, 17737, 1658, 1204, 5126, 11960, 722, 1683, 3189, 847, 194, 1577, 593, 236, 5388, 12076, 3575, 3157, 3221, 1834, 3275, 14663, 874, 8147, 4553, 16384, 812, 407, 8742, 10197, 8888, 16384, 36066, 778, 314, 1693, 904, 236, 2230, 8184, 687, 7862, 12773, 1861, 13828, 1192, 16384, 1302, 3739, 1477, 596, 4267, 12260, 6448, 11730, 2338, 1992, 3570, 1564, 15437, 346, 6125, 2110, 343, 17548, 14028, 6523, 3046, 397, 1493, 642, 1338, 1574, 899, 431, 4503, 2628, 3653, 6963, 6722, 12450, 5532, 3311, 1269, 483, 3824, 1449, 12176, 1147, 2719, 2732, 395, 16376, 224, 2702, 11745, 4528, 899, 622, 1402], "output_lens": [12, 57, 10, 37, 1, 11, 1, 5, 12, 0, 9, 8, 12, 8, 11, 1, 19, 12, 41, 13, 6, 7, 17, 9, 12, 56, 1, 14, 12, 3, 12, 23, 5, 12, 2, 10, 20, 9, 11, 10, 1, 6, 1, 22, 10, 8, 22, 17, 8, 2, 10, 3, 8, 12, 5, 9, 1, 35, 1, 12, 11, 12, 1, 5, 1, 8, 9, 2, 12, 0, 8, 5, 5, 8, 8, 11, 0, 1, 1, 2, 1, 2, 1, 11, 25, 1, 6, 12, 2, 3, 1, 2, 16, 0, 4, 4, 8, 10, 39, 12, 6, 12, 9, 14, 17, 6, 11, 1, 30, 12, 37, 1, 11, 29, 2, 20, 1, 26, 11, 54, 9, 10, 9, 11, 27, 32, 1, 17, 15, 15, 11, 21, 1, 19, 28, 1, 6, 3, 1, 32, 12, 13, 3, 2, 2, 12, 4, 15, 7, 9, 30, 21, 6, 12, 6, 13, 12, 7, 11, 9, 12, 20, 38, 11, 12, 11, 12, 4, 11, 11, 11, 1, 3, 4, 4, 44, 17, 4, 2, 1, 5, 6, 5, 11, 12, 1, 12, 5, 12, 10, 2, 3, 12, 5, 7, 24, 12, 33, 18, 2, 1, 16, 12, 21, 12, 12, 11, 5, 25, 23, 11, 8, 37, 7, 12, 11, 7, 4, 18, 12, 8, 1, 5, 8, 8, 16, 1, 1, 3, 2, 3, 1, 5, 13, 77, 8, 29, 3, 44, 1, 1, 7, 13, 13, 1, 13, 2, 7, 1, 11, 1, 0, 2, 3, 3, 2, 2, 32, 8, 7, 4, 12, 12, 6, 3, 12, 3, 1, 12, 5, 3, 12, 9, 2, 11, 12, 18, 4, 11, 6, 11, 10, 13, 12, 99, 15, 12, 4, 10, 9, 19, 11, 8, 11, 10, 23, 10, 18, 12, 12, 7, 10, 10, 51, 9, 39, 12, 12, 3, 8, 11, 4, 2, 10, 14, 11, 15, 5, 6, 7, 3, 0, 9, 2, 1, 11, 1, 8, 12, 58, 11, 4, 11, 2, 42, 22, 2, 1, 41, 49, 4, 3, 11, 81, 4, 7, 7, 10, 4, 11, 12, 8, 5, 13, 12, 4, 6, 11, 1, 1, 19, 11, 10, 31, 12, 12, 41, 12, 5, 2, 1, 0, 1, 12, 9, 12, 11, 1, 11, 40, 11, 11, 1, 13, 1, 6, 5, 29, 9, 1, 4, 9, 12, 4, 23, 3, 16, 0, 23, 12, 35, 1, 3, 12, 6, 1, 19, 2, 2, 11, 8, 3, 12, 8, 18, 7, 27, 0, 26, 15, 7, 7, 12, 1, 3, 15, 21, 12, 11, 0, 11, 8, 24, 5, 12, 12, 21, 6, 52, 1, 8, 11, 11, 4, 8, 19, 24, 12, 1, 11, 4, 16, 7, 11, 4, 18, 37, 6, 1, 44, 12, 28, 46, 33, 11, 60, 9, 4, 12, 34, 1, 12, 6, 11, 4, 12, 2, 12, 2, 16, 4, 22, 3, 12, 11, 12, 11, 12, 14, 4, 11, 4, 5, 11, 4, 12, 5, 3, 36, 9, 11, 8, 1, 3, 12, 7, 0, 7, 5, 25, 1, 12, 0, 6, 3, 14, 12, 6, 4, 4, 1, 4, 11, 19, 8, 12, 2, 20, 8, 4, 3, 2, 60, 7, 12, 9, 26, 12, 1, 16, 52, 12, 5, 15, 9, 14, 12, 12, 6, 9, 12, 1, 5, 10, 3, 12, 1, 12, 12, 11, 39, 11, 3, 12, 4, 11, 12, 11, 13, 8, 5, 9, 2, 0, 12, 17, 12, 12, 11, 1, 12, 2, 12, 3, 2, 49, 1, 1, 9, 13, 3, 20, 12, 11, 2, 12, 0, 12, 11, 11, 7, 11, 1, 0, 39, 30, 0, 12, 8, 11, 46, 11, 1, 34, 12, 12, 10, 5, 1, 33, 0, 12, 23, 12, 1, 6, 26, 21, 12, 11, 1, 12, 1, 12, 6, 3, 3, 1, 11, 24, 11, 77, 23, 20, 8, 2, 7, 12, 6, 2, 12, 12, 2, 23, 11, 11, 1, 3, 9, 1, 20, 3, 7, 1, 4, 12, 12, 21, 3, 0, 11, 3, 3, 1, 12, 1, 35, 12, 0, 11, 6, 12, 1, 2, 9, 1, 5, 13, 2, 2, 8, 1, 12, 25, 10, 1, 15, 4, 7, 3, 16, 11, 31, 23, 12, 12, 3, 1, 13, 11, 8, 16, 6, 6, 7, 29, 3, 12, 4, 10, 4, 10, 8, 7, 5, 1, 11, 9, 4, 3, 2, 12, 11, 4, 4, 0, 12, 2, 25, 9, 11, 14, 2, 2, 12, 4, 12, 1, 12, 11, 8, 11, 8, 18, 1, 12, 12, 12, 45, 8, 1, 1, 10, 13, 6, 10, 2, 2, 37, 3, 12, 6, 12, 1, 4, 5, 7, 1, 2, 32, 10, 2, 34, 11, 4, 33, 11, 12, 1, 12, 4, 2, 5, 20, 12, 6, 1, 2, 15, 10, 7, 1, 10, 4, 33, 11, 8, 40, 13, 0, 0, 12, 1, 24, 1, 1, 11, 20, 12, 39, 8, 1, 1, 11, 4, 14, 9, 4, 21, 1, 18, 22, 1, 5, 12, 9, 14, 23, 12, 1, 12, 3, 18, 46, 1, 14, 16, 8, 12, 7, 12, 10, 27, 12, 21, 17, 12, 2, 5, 9, 8, 2, 6, 20, 1, 13, 7, 11, 5, 12, 30, 3, 36, 5, 9, 9, 2, 11, 1, 12, 8, 12, 0, 5, 14, 12, 6, 12, 1, 1, 1, 5, 11, 5, 5, 11, 1, 28, 13, 2, 11, 5, 4, 12, 22, 10, 12, 9, 1, 20, 4, 6, 42, 12, 12, 12, 13, 23, 12, 12, 1, 7, 23, 1, 33, 12, 4, 9, 1, 1, 12, 4, 3, 46, 16, 1, 5, 3, 12, 5, 12, 11, 38, 1, 6, 3, 11, 7, 29, 12, 12, 9, 6, 12, 3, 12, 1, 20, 23, 2, 11, 1, 21, 39, 12, 11, 11, 4, 5, 28, 1, 14, 34, 1, 2, 1, 1, 13, 15, 4, 9, 13, 12, 7, 7, 0, 2, 1, 15, 9, 5, 9, 0, 7, 11, 42, 11, 4, 9, 3, 38, 41, 1, 12, 9, 11, 12, 5, 1, 33, 12, 5, 1, 12, 19, 15, 1, 35, 0, 1, 12, 10, 7, 11, 6, 4, 12, 26, 6, 5, 12, 23, 1, 11, 9, 1, 12, 6, 12, 12, 2, 23, 4, 5, 12, 1, 21, 12, 3, 11, 1, 20, 1, 12, 15, 0, 16, 12, 11, 3, 5, 12, 12, 6, 41, 37, 19, 3, 0, 10, 1, 11, 8, 7, 9, 41, 11, 4, 12, 9, 1, 0, 11, 12, 21, 3, 1, 2, 1, 12, 3, 9, 1, 12, 8, 5, 11, 5, 11, 53, 19, 12, 24, 12, 8, 4, 50, 16, 1, 7, 1, 12, 3, 11, 3, 16, 11, 12, 11, 28, 12, 11, 30, 2, 2, 12, 2, 11, 16, 0, 9, 11, 10, 13, 1, 4, 12, 13, 4, 1, 3, 12, 7, 5, 1, 1, 12, 12, 13, 4, 2, 1, 14, 14, 3, 8, 2, 2, 15, 6, 5, 12, 4, 1, 5, 12, 33, 40, 3, 11, 10, 4, 16, 12, 2, 12, 0, 5, 1, 7, 30, 9, 11, 12, 52, 12, 12, 7, 9, 5, 4, 12, 17, 1, 1, 1, 12, 11, 12, 10, 13, 5, 39, 30, 11, 11, 11, 4, 2, 35, 7, 12, 18, 12, 3, 11, 12, 1, 33, 12, 12, 28, 4, 6, 11, 7, 16, 12, 12, 12, 0, 5, 8, 23, 11, 12, 2, 13, 12, 4, 1, 1, 12, 1, 11, 12, 37, 16, 1, 13, 1, 1, 1, 2, 0, 13, 24, 12, 5, 9, 11, 1, 12, 11, 12, 4, 11, 7, 18, 11, 12, 12, 12, 6, 6, 19, 12, 1, 5, 2, 4, 7, 62, 7, 9, 1, 7, 5, 7, 2, 12, 1, 11, 4, 19, 9, 51, 7, 13, 44, 1, 12, 4, 4, 11, 45, 1, 51, 26, 36, 1, 5, 2, 8, 3, 1, 11, 12, 34, 2, 6, 13, 1, 35, 41, 12, 12, 10, 1, 8, 11, 12, 2, 9, 12, 11, 1, 6, 1, 2, 3, 8, 11, 0, 12, 11, 5, 2, 12, 9, 11, 19, 21, 12, 10, 9, 22, 7, 1, 27, 12, 9, 12, 18, 2, 6, 12, 25, 30, 14, 1, 7, 6, 33, 2, 4, 1, 10, 2, 0, 9, 12, 3, 13, 21, 25, 17, 11, 11, 15, 33, 12, 2, 0, 2, 2, 5, 0, 12, 6, 12, 1, 5, 0, 7, 6, 12, 12, 52, 1, 42, 12, 6, 1, 6, 11, 2, 4, 2, 1, 12, 14, 33, 2, 12, 0, 29, 10, 5, 11, 10, 18, 12, 7, 12, 7, 13, 12, 6, 43, 23, 20, 12, 12, 3, 12, 5, 5, 11, 8, 1, 9, 6, 39, 12, 14, 12, 14, 4, 11, 5, 7, 29, 7, 1, 1, 21, 1, 87, 34, 8, 4, 12, 12, 45, 3, 47, 12, 12, 11, 5, 7, 34, 17, 31, 5, 1, 2, 4, 10, 3, 18, 12, 12, 12, 13, 21, 12, 12, 45, 13, 12, 10, 11, 11, 102, 1, 12, 8, 42, 2, 26, 2, 13, 12, 21, 47, 14, 5, 12, 22, 12, 12, 29, 1, 40, 4, 24, 1, 41, 12, 44, 12, 3, 1, 12, 12, 10, 1, 33, 20, 11, 7, 13, 10, 65, 7, 12, 14, 6, 8, 6, 12, 12, 1, 23, 9, 6, 7, 2, 5, 3, 9, 12, 0, 23, 12, 7, 2, 7, 11, 3, 12, 16, 8, 11, 2, 29, 1, 8, 11, 2, 0, 12, 1, 1, 19, 25, 8, 6, 6, 12, 1, 12, 2, 27, 12, 28, 2, 2, 3, 11, 9, 4, 5, 23, 1, 36, 8, 22, 2, 12, 0, 1, 12, 14, 11, 14, 4, 6, 1, 12, 0, 2, 1, 0, 6, 5, 12, 10, 15, 1, 7, 12, 3, 6, 1, 11, 8, 8, 8, 19, 9, 4, 10, 46, 10, 2, 12, 39, 6, 1, 26, 6, 12, 11, 0, 5, 31, 11, 11, 1, 1, 13, 23, 0, 37, 12, 25, 16, 7, 1, 12, 5, 3, 47, 12, 49, 12, 5, 17, 11, 8, 12, 12, 1, 3, 12, 1, 26, 7, 1, 29, 1, 2, 23, 43, 1, 1, 10, 0, 12, 9, 19, 6, 3, 11, 9, 12, 26, 6, 10, 11, 1, 18, 9, 11, 11, 4, 17, 13, 12, 44, 7, 1, 6, 1, 12, 72, 26, 25, 16, 13, 13, 8, 3, 16, 1, 4, 0, 11, 7, 8, 12, 1, 4, 4, 0, 21, 3, 12, 10, 26, 12, 7, 14, 14, 0, 1, 29, 8, 2, 5, 3, 1, 4, 9, 12, 12, 3, 0, 8, 12, 27, 3, 6, 1, 7, 6, 0, 19, 9, 1, 12, 3, 16, 35, 8, 1, 12, 5, 20, 6, 29, 13, 5, 2, 2, 24, 1, 2, 14, 2, 1, 3, 5, 8, 18, 22, 12, 11, 1, 9, 1, 28, 5, 8, 0, 8, 16, 10, 12, 8, 11, 12, 24, 2, 4, 6, 3, 1, 1, 8, 1, 3, 11, 11, 1, 34, 3, 10, 29, 70, 2, 19, 1, 11, 11, 6, 14, 6, 5, 6, 16, 12, 39, 11, 13, 15, 12, 18, 8, 12, 1, 2, 3, 2, 11, 1, 1, 2, 12, 29, 17, 7, 12, 12, 7, 12, 12, 7, 1, 10, 7, 38, 1, 67, 18, 39, 3, 17, 3, 11, 1, 8, 5, 23, 39, 1, 12, 2, 17, 12, 17, 12, 40, 5, 9, 15, 11, 9, 35, 12, 11, 6, 21, 30, 5, 0, 8, 6, 15, 2, 38, 12, 2, 12, 33, 15, 26, 23, 11, 12, 5, 5, 1, 11, 13, 18, 31, 32, 9, 20, 7, 5, 52, 0, 31, 14, 6, 7, 29, 3, 9, 1, 4, 2, 6, 20, 7, 0, 10, 14, 2, 1, 11, 5, 11, 12, 12, 1, 11, 29, 23, 12, 1, 10, 5, 13, 12, 8, 22, 6, 4, 15, 1, 5, 8, 1, 1, 11, 12, 36, 12, 7, 15, 1, 1, 4, 12, 2, 6, 88, 4, 22, 1, 19, 8, 17, 1, 11, 2, 4, 20, 14, 4, 29, 1, 3, 3, 1, 11, 12, 12, 12, 0, 12, 41, 12, 22, 12, 0, 10, 11, 42, 61, 29, 7, 11, 1, 4, 11, 1, 12, 12, 1, 2, 14, 12, 1, 11, 1, 5, 4, 1, 11, 8, 4, 5, 12, 12, 4, 11, 7, 36, 4, 2, 36, 3, 1, 11, 36, 3, 28, 0, 12, 24, 5, 6, 2, 11, 12, 10, 11, 10, 6, 2, 1, 6, 12, 6, 12, 12, 9, 1, 11, 12, 10, 59, 22, 6, 6, 15, 2, 12, 13, 0, 0, 0, 37, 1, 14, 0, 0, 0, 0, 0, 16, 12, 1, 12, 12, 9, 12, 0, 0, 0, 10, 0, 0, 5, 5, 12, 12, 1, 0, 0, 1, 13, 0, 0, 0, 10, 0, 0, 5, 22, 11, 12, 12, 3, 0, 0, 0, 0, 6, 12, 20, 0, 12, 0, 0, 1, 14, 12, 20, 0, 0, 11, 30, 11, 15, 5, 0, 0, 0, 0, 0, 28, 0, 0, 0, 0, 0, 12, 3, 0, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 6, 0, 7, 0, 0, 0, 14, 0, 0, 0, 0, 12, 11, 0, 13, 1, 0, 20, 0, 0, 0, 0, 0, 0, 0, 81, 12, 11, 87, 11, 11, 12, 6, 6, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 1, 9, 0, 0, 0, 0, 43, 58, 0, 0, 11, 26, 8, 1, 0, 11, 0, 2, 1, 0, 0, 0, 0, 12, 3, 33, 11, 1, 33, 10, 12, 1, 6, 0, 0, 0, 0, 0, 0, 6, 1, 11, 0, 11, 4, 4, 0, 0, 28, 0, 0, 13, 17, 0, 0, 13, 11, 0, 0, 0, 0, 0, 1, 12, 4, 0, 1, 7, 8, 72, 8, 18, 1, 12, 8, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 5, 12, 13, 0, 0, 12, 23, 9, 0, 0, 0, 0, 30, 0, 0, 13, 11, 22, 0, 0, 24, 0, 7, 0, 3, 12, 0, 0, 0, 0, 0, 0, 19, 5, 24, 0, 0, 0, 0, 0, 0, 0, 3, 0, 1, 4, 3, 13, 12, 12, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 13, 10, 2, 3, 12, 3, 11, 55, 11, 0, 0, 34, 11, 0, 0, 0, 0, 0, 12, 5, 1, 12, 0, 0, 0, 4, 1, 17, 19, 3, 23, 0, 11, 0, 0, 0, 0, 0, 12, 5, 12, 2, 27, 25, 12, 2, 11, 7, 0, 8, 0, 0, 2, 9, 14, 1, 23, 0, 0, 0, 0, 0, 0, 13, 11, 0, 0, 0, 8, 8, 9, 12, 24, 22, 4, 1, 0, 17, 0, 21, 6, 0, 10, 11, 0, 0, 0, 34, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 1, 0, 11, 0, 0, 0, 0, 0, 12, 8, 0, 0, 0, 0, 4, 6, 0, 0, 1, 1, 13, 11, 0, 12, 3, 0, 0, 0, 13, 0, 0, 6, 3, 0, 27, 29, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 12, 21, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 46, 9, 6, 7, 37, 0, 0, 0, 14, 7, 12, 9, 0, 10, 1, 0, 0, 0, 0, 0, 0, 0, 10, 31, 0, 12, 12, 11, 2, 12, 0, 0, 12, 10, 0, 0, 0, 12, 6, 8, 0, 0, 0, 1, 11, 9, 14, 0, 10, 15, 27, 44, 0, 0, 6, 4, 0, 0, 1, 2, 0, 0, 0, 0, 0, 5, 12, 3, 8, 77, 0, 0, 0, 0, 0, 0, 40, 7, 0, 0, 0, 53, 6, 0, 0, 0, 11, 0, 0, 4, 11, 0, 0, 0, 0, 12, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 5, 5, 19, 3, 2, 0, 0, 0, 0, 0, 0, 5, 2, 0, 0, 25, 7, 0, 0, 0, 0, 0, 3, 4, 5, 9, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 8, 33, 16, 12, 14, 11, 16, 9, 9, 4, 0, 0, 0, 0, 12, 0, 0, 0, 0, 0, 31, 5, 2, 12, 0, 0, 0, 0, 0, 0, 11, 8, 0, 0, 0, 0, 0, 0, 0, 14, 0, 0, 0, 7, 8, 39, 0, 0, 13, 0, 0, 0, 0, 0, 0, 0, 0, 1, 12, 11, 7, 12, 11, 0, 12, 0, 0, 0, 0, 0, 0, 3, 5, 0, 0, 6, 11, 0, 0, 0, 11, 46, 0, 31, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 24, 44, 15, 12, 41, 11, 2, 11, 46, 4, 0, 12, 5, 0, 0, 0, 1, 1, 0, 0, 0, 0, 46, 18, 8, 12, 37, 3, 0, 0, 0, 0, 0, 2, 12, 11, 11, 11, 4, 9, 3, 0, 0, 0, 0, 1, 49, 2, 34, 13, 0, 18, 8, 0, 1, 34, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 12, 0, 7, 0, 0, 0, 0, 0, 9, 0, 0, 12, 8, 0, 0, 0, 0, 0, 4, 0, 0, 1, 2, 10, 5, 12, 0, 0, 0, 0, 0, 0, 0, 12, 6, 4, 31, 13, 5, 0, 32, 8, 31, 12, 12, 0, 0, 2, 7, 0, 0, 0, 12, 24, 0, 0, 0, 12, 0, 0, 0, 0, 0, 1, 1, 7, 1, 12, 0, 0, 6, 7, 9, 52, 4, 2, 0, 0, 29, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 1, 6, 0, 0, 0, 11, 1, 0, 36, 6, 4, 1, 0, 12, 1, 0, 0, 0, 0, 8, 10, 0, 0, 0, 0, 0, 0, 0, 5, 0, 20, 1, 0, 0, 2, 8, 0, 0, 0, 0, 25, 1, 0, 4, 9, 0, 0, 0, 0, 0, 0, 7, 11, 0, 0, 12, 12, 12, 0, 0, 0, 12, 4, 14, 1, 0, 0, 11, 0, 1, 16, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 19, 0, 1, 12, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 12, 3, 2, 11, 0, 0, 1, 4, 6, 0, 20, 2, 36, 2, 12, 64, 12, 0, 0, 14, 0, 0, 0, 0, 0, 10, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 2, 0, 0, 0, 0, 16, 0, 9, 6, 0, 0, 0, 5, 12, 30, 1, 11, 4, 10, 1, 0, 24, 12, 0, 12, 0, 0, 0, 0, 0, 27, 15, 0, 34, 1, 0, 4, 0, 1, 2, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 2, 0, 3, 9, 0, 0, 1, 12, 0, 0, 11, 36, 0, 12, 0, 0, 0, 0, 1, 0, 0, 12, 0, 0, 12, 14, 7, 0, 0, 6, 0, 1, 0, 38, 1, 11, 3, 0, 11, 0, 0, 0, 0, 1, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 1, 60, 0, 0, 0, 0, 1, 0, 0, 12, 0, 0, 0, 0, 0, 28, 5, 23, 1, 12, 0, 0, 0, 0, 0, 0, 12, 0, 0, 0, 0, 0, 1, 1, 3, 11, 3, 1, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 0, 0, 0, 11, 5, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 2, 10, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 40, 6, 0, 0, 0, 0, 6, 10, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 11, 1, 38, 10, 12, 0, 0, 0, 0, 0, 0, 0, 7, 12, 6, 0, 0, 35, 0, 0, 0, 12, 35, 1, 0, 0, 3, 6, 4, 0, 0, 0, 0, 0, 0, 0, 0, 19, 2, 0, 17, 16, 11, 2, 1, 6, 8, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 10, 5, 11, 10, 0, 0, 0, 0, 12, 4, 0, 12, 0, 0, 12, 0, 0, 0, 0, 0, 0, 11, 1, 12, 1, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 44, 0, 0, 0, 0, 0, 0, 0, 11, 12, 4, 1, 1, 1, 5, 7, 11, 42, 2, 11, 13, 11, 12, 1, 2, 0, 0, 0, 1, 1, 1, 12, 3, 0, 0, 0, 0, 0, 11, 12, 2, 0, 0, 11, 11, 0, 0, 5, 0, 0, 15, 1, 4, 9, 0, 0, 12, 8, 0, 0, 8, 0, 12, 0, 0, 10, 12, 0, 5, 6, 0, 0, 0, 0, 0, 0, 38, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 20, 0, 11, 0, 0, 0, 0, 0, 5, 12, 11, 1, 22, 9, 6, 0, 0, 0, 0, 0, 1, 5, 0, 0, 0, 0, 0, 7, 12, 0, 0, 0, 0, 3, 25, 9, 0, 4, 16, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 6, 0, 0, 1, 1, 0, 0, 0, 0, 0, 12, 0, 28, 7, 25, 0, 0, 0, 20, 0, 2, 0, 0, 9, 11, 0, 0, 1, 0, 0, 0, 7, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 25, 0, 3, 1, 8, 0, 0, 0, 0, 8, 0, 0, 4, 5, 11, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 18, 2, 4, 2, 12, 0, 0, 8, 3, 3, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 12, 17, 0, 0, 1, 0, 6, 0, 1, 0, 0, 0, 0, 18, 0, 0, 0, 12, 0, 0, 0, 7, 0, 0, 0, 36, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 18, 1, 1, 3, 11, 10, 12, 5, 1, 7, 4, 6, 11, 44, 5, 5, 3, 11, 4, 8, 0, 12, 78, 2, 8, 0, 0, 0, 0, 0, 0, 2, 2, 6, 8, 96, 23, 16, 20, 6, 13, 1, 0, 0, 0, 0, 0, 11, 10, 12, 41, 30, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 76, 0, 0, 0, 0, 0, 1, 24, 4, 5, 2, 10, 9, 5, 13, 12, 1, 12, 6, 12, 33, 0, 0, 0, 0, 11, 12, 11, 11, 2, 0, 0, 11, 44, 1, 11, 11, 11, 4, 5, 14, 12, 11, 12, 0, 0, 0, 1, 0, 0, 20, 0, 0, 0, 0, 0, 0, 12, 0, 0, 12, 0, 0, 0, 0, 73, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 12, 12, 11, 18, 11, 0, 11, 11, 17, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 1, 1, 12, 17, 12, 1, 5, 17, 0, 10, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 18, 8, 0, 0, 0, 1, 1, 0, 0, 0, 2, 12, 6, 0, 0, 0, 0, 4, 0, 0, 0, 39, 0, 0, 9, 0, 0, 0, 0, 11, 11, 0, 13, 0, 0, 1, 11, 1, 0, 0, 0, 9, 11, 0, 11, 0, 0, 69, 42, 0, 0, 0, 12, 3, 1, 9, 0, 0, 1, 0, 0, 0, 6, 18, 0, 0, 0, 0, 0, 0, 0, 11, 4, 0, 0, 13, 30, 8, 0, 0, 0, 27, 0, 0, 0, 2, 0, 0, 0, 0, 0, 5, 0, 0, 5, 0, 0, 0, 3, 12, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 11, 1, 3, 7, 13, 11, 9, 0, 0, 0, 11, 11, 10, 11, 16, 0, 0, 12, 14, 1, 3, 9, 0, 1, 8, 6, 11, 11, 12, 11, 9, 14, 12, 1, 2, 12, 1, 22, 1, 11, 2, 12, 13, 14, 25, 4, 26, 2, 12, 28, 3, 57, 2, 0, 0, 0, 2, 17, 6, 4, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 31, 1, 14, 1, 0, 3, 0, 0, 0, 0, 0, 0, 0, 5, 5, 1, 5, 13, 25, 0, 0, 0, 32, 7, 12, 34, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 6, 5, 10, 2, 30, 11, 0, 15, 8, 6, 32, 11, 4, 0, 9, 12, 0, 0, 9, 0, 0, 12, 0, 0, 0, 0, 0, 0, 0, 0, 11, 7, 7, 12, 12, 0, 20, 1, 12, 17, 24, 0, 0, 0, 1, 9, 34, 5, 4, 2, 0, 0, 9, 4, 0, 0, 5, 0, 0, 0, 2, 0, 11, 0, 0, 11, 1, 0, 0, 0, 0, 7, 0, 0, 0, 0, 8, 0, 1, 0, 0, 0, 28, 1, 21, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 4, 12, 0, 0, 0, 11, 0, 0, 8, 13, 7, 5, 12, 3, 1, 12, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 49, 3, 12, 12, 12, 32, 8, 57, 0, 3, 11, 6, 0, 0, 0, 2, 0, 0, 0, 0, 0, 37, 0, 0, 0, 0, 0, 0, 14, 88, 7, 30, 1, 12, 9, 11, 9, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 20, 0, 0, 0, 0, 0, 23, 1, 2, 15, 5, 5, 7, 6, 5, 8, 0, 0, 0, 0, 0, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 18, 5, 1, 7, 0, 0, 0, 0, 0, 0, 0, 10, 1, 1, 12, 5, 12, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 11, 0, 0, 0, 0, 0, 13, 0, 0, 0, 0, 3, 0, 0, 0, 0, 2, 1, 21, 0, 7, 0, 0, 20, 11, 1, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 8, 2, 0, 11, 12, 20, 12, 9, 12, 1, 12, 4, 18, 5, 12, 10, 4, 34, 4, 1, 0, 0, 2, 0, 0, 0, 0, 0, 1, 9, 12, 12, 30, 7, 0, 12, 4, 3, 1, 11, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 13, 6, 1, 0, 3, 5, 41, 4, 8, 0, 1, 3, 11, 1, 0, 8, 0, 0, 0, 0, 0, 0, 12, 0, 0, 0, 0, 0, 38, 0, 0, 0, 0, 0, 1, 11, 5, 4, 6, 7, 0, 28, 3, 3, 0, 0, 9, 19, 0, 0, 0, 10, 7, 8, 11, 5, 2, 1, 0, 31, 12, 3, 18, 2, 6, 17, 7, 16, 4, 29, 0, 9, 47, 6, 0, 1, 11, 34, 42, 11, 2, 12, 7, 4, 0, 22, 11, 0, 11, 18, 0, 14, 1, 3, 36, 1, 26, 6, 0, 0, 12, 8, 12, 0, 0, 11, 8, 19, 0, 0, 0, 0, 9, 0, 0, 92, 30, 3, 7, 0, 0, 0, 29, 0, 0, 0, 0, 1, 10, 12, 0, 0, 0, 0, 0, 1, 3, 2, 9, 0, 1, 0, 0, 0, 11, 12, 17, 0, 0, 0, 11, 11, 28, 8, 11, 0, 6, 11, 50, 23, 0, 8, 21, 5, 2, 0, 3, 5, 11, 24, 5, 6, 11, 11, 0, 0, 0, 0, 0, 0, 23, 12, 6, 6, 3, 3, 0, 0, 4, 0, 38, 5, 0, 0, 27, 1, 4, 12, 2, 39, 11, 35, 3, 36, 1, 1, 21, 11, 3, 22, 0, 0, 0, 33, 24, 0, 1, 0, 12, 7, 0, 2, 11, 6, 17, 6, 1, 5, 1, 60, 25, 50, 10, 10, 4, 3, 3, 8, 20, 11, 28, 12, 0, 0, 0, 0, 0, 5, 1, 0, 12, 0, 0, 50, 8, 0, 12, 2, 13, 34, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 17, 0, 9, 12, 8, 0, 0, 0, 0, 0, 0, 30, 26, 0, 0, 0, 1, 1, 0, 0, 9, 0, 0, 0, 0, 7, 5, 0, 0, 7, 0, 0, 0, 1, 15, 12, 11, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0], "ttfts": [0.06407404899982794, 0.14900659999875643, 0.2790195070010668, 0.7364444510003523, 1.1499174509990553, 1.1223636790000455, 1.1191863490003016, 1.2710439049988054, 1.1873514140006591, 0.0, 2.699377580000146, 2.894019148998268, 3.085691633999886, 3.0813886349988024, 3.0260942909990263, 3.223801476000517, 3.3703810860006342, 3.3327709729983326, 3.0807690159999765, 3.1383636110003863, 3.0884536479989038, 3.0848443070008216, 3.159380052000415, 3.106830530001389, 3.533029993999662, 3.5222943409989966, 3.4713284589997784, 3.420198405001429, 4.079486862001431, 4.2579267820001405, 4.234795965001467, 4.439164064999204, 4.362144482000076, 4.658377773999746, 4.574902537000526, 4.528241942000022, 4.945092142999783, 5.071643569999651, 5.061341995999101, 5.019281606999357, 5.062477141998897, 5.042307028999858, 5.041393007999432, 5.6829443179995, 5.64403584899992, 5.598497135000798, 5.517507657999886, 5.697974847000296, 5.877713530000619, 5.818453379999482, 5.758574244000556, 5.83597268199992, 5.687021559999266, 5.597415459000331, 5.576603774001342, 5.77489457899901, 5.752350879000005, 5.7008059170002525, 5.577200967998579, 5.7684484040000825, 5.766624072000923, 5.700123688000531, 5.652594111999861, 5.612825782998698, 5.596347228000013, 5.583871700999225, 5.5369278239995765, 5.741967807000037, 5.710251976999643, 0.0, 6.322960006000358, 6.407204686000114, 6.610060593999151, 6.509137956998529, 6.472291600999597, 6.3092023320004955, 0.0, 6.864833390000058, 6.789811265000026, 6.735230693999256, 7.08004559300025, 7.201384521000364, 7.137276692999876, 7.1115716910007905, 7.325380774000223, 7.688122020999799, 7.84513684599915, 7.842004062000342, 7.807581265999033, 8.233135230000698, 8.047032974000103, 8.128533548000632, 8.09692791100133, 0.0, 9.480181021001044, 9.448286183000164, 9.437162222000552, 9.86338449700088, 9.984735935999197, 9.978663375000906, 10.3613022490008, 10.31756765800128, 10.301477876000718, 10.439423900999827, 10.567734914000539, 10.97022277600081, 11.157006596999054, 11.12941150700135, 11.497209646000556, 11.688014966000992, 12.059530353999435, 12.244543286999033, 12.147105580999778, 12.586397519000457, 12.570309245000317, 12.770243135999408, 12.656121080999583, 12.83293014300034, 12.778301681999437, 12.914825710000514, 12.914130965000368, 12.865414456000508, 13.006575511000847, 13.134617896999771, 13.035595104000095, 13.02250581699991, 12.993056325998623, 13.41115314200033, 13.522054400000343, 13.439255813000273, 13.431117996000467, 13.3462247009993, 13.387595281999893, 13.250764479000281, 13.462982237000688, 13.51063312000042, 13.366884269000366, 13.155692378999447, 13.309645563998856, 13.297808949000682, 13.28829358999974, 13.245321312999295, 13.403209407000759, 13.395687979000286, 13.841212835000988, 14.048040891999335, 14.010820464000062, 14.17813016099899, 14.16705900099987, 14.145467127000302, 14.52025897799831, 14.717019006000555, 14.713336356000582, 14.67142140100077, 14.847438992999741, 14.753046665000511, 14.962640616000499, 14.930336383000395, 14.72527236499991, 14.703424072000416, 14.62120862700067, 14.700675082000089, 14.675443538000764, 14.612916710999343, 14.528491913000835, 14.49045928400119, 14.289454168998418, 14.241361566000705, 14.438878290000503, 14.37336289599989, 14.453144744000383, 14.549153982001371, 14.673417533000247, 14.670869679001044, 14.634046626000782, 14.830641976999686, 14.797311397998783, 14.766588483000305, 14.65795903399885, 14.6077301360001, 14.460722994999742, 14.655395700001463, 14.518657571001313, 14.488610782998876, 14.350887114000216, 14.308360924000226, 14.191917919999469, 14.372874947001037, 14.359341095001582, 14.48428555099963, 14.385585210999125, 14.36767269899974, 14.753437733001192, 14.727077172999998, 14.672377202999996, 15.006039027999577, 14.981837258999803, 15.160196644999814, 15.517193891000716, 15.718971681999392, 15.65606125100021, 15.789975022998988, 15.777873345999978, 15.950556088000667, 15.852978506, 15.828390703998593, 16.038601182999628, 16.029365959999268, 16.00853912799903, 15.889316984999823, 16.090916307999578, 16.07724350800163, 16.251614397000594, 16.229288827000346, 16.18813385899921, 15.677113764999376, 15.835069888998987, 15.818535088999852, 16.101318609998998, 16.076113736999105, 15.99363801400068, 16.134439015999305, 16.078336047999983, 16.005220847999226, 16.004367386000013, 15.953422066999337, 16.14911428400046, 16.125111460998596, 16.1171857850004, 16.10201476600014, 16.077781739000784, 16.276583037999444, 16.215501989001496, 16.208935503000248, 16.158898903999216, 16.340122699000858, 16.492431980999754, 16.468122161999418, 16.570314802000212, 16.5685720700003, 16.4135752279999, 16.273802198998965, 16.448932256000262, 16.411578797999027, 16.395745161000377, 16.323108194999804, 16.429263025000182, 16.615176893001262, 16.393314353999813, 16.390372197000033, 16.365844926000136, 0.0, 17.029839369999536, 17.00467454599857, 16.84137191299851, 16.932897362999938, 16.77610387799905, 16.76077559800069, 16.6737117520006, 16.875199062998945, 16.840634658001363, 16.7845221890002, 16.776827009000044, 16.59806552400005, 16.595429738999883, 16.79901469499964, 16.78990643999896, 16.70397519299877, 16.671836496998367, 16.82575873499991, 16.769928044999688, 17.15380623800047, 17.693328090999785, 17.677115919001153, 17.61960340600126, 17.578939324999737, 17.761932585000977, 17.700700540999605, 17.658319153000775, 18.045416318000207, 18.005638074999297, 18.16890678799973, 18.37717826500011, 18.685401992999687, 18.681306492999283, 18.836946157000057, 18.802562308999768, 18.996826513999622, 18.958225917000163, 19.135019702000136, 19.081656846999977, 19.062530664001315, 19.432766226998865, 19.527305167999657, 19.898425384999427, 19.77643165399968, 19.935161463999975, 19.934782156000438, 19.877351429000555, 19.817409400999168, 19.79245521300072, 19.671115882998492, 19.865982624000026, 19.86089626300054, 19.835817674000282, 19.80654193400005, 19.769772448000367, 19.721751958999448, 19.900964237000153, 19.788661052998577, 19.77006233800057, 19.92310781999913, 19.853041189999203, 19.823272812998766, 20.015835222999158, 19.915742773000602, 19.886622060999798, 19.866586550999273, 19.990193175000968, 19.95417407700006, 19.861981183001262, 0.0, 19.775110219999988, 20.63452907300052, 20.61958613099887, 20.55248524700073, 20.740964515000087, 21.135961658999804, 21.086804741999003, 20.970346482999958, 21.138195167999584, 21.136580391999814, 21.263717261999773, 21.20713757700105, 21.3330861559989, 21.508467724001093, 21.388588080000773, 21.168469903001096, 21.15812066699982, 21.412394318000224, 21.58146151999972, 21.492634142001407, 21.490652821001277, 21.401541428998826, 21.378397740001674, 21.30021866900097, 21.287740620999102, 21.390096556999197, 21.373762647001058, 21.54225507299998, 21.538748412000132, 21.466585406999002, 21.671760831999563, 21.596043957000802, 21.56134518900035, 21.520999970000048, 21.505858664999323, 21.436603475000084, 21.635233323999273, 21.437092260999634, 21.599214992998895, 21.587501653999425, 21.726170325999192, 21.905526569000358, 21.82132004199957, 21.963153341999714, 21.958334721999563, 21.823413160998825, 21.621103277000657, 21.541377585999726, 21.751757105999786, 0.0, 22.329223668999475, 22.154514496000047, 22.28566996200061, 22.257901925000624, 22.445724278999478, 22.441101157999583, 22.376360369000395, 22.345875162000084, 22.28170671099906, 22.296389192000788, 22.269886781001333, 22.240521367000838, 22.232305442001234, 22.228133885000716, 22.200754740000775, 22.082413140000426, 22.374116801998753, 22.34400000000096, 22.448886948999643, 22.20553217000088, 22.100564201000452, 21.82378893400164, 21.820283078999637, 21.815230471998802, 22.17698720700173, 0.0, 23.240382824000335, 23.197201175000373, 22.929774782000095, 22.885209332998784, 22.90817594800137, 22.90408926099917, 22.76309094499993, 22.950531751001108, 22.857149105000644, 23.0379724480008, 22.98052594299952, 22.974017448999803, 22.965479356000287, 23.161858560999462, 23.093609802001083, 23.03343357199992, 23.461553119999735, 23.405689495999468, 23.58430898000006, 0.0, 24.62588202400002, 24.953884098000344, 24.93136229400079, 25.089029918999586, 25.05507377200047, 24.785368390999793, 24.731843323999783, 24.723841015998914, 24.839767868999843, 24.76447252499929, 24.74488657999973, 0.0, 25.86424176699984, 25.709907890999602, 25.85264643499977, 25.74805570999888, 25.679762317000495, 25.50058856800024, 25.696391211000446, 25.675554472998556, 25.86676828600139, 25.580970345001333, 25.44744369, 25.364072308000686, 25.53645192499971, 25.513056518000667, 25.655185857000106, 25.442321880000236, 25.3496402210003, 25.319598447998942, 25.259851071999947, 25.462350121999407, 25.372787456999504, 25.362283040001785, 25.54891833200054, 25.488190670999757, 25.664549946999614, 26.034243062000314, 26.017553466999743, 26.009978587999285, 25.971225171999322, 26.401696069000536, 26.388668841000253, 26.449640123999416, 26.382233276999614, 26.287687051999455, 26.101253308001105, 26.549633983000604, 26.53450673899897, 26.374895251001362, 26.342150569000296, 26.369928940001046, 26.29838464900058, 26.227148089001275, 26.198629910000818, 26.161725848998685, 26.526313305001167, 26.64542957699996, 26.864650724000967, 26.94074781100062, 26.86013826999988, 26.940631149000183, 27.37384575499891, 27.574791033999645, 27.545804022000084, 27.53615789700052, 27.701982836000752, 27.69745163299922, 27.83083368000007, 28.00180908599941, 27.98715057499976, 27.90109828000095, 28.11101622299975, 28.324626725998314, 28.485181558000477, 28.691668884001047, 29.093871050001326, 28.881239087999347, 29.27447929200025, 29.198832599000525, 29.173407121999844, 29.055432158000258, 28.78459777200078, 28.89438834900102, 29.041523305000737, 28.77176734099885, 28.631635986999754, 28.526250120999975, 0.0, 29.448968504999357, 29.284976717999598, 29.50485888900039, 29.54585902800136, 29.71902607999982, 0.0, 30.706993723000778, 30.66964893399927, 30.539128831998823, 30.51005083900054, 30.782714837998356, 30.991147486000045, 31.397175736999998, 31.395224829000654, 31.31898649499999, 31.286231681000572, 31.279420147000565, 31.24149579600089, 31.1843984620009, 31.52093809500002, 31.715720868000062, 31.608967914999084, 31.707478914000603, 31.580283810000765, 31.725105469999107, 31.911433266999666, 31.65218651000032, 31.46560024899918, 31.460373685000377, 31.41213253100068, 31.40766534999966, 31.53768855599992, 31.905216115999792, 31.465662538001197, 31.789333753999017, 31.77496327100016, 31.987702786000227, 32.40228992700031, 32.29072517500026, 32.474860280999565, 32.3221897200001, 32.504222692999974, 32.44484370800092, 32.35986146799951, 32.139026353999725, 32.23204571399947, 32.11735132300055, 32.104162158999316, 32.51948448300027, 32.48480188999929, 32.43885736300035, 32.416215684001145, 32.36531240899967, 32.757102775998646, 32.726515499000016, 32.87520170599964, 32.84101921600086, 32.81852060200072, 32.80021151999972, 32.78168222400018, 32.981330733000505, 32.967442952000056, 33.10873228699893, 33.19386377000046, 33.06490831600058, 33.039244632998816, 0.0, 33.91867898400051, 34.079626963999544, 34.04853342699971, 34.04366386000038, 33.94567334800013, 33.970466146000035, 33.91701647800073, 34.527352634000636, 34.520147487999566, 34.48565021499962, 34.652208015000724, 34.64107165599853, 34.786324995999166, 34.635981043000356, 34.795899472999736, 34.669950009001695, 34.606836233999275, 34.78552883199882, 34.74255332299981, 34.65957064400027, 34.65585913299947, 34.831551557999774, 0.0, 35.41046732599898, 35.394343334999576, 35.58683719600049, 35.47571603100005, 35.41776395499983, 35.835523611998724, 0.0, 36.4605411600005, 36.37840276600036, 0.0, 37.46350047600026, 37.452330490999884, 37.440979188999336, 37.435257070999796, 37.328334806001294, 37.5274245519995, 37.44644760200026, 37.60810002400103, 37.517660733999946, 37.92106575300022, 37.916506278999805, 38.3254086550005, 38.2889578459999, 0.0, 38.68480601699957, 38.87802974900114, 38.851845410999886, 38.681481413001165, 38.37302603599892, 38.334259520999694, 38.728537590001, 38.68815743699997, 38.64340789099879, 38.811659685999985, 38.73226753699964, 38.65306743399924, 38.64400986700093, 38.6332273479984, 38.79001165699992, 38.72144199499962, 38.69357202200081, 38.759645254000134, 38.980623780000315, 38.911775671000214, 39.11442513700058, 39.221858795001026, 39.17381170699991, 39.125511856998855, 39.265828413001145, 39.187648810999235, 39.20631311899888, 39.11809010900106, 39.31200027200066, 39.275134801000604, 39.2468615100006, 39.390687450999394, 39.358814690000145, 39.56236729800003, 39.4004021890014, 39.36591723899983, 39.18481189200065, 39.10409245200026, 39.1546326560001, 39.046360870999706, 38.97885121999934, 38.97515751799983, 38.85956373100089, 38.993296905000534, 38.79394979499921, 38.78431604099933, 38.98963704699963, 38.94317911200051, 0.0, 39.411902656000166, 39.5554345670007, 39.51575919999959, 39.50236144200062, 39.67294968100032, 39.63447207399986, 39.632166696999775, 39.82568010000068, 0.0, 40.68846867399952, 40.65407505999974, 40.84394939500089, 40.83618997799931, 41.03404858199974, 40.95898726500127, 40.76429108999946, 41.17984292899928, 41.16995861000032, 41.14999882899974, 41.584752815000684, 41.782177003999095, 41.71288323800036, 41.68115559299986, 41.66359148599986, 41.82105456800127, 41.67526605800049, 41.87611981699956, 41.818614088000686, 41.74796688399874, 41.92245288800041, 41.763907518999986, 41.750717724000424, 41.751636388000406, 41.84074304600108, 41.808899421001115, 42.140849950999836, 42.01340256500043, 42.443345390000104, 42.54098981700008, 42.45026900800076, 42.35685073999957, 42.52562756899897, 42.46616851199906, 42.446454815000834, 42.6553023059987, 42.573945334999735, 42.77186477599935, 42.74891487199966, 42.74578828000085, 42.90746852899974, 42.785438502000034, 42.78008868500001, 42.95415079399936, 42.84238825599823, 42.748546233000525, 42.73355060499853, 42.9237791329997, 43.070101742998304, 43.052835488999335, 43.23180104899984, 43.13513356200019, 43.07318707899867, 43.066468966000684, 43.034617743000126, 43.46618686700094, 0.0, 44.143762382000205, 44.10020638700007, 43.986167966999346, 43.91359958199973, 43.87255316399933, 43.718229781001355, 43.92576882600042, 43.741830424, 43.6093021509987, 43.72931457900086, 43.57242836500154, 43.763303339999766, 43.63443145899873, 43.59108129700144, 43.78772326199942, 43.974539528000605, 44.39217522099898, 44.46720752900001, 44.6576169279997, 44.63804254899878, 44.80630343099983, 44.79210163799871, 44.628291854000054, 45.00747088800017, 44.93586312200023, 44.77965817400036, 44.97565037899949, 44.95521851200101, 45.09435751199999, 45.019846229000905, 44.907334715000616, 44.826102155000626, 45.2622854300007, 45.40627989299901, 45.3080709829992, 45.17947995799841, 45.05064758499975, 45.036085096000534, 45.01817051600119, 45.16395632000058, 45.12378323700068, 45.09322795800108, 45.10028641200006, 45.085387200000696, 45.40148443900034, 45.34322670199981, 45.47501459900013, 45.380776705000244, 45.33984081199924, 45.11037153699908, 45.27402553700085, 45.2527824280005, 45.10286146399994, 45.26746378799908, 45.10223778100044, 45.053714056999524, 45.03722878799999, 45.22355346099903, 45.40879826800119, 45.393976400999236, 45.36447226199925, 45.34279482000056, 45.47202088299855, 45.45398711999951, 45.56639901699964, 45.36736020900025, 45.530869571999574, 45.48741639000036, 45.610209103999296, 45.7804855710001, 45.77591363099964, 45.7255623559995, 45.67775017399981, 0.0, 0.0, 47.20145450000018, 47.361382901999605, 47.35088166600144, 47.56319937899934, 47.95244855099918, 47.92362692799907, 48.04908097600128, 48.22159019500032, 48.0724384719997, 48.06089668000095, 47.907992168999044, 47.89581946599901, 48.08371919899946, 48.0677522499991, 47.971514865001154, 47.937544120000894, 48.263415189001535, 48.61582934600119, 48.60890131999986, 48.606564444999094, 48.76974408299975, 48.84259585399923, 49.04216262299997, 49.21542164799939, 49.2121835930011, 49.17112945000008, 49.07007378799972, 49.2327645080004, 49.19681300299999, 49.38740943099947, 49.338500814001236, 49.22364079399995, 49.83055029699972, 49.80892169899926, 49.71197541199945, 49.91156657300053, 49.9070058289999, 49.89265465900098, 49.845513705000485, 49.822978607999175, 49.749299590999726, 49.6333446489989, 49.80598233300043, 49.71836986699964, 49.6998391369998, 49.590979554001024, 49.429621246999886, 49.397204463999515, 49.39224204899983, 49.56923632700091, 49.747531319999325, 49.70259593999981, 49.6572429150001, 49.527959946999545, 49.66955144399981, 49.66429234700081, 49.597715869998865, 49.49935469000047, 49.70117112099979, 49.893897349000326, 49.74213254999995, 49.548042600999906, 49.540986284999235, 49.58466482299991, 49.12359015700167, 49.08198749300027, 48.97087709600055, 48.95533555500151, 48.9148715299998, 49.12081813699842, 49.044379041000866, 0.0, 50.219094612000845, 50.20270480199906, 50.19228730300165, 50.37333883999963, 50.256429180999476, 50.21758037199834, 50.35812818100021, 50.16250867999952, 50.522647902000244, 50.5053411300014, 50.49986618499861, 50.61134927999956, 51.02743838800052, 50.96509401000003, 50.80813210300039, 51.20479173000058, 51.15941147100057, 51.1293066649996, 51.08521769099934, 51.013843443999576, 51.1667051179993, 51.27159436799957, 51.423142829000426, 51.38998846499999, 51.144769294998696, 51.28399598500073, 51.409066267000526, 51.376188764999824, 51.29713786100001, 51.39510463499937, 51.33686990099886, 51.32915887300078, 51.491384843999185, 51.474161608999566, 51.4396630730007, 51.59873566399983, 51.52211555499889, 51.48641841599965, 51.88948503899883, 52.10427878900009, 52.23761139199996, 52.23407808200136, 52.653584666000825, 52.58549392100031, 52.56231476299945, 52.91318436099937, 52.94727791399964, 53.099499976000516, 53.19247852499939, 53.270877220998955, 53.25426095500006, 53.05987853700026, 53.03002532699975, 53.02589934400021, 53.43606038500002, 53.42373701299948, 53.404141164000976, 53.5606040549992, 53.716220263999276, 53.70388460399954, 54.11746467899866, 54.056608980999954, 54.214148789998944, 54.16290373499942, 54.224987689000045, 54.353236843999184, 54.33107156400001, 54.289541050999105, 54.28337389800072, 54.680539290000524, 54.50527990300179, 54.42996669199965, 54.347138570001334, 54.31332254300105, 54.26502250200065, 54.497183823999876, 55.09495258300012, 55.056532389000495, 54.973637704000794, 55.11534256900086, 54.89617467700009, 54.904367574999924, 54.80427997699917, 54.784074630999385, 54.94795647799947, 54.9794943779998, 55.18718230000013, 55.180249916998946, 55.139604530000724, 55.28296999900158, 55.484620958999585, 55.90096870799971, 55.456745101000706, 55.81255280199912, 55.797199103999446, 55.887855508999564, 55.83581989300001, 55.7722552539999, 56.21470118199977, 56.40967003300102, 56.380972831999316, 56.42640942500111, 0.0, 57.10839155299982, 57.30163610599993, 57.43273481200049, 57.40927173900127, 57.35216958000092, 57.30583909800043, 0.0, 57.851652645000286, 58.02441576899946, 57.899859266999556, 57.65362813399952, 57.8366913560003, 57.92419743000028, 57.84845819399925, 58.02658382599839, 57.774837596, 57.8452568470002, 57.816603332999875, 57.64849909500117, 57.568535513000825, 57.71221691500068, 57.691535724999994, 57.668240977000096, 57.849558222998894, 57.68896096000026, 57.857851464001214, 57.74437841600047, 58.148621071999514, 58.04558348899991, 58.044952678999834, 57.99463514800118, 58.29335634800009, 0.0, 59.45585684100115, 59.34663709099914, 59.553802524000275, 59.75894006499948, 59.6978213099992, 60.09115803399982, 59.98466439399999, 59.93009234300007, 59.92571600300107, 59.85831101800068, 59.856183051999324, 59.816443995001464, 59.77688056500119, 59.86846964800134, 59.787514382000154, 59.776492045999476, 59.944879142998616, 60.15441609800109, 60.16920388499966, 60.12589584000125, 60.07310197799961, 60.48656503700113, 60.481085584999164, 60.899462846999086, 60.974542893000034, 61.343187434000356, 61.317095389000315, 61.26160354499916, 61.1734287599993, 61.18661282699941, 60.98568989500018, 60.90781765000065, 60.78845294600069, 60.75741308100078, 60.85572677699929, 61.23667529999875, 0.0, 61.18880483599969, 62.579173821999575, 62.422579413001586, 62.32512558900089, 62.207085525000366, 62.16186854899934, 62.34806297199975, 62.18812213000092, 62.13711896699897, 62.325405800000226, 62.36217855799987, 62.34821632100102, 0.0, 63.42676870499963, 63.322815321000235, 63.26152845599972, 63.21484697100095, 63.17272916799993, 63.37736643000062, 63.34178118199998, 63.529985508999744, 63.12700508499984, 63.48266976800005, 63.40068538199921, 63.31513676299983, 0.0, 63.86801699500029, 63.85492043299928, 63.965906447001544, 63.96104838999963, 63.926806908999424, 63.87395907500104, 63.86321017699993, 64.05146712299938, 64.04783713500001, 64.0414939050006, 64.02962171800027, 64.45657287200083, 64.88755041100012, 64.82843554200008, 65.03099607399963, 64.98183184499976, 64.97771152600035, 65.12030471199978, 65.09458146399993, 65.05994907200147, 65.276808487999, 65.11457159299971, 65.23074624800029, 65.22775365800044, 65.11860141899888, 65.289198425, 65.4760480399982, 65.42613047699888, 65.21548410299874, 65.38893371199993, 65.57532433500091, 65.52287778200116, 65.95080243300072, 66.3430099849993, 66.3151764209997, 66.28344789099901, 66.4197836330004, 66.62085462499999, 66.56993216000046, 66.76181452700075, 66.73676466699908, 66.68487930500123, 66.83842602500044, 66.8010429549995, 66.84311021099893, 66.83257478400083, 66.82183008900029, 0.0, 67.45757648499966, 67.64501012500114, 67.57728355399922, 67.68060159699962, 67.67474652700002, 67.49228263400073, 67.58435743600057, 67.56185132800056, 67.68407682200086, 67.67145601099946, 67.53170837499965, 67.46559962699939, 67.77710176499932, 67.7424638930006, 67.62781117300074, 67.7936917219995, 67.70507316600015, 67.70470461200057, 67.8990203379999, 67.84311433199946, 67.77780068200082, 68.20830073400066, 68.19100566400084, 68.32085527299932, 68.29985918800048, 68.44219691800026, 68.6135131530009, 68.49498454499917, 68.64703884899973, 68.80196328599959, 68.7795921830002, 68.9787309050007, 69.18417635599872, 69.2971634630012, 69.26793862900013, 69.43882162400041, 69.71181567799977, 69.91205173699927, 69.84843042100147, 70.02180303800014, 70.02114156100106, 69.94712416399852, 70.1534273239995, 70.08401509500072, 70.48118983099994, 70.41957715299941, 0.0, 71.27447196399953, 71.43279059999986, 71.3016429269992, 71.6137339320012, 71.72422681399985, 71.51050653899983, 71.43759727899851, 71.34116672199889, 71.31928128300024, 71.52240713500032, 71.48352667299878, 71.69118666299983, 71.59922373799964, 71.56634075999864, 71.74770883699966, 71.95120987799964, 71.74792873200022, 71.91770969299978, 72.06342265999956, 71.91013026300061, 71.78883492900059, 71.75521153400041, 71.91933472100027, 71.9075770090003, 71.70750373400006, 71.76911625899993, 71.91939994699896, 71.89656152300086, 71.75000827099939, 71.73177487599969, 71.73284427600083, 72.11314785299874, 72.00812311700065, 72.00812842699997, 72.13852847700036, 72.08215229099915, 72.28161276900028, 72.26058050000029, 72.14685075600028, 72.2898161159992, 72.25902539300114, 72.24668843499967, 72.40724243499972, 72.34004135599935, 72.33610724499886, 72.75851158300065, 72.73803162500008, 72.6889581029991, 72.73614462600017, 72.66498427099941, 72.66514026700133, 72.5720126569995, 72.786561506, 0.0, 73.87315396200029, 73.72607767999943, 74.11473084099998, 74.0863397159992, 74.02472383300119, 74.2259097949991, 74.22449606999908, 74.2085277310016, 74.08768421599962, 74.49733148900123, 74.59368485699997, 74.57161227100005, 74.49502010099968, 74.6962446389989, 74.51703907099909, 74.61672309200003, 74.83170410899947, 75.02126369600046, 75.01868668700081, 74.76807424700019, 74.63702488100171, 74.8260220939992, 74.76600181499998, 0.0, 75.2357827779997, 75.21833242499997, 75.40426669100088, 75.34750342999905, 75.53484063099859, 75.52535119200002, 75.51486177299921, 75.09716062900043, 75.63848957499977, 75.58480096499989, 75.57270602899916, 75.57220359599887, 75.95337958299933, 75.95102460399903, 76.26011946300059, 76.20785944899944, 76.43010501699973, 76.84154663999834, 76.83649707899895, 76.75600345099883, 76.89173265400132, 76.84006116700039, 76.7753143989994, 76.72722762299964, 76.7258222140008, 76.84586554400084, 76.82830712400028, 76.86178477000067, 77.0549385939994, 77.02547246600079, 76.9939241129996, 76.9890905049997, 76.97869841500142, 76.99079247899863, 76.95684470800006, 76.89920500399967, 76.87894884399975, 76.86169836200133, 76.82383267200021, 76.96201576599924, 77.15819910900063, 77.01975933599897, 76.9880713349994, 77.10726792399873, 77.33842891099994, 77.12744619099976, 77.27196777599966, 77.1460250300006, 77.08013421600117, 76.9439649520009, 77.30928521900023, 77.23793012700116, 77.20079628299936, 77.38102576800156, 77.28702906800027, 77.27158374399914, 77.09187053300047, 76.89022060100069, 77.13207820599928, 77.10787260300094, 77.32571181899948, 77.31885296800101, 77.24307632099953, 77.21844135899846, 77.21726617700006, 77.19732033999935, 77.06512569699953, 77.21853391600052, 77.2081533920009, 77.13151665300029, 76.99963395499981, 77.06415748100153, 77.04095386900008, 77.22071238900025, 77.60163797200039, 77.59046518200012, 78.24774261999846, 78.24027573100102, 78.10624059099973, 78.08969918300136, 78.08911928699854, 78.08394250099991, 78.50756584699957, 78.49804404799943, 78.66503797800033, 78.46523511399937, 78.41126650700062, 78.57278386799953, 0.0, 79.15623857799983, 79.1068842170007, 79.0662654989992, 79.01903543499975, 79.13435112099978, 79.02311398200072, 79.23127156800001, 79.66972107899892, 79.59992039600002, 80.01010630599922, 80.41544086900103, 80.38892901700092, 80.33090594700116, 80.25488416100052, 80.16602932400019, 80.1586476550001, 80.34586140200008, 80.54030538799998, 80.51307405700027, 80.62295765999988, 80.60101327600023, 80.59706711999934, 80.55952722199982, 80.89838012899963, 80.87078545199984, 81.02424862100088, 81.00066173399864, 81.15307998299977, 81.31982170300034, 81.68936365700029, 81.60408070700032, 81.79795475199899, 81.78756694500044, 81.78105596700152, 81.7728706529997, 0.0, 82.77383652699973, 82.67769060300088, 82.868826377, 83.05973451300088, 82.98256885600131, 83.14650651899865, 83.36340462500084, 83.21150372699958, 83.15624862799996, 83.35732229800124, 83.48801645799904, 83.35334906099888, 83.52885310500096, 0.0, 83.71220738199918, 83.8836838369989, 83.86263380700075, 0.0, 84.84738964200005, 84.84568336300072, 84.77436316499916, 85.1480462999989, 85.07211581000047, 0.0, 85.69217189200026, 85.61709086399969, 86.00297537299957, 85.80952452499878, 86.20510428600028, 86.38827579600002, 86.36499021800046, 86.36327756699939, 86.27104777600107, 86.2214734549998, 86.20077106499957, 86.1964733069999, 86.60982646800039, 86.56249869900057, 86.45723403600095, 86.41260832900116, 86.31836849000138, 86.08189542800028, 86.2745731849991, 86.2638110450007, 86.36900187799984, 0.0, 86.73713898499955, 86.68120918600107, 86.40763660599987, 86.5337952689988, 86.47454086499965, 86.46170432399958, 86.44917706399974, 86.58971108600053, 86.50670727999932, 86.49903921499936, 86.70182385500084, 86.60389060800117, 86.72359214700009, 86.66748136899878, 87.06873536600142, 87.04677591799918, 87.15385796800001, 87.57165191899912, 87.55989250200037, 87.74616785899889, 87.73503739800071, 87.64315891100159, 87.76380212799995, 87.69020148799973, 87.64381787900129, 87.748785658001, 87.7238259450005, 87.90475421299925, 87.86187582099956, 87.83679767800095, 87.7796543580007, 87.77194469699862, 87.75069356099993, 87.68830988100126, 88.07661549499971, 88.27767506700002, 88.25603499000135, 88.02284730599968, 87.82993089800038, 87.81373426400023, 88.1931237179997, 88.12983290900047, 88.41124872100045, 88.27201787800004, 88.35910704799971, 88.12971199399908, 88.12825449299999, 88.10123028799899, 88.30561429099907, 88.27950351100117, 88.66794586800097, 88.65332259000024, 88.64490896000098, 88.84708230199976, 88.42704301500089, 88.34200970299935, 88.2307396819997, 88.27677277399926, 88.22728767999979, 88.23948104800002, 88.39402362100009, 88.48660640900016, 88.83029210799941, 88.81434027599971, 88.93675125000118, 89.0039414920011, 88.9841408329994, 88.86521757599985, 88.82542676499907, 88.84514671100078, 89.21927796399905, 89.21459794799921, 89.20317236299888, 89.20193644599931, 89.15074746799837, 89.1748510890011, 89.1613670480001, 89.03002014900085, 89.0140412619985, 89.0289439219996, 89.0260368649997, 89.0239102659998, 89.15773558799992, 89.61648926100133, 89.54432214400003, 89.64628568199987, 89.56505740600005, 89.70282206400043, 89.69517798999914, 89.68221238499973, 89.70871334100048, 89.63657935399897, 89.5473025249994, 89.39911083200059, 89.81438138399972, 89.70978771000046, 89.70732219099955, 90.03401728399876, 89.93684641999971, 90.19900547100042, 90.64642011999968, 90.85561447200052, 90.83264487199995, 90.819223262999, 90.81065744100124, 90.75737672300056, 90.71674248400086, 90.91923658399901, 91.37862013000085, 91.36839327600137, 91.34292799899958, 91.2717706830008, 91.61092066000128, 92.22482450300049, 92.21329630200125, 92.14208608099943, 92.27164505099972, 92.11628249400019, 92.0979517199994, 92.23423825700047, 91.96619025899963, 92.36236891800036, 92.27246629799993, 92.48978209500092, 92.62756745500155, 92.61923627400029, 92.7440283929991, 92.70082323300085, 92.65098713600128, 92.95066466800017, 93.10921237399998, 93.28425284600053, 93.24612166899897, 93.19743759999983, 93.35071882900047, 93.55290151599911, 93.47863547199995, 93.43991821799864, 0.0, 94.3492160120004, 94.3161584419995, 94.30565133500022, 94.50318423200042, 94.47017129699998, 94.31214971700138, 94.2275194140002, 94.21808014099952, 94.5852315709999, 94.98613533800017, 95.09324921100051, 94.95919866700024, 95.12434082499931, 95.10870661400077, 95.10506918599822, 95.07841342000029, 95.19071638899914, 0.0, 96.26383454999996, 96.25508822499978, 96.10324634599965, 96.54508175200135, 96.95905677399969, 97.1347749889992, 97.59029978699982, 97.58256495299975, 97.42948879099822, 97.48840460099927, 97.56900045799921, 97.55925166099951, 97.74336061000031, 97.72356624900021, 97.87240413299878, 97.75834409600066, 97.79258422199928, 97.76565502400081, 97.73521044500012, 97.63760747000015, 97.59508070300035, 97.46269249999932, 97.63290676799988, 97.6068152659991, 97.55739390300005, 97.47885861800023, 97.44976082699941, 97.60915338500126, 97.89623251599915, 0.0, 98.10244193200015, 98.26421779599877, 98.59451255299973, 98.5409652519993, 98.92660798700126, 98.76952675400025, 99.13241281599949, 99.36765132999972, 99.23513967299914, 0.0, 100.00407303799875, 99.98299617299926, 0.0, 101.04468488100065, 101.00166217900005, 100.95518065299984, 101.27064539599996, 101.17831168400153, 101.125448331999, 101.11865226699956, 101.28605071699894, 101.23321366500022, 101.1896610040003, 101.04139968599884, 101.13043196699982, 101.12278997400063, 100.86725707299956, 100.83681510000133, 101.12616853799955, 101.09275542499927, 101.07067953200021, 100.9934273229992, 101.60316132400112, 101.5250658469995, 101.51361052999891, 101.43852964399957, 102.00834718100123, 101.98688375799975, 102.27777723799954, 102.17639010099992, 102.10722072399949, 102.09477626099942, 101.822845228, 0.0, 102.86414107600103, 102.8693530290002, 102.8440503210004, 102.92433976800021, 102.89358607000031, 102.83745276799891, 102.82691652600079, 103.02092277199881, 0.0, 103.5856947680004, 103.46865517200058, 103.49251777800055, 103.43553711200002, 103.32163836899963, 103.44608147300096, 103.37280444899989, 103.36461543799851, 103.49857039700146, 103.4949514279997, 103.44725096600087, 103.6330223169989, 104.07517398599884, 104.00197712999943, 104.189742655999, 104.18392503700125, 104.15333558699967, 104.4961909679987, 104.52906360900124, 104.51301935900119, 104.69772477600054, 104.66782887000045, 104.73759016400072, 104.66340555999886, 104.65848441299931, 104.65503368200007, 105.07343794100052, 105.24433176500133, 104.98581279800055, 104.94901232099983, 105.08714471799976, 104.99999309300074, 104.86921951300064, 105.04241800399905, 0.0, 105.70276513099998, 105.64880956199886, 105.77074533599989, 105.70140476899905, 106.09039210300034, 106.06527162100065, 106.03800126900023, 105.94230855099886, 106.09853024099903, 106.04415725300169, 105.987447513, 105.89838167400012, 105.91336503299863, 105.89195196899891, 105.6365346370003, 105.60251132799931, 105.3202112910003, 105.307684419, 105.39859208999951, 105.37371707799866, 105.29459471399969, 105.405842406999, 105.60262915600106, 105.5922009470014, 105.57487730600042, 105.49759890600035, 105.46224608900047, 105.42796297200039, 105.42122514100083, 105.37848529099938, 105.79789217500002, 106.2280918689994, 106.41605207200155, 106.39473169600024, 106.74047875500037, 106.80377082099949, 106.6689398819999, 106.50745836100032, 0.0, 107.14997802399921, 107.07349569199869, 107.25979908499903, 107.24200627899882, 107.22189080899989, 107.16003375100081, 107.12282311499985, 0.0, 108.8503695620002, 108.82913282899972, 108.80007499699968, 109.41200995399959, 109.38558181199915, 109.31697436699869, 109.56330189599976, 109.72884738799985, 109.64365952000117, 0.0, 110.4459251570006, 110.56110012200043, 110.89051979500073, 110.8818049140009, 110.88040560800073, 110.81265501500093, 110.73044105199915, 110.92554316400128, 110.9294943140012, 111.04910592700071, 111.00334466300046, 111.43556621199969, 0.0, 112.30882439299967, 112.44219483100096, 112.4081656620001, 112.5535470119994, 112.24839273999896, 112.43188611699952, 112.56241843700082, 112.50063901499925, 0.0, 113.4919090530002, 113.77701044400055, 113.771623790999, 113.71180530399943, 113.68769475999943, 113.72903361299905, 114.1442142370015, 114.2792151449994, 114.25614213500012, 114.21197626399953, 114.33372605800105, 114.07619230000091, 113.89743217900104, 113.82376042100077, 114.02883770799963, 114.23806988599972, 114.07332478399985, 114.24761373799993, 114.4057372870011, 114.28347243100143, 114.3593274169998, 114.7780280320003, 114.9397247320012, 115.30504993199975, 115.26886967700011, 115.2163095069991, 115.16719840500082, 115.28535107300013, 115.18236633199922, 115.44139448500027, 115.26192613800049, 115.73626100399997, 115.29167477300143, 115.94184148500062, 115.8983200549992, 115.89315783600068, 116.19824346600035, 0.0, 116.06816143499964, 117.2086825360002, 117.1830658380004, 116.97008538500086, 117.15281084900016, 117.1368355149989, 117.11376533399925, 117.05828290999852, 117.00567813499947, 117.16837095899973, 117.37603285700061, 117.2983063669999, 117.47757281800114, 117.42895967600089, 117.36175577799986, 117.24495949799893, 117.22159776800072, 117.17982026800019, 117.31733423200058, 117.25820418799958, 117.14743155399992, 117.12591495499873, 117.33359163799832, 117.53028004500084, 117.37113662900083, 117.53416921500138, 117.52460984699974, 117.3488308119995, 117.34745997500067, 117.52149564999854, 117.49517261099936, 117.6011536950009, 117.78017132999958, 117.72231404299964, 118.11229917499986, 118.09179089600002, 117.76268150600117, 117.72799642800055, 117.91444201299964, 118.06119241499982, 118.03590347800127, 117.991316869, 117.95040729999891, 117.87796247799997, 118.0520585180002, 118.0336730529998, 117.87454661799893, 117.85651726499964, 117.97009872900162, 117.9626710020002, 117.92147562000173, 117.86786749400017, 118.03934331199889, 117.91341604799891, 117.83588094600054, 117.7055624830009, 117.81723587600027, 117.80322402300044, 117.69238082899938, 117.66154975399877, 117.86493173399867, 117.85581123200063, 117.67487231300038, 117.66277128299953, 117.85647220700048, 118.27416824799911, 118.21046684999965, 118.19151708199934, 118.17203209400031, 118.35025542999938, 118.7844122259994, 118.86568183700001, 118.70051601100022, 119.13698628800012, 118.988723501001, 118.92561061000015, 119.13392502100032, 119.0410978839991, 119.2396635389996, 119.01982689400029, 119.52189758599889, 119.45777015199928, 119.48351973399986, 119.48087172899977, 119.41457416599951, 119.84450179299893, 119.76192361500034, 119.78564440599985, 119.5464632559997, 119.33651864500098, 119.31470608799827, 119.30114442299964, 119.51134081799864, 119.84435520900115, 119.82895688600001, 119.78596527799891, 119.93564274399978, 120.1184167020001, 120.33073203999993, 120.23790658000144, 0.0, 121.1125219709993, 121.2941311300001, 121.65069600500101, 121.60021879300075, 121.90601611700004, 121.83360476400048, 121.80984239999998, 121.80450311700042, 122.26968238500012, 121.92684264499985, 122.1226047550008, 122.11206559199854, 122.10251453300043, 122.09317699299936, 122.26585553899895, 122.12842607499988, 122.79111601799923, 122.77999728400027, 122.7727467349996, 122.88396811499842, 122.8205238649989, 122.7391134369991, 122.7353279529998, 122.85248220500034, 122.8212029639999, 122.67028609499903, 122.8844795999994, 0.0, 124.25393496699871, 124.22621646300104, 124.3850906860007, 124.19828529799997, 124.13573832200018, 124.0713566939994, 124.05433866400017, 124.0287459909996, 123.77839011499964, 123.92385079500127, 123.83032994200039, 123.80186228299863, 124.11156117500104, 0.0, 125.17324199899849, 125.29777672100136, 125.67207186399901, 125.8255535929984, 125.61660361099894, 125.45103529500011, 125.52551270200092, 125.94354244900023, 125.90180906800015, 126.09953127799963, 126.09641523299979, 125.89776986499965, 126.05070008899929, 125.94345711100141, 125.85503190700001, 125.89260377699975, 125.86154252599954, 125.73389575100009, 125.6704326909985, 125.87685879499986, 125.84248821100118, 125.69904323100127, 125.66560221700092, 125.4761409670009, 125.40155280399995, 125.56569448099981, 125.55866905400035, 125.47587567899973, 125.45778643300036, 125.66048678300103, 125.18480019500021, 125.55980317500143, 125.50369273700016, 125.45490540100036, 125.81932174800022, 125.77836230499997, 125.69281609799873, 125.64891550299944, 125.59693366600004, 125.58753664399956, 125.42635521699958, 125.77134337899952, 125.69470286399883, 125.69276191200152, 125.4923787179996, 125.3562676420006, 125.41290883799957, 125.28864766099832, 125.31856963999962, 125.29586921999908, 125.27533328800018, 125.47878127600052, 125.45552409599986, 125.57798434100005, 125.46258889199999, 125.43814399000075, 125.58998880200124, 125.46391124699949, 125.30790749100015, 125.26442487000168, 125.45705191399975, 125.22304383400115, 125.28886363899983, 125.24422848699942, 0.0, 126.71095690499897, 126.8913601430013, 127.05278256599922, 127.05230971399942, 127.25135791499997, 0.0, 127.65091116500116, 127.71940732700023, 128.1312182390011, 128.00232851700093, 128.39654647300085, 128.8057172610006, 128.99742033099938, 128.862400987, 128.73901742199996, 128.83609584499936, 128.78839029899973, 128.782097719999, 128.59716399599893, 128.56557329000134, 128.76959129200077, 128.82508757200048, 128.6239655540012, 128.57847600399873, 128.51898580499983, 128.72993623500042, 128.66699931699986, 128.54586848399958, 128.96280141500029, 129.11087141899952, 128.99888169299993, 128.8786336689991, 128.86774604200036, 129.06338468600006, 129.47608061200117, 129.43148596600076, 129.6245002099986, 129.60577950400148, 129.58687458500026, 129.48354661399935, 129.43163293600082, 129.82626942299976, 129.80768939399968, 129.882591779, 130.03030433000094, 129.93080005500087, 130.13526858099976, 129.9569828549993, 0.0, 130.9828340039985, 130.89528522699948, 130.8794184769995, 131.26775616899977, 131.25498430399966, 131.42611947800106, 131.4101626619995, 131.2147348540002, 131.0885347600015, 131.28777923100097, 131.48080119299993, 131.38871554099933, 131.5063807689985, 131.87575032099994, 131.8017287549992, 131.9875049809998, 132.0981996390001, 131.8699630480005, 131.81428286400114, 132.00182082100036, 131.9218864939994, 131.8982688749984, 131.74726185100008, 131.95052329499958, 132.15253233600015, 132.3496586959991, 132.3142081369988, 132.27514063300077, 132.21800069500023, 132.63880825399974, 132.79004731200075, 0.0, 0.0, 0.0, 132.90595566699994, 133.1053190219991, 133.27952891799941, 0.0, 0.0, 0.0, 0.0, 0.0, 133.56547353399947, 133.5382043139998, 133.5100384969992, 133.64078088399947, 133.58199224000055, 133.75353776500015, 133.69694205000087, 0.0, 0.0, 0.0, 133.53079858500132, 0.0, 0.0, 133.2763208590004, 133.1135723490006, 133.5479303789998, 133.53608974100098, 133.65509518899853, 0.0, 0.0, 133.48947400399993, 133.6769100399997, 0.0, 0.0, 0.0, 133.4586403680005, 0.0, 0.0, 133.28329435499836, 133.26910500300073, 133.4742713430005, 133.4490492950008, 133.22516751299918, 133.16394327200032, 0.0, 0.0, 0.0, 0.0, 132.6762046269996, 132.60745608300022, 132.59060514700104, 0.0, 132.44120758499957, 0.0, 0.0, 133.21457063399976, 133.39615234600024, 133.56520610500047, 133.4212866609996, 0.0, 0.0, 133.03651009200075, 132.84110225699987, 133.00525698899946, 133.42187936700066, 133.39259465100076, 0.0, 0.0, 0.0, 0.0, 0.0, 133.01584263699988, 0.0, 0.0, 0.0, 0.0, 0.0, 132.9040290489993, 133.06663880999986, 0.0, 132.96754960999897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 132.62496308899972, 132.59442983699955, 0.0, 132.62295931600056, 0.0, 0.0, 0.0, 132.45399304600141, 0.0, 0.0, 0.0, 0.0, 132.4146418780001, 132.38358280899956, 0.0, 132.1942853599994, 132.26213120900138, 0.0, 132.19439622699974, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 131.62144193099994, 131.7259546589994, 131.5718060069994, 131.76168208199852, 131.72904717299934, 131.70721455000057, 131.4926278999992, 131.87124686900097, 131.82354592800039, 0.0, 0.0, 131.597587070999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 131.3239443099992, 131.53405704499892, 0.0, 0.0, 0.0, 0.0, 131.41504542700022, 131.3594042069999, 0.0, 0.0, 131.97140356099953, 132.22604112999943, 132.10833411500062, 132.07399019500008, 0.0, 132.6217282359994, 0.0, 132.68672186600088, 132.8649835870001, 0.0, 0.0, 0.0, 0.0, 132.6912043930006, 132.5774760130007, 132.21238866399835, 132.3537978129989, 132.34148071100026, 132.32306677500128, 132.22997228699933, 132.36216441599936, 132.54069902999981, 132.63001719599924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 132.12199398899975, 131.9906705249996, 131.97317192300034, 0.0, 131.82179967999946, 131.76188308999917, 131.94461632399907, 0.0, 0.0, 131.8096556420005, 0.0, 0.0, 131.57110364099935, 131.97976367000047, 0.0, 0.0, 131.86284364099993, 131.8570234960007, 0.0, 0.0, 0.0, 0.0, 0.0, 131.82786827900054, 131.82659420000164, 131.68653914399874, 0.0, 132.02187141600007, 131.9846458459997, 131.88427695599967, 131.84722710900132, 131.9701101819992, 131.85836639300032, 131.77761025600012, 131.9479044540003, 132.12555153700123, 0.0, 0.0, 0.0, 0.0, 0.0, 131.8154194919989, 0.0, 0.0, 0.0, 0.0, 131.6089131489989, 131.5430356199995, 131.74111457100116, 0.0, 0.0, 131.96706808099952, 131.87052224900071, 131.78942391800047, 0.0, 0.0, 0.0, 0.0, 131.80851441099912, 0.0, 0.0, 131.5554589179992, 131.5402444020001, 131.6854140589985, 0.0, 0.0, 131.76768136199826, 0.0, 131.5305542770002, 0.0, 131.3046100749998, 131.4734223659998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 131.19013907999943, 131.16162561799865, 131.14425228000073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 130.85790617100065, 0.0, 130.73390813699916, 130.71810631900007, 130.5814896569991, 130.5753237329991, 130.40824933399927, 130.36632178000036, 130.5130237279991, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 130.16775619700093, 130.22657304199856, 130.22023640299994, 130.1648440099998, 130.35076366400062, 130.3120936080013, 130.4459060090012, 130.32109748999937, 130.1031243689995, 130.1010931180008, 0.0, 0.0, 130.16531875799956, 130.10776642200108, 0.0, 0.0, 0.0, 0.0, 0.0, 130.0069893609998, 130.21190170199952, 130.34740679900096, 130.44355619999988, 0.0, 0.0, 0.0, 130.16834664499947, 130.32293389500046, 130.68849196800147, 131.09952430399971, 131.23432281299938, 131.20273314100086, 0.0, 131.32432645500012, 0.0, 0.0, 0.0, 0.0, 0.0, 131.08072965099927, 131.26844637999966, 131.1556897679984, 130.9280985660007, 130.91061835799883, 131.0651590180005, 131.03136874700067, 130.91365479399974, 130.91347281499839, 130.87546951399963, 0.0, 130.65820864000125, 0.0, 0.0, 130.64344981400063, 130.6268000150012, 130.56897306799874, 130.70967379600006, 130.64363692400002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 130.66010340100001, 130.79009808199953, 0.0, 0.0, 0.0, 131.03969763999885, 130.96290825399956, 130.92673960899992, 130.868901799, 131.06935743699978, 131.0514348249999, 131.01583250300064, 130.89187278999998, 0.0, 130.52659137699993, 0.0, 130.64967026799968, 130.6102486689997, 0.0, 130.47176951300025, 130.6142386320007, 0.0, 0.0, 0.0, 130.45569567100029, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 129.9892234150011, 129.8954339060001, 0.0, 129.97361015299975, 0.0, 0.0, 0.0, 0.0, 0.0, 129.80435798300095, 129.97050605599907, 0.0, 0.0, 0.0, 0.0, 129.76393497699974, 130.16718378900077, 0.0, 0.0, 130.48679850699955, 130.4778655450009, 130.68684314100028, 130.6703010989986, 0.0, 130.69647679599984, 130.664800853001, 0.0, 0.0, 0.0, 130.36398047199873, 0.0, 0.0, 130.46184656400146, 130.38137195799936, 0.0, 130.21391833599955, 130.39692445500077, 0.0, 0.0, 0.0, 130.00278826300018, 130.19903486000112, 0.0, 0.0, 0.0, 0.0, 0.0, 129.8763547030012, 129.8685360950003, 129.86249565899925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 129.63615035899966, 129.3290158839991, 129.38195830399854, 129.5965891070009, 129.51581839499886, 0.0, 0.0, 0.0, 129.21043270299924, 129.0282784030005, 129.02425735199904, 129.0074376299999, 0.0, 129.05297079400043, 129.01461726600064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 128.5924749149999, 128.74145728499934, 0.0, 128.68799969500105, 128.79157331200076, 128.92839230400023, 128.88576444700084, 128.80289995099884, 0.0, 0.0, 128.68539620600131, 128.8503132120004, 0.0, 0.0, 0.0, 128.67609252699913, 128.64394381799866, 128.79513782499998, 0.0, 0.0, 0.0, 128.5534912259991, 128.7281136670008, 129.19335888800015, 129.38489459300035, 0.0, 129.21833605999927, 129.36776478899992, 129.23675330900005, 129.3815430550003, 0.0, 0.0, 129.1669908090007, 129.03065462700033, 0.0, 0.0, 128.8186613960006, 128.8152842140007, 0.0, 0.0, 0.0, 0.0, 0.0, 129.0404577929985, 128.77270567300002, 128.9527178570006, 128.90168948800056, 129.01699407500018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 128.62220688699927, 129.02328948899958, 0.0, 0.0, 0.0, 129.04543780800122, 129.0106730970001, 0.0, 0.0, 0.0, 129.22159275300146, 0.0, 0.0, 129.22119684899917, 129.2015057610006, 0.0, 0.0, 0.0, 0.0, 128.9995044119987, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 129.57999747800022, 0.0, 0.0, 0.0, 129.33682171200053, 129.33148701900063, 129.4573760960011, 129.20893195700046, 129.18809858199893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 129.29673066599935, 129.71828680499857, 0.0, 0.0, 129.44098368900086, 129.44437502499932, 0.0, 0.0, 0.0, 0.0, 0.0, 129.13933335000002, 128.99296397300168, 129.1506817519985, 129.0701479290001, 0.0, 129.2292748029995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 128.33103857800052, 128.52415432999987, 128.48435021600017, 128.4495204190007, 128.62982026999998, 128.56960755399996, 128.7502935800003, 128.92186358599974, 128.74515077700016, 128.56306270099958, 128.5584389530013, 0.0, 0.0, 0.0, 0.0, 128.37477337699966, 0.0, 0.0, 0.0, 0.0, 0.0, 128.33997971699864, 128.49162346000048, 128.2463667030006, 128.23059781099983, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 127.92250307900031, 127.88993290299913, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 127.4021181950011, 0.0, 0.0, 0.0, 127.01647245500135, 127.21230380199995, 127.20188236800095, 0.0, 0.0, 127.2678357299992, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 126.81409556499966, 126.63890694400106, 126.62876670100013, 126.59544739100056, 126.75637087599898, 126.68868595399908, 0.0, 126.62524733600003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 126.82537404600043, 126.80228839099982, 0.0, 0.0, 126.61011964300087, 126.79886340499979, 0.0, 0.0, 0.0, 126.82779676500104, 126.77562922300058, 0.0, 126.60973147200093, 126.81396477999988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 126.48166269899957, 126.46622663900052, 126.40772978399946, 126.48456557999998, 126.40127595500053, 126.30504663200009, 126.45316741600072, 126.42895071900057, 126.2340454109999, 126.19163886299975, 126.29904160200022, 0.0, 126.24700094799846, 126.42464274200029, 0.0, 0.0, 0.0, 126.03651483999965, 125.9770322559998, 0.0, 0.0, 0.0, 0.0, 125.9435061990007, 125.83511147999889, 125.82780023900159, 125.70915614200021, 125.6755313119993, 125.60974140199869, 0.0, 0.0, 0.0, 0.0, 0.0, 126.69824096299999, 126.72508906199982, 126.57028296299904, 126.50407689500025, 126.44361670299986, 126.5314792549998, 126.66342215300028, 126.62448880199918, 0.0, 0.0, 0.0, 0.0, 126.25028484799986, 126.31053836800129, 126.28848719300004, 126.27186575300038, 126.47670462899987, 0.0, 126.18124706499839, 125.9696919320013, 0.0, 126.60955498600015, 126.53000998099924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 126.24027225399914, 126.42611510300048, 0.0, 126.04736375299944, 0.0, 0.0, 0.0, 0.0, 0.0, 126.00069153600089, 0.0, 0.0, 125.80578226600119, 125.99006587900112, 0.0, 0.0, 0.0, 0.0, 0.0, 125.98731103600039, 0.0, 0.0, 125.98983793400112, 125.83647091700004, 125.75381220800045, 125.74065138300102, 125.73557995800002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 125.3702898219999, 125.55016074099876, 125.6986542980012, 125.84751659699941, 125.99033244199927, 126.0978714339999, 0.0, 126.92085772300015, 127.12399387499863, 127.0561332920006, 127.03972154000076, 127.01043033799942, 0.0, 0.0, 126.86838166900088, 126.66850061600053, 0.0, 0.0, 0.0, 126.22830105200046, 126.35003379199952, 0.0, 0.0, 0.0, 126.44077691600069, 0.0, 0.0, 0.0, 0.0, 0.0, 126.38747811199937, 126.51973837699916, 126.45492433900108, 126.36883953599863, 126.35227249200034, 0.0, 0.0, 126.04951940399951, 126.02741687999878, 126.23000135599978, 126.20661131899942, 126.14253918500071, 126.2210966040002, 0.0, 0.0, 125.8224854300006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 125.23812010499933, 0.0, 0.0, 0.0, 0.0, 0.0, 124.81680788999984, 124.98300389399992, 0.0, 0.0, 0.0, 124.84616919799919, 124.79469939199953, 0.0, 124.687021705, 124.53789938699992, 124.51978999800122, 124.69022203199893, 0.0, 124.59471484999995, 124.57670715400127, 0.0, 0.0, 0.0, 0.0, 124.35085618100129, 124.33127992000118, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 125.07974524900055, 0.0, 126.08047323600113, 126.07969678100017, 0.0, 0.0, 125.85583540300104, 126.17860241299968, 0.0, 0.0, 0.0, 0.0, 126.05503834000046, 126.0488176050003, 0.0, 126.08538733600108, 126.52257291100068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 126.24589677499898, 126.21182395899996, 0.0, 0.0, 126.21888513399972, 126.11739599800057, 126.08482799699959, 0.0, 0.0, 0.0, 126.03037591300017, 125.9405176780001, 125.92308373000014, 126.34861895700124, 0.0, 0.0, 126.45518817800075, 0.0, 126.05877488099941, 125.99276812800053, 125.91923680099899, 125.90833472200029, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 125.50236225299886, 125.71386604500003, 0.0, 125.54231135699956, 125.46672982000018, 0.0, 0.0, 0.0, 0.0, 126.62795177000044, 0.0, 0.0, 0.0, 0.0, 0.0, 126.2000711310011, 126.38487841799906, 126.36518963299932, 126.32808773599936, 0.0, 0.0, 126.18473710299986, 126.17621829400014, 125.9269776279998, 0.0, 125.80467126599979, 125.77448987000025, 125.71434797800066, 125.65952954099885, 125.60160562700003, 125.59761937800067, 125.7000247019987, 0.0, 0.0, 125.70929216600052, 0.0, 0.0, 0.0, 0.0, 0.0, 125.47979021500032, 125.47357569199994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 125.20557935400029, 0.0, 0.0, 0.0, 0.0, 125.02082724599859, 0.0, 0.0, 0.0, 0.0, 124.72451672699935, 0.0, 124.60855207700115, 124.60681297500014, 0.0, 0.0, 0.0, 124.63288461299999, 124.60712888700073, 124.9661371179991, 124.92449961800048, 124.85183598600088, 124.94384814499972, 125.09071113299979, 125.27791600300043, 0.0, 125.13213571100096, 124.98090132799916, 0.0, 124.78907579900078, 0.0, 0.0, 0.0, 0.0, 0.0, 125.00247668100019, 124.88811752699985, 0.0, 125.25206640800025, 125.1380119409987, 0.0, 125.53782946299907, 0.0, 125.59336266799983, 125.46103557699826, 125.40224808700077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 124.40511022499959, 124.31989228200109, 0.0, 124.05097312699945, 124.21929092000028, 0.0, 0.0, 123.85920129599981, 123.84628875300041, 0.0, 0.0, 123.87062230899937, 123.77092104700023, 0.0, 123.87980183799846, 0.0, 0.0, 0.0, 0.0, 124.58074396099983, 0.0, 0.0, 124.25424492999991, 0.0, 0.0, 124.14486868499989, 124.32211336299952, 124.2466275049992, 0.0, 0.0, 124.43365045599967, 0.0, 124.30078630999924, 0.0, 124.07746883900109, 124.1510394959987, 124.09391626300021, 124.29260499100019, 0.0, 124.13318823699956, 0.0, 0.0, 0.0, 0.0, 123.88298716900135, 124.03340240800026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 123.45583873400028, 123.4504315539998, 123.40761313199982, 0.0, 0.0, 0.0, 0.0, 123.14292635899983, 0.0, 0.0, 123.08660473499913, 0.0, 0.0, 0.0, 0.0, 0.0, 123.06958347399996, 123.0465179999992, 123.24284288699891, 123.10531551399981, 123.0773969740003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 123.27693492100116, 0.0, 0.0, 0.0, 0.0, 0.0, 123.43999524900028, 123.30213141099921, 123.0198891050004, 122.99184893200072, 123.09228518700002, 123.02404608000143, 123.20059128799949, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 122.97412161200009, 0.0, 0.0, 0.0, 122.67830402199979, 123.03629533100138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 122.91699861799862, 0.0, 0.0, 0.0, 0.0, 122.73618213599912, 122.81679701999929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 122.7250050090006, 0.0, 0.0, 0.0, 0.0, 0.0, 122.88260332800019, 122.871555351001, 0.0, 0.0, 0.0, 0.0, 122.63335034400006, 122.58330839799964, 0.0, 0.0, 122.40617980000025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 121.78498811399913, 121.5601207489999, 121.93522317699899, 121.84319630400023, 121.97834138799954, 121.82864165499996, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 121.32292491199951, 121.48625955099851, 121.30145998300031, 0.0, 0.0, 121.52993021600014, 0.0, 0.0, 0.0, 121.39117769499899, 121.74273565099975, 121.69110082500083, 0.0, 0.0, 121.5718096290002, 122.00799224600087, 122.16507418200126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 122.25803703999918, 122.44866099199862, 0.0, 122.29588573000001, 122.71497650499987, 122.84339757999987, 122.94040125399988, 122.87395781099985, 122.85300111499964, 123.26045454300038, 0.0, 0.0, 0.0, 123.11250636599834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 122.87086999200073, 122.6480232390004, 122.76588158100094, 122.66759686099977, 0.0, 0.0, 0.0, 0.0, 122.40515074699942, 122.39471644700097, 0.0, 123.31705528100065, 0.0, 0.0, 125.08776040500015, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 124.98958062800011, 125.1880504109995, 125.17081494500053, 125.09880816900113, 0.0, 125.89984875899972, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 125.51684510800078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 125.78864741399957, 125.76919452699985, 125.89620015100081, 125.63216983799975, 125.57123630100068, 125.70648181700017, 125.65402587500103, 125.75381682700026, 125.74108346400135, 125.66504307800096, 125.64974115699988, 125.77992345500024, 125.77543588799927, 125.97096433400111, 125.95622484200067, 126.13965030800136, 126.12483759800125, 0.0, 0.0, 0.0, 126.34987975200056, 126.34816348000095, 126.1660253329992, 126.34484137300024, 126.54465366800105, 0.0, 0.0, 0.0, 0.0, 0.0, 126.28103648999968, 126.22102487300072, 126.16048446500099, 0.0, 0.0, 126.26013063900064, 126.25774830199953, 0.0, 0.0, 125.99061158199947, 0.0, 0.0, 125.6261032049988, 125.98654460599937, 125.98031272300068, 125.76991570099926, 0.0, 0.0, 125.81127818500136, 126.24291030999848, 0.0, 0.0, 126.15660841300087, 0.0, 125.92610563100061, 0.0, 0.0, 125.8976074809998, 126.23273038800107, 0.0, 126.28141629600032, 126.26929166000082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 126.21445380600017, 0.0, 126.07076968399997, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 125.12503550499969, 125.54139377899992, 0.0, 125.37848225699963, 0.0, 0.0, 0.0, 0.0, 0.0, 124.94870161200015, 124.93594936899899, 125.06641137800034, 124.82806794099997, 124.7935144990006, 124.91318695900009, 124.74378096700093, 0.0, 0.0, 0.0, 0.0, 0.0, 124.73599254000146, 124.68014908199984, 0.0, 0.0, 0.0, 0.0, 0.0, 124.27203635600017, 124.4698425860006, 0.0, 0.0, 0.0, 0.0, 124.19522072200016, 124.19095813499916, 124.33635340799992, 0.0, 124.62141474300006, 124.49934475900045, 0.0, 0.0, 0.0, 124.1959295910001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 123.79610769600004, 0.0, 0.0, 123.72117833799894, 0.0, 0.0, 123.74078080400068, 123.90241289199912, 0.0, 0.0, 0.0, 0.0, 0.0, 123.7492668369996, 0.0, 123.64756254300119, 123.51744052899994, 123.87442285999896, 0.0, 0.0, 0.0, 123.65205366700138, 0.0, 123.81394215900036, 0.0, 0.0, 123.4825143040016, 123.59287638800015, 0.0, 0.0, 122.97494520600048, 0.0, 0.0, 0.0, 123.03438137800003, 0.0, 0.0, 122.78203422899969, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 122.17661958099961, 122.14372232599999, 0.0, 121.95341614999961, 122.12765608500013, 122.09491068200077, 0.0, 0.0, 0.0, 0.0, 121.95908306400088, 0.0, 0.0, 121.6446298789997, 121.83722816200134, 121.81256050800039, 121.68060204500034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 121.96838497299905, 121.90603697299957, 122.00768887800041, 122.17345683999883, 122.14371999899959, 0.0, 0.0, 121.8345138579989, 121.95552662500086, 121.92231650999929, 0.0, 0.0, 121.95106071100054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 121.52144663299987, 0.0, 0.0, 121.28983788999903, 121.28099193200069, 0.0, 0.0, 120.64866440100013, 0.0, 120.78613552600109, 0.0, 120.56822619499872, 0.0, 0.0, 0.0, 0.0, 120.29395534000105, 0.0, 0.0, 0.0, 120.00641364999865, 0.0, 0.0, 0.0, 119.72464407199914, 0.0, 0.0, 0.0, 120.21158381200075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 119.66716225900018, 119.6301419370011, 119.29591744500067, 119.65787344300043, 119.86173012899962, 119.8425978719988, 119.8408355169995, 119.66968094000003, 119.6248799570003, 119.67094740799985, 119.60151766700073, 119.54952748100004, 119.74565133800024, 119.70806339599949, 119.57083003999833, 119.76072153300083, 120.1961582649983, 120.32094893900103, 120.32059385499997, 120.4498506609998, 120.56236376700144, 0.0, 120.12269770200146, 120.51119221899899, 120.50020485999994, 120.35593073400014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 120.06780252899989, 120.27464090799913, 120.18972557700181, 120.16175290199863, 120.27237023499947, 120.19659848599986, 120.14391539500139, 120.29774894699949, 120.72772839800018, 120.67718457299998, 120.65406656800042, 0.0, 0.0, 0.0, 0.0, 0.0, 120.65768808400026, 120.6042407290006, 120.5482689269993, 120.73740591800015, 120.62823229300011, 120.81395861499914, 120.78673419500046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 120.98931678000008, 0.0, 0.0, 0.0, 0.0, 0.0, 120.62180935099968, 120.52631921699867, 120.47703000000001, 120.30884109699946, 120.25348635000046, 120.4522617700004, 120.43621434899978, 120.19580712800052, 120.37817332799932, 120.56175540999902, 120.51446597299946, 120.51305252200109, 120.46089177999966, 120.65830511599961, 121.06874132499979, 0.0, 0.0, 0.0, 0.0, 120.90888816099869, 120.90178587199989, 120.89447402800033, 121.10802201700062, 120.88650519400107, 0.0, 0.0, 121.12315676199978, 121.01696586700018, 120.75290526400022, 120.79353956900013, 120.7173194320003, 120.71573497499958, 120.92511507699965, 120.6316481949998, 120.5970022299989, 120.4945003770008, 120.44527930600088, 120.27495692899902, 0.0, 0.0, 0.0, 120.26496183699965, 0.0, 0.0, 120.0389239289998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 119.98813330000121, 0.0, 0.0, 119.84318776799955, 0.0, 0.0, 0.0, 0.0, 120.06791242800136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 119.64067743000123, 0.0, 0.0, 0.0, 0.0, 0.0, 120.60016232199996, 120.50076373299999, 120.3921540930005, 120.2765027229998, 120.46940325799915, 0.0, 120.30075049100014, 120.48111302899997, 120.59582147900073, 120.98718298800122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 120.68745040500107, 120.5844520720002, 121.00627469900064, 120.7817110649994, 121.13534282799992, 120.86593885199909, 120.85951589499928, 121.05890431199987, 121.01540874199964, 0.0, 120.77391424200141, 120.75124131300072, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 119.594078660999, 119.55531631600024, 0.0, 0.0, 0.0, 119.63436762299898, 119.50643063499956, 0.0, 0.0, 0.0, 119.36867693100066, 119.6878891410015, 119.57428349900147, 0.0, 0.0, 0.0, 0.0, 119.53849486299987, 0.0, 0.0, 0.0, 119.62193348599976, 0.0, 0.0, 119.30484179999985, 0.0, 0.0, 0.0, 0.0, 119.000926617, 119.08042574899991, 0.0, 119.02342520099955, 0.0, 0.0, 119.0276591210004, 119.01952955600063, 119.22901060299955, 0.0, 0.0, 0.0, 119.18155083800048, 119.11188373699952, 0.0, 119.00191281300067, 0.0, 0.0, 119.19759999000053, 119.1908866699996, 0.0, 0.0, 0.0, 118.90346976100045, 118.80868077000014, 118.78797068099993, 118.96262005900098, 0.0, 0.0, 118.77947404299994, 0.0, 0.0, 0.0, 118.54121288200076, 118.74809198100047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 118.48743913300132, 118.64505255299991, 0.0, 0.0, 118.49201356599951, 118.68512291400111, 118.6068969830012, 0.0, 0.0, 0.0, 119.0549197520013, 0.0, 0.0, 0.0, 118.90314308099914, 0.0, 0.0, 0.0, 0.0, 0.0, 118.62166758499916, 0.0, 0.0, 118.45872207100001, 0.0, 0.0, 0.0, 118.59894001000066, 118.79970091999894, 118.95313848799924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 118.4981671229998, 0.0, 0.0, 117.94680655100092, 117.83316433099935, 117.7872613970012, 117.95284113299931, 117.92226757999924, 117.8350312420007, 117.80285783, 0.0, 0.0, 0.0, 117.87966946899905, 117.83567309499995, 117.95056873100111, 117.83396721700046, 117.91159454400076, 0.0, 0.0, 117.84005100300055, 117.7336703990004, 117.64653197900043, 117.79285035500106, 117.99670291700022, 0.0, 117.5135892369999, 117.44684679300008, 117.63941142600015, 117.77900540399969, 117.73035164300018, 117.71223311600079, 117.656192208, 117.81459776600059, 118.01596546699875, 118.01437355900089, 118.07198027999948, 118.00503685299918, 117.87124180699902, 118.18321159100014, 118.14846446800038, 118.10960626199994, 118.23383316800027, 118.20970261500042, 118.17562895399897, 118.13577403400086, 118.182798894999, 118.15799902099934, 118.554524313, 118.72070134800015, 119.11745760799931, 119.10837040800106, 119.07440221899924, 119.16558593100126, 119.13266699999986, 119.10575467600029, 0.0, 0.0, 0.0, 118.90182507300051, 119.06590354000036, 118.92904625200026, 118.87524521199884, 0.0, 0.0, 0.0, 118.76823877999959, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 118.41848710999875, 118.36607998699947, 118.53414248300032, 118.86573259400029, 0.0, 118.73423609200108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 118.05984840200108, 118.46408048400008, 118.73103238099975, 118.7063761770005, 118.66121289700095, 118.84433170699958, 0.0, 0.0, 0.0, 118.75368597200031, 118.59847505000107, 118.5941261980006, 118.77456975099994, 0.0, 0.0, 0.0, 0.0, 0.0, 118.51291888599917, 0.0, 0.0, 0.0, 0.0, 0.0, 118.52080489699983, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 118.0831358180003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 117.31021544800024, 117.15192573799868, 117.28285810399939, 117.2611190330008, 117.48351917900072, 117.43693316900135, 0.0, 118.9841573270005, 118.85479759599912, 119.19811794999987, 119.06116496399954, 119.01237599600063, 118.95268425700124, 0.0, 119.06317249399945, 119.05939040699923, 0.0, 0.0, 118.87051234899991, 0.0, 0.0, 118.65235839600064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 118.33014180600003, 118.31467922899901, 118.22243029899983, 118.17888439600029, 118.29233181600102, 0.0, 118.14878634100023, 118.52544924199901, 118.49730233500122, 118.85129136400064, 118.77962388600099, 0.0, 0.0, 0.0, 118.55410311100059, 118.50648666699999, 118.6783145139998, 118.65014102900022, 118.95003237499986, 118.87951219499882, 0.0, 0.0, 118.65590294400135, 118.71732689300006, 0.0, 0.0, 118.62857965399962, 0.0, 0.0, 0.0, 118.32993535700007, 0.0, 118.10927026199897, 0.0, 0.0, 118.1001671619997, 118.09742749799989, 0.0, 0.0, 0.0, 0.0, 117.69700360299976, 0.0, 0.0, 0.0, 0.0, 117.59907277300044, 0.0, 118.27870914800042, 0.0, 0.0, 0.0, 117.91993224900034, 117.87407070300105, 117.82980115600003, 117.80606782200084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 117.73931304399957, 0.0, 0.0, 0.0, 0.0, 0.0, 117.73962166599995, 117.65758195400122, 0.0, 0.0, 0.0, 117.51318845300011, 0.0, 0.0, 117.53995221999867, 117.94508188799955, 117.91209770899877, 117.78805609899973, 117.68689290300063, 118.09212552999998, 118.03363945799902, 118.01164590799999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 117.59432364199893, 0.0, 0.0, 117.30124039899965, 117.27311130499947, 117.17987984999854, 117.09251309899992, 117.12900003399955, 117.04128897999908, 117.23143600700132, 117.23121799399996, 0.0, 117.35112253300031, 117.33541447300013, 117.28811131700058, 0.0, 0.0, 0.0, 117.09442657900036, 0.0, 0.0, 0.0, 0.0, 0.0, 116.95439369800079, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 116.50112337099927, 116.70654669800024, 116.66376336699977, 116.42135197099924, 116.37310305699975, 116.53819480200036, 116.50045138299902, 116.63665574600054, 116.60286870500022, 0.0, 0.0, 0.0, 0.0, 116.27242640899931, 0.0, 0.0, 0.0, 0.0, 116.24224848300037, 116.4467724749993, 0.0, 0.0, 0.0, 0.0, 0.0, 116.36786601600033, 116.3400148210003, 116.27376319800169, 116.66089264899892, 116.65924142800031, 116.60485630699986, 116.5895304149999, 116.78768536799907, 116.9609356309993, 116.94920905400068, 0.0, 0.0, 0.0, 0.0, 0.0, 116.81816598399928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 116.59718513100051, 116.80082805699931, 116.79434632700031, 116.82871664900085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 116.4465803259991, 116.620742866, 116.59160456999962, 116.80147981699884, 116.79789132500082, 116.79292674399949, 117.16239264400065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 116.8035364389998, 116.78497325900025, 0.0, 0.0, 0.0, 0.0, 0.0, 116.61272255999938, 0.0, 0.0, 0.0, 0.0, 116.29913479899915, 0.0, 0.0, 0.0, 0.0, 116.40710039100122, 116.37967902200035, 116.36887687799936, 0.0, 116.12989405199914, 0.0, 0.0, 116.12631330400109, 116.19948875299997, 116.177598141001, 116.62005254500036, 0.0, 0.0, 116.38332130399976, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 116.18630824399952, 0.0, 0.0, 0.0, 116.15997812400019, 116.07675109100092, 0.0, 116.09345576899977, 115.79406534599912, 115.63943722499971, 115.48011147800025, 115.46637328500037, 115.82906720399842, 116.02376361200004, 116.00479989000087, 116.44728576400121, 116.44201602200155, 116.6418061000004, 116.61661663799896, 116.55917496999973, 116.41623506500036, 116.85826973599978, 116.84027780899851, 117.01025887799915, 0.0, 0.0, 116.85376894299952, 0.0, 0.0, 0.0, 0.0, 0.0, 116.56500059000064, 116.47769446400162, 116.46302436299993, 116.22749983599897, 116.26185860499936, 116.25633647799987, 0.0, 116.01944242699938, 116.36032875899946, 116.26228565400015, 116.18252102800034, 116.17474233899884, 0.0, 0.0, 0.0, 0.0, 115.80012909300058, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 115.79986246700173, 115.76192619300127, 115.96515646999978, 0.0, 115.81761978800023, 115.80887690399868, 115.78804592699998, 115.71227555500082, 115.67605650299993, 0.0, 115.5880123070001, 115.44220184000005, 115.5804130810011, 115.53688906800016, 0.0, 115.34797263800101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 115.72121485400021, 0.0, 0.0, 0.0, 0.0, 0.0, 115.54773574299907, 0.0, 0.0, 0.0, 0.0, 0.0, 115.26073530100075, 115.03692341999886, 115.192287803, 115.18621273600002, 115.24262245299906, 115.44458057600059, 0.0, 115.80834423299893, 116.01397437999913, 115.97981022599924, 0.0, 0.0, 115.87386642399906, 116.03943851799886, 0.0, 0.0, 0.0, 115.91953139899852, 115.89214756100046, 115.6040597379997, 115.56836815499992, 115.4828827170004, 115.63457563600059, 115.78770665500087, 0.0, 116.64143342600073, 116.61345978899953, 116.63945968699954, 116.49103483100043, 116.93487953099975, 116.90902936400016, 116.89301594999961, 116.84121998299997, 117.26547983300043, 117.4324188419996, 117.62685817300007, 0.0, 118.14889662199857, 118.26505531000112, 118.25608398100121, 0.0, 118.17328959599945, 118.14355573699868, 118.0168104430013, 118.22071764999964, 118.07936975200028, 118.23577165200004, 118.17265093100104, 118.61011561600026, 118.484161675, 0.0, 118.53814229599993, 118.4414569239998, 0.0, 119.02719787100068, 119.23449199899915, 0.0, 119.48945802799972, 119.47753753899997, 119.45205293599975, 119.3615442219998, 119.28937888399923, 119.2317377090003, 119.21723925900005, 0.0, 0.0, 119.04777131599985, 118.99814063200029, 119.4369782800004, 0.0, 0.0, 119.05764206200001, 119.25797154400061, 119.18579019999925, 0.0, 0.0, 0.0, 0.0, 118.80814512899997, 0.0, 0.0, 118.66464744299992, 118.84320446000129, 118.82035953000013, 119.00737830300022, 0.0, 0.0, 0.0, 118.83924143799959, 0.0, 0.0, 0.0, 0.0, 118.66227390000131, 118.65790069499963, 118.63584357000036, 0.0, 0.0, 0.0, 0.0, 0.0, 118.33566234600039, 118.53423499900055, 118.52384044700011, 118.52130361199852, 0.0, 118.43976173900046, 0.0, 0.0, 0.0, 117.97762565099947, 117.95800775499993, 118.33060613500129, 0.0, 0.0, 0.0, 118.4052054499989, 118.40173257499919, 118.38357767600064, 118.35811882100097, 118.54836875599904, 0.0, 118.35320418999981, 118.51057176500035, 118.44224049399963, 118.58972771700064, 0.0, 118.38884936499926, 118.37050546700084, 118.24508548400081, 118.23756886800038, 0.0, 118.34289238199926, 118.15659285199945, 118.0470197579998, 118.03436456700001, 117.82790370899966, 117.987141384001, 117.9076323420013, 118.08451730500019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 117.94820782100032, 117.88069888799873, 117.9184342539993, 117.83741279400056, 117.82459263700002, 117.80430763599907, 0.0, 0.0, 117.89541482599998, 0.0, 117.6712096049996, 117.60435612100082, 0.0, 0.0, 117.16393078799956, 116.99904383899957, 117.40347747300075, 117.38854396600073, 117.59381099700113, 117.76254968800095, 117.92476016399996, 117.90837628500049, 117.85191823100104, 118.02057308799886, 117.92592589100059, 117.91530335799871, 117.77215479599909, 117.87928807900062, 117.79455949899966, 117.63594043200101, 0.0, 0.0, 0.0, 117.70662086000084, 117.65585213699887, 0.0, 118.07288758200048, 0.0, 117.97220844899857, 118.41281991599863, 0.0, 118.41084959199907, 118.46624681699905, 118.08065077399988, 118.5259949299998, 118.52553161500146, 118.45385686100053, 118.65142474700042, 118.78450774400153, 118.97194426199894, 118.96942733600008, 118.9661942319999, 118.93187050900087, 118.79992088799918, 118.70616915399842, 118.61858336300065, 118.61310550100097, 118.31419446299878, 118.74084693700024, 118.72754965099921, 118.83983114200055, 118.82443797600172, 0.0, 0.0, 0.0, 0.0, 0.0, 118.80269673700059, 119.14999514999909, 0.0, 118.95574836100059, 0.0, 0.0, 118.99697495600049, 119.31814360600038, 0.0, 119.16056785900037, 119.07489110499955, 119.0305509310001, 118.9787180050007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 118.59920367400082, 0.0, 0.0, 0.0, 118.32942168299996, 0.0, 118.34683413499988, 118.32131962400126, 118.3011257170001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 118.83355506800035, 118.99796668400086, 0.0, 0.0, 0.0, 119.05918010799905, 118.91475149699909, 0.0, 0.0, 118.78721506700094, 0.0, 0.0, 0.0, 0.0, 118.78488708999976, 118.76971517700076, 0.0, 0.0, 118.82215350299884, 0.0, 0.0, 0.0, 118.57191818999854, 118.87721211299868, 118.78957586999968, 118.74776311400092, 0.0, 118.53284000200074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "itls": [[0.00017762899915396702, 0.09852272200078005, 0.000289977000647923, 0.16339019899896812, 0.0031726150009490084, 0.004982283999197534, 0.005319628000506782, 0.005400279998866608, 0.005594229000053019, 0.005813489000502159, 0.009601993000615039], [0.000341318000209867, 0.16337786999974924, 0.0031795830000191927, 0.004976503001671517, 0.005319575999237713, 0.005396247999669868, 0.005616562000795966, 0.005812854999021511, 0.009492167000644258, 0.004521148999629077, 0.21372254900052212, 0.23529683999913686, 0.22025424000094063, 0.22532029099966167, 0.21020740700078022, 0.20383128299909004, 0.22285859799922036, 0.24240066700076568, 0.2716335410004831, 0.28335490499921434, 0.30169580100118765, 0.20945539499916777, 0.21283646399933787, 0.20469440300075803, 0.20907473800070875, 0.21282657899973856, 0.20650492899949313, 0.20773283000016818, 0.22244260300067253, 0.22041667099983897, 0.2099914459995489, 0.23320162799973332, 0.22581004300081986, 0.21900954599914257, 0.20525808599995798, 0.2211684489993786, 0.20906699800070783, 0.21999652399972547, 0.22833798099964042, 0.19407768800010672, 0.22133244100041338, 0.21036992500012275, 0.232526076000795, 0.21275508500002616, 0.2108265519982524, 0.218469860001278, 0.20714774999942165, 0.20492663100048958, 0.20610746800048219, 0.20552773300005356, 0.22158884199961904, 0.23956471599922224, 0.22285696400103916, 0.20857829699889407, 0.20843364900065353, 0.22069317099885666], [0.0027154679992236197, 0.004950975000610924, 0.005316221999237314, 0.005401544000051217, 0.005605743999694823, 0.005798785001388751, 0.009736631998748635, 0.0042774060002557235, 0.21380091200080642], [0.22556731100121397, 0.20926853200035112, 0.20432510199862008, 0.22299297000063234, 0.24241586599964648, 0.27163206600016565, 0.28334779900069407, 0.3018781549999403, 0.20898707599917543, 0.21224255400011316, 0.2051533970006858, 0.20900122499915597, 0.21296972100026323, 0.2062016500003665, 0.20757759399930364, 0.22296361200096726, 0.22026210100011667, 0.2101534419998643, 0.23308572600035404, 0.2261607410000579, 0.21789465499932703, 0.20582098600061727, 0.22136256799967668, 0.20922675200017693, 0.21997653499965963, 0.22793263399944408, 0.1939999740006897, 0.22224811399973987, 0.21003562999976566, 0.2321088040007453, 0.21346723199894768, 0.21055308900031378, 0.2188626170009229, 0.20712380599979952, 0.2049120129995572, 0.20621199699962744], [], [0.2038243370006967, 0.22286247199917852, 0.2423967939994327, 0.27163371100141376, 0.28335178699853714, 0.3017927500004589, 0.20935972100051004, 0.21283973699974013, 0.2044086839996453, 0.2092718080002669], [], [0.22307239000110712, 0.2423679469993658, 0.27162653699997463, 0.28327837600045314], [0.22287632000006852, 0.24239407499953813, 0.27163279700107523, 0.2833515649999754, 0.3017900719987665, 0.20936029400036205, 0.21284410599946568, 0.20441013200070302, 0.2088776370001142, 0.21331690999977582, 0.2063357660008478], [], [0.21285010099927604, 0.204422897000768, 0.20888274299977638, 0.21318803899885097, 0.20637633700061997, 0.20734455199999502, 0.2229449599999498, 0.22024198600047384], [0.20450393500141217, 0.20889037499910046, 0.2131897380004375, 0.20620281499941484, 0.20738695399995777, 0.22304845200051204, 0.22017657899959886], [0.20910107399868139, 0.2130109090012411, 0.205738222999571, 0.20788788900063082, 0.22281861800001934, 0.2201599959989835, 0.21046191499954148, 0.23307201200077543, 0.22616347999974096, 0.2176868900005502, 0.2054037359994254], [0.20891837700037286, 0.21280744799878448, 0.20650627400027588, 0.2077362460004224, 0.22244090599997435, 0.22047568400012096, 0.2101274579999881], [0.2090801720005402, 0.21282910599984461, 0.2064252039999701, 0.20777477199953864, 0.2224577489996591, 0.22041330700085382, 0.21000658899902191, 0.2331908129999647, 0.22582521100048325, 0.21891999800027406], [], [0.20676112799992552, 0.20734967999851506, 0.22295077499984473, 0.22023789800005034, 0.21019814800092718, 0.23295383699951344, 0.22614408600020397, 0.21864284699950076, 0.20521757900132798, 0.22149667699886777, 0.2090627890011092, 0.2199977169984777, 0.22781360100088932, 0.19399953299944173, 0.22172245100045984, 0.2105523139998695, 0.23210470100093517, 0.21263851699950465], [0.20629625000037777, 0.20732442799999262, 0.22293809999973746, 0.2203052189997834, 0.21014237700001104, 0.2330812460004381, 0.22599118699872633, 0.21890762300063216, 0.20526821100065717, 0.22123331499824417, 0.20903844900021795], [0.2060526450004545, 0.20753587000035623, 0.22296302399990964, 0.22026221699888993, 0.2101506340004562, 0.23308806299974094, 0.22615336000126263, 0.21790594599951874, 0.20581930099979218, 0.22130729600030463, 0.20923894499901508, 0.21996724600103335, 0.22792908900009934, 0.19399639699986437, 0.22150544099895342, 0.21078968599977088, 0.2321093930004281, 0.21258027400108404, 0.21126992599965888, 0.2185165569990204, 0.20622083300077065, 0.20542094399934285, 0.2051641110010678, 0.20648086099936336, 0.22207044900096662, 0.23972922999928414, 0.22211584899923764, 0.2091346400011389, 0.20762097999977414, 0.22123384299993631, 0.24645029500061355, 0.20888915299838118, 0.2153746760013746, 0.21772616299858782, 0.20845396900040214, 0.21630677500070306, 0.21413738800038118, 0.23079889200016623, 0.20939443599854712, 0.21072020800056634], [0.20773300099972403, 0.22244239800056675, 0.2204167049985699, 0.2099988640002266, 0.23319394200007082, 0.22581887300111703, 0.2190058259984653, 0.20524785100133158, 0.22118053499980306, 0.20906765799918503, 0.2199913149997883, 0.22824577299979865], [0.20730950200049847, 0.22293385000011767, 0.2203103869996994, 0.21013568499984103, 0.23308806700151763], [0.2075842169997486, 0.22296231500149588, 0.21990593199916475, 0.21051382000041485, 0.23308325699872512, 0.22610176500165835], [0.22254093600167835, 0.2202687689987215, 0.21013062299971352, 0.23319855400040979, 0.22585274599987315, 0.21891633900122542, 0.2052692939996632, 0.22122287199999846, 0.20911258699925384, 0.21998425800120458, 0.2282365769988246, 0.1940569870002946, 0.2212594770007854, 0.2105139319992304, 0.23209373799909372, 0.213073107001037], [0.22246013299991318, 0.22041452299890807, 0.21001178400001663, 0.23318926200045098, 0.22583083800054737, 0.2189187399999355, 0.205281909000405, 0.22120623699993303], [0.21155257900136348, 0.23302661599882413, 0.22580189700056508, 0.21900929100047506, 0.2052674129990919, 0.22115722600028676, 0.2090686520004965, 0.22000323300017044, 0.22834577299909142, 0.19407108100131154, 0.22150990999944042], [0.20978120199833938, 0.23307600500083936, 0.22600456299915095, 0.21865391500068654, 0.2052143180007988, 0.22149227399859228, 0.20906120000108785, 0.22000711399959982, 0.22825207499954558, 0.19355873700078519, 0.2221178609997878, 0.21036805500079936, 0.23254004299997177, 0.21273334699981206, 0.2106361329988431, 0.2187687019995792, 0.20711104700058058, 0.20488376200046332, 0.20612479299961706, 0.20552338699963002, 0.221582591000697, 0.23963641099908273, 0.22278769200056558, 0.20857264600090275, 0.20857327599878772, 0.22075708600095822, 0.2464678759988601, 0.2085247220002202, 0.21517546100039908, 0.2177244750000682, 0.20924586299952352, 0.21625201700044272, 0.2134053709996806, 0.23055334099990432, 0.2103516010010935, 0.20989541400012968, 0.2295332479989156, 0.21522757599996112, 0.20552336299988383, 0.218486355001005, 0.23362118200020632, 0.26672775899896806, 0.2737783140000829, 0.30055678200005786, 0.20861958199930086, 0.21189723400129878, 0.2225276789995405, 0.20595988700006274, 0.2201109510006063, 0.22030185999938112, 0.20863562699923932, 0.22446837200004666, 0.22392346000015095, 0.2292546830012725, 0.21157315699929313], [], [0.21002272399891808, 0.23318533100064087, 0.22583978299917362, 0.21891967300143733, 0.2052728209982888, 0.22121462900031474, 0.20911752800020622, 0.21998656799951277, 0.22824141000091913, 0.19418850500005647, 0.22133220000068832, 0.2103731549996155, 0.23204583400001866], [0.21763493500111508, 0.20499444699999003, 0.22148312399986025, 0.20906098999876122, 0.22001502300008724, 0.22826607400020293, 0.19354322500112175, 0.2217056509998656, 0.21054471699972055, 0.23210819799896854, 0.21271068700116302], [0.20522353700107487, 0.22139923099894077], [0.20567943500100228, 0.2213712590000796, 0.20923202299854893, 0.21991114200136508, 0.22667611799988663, 0.19526817699988896, 0.22203803899901686, 0.21039464000023145, 0.23211383799934993, 0.21287993500118318, 0.2118252330001269], [0.22124267400067765, 0.20903950599858945, 0.22002195700042648, 0.228272119000394, 0.19353658299951348, 0.221785613000975, 0.2104626479995204, 0.23210955899958208, 0.21278137400076957, 0.2112596389997634, 0.2184216080004262, 0.20625771099912527, 0.2057460890009679, 0.2050730979990476, 0.20625653299975966, 0.22199022300083016, 0.23964364499988733, 0.2227878169996984, 0.20842578300107562, 0.20800053799939633, 0.22118004399999336, 0.24631746799968823], [0.22133718300028704, 0.20925499999975727, 0.21996162200048275, 0.2278048089992808], [0.22026648000064597, 0.22780477199921734, 0.19401464400107216, 0.2224197979994642, 0.21001056900058757, 0.2321111639994342, 0.21350010800051678, 0.2103489189994434, 0.21906210199995257, 0.2071201469989319, 0.20487707600113936], [0.22006325400070637], [0.2201199760002055, 0.22768211400034488, 0.19400158899952658, 0.22185034200083464, 0.21042784900055267, 0.2321064629995817, 0.2128266750005423, 0.21120550999876286, 0.2184333630011679], [0.19375480599956063, 0.2227075770006195, 0.2098133580002468, 0.232235811999999, 0.21358183899974392, 0.2100200210006733, 0.2193888389992935, 0.2071157160007715, 0.20487763299934159, 0.2062616330003948, 0.2055147909995867, 0.22150585700001102, 0.23962245599977905, 0.22278152000035334, 0.20854699600022286, 0.20869660300013493, 0.2210612669987313, 0.24604859800092527, 0.2086273330005497], [0.2217177599995921, 0.21003177300008247, 0.23210890500013193, 0.21338267200007976, 0.2106588169990573, 0.21876166200127045, 0.20719813399955456, 0.2048589610003546], [0.22211161400082347, 0.21032917499906034, 0.2321149859999423, 0.21292407300097693, 0.210740997999892, 0.21889392999946722, 0.2063088320010138, 0.20574811699952988, 0.20474568600002385, 0.20644155099944328], [0.221163500998955, 0.21054398900014348, 0.23204784399968048, 0.21311223700104165, 0.21093221499904757, 0.21848444500028563, 0.20629330200063123, 0.20558287399944675, 0.20516872100051842], [], [0.21066447300108848, 0.23209688499991898, 0.21254845499970543, 0.21143761100029224, 0.21828270599871757], [], [0.2112487960002909, 0.21854662199984887, 0.20603725599903555, 0.20494566100023803, 0.20545609100008733, 0.2067965109999932, 0.22207515999980387, 0.23959135200129822, 0.22224234099849127, 0.20897191800031578, 0.2075790960006998, 0.22138575399912952, 0.24650953899981687, 0.20889568000166037, 0.21537733499826572, 0.21766274200126645, 0.2083043059992633, 0.2165272050006024, 0.2140685680005845, 0.23088290999839955, 0.20924382100020011], [0.21152842700030305, 0.21819295699970098, 0.2062252340001578, 0.20542092799951206, 0.20516211500034842, 0.2064788449988555, 0.2220685370011779, 0.23973200599903066, 0.22268150600029912], [0.21138525899914384, 0.2179111160003231, 0.20630553000046348, 0.20556799599944497, 0.20524611799919512, 0.20651774799989653, 0.22156415600147739], [0.21090646499942522, 0.21846686900062195, 0.2063014289997227, 0.2055747189988324, 0.2052388490010344, 0.20611253599963675, 0.22197203200084914, 0.23964595399957034, 0.2227875979988312, 0.20866208000006736, 0.20843097700162616, 0.2206886759995541, 0.24626651699873037, 0.20896691100097087, 0.21516673299993272, 0.21769750000021304, 0.2087965089995123, 0.2167339110001194, 0.21341100900099264, 0.2305733719986165, 0.21027196800059755], [0.218164247000459, 0.20712093099973572, 0.20491167600084736, 0.20611670600010257, 0.2055228379995242, 0.22158710999974573, 0.23956390700004704, 0.2228596879995166, 0.20857226500083925, 0.2084380769993004, 0.2207941460001166, 0.24614759200085246, 0.20895331999963673, 0.21518070999991323, 0.21772553700066055, 0.20918008099943108], [0.20710796599996684, 0.20539540800018585, 0.2052513460002956, 0.2065281879986287, 0.22160884600089048, 0.239573326000027, 0.22279025699936028], [0.20617490200129396], [0.2071027440015314, 0.20489259399982984, 0.20612139500008198, 0.20552155699988361, 0.22158437899997807, 0.23963296500005526, 0.22279174399955082, 0.20856710400039447, 0.20844311799919524], [0.20517044900043402, 0.20591418799995154], [0.205159499999354, 0.20536570799959009, 0.20652799500021501, 0.2220748290001211, 0.23960424400138436, 0.2222357059999922, 0.20908627599965257], [0.20486632000029203, 0.20627166899976146, 0.20543191400065552, 0.2219669169990084, 0.23916119300156424, 0.22277971999938018, 0.20870749700043234, 0.20856927999921027, 0.2210695770008897, 0.24603174199910427, 0.20869166299962671], [0.2052971829998569, 0.20514215500043065, 0.20647786900008214, 0.22206752199963375], [0.20616914200036263, 0.20536692799942102, 0.2219810820006387, 0.23914428199896065, 0.22325482700034627, 0.2082537490005052, 0.2085339869991003, 0.2210987570015277], [], [0.20516957299878413, 0.206485579999935, 0.22207271300067077, 0.23972448799941048, 0.22211864500059164, 0.20913970199944742, 0.20739578299981076, 0.22144766500059632, 0.24644844999966153, 0.20889216500108887, 0.2153606839983695, 0.2176559690014983, 0.2085328169996501, 0.21631358900049236, 0.21412787000008393, 0.23081472799822222, 0.20937938200040662, 0.21071000499978254, 0.22969898100018327, 0.21508178200019756, 0.2056679899997107, 0.2184937150013866, 0.23354807599935157, 0.26676740599941695, 0.2737728980009706, 0.30059945799985144, 0.2085102189994359, 0.21195695899950806, 0.2225339430005988, 0.20581235099962214, 0.22028154500003438, 0.22033391799959645, 0.2084394860012253, 0.22452386899931298], [], [0.2059043709996331, 0.22159188399928098, 0.2395681699999841, 0.22285242700127128, 0.20858501799921214, 0.2084302849998494, 0.22068981600023108, 0.24626632800027437, 0.2089603749991511, 0.21488058800059662, 0.21765136999965762], [0.20620129900089523, 0.22197425800004567, 0.23964408800020465, 0.2227878449994023, 0.2084191430003557, 0.20800616499946045, 0.22118646499984607, 0.24638854099976015, 0.20899440600078378, 0.21498285899906477], [0.20625929699963308, 0.2219933830001537, 0.23964495499967597, 0.22278543399988848, 0.2084344989998499, 0.20799298300153168, 0.22117499899832183, 0.246318561001317, 0.2090940709986171, 0.21498118900126428, 0.21772521799903188], [], [0.20540477800022927, 0.2219758080009342, 0.23914937699919392, 0.22277886800111446], [], [0.20543005199942854, 0.22156425600041985, 0.23963870300030976, 0.2227845929992327, 0.20854706799946143, 0.20856497500062687, 0.22069337500033726], [0.20644318300037412, 0.22212939400014875, 0.23964906499895733, 0.22277899900109333, 0.20844700199995714, 0.20763555699886638, 0.22123257600105717, 0.2464475209999364], [0.22219565600062197], [0.22150748499916517, 0.23962635099996987, 0.22278237499995157, 0.20855254100024467, 0.2086920050005574, 0.22052491700014798, 0.2461402659992018, 0.20894586999929743, 0.2152016950003599, 0.21772262000013143, 0.20924824900066596], [], [0.20826645700071822, 0.2085364180002216, 0.22108491699873412, 0.24602291100018192, 0.2087229090011533, 0.21485763199962093, 0.21769175400004315], [0.20857157299906248, 0.221054264000486, 0.24603881599978195, 0.2086612260009133], [0.22075397399930807, 0.24628987000141933, 0.20897984399925917, 0.21509312799935287], [0.22117721399990842, 0.24655009700109076, 0.209009172000151, 0.21543945299890765, 0.2177189329995599, 0.20927965600094467, 0.2162113619997399], [0.2211649420005415, 0.2463277780007047, 0.2089978739986691, 0.21497921999980463, 0.21767719099989336, 0.2082834400007414, 0.2164195320001454], [0.22068417700029386, 0.24627372099894274, 0.2089724940015003, 0.21515609999914886, 0.2177014839999174, 0.20872817800045596, 0.21679532300004212, 0.21340960199995607, 0.23058575399954861, 0.21017864100031147], [], [], [], [0.21513503700043657], [], [0.21594849200118915], [], [0.2167872889986029, 0.21340478400088614, 0.23056388499935565, 0.2103400710002461, 0.21014257800015912, 0.22949838400018052, 0.21506683900042844, 0.20575165999980527, 0.2184791210002004, 0.23338941399924806], [0.21337905099971977, 0.23063925799942808, 0.21016997700098727, 0.2103741020000598, 0.229505496999991, 0.21505292399888276, 0.20575352500054578, 0.2184928780006885, 0.23363999199864338, 0.2664568630007125, 0.27377722799974435, 0.30055538000124216, 0.20933137699830695, 0.2112720029999764, 0.2237075900011405, 0.205412745999638, 0.2195135689999006, 0.2203077129997837, 0.20911383000020578, 0.22403726300035487, 0.22401102900039405, 0.22903818899976613, 0.2119849049995537, 0.22403999800008023], [], [0.21026062300006743, 0.22945748399979493, 0.21521538699926168, 0.20552427300026466, 0.21849216599912324], [0.21067422600026475, 0.22953426999993098, 0.2152386040015699, 0.20552351499827637, 0.21847646100104612, 0.23362800599898037, 0.2667207900012727, 0.27377786800025206, 0.30055691199959256, 0.20862005100025272, 0.21183399399888003], [0.2293898360003368], [0.2060870019995491, 0.21845214900167775], [], [0.21813616700092098], [0.21839536200059229, 0.23361103299976094, 0.26647776500067266, 0.27377292699929967, 0.3005400490001193, 0.20933406299991475, 0.21125967599982687, 0.2237092750001466, 0.20541277000120317, 0.2195139499999641, 0.22031208899898047, 0.20911563499976182, 0.22403336500065052, 0.2240124919990194, 0.22903126700111898], [], [0.2116138969995518, 0.22370325199881336, 0.20501118800166296], [0.2112858940017759, 0.22370037299879186, 0.20535059699977865], [0.2111016640010348, 0.22369067199906567, 0.20540975600124511, 0.21951550399899133, 0.22032154699991224, 0.20911461000105191, 0.22432371499962755], [0.20476216499992006, 0.22011926599952858, 0.22029811600077664, 0.20863775099860504, 0.22446918400055438, 0.2239219220009545, 0.22926527399977203, 0.21155747400007385, 0.22424338599921612], [0.21991801500007568, 0.22026931999971566, 0.20863483599896426, 0.22447149000072386, 0.22392183699957968, 0.2292449550004676, 0.211647546999302, 0.2242798910010606, 0.2191527449995192, 0.21594516500044847, 0.22909329399954004, 0.21326040100029786, 0.21040725499915425, 0.2243918770000164, 0.2180468890001066, 0.20766251200075203, 0.20638651399895025, 0.20764840100127913, 0.21288179499970283, 0.20744475399988005, 0.21724361599990516, 0.2222878150005272, 0.205770427999596, 0.20711414600009448, 0.21486949499922048, 0.20881655900120677, 0.20688268199955928, 0.20845193399873096, 0.21965522600112308, 0.22754683200037107, 0.21933462299966777, 0.20062064599915175, 0.22293617600007565, 0.21469072200125083, 0.22201447999941593, 0.20751300899974012, 0.21032539500083658, 0.22115814499920816], [0.2195810920002259, 0.22024121899994498, 0.20916822999970464, 0.22405376900132978, 0.22382213699893327, 0.22922893299983116, 0.21198383900082263, 0.22402570699887292, 0.21912800100108143, 0.21617408099882596, 0.22902277000139293], [0.20892390800145222, 0.22446859699994093, 0.22392376199968567, 0.2292780709994986, 0.21143311000014364], [0.2083710989991232, 0.22459813300156384, 0.2240561059988977, 0.22930259399981878, 0.2098630630007392, 0.22593226699973457, 0.2193189520003216, 0.2148007180003333, 0.23007415999927616, 0.21340481100014586, 0.20982674500010035], [0.20911691400033305, 0.2240409539990651, 0.22400890400058415, 0.22904775099959807, 0.211985113000992, 0.22403456899883167, 0.21912725299989688, 0.21617797700127994], [0.2240676440014795, 0.22382315499999095, 0.2292365229986899, 0.21198186800029362, 0.2240195340000355, 0.21912836199953745, 0.21595756900023844, 0.2292020130007586, 0.21311517100002675, 0.21041494899873214, 0.22441157000139356, 0.21801975599919388, 0.20769362300052308], [0.2244426300003397, 0.22906008399877464, 0.21198541299963836, 0.2240298860015173, 0.21912808199886058, 0.21617545099979907, 0.2289864670001407, 0.21311205700112623, 0.211054952998893, 0.22375429500061728, 0.21801221299938334, 0.20822037700054352, 0.20655773299949942, 0.20731059500030824, 0.2127207270004874, 0.20796336499915924], [0.21058798199919693, 0.22410397900057433, 0.21914766099871485, 0.2159531289998995, 0.22908448900125222], [0.22401629900014086, 0.2191308649998973, 0.21595492999949784, 0.2291989610002929, 0.21312215899888542, 0.21041185000103724, 0.22439248000046064, 0.21803540600012639, 0.20767423899997084, 0.20639023199873918], [], [0.21630905999882089, 0.22900655299963546, 0.21311392900133797, 0.21041419900029723, 0.224376072999803, 0.21802652499900432, 0.20768481100094505, 0.20648349600014626, 0.2076156329985679, 0.21291981000103988, 0.2073311919994012, 0.2172437829995033, 0.22226898500048264, 0.20473258300080488, 0.20763662199897226, 0.21425429200098733, 0.20907601599901682, 0.20649334700101463, 0.2083142779993068, 0.22056233399962366, 0.22759954100001778, 0.21837830300137284, 0.2012212779991387, 0.22317665800073883, 0.21493067600022187, 0.22210318599900347, 0.20732876799957012, 0.2096854120009084, 0.22168984900054056], [0.2292360440005723, 0.21326557299835258, 0.21039162300075986, 0.22438493600020593, 0.21792841400019825, 0.2076228229998378, 0.20646079300058773, 0.20712201499918592, 0.21301119700001436, 0.20713351700032945, 0.21741100100007316], [0.21149678700021468, 0.22353127700080222, 0.2179824020004162, 0.20942242199998873, 0.20568468300007225, 0.20713189100024465, 0.21262072099852958, 0.2080952910000633, 0.21653852900089987, 0.2221144409995759, 0.20563180200042552, 0.2071134220004751, 0.2141151859996171, 0.20945710399973905, 0.20698128500043822, 0.2075172869990638, 0.22035439100000076, 0.22769939499994507, 0.2191041980004229, 0.20094358899950748, 0.2229226600011316, 0.21470190799846023, 0.22201758000119298, 0.20750376199976017, 0.20981850399948598, 0.22167183500096144, 0.22626195900011226, 0.21020532100010314, 0.20964477099914802, 0.2138624470007926, 0.2102337999986048, 0.21789747700131556, 0.20949427300001844, 0.20938720099911734, 0.20635724100066, 0.2114615739992587], [], [0.2236986789994262, 0.2179895690005651, 0.20940360099848476, 0.20569549500032736, 0.20713279700066778, 0.21261921000041184, 0.20810420799898566, 0.21653298199998972, 0.22211957900071866, 0.20572055999946315], [0.20867146800082992, 0.2064001950002421, 0.20735733099900244, 0.21267002900094667, 0.20801156199922843, 0.2165811560007569, 0.22215357899949595, 0.20565234599962423, 0.2071159320003062, 0.2141155080007593, 0.20945337599914637, 0.2066595750002307, 0.20775308100019174, 0.22040736899907643, 0.2275590050012397, 0.21857058099885762, 0.20150403600018763, 0.22303037900019262, 0.21472616500068398, 0.22196658599932562, 0.20751545399980387, 0.20982187499976135, 0.22167972200077202, 0.22625354000047082, 0.21021765299883555, 0.20946647399978247, 0.21379348400114395, 0.2103643890004605], [0.20753701700050442], [0.2065604470008111, 0.207318505999865, 0.21271997000076226, 0.20762670499971136, 0.21692261600037455, 0.2222245249995467, 0.205745252998895, 0.2071143290013424, 0.21487686299951747, 0.20909872399897722, 0.2067079520002153, 0.2083486580013414, 0.21965459599960013, 0.22753494999960822, 0.2193898990008165, 0.20061881199944764, 0.22329641099895525, 0.21454942100172048, 0.22173127699898032], [], [0.2073857899995346, 0.21272350199978973, 0.20727536699996563, 0.21724121900115279, 0.2222561870003119, 0.20569934399827616, 0.2071144360015751, 0.21411439499934204, 0.2094557039999927, 0.20698151299984602, 0.2075184690002061, 0.22035537999909138, 0.2277008470009605, 0.21843126800013124, 0.20154236700000183, 0.22297342300043965, 0.21471338699848275, 0.2219602510012919, 0.20752667499982635, 0.20982634000029066, 0.22167866499876254, 0.22627663200000825, 0.21020733400109748, 0.20944803599923034, 0.2138208800006396], [0.20713373999933538, 0.21262251299958734, 0.2080086170008144, 0.21658836099959444, 0.22214214899940998, 0.2057345550001628, 0.20712123300108942, 0.2148781309988408, 0.20909957799995027, 0.206701923001674], [0.2128950399983296, 0.2074511730006634, 0.21724209999956656, 0.22229632300150115, 0.20594211899879156, 0.20705157600059465, 0.21492271199895185, 0.2097831760002009, 0.20599866500015196, 0.20831916400129558, 0.22103072099889687, 0.22618775800037838, 0.21933383099894854, 0.20064708400059317, 0.22330169700035185, 0.21454030700078874, 0.22184140599892999, 0.20741959999941173, 0.2108031640000263, 0.22118142600083956, 0.22615328800020507, 0.2104460829996242, 0.20902230499996222, 0.21524249399953987, 0.2102146930010349, 0.21666215699951863, 0.20979789699958928, 0.20901913300076558, 0.20635773100002552, 0.21185474000048998, 0.214678461999938, 0.21354257099847018, 0.21219355600078416, 0.21749735500088718, 0.2143214519983303, 0.20961053900100524, 0.22256418600045436, 0.2325344929995481, 0.20477412699983688, 0.21255088100042485, 0.2058820559996093, 0.21401839099962672, 0.20372426900030405, 0.20732619400041585, 0.2072579309988214, 0.22205987800043658, 0.22222939600032987, 0.21152013699975214, 0.20640802700108907, 0.21132901799865067, 0.2243934550006088, 0.21657043499908468, 0.2087318170015351], [0.21275036199949682, 0.20727776900093886, 0.21724289299891097, 0.2222624550013279, 0.20556529499845055, 0.20717574700029218, 0.21412856800088775, 0.2091440069998498], [0.2129260149995389, 0.2073381629998039, 0.21724454700051865, 0.22227799100073753, 0.20577732699894113, 0.20711354500053858, 0.21487472300032096, 0.2088090019988158, 0.20688602200061723], [0.20754165099970123, 0.21724129100039136, 0.22230696299993724, 0.20535072500024398, 0.20737108899993473, 0.21416566900006728, 0.20893141099986678, 0.20699303800029156], [0.2172768279997399, 0.22232746400004544, 0.20596191299955535, 0.20704702500006533, 0.2149238640013209, 0.20947456199974113, 0.20631110799877206, 0.20831376400019508, 0.22101653000027, 0.22616000100060774], [0.21717491900017194, 0.22223502199994982, 0.20556505199965613, 0.2071741079998901, 0.21412977900035912, 0.20926492900071025, 0.20680619699851377, 0.20766008300051908, 0.22054344800017134, 0.2275679400008812, 0.21855973599849676, 0.2011416850000387, 0.22313080800086027, 0.21498126199912804, 0.22197972100002517, 0.20749792200149386, 0.20973255399985646, 0.22172091999891563, 0.2261847839999973, 0.21033305400123936, 0.20948616699934064, 0.21376446099930035, 0.21036727000137034, 0.2180186429995956, 0.20951224300006288, 0.20896874699974433], [0.21652902499954507, 0.22212347000095178, 0.20572408599946357, 0.2071267200008151, 0.21487765599886188, 0.20910195000033127, 0.2067321329996048, 0.20830829300030018, 0.21965316600108054, 0.2275289930003055, 0.21939280399965355, 0.20061509299921454, 0.22330439600045793, 0.2145507679997536, 0.22179040999981225, 0.20744378400013375, 0.21070411300024716, 0.2208683890003158, 0.2261762300004193, 0.21075704399845563, 0.20911404300022696, 0.2152335310001945, 0.2095739489996049, 0.21721396500106493, 0.20956735399886384, 0.2093300860015006, 0.20638102999873809, 0.21166202400127077, 0.2148340019994066, 0.2133921709992137, 0.2122971389999293], [], [0.20501402099944244, 0.20764947399948142, 0.2142234090006241, 0.2089368060005654, 0.2064896960000624, 0.20831529699898965, 0.22056137500112527, 0.22758983099993202, 0.21853637299864204, 0.2010921290002443, 0.22318375900067622, 0.21499777300050482, 0.22199700999954075, 0.20733380199999374, 0.2096863429997029, 0.2217976190004265], [0.20737589599957573, 0.2141676589999406, 0.20893366000018432, 0.20648817900109862, 0.20831491199896846, 0.22055952899972908, 0.22758444600003713, 0.21854341800099064, 0.20115965900004085, 0.22311505300058343, 0.21499469599984877, 0.22199043499858817, 0.2074825140007306, 0.20956051699977252], [0.2071781969989388, 0.2141303410007822, 0.20892969200031075, 0.20715692500016303, 0.20766230600020208, 0.22054482199928316, 0.22757179600012023, 0.21855481599959603, 0.20114773200111813, 0.2231254929993156, 0.21498523599984765, 0.2219825629999832, 0.20749432900083775, 0.20967182699860132], [0.20712087599895312, 0.21411574900048436, 0.20945143300014024, 0.20666081799936364, 0.2077463000005082, 0.22041488099966955, 0.2275636049998866, 0.21856495100109896, 0.20113604799917084, 0.22313826599929598], [0.20695764400079497, 0.2148661789997277, 0.2097897780004132, 0.20599126999877626, 0.2083247830014443, 0.22103869399870746, 0.22617718600122316, 0.21933331699983682, 0.20064470899887965, 0.22330456400050025, 0.2145401590005349, 0.22183886699895083, 0.20742365300066012, 0.21080024100047012, 0.22117841399995086, 0.22736917699876358, 0.2092306880003889, 0.2090221920007025, 0.21524593399954028, 0.21022559700031707], [], [0.2142672690006293, 0.20901532999960182, 0.20601787399937166, 0.20885346300019592, 0.2205613509995601, 0.22762225100086653, 0.2183543989995087, 0.2012085759997717, 0.22318660100063425, 0.21495477600001323, 0.22197440299896698, 0.20721762100038177, 0.20960198200009472, 0.22197245700044732, 0.22647982600028627, 0.20971311799985415, 0.20991549300015322, 0.21376765899913153], [0.20883773100104008, 0.20688319100008812, 0.2075175499994657, 0.2203560819998529, 0.22769430100015597, 0.21910725199995795, 0.20093940699916857, 0.222929532001217, 0.2146956449996651, 0.2220173869991413, 0.2075077040008182, 0.20982060599999386, 0.2216688169992267, 0.2262613640014024, 0.21020560299984936, 0.20964024899876676, 0.21444803800113732, 0.20977531300013652, 0.21779736799908278, 0.20949340500010294, 0.20938438099983614, 0.20633585900031903, 0.21158094400016125, 0.21501764099957654, 0.21338886699959403, 0.21229616399978113, 0.21735463500044716], [], [0.20671578099972976, 0.2083437649998814, 0.21965586700025597, 0.22753971900056058, 0.21933637099937187], [0.20666322800025227, 0.2076394599989726], [], [0.2075193130003754, 0.22035703499932424, 0.2277013500006433, 0.21842849399945408, 0.20147944100062887, 0.22303768399979162, 0.21471800800100027, 0.22196490699934657, 0.20752033600001596, 0.20982425500005775, 0.22167917200022202, 0.22625856199920236, 0.21022707300107868, 0.20945361599842727, 0.21381221400042705, 0.2104809499996918, 0.21789957600049092, 0.20949680500052636, 0.2092600729993137, 0.20610155100075644, 0.21132511399991927, 0.21563077999962843, 0.21340779499951168, 0.2122581750008976, 0.21724809399893275, 0.2149245870004961, 0.20943425900077273, 0.22211528200023167, 0.23335368799962453, 0.20350982099989778, 0.21287165799913055], [0.20766529899992747, 0.22055236699998204, 0.2275773500005016, 0.21854864099987026, 0.20115479000014602, 0.22312009999950533, 0.21498943500046153, 0.22198671899968758, 0.20748879999882774, 0.2096660229999543, 0.22174410100160458], [0.20756047099894204, 0.22036582799955795, 0.22770050700091815, 0.21842884499892534, 0.20147355000153766, 0.22302215299896488, 0.2147331790001772, 0.221971040000426, 0.2075103549996129, 0.20981914200092433, 0.22167970800001058, 0.22615489399868238], [0.22019632500087027, 0.22765859500032093], [0.21955727900058264], [0.21901975499895343], [0.20094943100048113, 0.22291562099962903, 0.21470764500008954, 0.22195746099896496, 0.20753075200082094, 0.20983007500035455, 0.22167704299863544, 0.2262763790004101, 0.21020543700069538, 0.20944277299895475, 0.21389767100117751], [0.20110437400035153, 0.22317695099991397, 0.21491916500053776], [0.22301169099955587, 0.2147444540005381, 0.22197551600038423, 0.20750506199874508, 0.20981613700132584, 0.2216786699991644, 0.22615865499938081, 0.2103342430000339, 0.20947109600092517, 0.21378590399945097, 0.21036381299927598, 0.2180312030013738, 0.20950204499968095, 0.20915416400021059], [0.2232947519987647, 0.21454359800009115, 0.22178708300089056, 0.20744541000021854, 0.21070282299842802, 0.22086571600084426], [0.2229060860008758, 0.21466514200074016, 0.22201204499833693, 0.20751903200107336, 0.21034012500058452, 0.22117155399973853, 0.22622330199919816, 0.21020412700090674], [0.22232434200122952, 0.20732413299992913, 0.20968427200023143, 0.2216916659999697, 0.2264751669990801, 0.2099434140000085, 0.20984656200016616, 0.21374464200016519, 0.21037417899970023, 0.21657610200054478, 0.21050433699929272, 0.2086852810007258, 0.2062734979990637, 0.2120405040004698, 0.21547693100001197, 0.2133860949998052, 0.21228528000028746, 0.2168048319999798, 0.2157310200000211, 0.20873532100085868, 0.22240779099956853, 0.23356959400007327, 0.20237366299988935, 0.2132179130003351, 0.20769665199986775, 0.21313838300011412, 0.20331452899881697, 0.2071970209999563, 0.20785001300100703], [0.20800496599986218, 0.20956262999970932, 0.22186015700026473, 0.2262649730000703, 0.21013483299975633, 0.2096619740004826, 0.2137637989999348, 0.21036992600056692, 0.21660563799923693, 0.21049499999935506, 0.20902839200061862, 0.20611409999946773, 0.21191505000024335, 0.21573696300038137, 0.21314860500024224, 0.21225923400015745, 0.2174355649985955, 0.21515158000147494, 0.2088604620003025, 0.22236873899964849], [0.20741650099989783, 0.21068757100147195, 0.22125036799843656, 0.22615020500052196, 0.2104343000009976], [0.20750141700045788, 0.20982015600020532, 0.22167386000000988, 0.22622837599919876, 0.21019363900086319, 0.20945982599914714, 0.2138030850001087, 0.21047737700064317, 0.21790131099987775, 0.20950033199915197, 0.20920933000161313], [0.20968670699949143, 0.221702312999696, 0.2264773980004975, 0.20992367600047146, 0.2097066009991977], [0.21068584000022383, 0.22116746099891316, 0.2273782169995684, 0.2092218400011916, 0.20902118499907374, 0.21524958500049252, 0.2102915519990347, 0.2165773190008622, 0.20985942500010424, 0.20948796899938316, 0.20588883300115413, 0.2119111840002006], [0.22087303000080283, 0.2261728920002497, 0.2107559249998303, 0.2091198889993393, 0.2152243990003626, 0.20957345299939334, 0.21721658299975388, 0.20949105200088525, 0.2093828350007243, 0.2064003799987404, 0.21152572900064115], [0.2211824379992322, 0.22614792700005637, 0.21045292100097868, 0.20902321199901053, 0.2152386090001528, 0.21011801799977547], [0.22167828000056033, 0.22616796399961459, 0.21033363300011843, 0.20947797799999535, 0.21377499300069758, 0.2103654299990012, 0.21802840900090814, 0.20950377299959655, 0.20903377600006934, 0.20617578999917896], [0.22197741499985568, 0.22649046900005487, 0.2097013650000008, 0.20981046700035222, 0.21382756300045003, 0.21054856999944604, 0.21633115100121358, 0.21067122099884728], [0.22120553300010215, 0.22614896199957002, 0.21046252999985882, 0.2090253810001741, 0.21523424299994076, 0.21011112999985926, 0.2167750110002089, 0.2098032260000764, 0.20901635299924237, 0.20636267400004726, 0.21179405800103268], [0.2081403189986304, 0.20967624300101306, 0.21375259699925664, 0.21037420600077894, 0.21658137699887448, 0.21049965200109, 0.20868581499962602, 0.20627986100043927, 0.21203667999907339, 0.21546999500060338, 0.21338769199974195, 0.21228167600020242, 0.21741358600047533, 0.2151274329989974, 0.20876444500026992, 0.22238549100075033, 0.23357922399918607, 0.2023643760003324, 0.21322129699910874], [0.2092872820012417, 0.21466638699894247, 0.210119057999691, 0.21722037800100225, 0.2094927189991722, 0.20938320200002636, 0.20640534599988314, 0.21151812700009032, 0.21499789300105476, 0.21339249399898108, 0.21229669599961198, 0.2175981660002435, 0.21442092700090143, 0.20950859100048547, 0.22254888899988146, 0.23271856999963347, 0.20423250800013193, 0.21288328199989337, 0.2060961369988945, 0.213775723001163, 0.20379079600024852, 0.20669169799839437, 0.20781515700036834, 0.22161878000042634, 0.22274488900075085, 0.21139858300011838, 0.20648138699834817, 0.21124006600075518, 0.22448276899922348, 0.21642998000061198, 0.208736714999759, 0.20852218300024106, 0.223235907000344, 0.1987803169995459, 0.21424088099956862, 0.23596729000018968, 0.24692848900122044], [0.20949723299963807, 0.21375666499989165, 0.21036805999938224, 0.2165677989996766, 0.21049773600134358, 0.2090285189988208, 0.20611412200014456, 0.21191618900047615, 0.2157350729994505, 0.2130894880010601], [0.20908383800087904, 0.2152323999998771, 0.20957838799949968, 0.2172127760004514, 0.2095673509993503, 0.20932807300050627, 0.2063751189998584, 0.21169369199924404, 0.2148137250005675, 0.21339553899997554, 0.2123357100008434], [0.21385178600030486, 0.21023823299947253, 0.21789978599917958, 0.20949442100027227, 0.20926348700049857, 0.20646662099898094, 0.21095703600076376, 0.2156243200006429, 0.21341168700018898, 0.2122567299993534], [0.21376986199902603, 0.2105303210009879, 0.21646410999892396, 0.21063437900011195, 0.20853105400055938, 0.20609064499876695, 0.2121909900015453, 0.21553595599834807, 0.21338055100022757, 0.21242821400119283, 0.21668195299935178], [0.21374139900035516, 0.2103784379996796, 0.21646997000061674], [0.20978185899912205, 0.21779792300003464, 0.2094931980009278, 0.20938646499962488, 0.20632586700048705, 0.21115901099983603, 0.2154542729986133, 0.21338827399995353, 0.212294221000775, 0.2172931620007148], [0.2101096749993303, 0.21723281100094027, 0.20949344899963762, 0.20938361399930727, 0.20640983100020094, 0.21151284000006854, 0.2150059390005481, 0.21339016999991145, 0.2122963929996331, 0.21741426900007355], [0.2167830979997234, 0.20980656999927305, 0.20901700800095568, 0.2063689639999211, 0.21166411299964238, 0.21482352699968033, 0.2133935689998907, 0.21233273600046232, 0.2175510340002802, 0.21445664599923475], [], [0.2086588540005323, 0.20616600799985463], [0.2089799959994707, 0.20634019700082717, 0.2118657319988415], [0.20933366700046463, 0.20638672299901373, 0.21159559400075523], [0.20611482499953127, 0.2119176989999687, 0.2154391210005997, 0.21339044799969997, 0.2123368920001667, 0.21742855999946187, 0.215158576000249, 0.20870008599922585, 0.22250284800065856, 0.2336364559996582, 0.20318443799988017, 0.21254296799997974, 0.2079937600010453, 0.21245758700024453, 0.20331407799858425, 0.20719147800082283, 0.20794815800036304, 0.2217867319996003, 0.22269703799975105, 0.20760988199981512, 0.2092843090013048, 0.21169930699943507, 0.22412742899905425, 0.2168040699998528, 0.20827893600107927, 0.20942876099979912, 0.22283690699987346, 0.19884257900048397, 0.21451899000021513, 0.23577035999915097, 0.24705147100030445, 0.22405322399936267, 0.2058295820006606, 0.2074112240006798, 0.20662193199859757, 0.2065904020000744, 0.21997611400001915, 0.23728929900062212, 0.21014228499916499, 0.23308736800026963, 0.2086735390003014, 0.206842689000041, 0.22363596300056088], [0.20589682199897652, 0.21190532699984033, 0.21474671000032686, 0.21343793400046707, 0.21219342599943047, 0.21748208700046234, 0.2142777989993192, 0.20961876700130233, 0.22257149100005336, 0.23283490799985884, 0.2044617659994401, 0.21254606200091075, 0.20672879599987937, 0.21351733199844602, 0.20343959700039704, 0.20749070100100653], [0.2059980739995808, 0.21217181499923754, 0.2155249229999754], [0.20615478500076279], [], [0.20594743599940557, 0.21132113699968613, 0.2156363500016596, 0.2133631439992314], [0.2119075000009616, 0.21475680000003194, 0.21343781599898648, 0.21219269500033988, 0.21744809600022563], [0.2118491040000663, 0.2157165629996598, 0.2133527280002454, 0.21224906599854876], [0.21133129999907396, 0.21564206600123725, 0.21336139499908313, 0.21231449100014288, 0.21724370599986287, 0.21491334900019865, 0.20903353199901176, 0.22244358800162445, 0.23331043500002124, 0.2035469069996907], [0.2115008710006805, 0.21565208900028665, 0.21335875200020382, 0.212313763999191, 0.21724172600079328, 0.21490073599852622, 0.209047983000346, 0.22244019800018577, 0.23323251200054074, 0.20361897299881093, 0.21244938200106844], [], [0.21198235900010332, 0.21544802599964896, 0.21338864300014393, 0.21233928100082267, 0.21741976099838212, 0.21508751600049436, 0.20877395699972112, 0.22249644600015017, 0.2336204759994871, 0.2031981670006644, 0.2124968070002069], [0.21546456499891065, 0.2133867120010109, 0.21229343400045764, 0.21720373399875825], [0.21493231699969328, 0.21343873600017105, 0.2121908560002339, 0.2174508230000356, 0.21432267899945145, 0.20961546800026554, 0.22256737200041243, 0.23253446399940003, 0.2047671630007244, 0.21254962399871147, 0.20658059699962905], [0.21453413699964585, 0.21219308100080525, 0.21750130699911097, 0.21404359699954512, 0.20988127700002224, 0.2225595930012787, 0.2324899799987179, 0.20482521099984297, 0.21251440600099158], [0.21337367399974028], [0.21345443899917882, 0.21215879500050505], [0.21845910199954233, 0.21409718800168775, 0.20982872899912763, 0.22211470299953362, 0.23299695100104145, 0.20437558599951444, 0.2123928609998984, 0.20642593699994904, 0.21393149600044126, 0.2037885979989369, 0.20660945500094385], [0.21740416899956472, 0.21510853600011615, 0.2087620419988525, 0.22237979200144764], [0.21731876299963915, 0.214562062999903, 0.20939046500097902, 0.22243447399887373, 0.23310352100088494, 0.2036394360002305], [0.20964036599980318, 0.2223712519989931, 0.23362519800139125, 0.2031966039994586, 0.212545054999282, 0.2079908499999874, 0.21258351899996342, 0.2032284080014506, 0.2073090569992928, 0.20781112700024096, 0.2218482899988885, 0.22272489200076961, 0.20806912899934105, 0.2087467880010081, 0.21169307899981504, 0.22412210199945548, 0.21679245899940724, 0.20829481800137728, 0.20942651800032763, 0.2228228219992161, 0.19885652599987225, 0.21451934300057474, 0.23616405299981125], [0.20873967299849028, 0.22240837600111263, 0.23355636700034665, 0.20234245099891268, 0.2129856829997152, 0.20787406800081953, 0.21315727299952414, 0.20332055700055207, 0.2072362519993476, 0.20764354700077092, 0.22197885000059614], [0.22212001099978806, 0.23332806800135586, 0.2035302859985677, 0.21288252600061242, 0.20692066800074826, 0.21323862799908966, 0.20372858500013535, 0.2068458850008028, 0.2079356349986483, 0.22161029900053109, 0.2227780810007971, 0.21131546399919898, 0.20625775900043664, 0.2109449620002124, 0.22456285299995216, 0.2169520699990244, 0.20843393799987098, 0.2086688490016968, 0.22291037299874006, 0.19919705800020893, 0.2142630039998039, 0.23600441400049021, 0.2469142419995478, 0.2236971269994683, 0.2061924560002808, 0.2073589190003986, 0.20637194600021758, 0.20729162099996756, 0.21934297000007064, 0.23722687100053008, 0.20957376299884345, 0.23337410100066336], [0.2047244639998098, 0.21268265599974256, 0.20609930800128495, 0.21377630200004205, 0.2037913189997198, 0.20689196899911622, 0.20761197799947695, 0.22162169500006712, 0.22273805000077118, 0.21140811199984455, 0.206475988999955, 0.211243726000248, 0.2244786369992653, 0.21643095500076015, 0.20873550000032992, 0.20897986899944954, 0.2227799110005435], [0.21244906699939747], [], [0.20602119799877983, 0.2138514540001779, 0.2037896229994658, 0.2066932050001924, 0.20781794800132047, 0.2216171439995378, 0.2227510529992287, 0.21138376599992625, 0.20628514900090522, 0.21140672299952712, 0.2244637439998769, 0.21649042700119026, 0.20873486999880697, 0.20851922200017725, 0.223198637000678], [0.20680241000081878, 0.2132438659991749, 0.203347611000936, 0.2072727329996269, 0.2079756389994145, 0.22161493200110272, 0.222694533998947, 0.21107511099944531, 0.20659070600049745, 0.21094019300107902, 0.22452220400009537], [0.2130037490005634, 0.2036788899986277, 0.2068377640007384, 0.20794023099915648, 0.22161036699981196, 0.2227725510001619, 0.21133613100028015, 0.20623720900039189, 0.21125641999969957, 0.22470598300060374, 0.21649883899954148, 0.2084384059999138, 0.20866670800023712, 0.2229073739999876, 0.19919999500052654, 0.21426399499978288, 0.23599984999964363, 0.24692174600022554, 0.22365665100005572, 0.20608148199971765], [0.21419943000000785, 0.20373221299996658, 0.20731735299887077, 0.20726217000083125, 0.22205142100028752, 0.22224228399863932, 0.21151024200116808, 0.2064146559987421, 0.21123376700052177, 0.22446407099960197, 0.21649830900059897], [0.21336783799961268, 0.20321857499948237, 0.2074061180010176, 0.20774118899862515, 0.22184556300089753, 0.2227039480003441, 0.2083098089988198, 0.20888840400039044, 0.21136257000034675, 0.22410554400084948, 0.2167799559993], [0.2034471280003345, 0.20738269699904777, 0.20718995300012466, 0.22206065799946373, 0.22219950200087624, 0.21153600599973288, 0.20639805700011493, 0.21171903100002964, 0.22405071399953158, 0.21653053000045475], [0.2032299200000125, 0.20717439699910756, 0.2079504180001095, 0.22178561600048852], [0.20356699799958733, 0.20730090100005327, 0.20725581300030171, 0.22206794200064905, 0.22221752099903824, 0.21152885800074728, 0.20640209799967124, 0.2113358620008512, 0.22438589699959266, 0.21657296400007908, 0.20877273099904414, 0.2089422690005449, 0.22267336699951557, 0.19925133700053266, 0.21377386200038018, 0.2358843189995241, 0.24698979000095278, 0.22456101599891554, 0.20594499700018787, 0.20792255900050804, 0.20625921899954847, 0.20627832299942384, 0.2197889600010967, 0.23873226499927114], [0.2035584450004535, 0.20680769499995222, 0.20794420200036257, 0.22161292799864896, 0.22276409900041472, 0.21135637199949997, 0.2062187459996494, 0.21127498500027286, 0.22469547800028522, 0.2164919999995618, 0.2084388890016271, 0.20866983399901073, 0.22330589100056386, 0.1987997189989983, 0.21426508400145394, 0.23599552899941045, 0.246923581998999, 0.22362140100085526, 0.2060722389996954, 0.20749638199959008, 0.2063756959996681, 0.20723923800142074], [0.20685961500021222, 0.20793271600086882, 0.2216103970004042, 0.22278369999912684, 0.21100337999996555, 0.20657008700072765, 0.21094176699989475, 0.22456547299952945, 0.21695002100022975, 0.20837871999901836], [0.2066203049998876, 0.2079199649997463, 0.22161469099955866, 0.22275746900049853, 0.2113714360002632, 0.20629416599877004, 0.2113426520008943], [0.2072706589988229, 0.22203648300092027, 0.22226283999953012, 0.2114140369994857, 0.20647286799976428, 0.2112486860005447, 0.2244734050000261, 0.21643201100050646, 0.208735127998807, 0.20909525500064774, 0.22273803099960787, 0.19922843400127022, 0.21377809599835018, 0.2359021450010914, 0.24698793700008537, 0.22454393899897696, 0.20594506800080126, 0.20784429500054102, 0.20599723499981337, 0.20657024499996623, 0.21932062199994107, 0.23925006199897325, 0.20811337099985394, 0.23282785100127512, 0.20865840799888247, 0.20761202900030185, 0.22316944200065336, 0.22052188499947079, 0.20706550100112509, 0.2183591869998054, 0.2238168809999479, 0.20259348899890028, 0.21255845300038345, 0.20812856100019417, 0.21074827300071775, 0.21406846099853283], [0.20718980099991313, 0.2220585229988501, 0.222208450000835, 0.2115305259994784, 0.20640108000043256, 0.2116510619998735], [0.20774531200004276, 0.22184379000100307, 0.22271311799886462, 0.2080880330013315, 0.208738811999865, 0.21170529399933002, 0.22410768599911535, 0.2167871900001046, 0.20829798400154687, 0.20942602599825477, 0.2228176770004211], [0.20712006599933375, 0.22204786800102738, 0.22219112599850632, 0.2115406980010448, 0.2067026309996436, 0.21142231600060768, 0.22403843400024925, 0.21657251299984637, 0.20872041099937633, 0.20893585799967695], [0.2221365440000227, 0.22292702800041297, 0.20748712299973704, 0.20940019599947846, 0.21141785500003607, 0.22422227199967892], [0.22190595400024904, 0.2227115749992663, 0.2075009720010712], [0.208507395000197, 0.2088815049992263, 0.21137403700049617, 0.2241045699993265, 0.2167826100012462, 0.20830356499936897, 0.20942325699979847, 0.22288889800074685, 0.19877514299878385, 0.21462253300160228, 0.23610521699993114, 0.24656426000001375, 0.2240621499986446, 0.20582733800074493, 0.20767102299942053, 0.20647036000082153, 0.20717536699885386], [0.20754095799929928, 0.20926350300032937, 0.2116968629998155, 0.2241232670003228, 0.2167983399995137, 0.20828902299945184, 0.20942841800024325, 0.22282733599968196, 0.19884951200037904, 0.2145206599998346, 0.23576329400020768], [0.21151601400015352, 0.2067883649997384, 0.21136386100079108, 0.22404398099934042, 0.21652942299988354, 0.2087181339993549, 0.20902258200112556], [], [0.20642373099872202, 0.21122997700149426, 0.2244686449994333, 0.21643401099936455], [0.2064172589998634, 0.21128524699997797, 0.22453212199980044, 0.2170035920007649, 0.20766070600075182, 0.20941450099962822, 0.22288229100013268], [0.20629366799948912, 0.21127245100069558, 0.22452788400005375, 0.2170084429999406, 0.2082694540004013, 0.2088039279988152, 0.22291253200091887], [0.20939805800117028, 0.21149413599960099, 0.2242740239998966, 0.21702605800055608, 0.2073849690004863, 0.2098439449982834, 0.22239063500092016, 0.1990119849997427, 0.21518964300048538, 0.2357668000004196, 0.24714409899934253, 0.22389082100016822, 0.20560581000063394, 0.20693232899975555, 0.20684839999921678], [], [], [0.21136661099990306, 0.22401311800058465], [0.21123839500069153], [0.21123394900132553, 0.22444650899888074], [], [0.22425787699830835, 0.21681572500165203, 0.2080243349992088, 0.2093106459997216], [0.2241421859998809, 0.2165282309997565, 0.20877293000012287, 0.20893842300029064, 0.22267282199936744, 0.1992550939994544, 0.21377528099947085, 0.2359768130008888, 0.2468929360002221, 0.22456654099914886, 0.20594520700069552, 0.20791778800048633], [0.22440676800033543, 0.21656853199965553, 0.20873464400028752, 0.20899614399968414, 0.22267408200059435, 0.19924689300023601, 0.2137744819992804, 0.2358883449996938, 0.2469896950005932, 0.2245560650007974, 0.20594497099955333, 0.20792536599947198, 0.20625459199982288, 0.206286964001265, 0.21977091999906406, 0.23874832200090168, 0.20727563399850624, 0.23324135700022453, 0.20852060400102346, 0.20670040099867037, 0.22394021300169697, 0.22074098599841818, 0.20761783000125433, 0.2179587509999692, 0.22369988699938403, 0.20251532800102723, 0.2132268399982422, 0.20695616700140818, 0.21180670899957477, 0.2141734800006816, 0.2325140189986996, 0.21001493699986895, 0.22931107900149073, 0.21735407499909343, 0.20393040400085738, 0.20887930299977597, 0.2230074439994496, 0.20794438300072215, 0.20724864199837612, 0.2095834300016577, 0.20766457399986393, 0.21301809499891533, 0.20896315400023013, 0.2338127990005887, 0.25894518899985997, 0.23866734600051132, 0.21322758399946906, 0.22897911200016097, 0.21447413500027324, 0.20498596600009478, 0.2120198229986272, 0.2219796879999194, 0.20732707100069092, 0.21600132099956681, 0.21766378699976485, 0.20821832100045867, 0.20470157499948982, 0.2084101130003546, 0.2125221460009925, 0.20376078099980077, 0.21579786099937337, 0.20324021099986567, 0.22272543700091774, 0.20229855499928817, 0.21057954800016887, 0.2263333299997612, 0.2483681779995095, 0.21348011500049324, 0.2065541169995413, 0.2092902900003537, 0.2061085400000593, 0.21742694500062498, 0.2320206459990004, 0.2117265659999248, 0.21350474700011546, 0.22095928300041123], [0.21699491800063697, 0.20766262899996946, 0.20941941199998837, 0.22288698500051396, 0.19928157799949986, 0.21426295899982506, 0.2359763650001696], [0.210045435000211, 0.2089948920001916, 0.222677701000066, 0.1992385520006792, 0.2137758529988787, 0.2358944160005194, 0.24698959499983175, 0.22454933900007745, 0.20594601099946885, 0.20792958600031852, 0.20595969299938588, 0.20652628200150502, 0.2193320970000059, 0.23924343199905707, 0.20695173000058276, 0.23340277799979958, 0.20866554500025813, 0.20638214300015534, 0.22411493599975074, 0.22085504499955277, 0.20765743400079373, 0.21794648399918515, 0.2236128420008754, 0.20258125500004098, 0.21312214599856816, 0.20650892300000123, 0.21237164800004393, 0.2141212810001889], [0.20859125799870526, 0.20908757300094294], [0.20932285699927888, 0.22233055000106106, 0.1995220659991901, 0.2147342900007061, 0.23578003100010392, 0.2470539869991626, 0.22404027999982645, 0.20558262900158297, 0.2068262099983258, 0.20733715999995184, 0.20665629400173202, 0.21996717599904514, 0.23731309700087877, 0.20972819499911566, 0.23324412900001334, 0.20861366899953282, 0.2066063820002455, 0.2239414020004915, 0.22073834399998304, 0.20684651900046447, 0.21872046699900238, 0.22370973500073887, 0.2025123839994194, 0.2125408640004025, 0.2077679869998974, 0.21062990099926537, 0.2144778910005698, 0.23326184899997315, 0.21001562799938256, 0.22937716900014493, 0.21727978400122083, 0.20282943199890724, 0.20900984900072217, 0.22355557599985332, 0.20681139800035453, 0.2079738329994143, 0.2092556700008572, 0.2075277419990016, 0.2123304279994045, 0.20974133700110542, 0.23446306999903754, 0.2590251530000387, 0.23844111300059012], [], [], [0.20874015399931523, 0.2229133910004748, 0.19919484199999715, 0.21426403999976174, 0.23600555000120949, 0.2465081479986111], [0.22273941500134242, 0.19921139100006258, 0.21373726699857798, 0.23596288100088714, 0.24698547099978896, 0.2240133790000982, 0.20600839799953974, 0.20798946700051602, 0.20602085400059877, 0.20687188199917728, 0.2193141839998134, 0.23792166900057055], [0.22320726600082708, 0.19877774599990516, 0.2142646619995503, 0.23599174000082712, 0.2469257180000568, 0.22366511600012018, 0.20619800699932966, 0.2075483369990252, 0.20642449200022384, 0.20706875700125238, 0.21934073599913972, 0.2372234610011219], [], [0.22259553399999277, 0.1993712820003566, 0.21365582500038727, 0.2359775980003178, 0.24688700499973493, 0.22457166499953019, 0.2059461860008014, 0.20794827600002463, 0.20621749999918393, 0.2062709920010093, 0.2197991329994693, 0.23877569599972048], [0.19878247100132285], [0.21426308999980392, 0.23598398200010706, 0.246559592000267, 0.2240692190007394, 0.20582760099932784, 0.20766933800041443], [], [0.2142392710011336, 0.23597652399985236, 0.24692786199921102, 0.22406948900061252, 0.20594709099896136, 0.20740008400025545, 0.20665622399974382, 0.20689082700118888, 0.2193031789993256, 0.2372892020011932], [], [], [0.20599000299989711], [0.20562142500057234, 0.20812144400042598], [0.20571962199937843, 0.20808878500065475], [0.2076207069985685], [0.20697649700014153], [0.20741302399983397, 0.20662541700039583, 0.20658879300026456, 0.21998005399836984, 0.23728804900019895, 0.20975047200045083, 0.23336797199954162, 0.20853144700049597, 0.20676861200081476, 0.2237329999989015, 0.2209518340005161, 0.20660234699971625, 0.21880202000102145, 0.22387844799959566, 0.20233258199914417, 0.21245947900024476, 0.20790156400107662, 0.21064161999856879, 0.21463167200090538, 0.23320436699941638, 0.21010587899945676, 0.22911405800005014, 0.21724816800087865, 0.2028324570001132, 0.20901123899966478, 0.2235492069994507, 0.20701635099976556, 0.2079857640001137, 0.20927712699995027, 0.207930006999959, 0.21251464600027248], [0.20798170899979596, 0.20603325000047334, 0.20687970899962238, 0.21930940499987628, 0.2379083530013304, 0.2087489169989567, 0.23324685900115583], [0.2066386730002705, 0.20659064199935528, 0.21998227299991413, 0.23728976900019916, 0.20975552600066294, 0.23331190399949264], [0.20647125899995444, 0.20717718299965782, 0.2193906890006474], [0.20595222699921578, 0.20653670799947577, 0.21932616800040705, 0.23924738700043235, 0.20811602600042534, 0.23282564299915975, 0.20865256700017198, 0.20762113700038753, 0.22317120499974408, 0.2205121480001253, 0.20707253999898967], [0.20651304100101697, 0.20718855299855932, 0.2193963050012826, 0.23734860599870444, 0.2099636080001801, 0.23309938599959423, 0.20868140300080995, 0.2067723449999903, 0.223689975000525, 0.220801057999779, 0.20680601599997317], [0.20623188799982017, 0.20726118099992163, 0.219342444999711, 0.23722346700014896, 0.20929779700054496], [0.20659290599905944, 0.20711148900045373], [0.206904011000006, 0.21929888599879632, 0.2372854040004313, 0.20938867699987895, 0.23324476600100752, 0.20860983199963812, 0.20679350299906218, 0.22376316900044912, 0.22073407099924225, 0.20737074200042116, 0.2181888520008215], [0.20629902399923594, 0.21929209900008573], [], [0.20617982099975052, 0.21979392200046277, 0.23880163399917365, 0.20727460700072697, 0.2334281990006275, 0.20869214399863267, 0.2067404350000288, 0.22357223600010911, 0.22094396800093818, 0.2079697009994561, 0.21747236600094766], [0.2200704829992901, 0.23732409500007634, 0.2097130920010386, 0.2331341839999368], [0.21977543600041827, 0.23723850500027766], [0.20811741999932565, 0.23283328900106426, 0.20866549299898907, 0.20728975100064417, 0.223479648000648, 0.220526062999852, 0.20650043199930224, 0.21893085900046572, 0.2237957319994166, 0.20233460599956743, 0.21246400300151436], [0.20682323899927724, 0.22394464399985736, 0.22074472900021647, 0.20658001899937517, 0.21900842700051726, 0.2236854359998688, 0.20252121300109138, 0.2119790369997645], [0.20666787400114117], [0.20675766400017892, 0.2237386910001078, 0.22095137200085446, 0.2070326009998098, 0.21838100000059057, 0.22371919299985166, 0.20246385099926556, 0.21272287300052994, 0.2076409839992266, 0.21071554500122147], [0.2067277580008522, 0.2235504589989432, 0.22095277800144686, 0.20799237299979723, 0.21746680199976254, 0.2238398209992738, 0.2023342850006884, 0.21335232499950507, 0.20700376400054665, 0.21201855300023453, 0.2138115439993271], [0.22347531500054174, 0.22053435700036061, 0.2070838609997736, 0.21835323000050266, 0.22382349299914495, 0.2023350590006885, 0.2126469119993999, 0.20827696199921775, 0.21032004400149162, 0.21451073499883933, 0.2332027200009179, 0.21071804500024882, 0.22834552799940866, 0.21765165999931924, 0.20336749099988083, 0.20887536400005047, 0.22289144200112787], [0.22363225799927022, 0.22062019700024393, 0.20694551399901684], [0.22345047300041188, 0.22094779199869663, 0.20713792000060494, 0.21831278299941914, 0.22384669900020526, 0.20233483000083652, 0.21266483399995195, 0.20768961399880936, 0.2109059040012653, 0.214395863999016], [0.20748038199963048, 0.2187223750006524, 0.2238226850004139, 0.20259716999862576, 0.21223531600116985], [0.20720298100059154, 0.2182236999997258, 0.22363965200020175, 0.20251059099973645, 0.21278872599941678, 0.20752683499995328, 0.2110670680012845, 0.21439704899967182, 0.2330767690000357, 0.20998720900024637], [0.21747624599993287, 0.22383312199963257, 0.20233133200054, 0.21335670400003437, 0.2070042960003775, 0.21202370100036205, 0.21380442499867058, 0.23265181300121185, 0.21011184599956323], [0.22422663299948908, 0.202336311000181, 0.2133752280005865, 0.20698460699895804, 0.21155629699933343, 0.21417729099994176, 0.23274247000153991, 0.21009614799913834, 0.22912950099998852, 0.2172511900007521, 0.20396601099855616, 0.20881537900095282], [0.21348396899884392, 0.20648363700092887, 0.21227603499937686, 0.21417174700036412, 0.23245929199947568, 0.20999975400081894, 0.22928946299907693, 0.21733160599978874, 0.20404817200142134, 0.20887786200000846, 0.22295380699870293], [0.212177168999915, 0.20851483400110737, 0.20999156899961235, 0.21463548400060972, 0.23340705199916556, 0.21072077300050296, 0.22833653199995751, 0.2176489239991497, 0.2025723040005687, 0.20936332999917795, 0.22309137100091903, 0.20742622999932792, 0.2076956609998888, 0.20918203800101765, 0.20792305299983127, 0.2125804249990324, 0.20887817300172173, 0.23446133899960842, 0.2591514189989539, 0.23860806000084267, 0.21234467899921583, 0.23040262600079586, 0.21494084500045574, 0.20561048699892126, 0.21164946600038093, 0.22168813399912324, 0.20593116100098996, 0.2170339629992668, 0.21741314199971384, 0.20753755500118132, 0.20489065499896242, 0.2079271520015027, 0.2119028580000304, 0.20387719199970888, 0.2164960099999007, 0.2032791419987916, 0.22261291200084088, 0.20175413399920217, 0.21036219900088327, 0.226822672999333, 0.24910759200065513, 0.21200386899909063, 0.20712021200051822, 0.21003015099995537, 0.20482485399952566, 0.2186642180004128, 0.23195841500091774, 0.21056107999902451, 0.21402965699962806, 0.22100750300160144, 0.21949345999928482, 0.23767690999920887, 0.25856652299989946, 0.21060790500087023, 0.21719257299992023, 0.21141247100058536, 0.21567382699868176, 0.20633012899997993, 0.20804786500048067, 0.22275978600009694, 0.21489336600097886, 0.20860480499868572, 0.22981660400000692, 0.24928382000143756, 0.27586903699921095, 0.21251390100042045, 0.21864635199926852, 0.22438925899950846, 0.2177747850000742, 0.2000656300006085, 0.20772583700090763, 0.21495016599874361, 0.2332066670005588, 0.25502059800055576, 0.2807780869989074, 0.23761950900006923, 0.21190873500017915, 0.20773893099976704, 0.20742792599958193, 0.20676809799988405, 0.20786133900037385, 0.20646721699995396, 0.20853084600094007, 0.2115727689997584, 0.228331234999132, 0.22206503100096597, 0.2109015719997842, 0.23622217800038925, 0.20397652399879007, 0.22018297200156667, 0.22927879599956213, 0.20540246899872727, 0.21584596100001363, 0.22096091900129977, 0.21141271899978165, 0.22745313399900624, 0.2117821380015812, 0.2072642650000489], [0.20696247400155698, 0.21157882999978028, 0.2141748430003645, 0.2327390579994244, 0.2100942369997938, 0.22913987500032817, 0.21725339099975827, 0.20389710800009198, 0.20887910800047393, 0.2230114149988367, 0.20793832399976964, 0.20724447000065993, 0.20958367400089628, 0.20767184699980135], [0.2076279400007479, 0.2107709359988803, 0.2144818300002953, 0.23324369600049977, 0.21001620899914997, 0.22931553200032795, 0.21735645099943213, 0.20282890500129724, 0.20901062799930514, 0.22355570800027635, 0.20669336399987515], [0.21028620400102227, 0.2144042609997996, 0.2332173499999044], [0.21058608800012735, 0.21467038999981014, 0.23326433399961388, 0.21001313799933996, 0.22932141199999023, 0.21727538600134721, 0.20270969400007743, 0.20912123899870494, 0.22352417200090713], [0.21380243099883955, 0.2326903780012799, 0.21017994699832343, 0.22901463500056707, 0.21724942900073074, 0.2039639550002903, 0.20892364799874485, 0.2228821720000269], [0.2138387370014243, 0.23270548999971652, 0.21071155999925395, 0.2283621780006797, 0.21765239900014421, 0.20366835200002242, 0.20884832199953962, 0.22341901199979475, 0.2074296120008512, 0.20716427199840837, 0.20958339000026172, 0.20791410300080315, 0.21292890599943348, 0.20882042800076306, 0.23420605499995872, 0.2589360399997531, 0.23832191200017405, 0.21328398699915851], [0.21462856400103192, 0.23298804699879838, 0.21001613800035557, 0.22937508299946785, 0.21727505800117797, 0.20284025599903543, 0.2090111050001724, 0.2235520699996414, 0.20682204500008083, 0.20796541900017473], [0.21086839699819393, 0.22878663900155516, 0.21765229299853672, 0.2036636790016928, 0.20884812099939154, 0.22341431499989994, 0.2073762660002103], [0.22928536499966867, 0.21725895300005504, 0.20284763900053804, 0.20901066999977047, 0.22354982999968342, 0.20682661499995447, 0.20801928100081568, 0.20919898200008902, 0.20766388499941968, 0.21222248999947624], [0.2037838650012418, 0.208971500998814, 0.2230619680012751, 0.2075045039982797, 0.20762553400163597, 0.20968352599993523, 0.2076734980000765, 0.21267054899908544, 0.20875864300069225], [0.20366029700016952, 0.20884886200110486, 0.22340367099968717, 0.207391492998795, 0.20724215900008858, 0.20958361700104433, 0.20773533300052804, 0.21293646300000546, 0.2089684459988348, 0.23381164999955217, 0.2593128170010459, 0.23834990999966976, 0.21326615600082732, 0.22900693900010083, 0.2150537779998558, 0.20455169999877398, 0.21200342700103647, 0.22179175800010853, 0.2072779640002409, 0.21629688399843872, 0.21742617700147093, 0.20843223199881322], [0.2091868399984378, 0.22306355300133873, 0.20742936900023778, 0.2076862509984494, 0.2091891360014415, 0.2079221679996408, 0.21258104600019578, 0.20887847999983933, 0.2344591130004119], [0.2088039200007188, 0.2229677659997833, 0.20797449499877985, 0.2071465110002464, 0.20975358900068386, 0.20761802999913925, 0.2129666270011512, 0.20904704999884416, 0.233853679999811, 0.25894496200089634, 0.2386856449993502, 0.2127840829998604, 0.22978191100082768, 0.2149450100005197, 0.20559156099989195, 0.21166301399898657, 0.22164341999996395], [0.20937376400070207, 0.22309865499846637, 0.2071023509997758, 0.20797657100047218, 0.20920972299973073, 0.20792289800010622, 0.21258271700025944, 0.2088762460007274, 0.23446197900011612, 0.25915009999880567, 0.23855127800015907], [0.22312535899982322, 0.2071045310003683, 0.20798350400036725, 0.2092037899983552, 0.20792030700067698, 0.21258521100025973, 0.20887705600034678, 0.23446175099888933, 0.2591475490007724, 0.23855713400007517, 0.21232119699925533], [0.22302423600012844, 0.20749816599891346, 0.2076167710001755, 0.20968550300131028, 0.20767995999995037, 0.2128903309985617], [0.2052643059996626, 0.20799413800159527, 0.20927065099931497, 0.20750735600086045, 0.21289558099852002, 0.2090023700002348, 0.23446272699948167, 0.25914478600134316, 0.23849704299937002], [0.20725482499983627, 0.20958344300015597, 0.2076541759997781, 0.21302836799986835, 0.20895601400115993, 0.23381567399883352, 0.25894505299947923, 0.23867369400068128, 0.2128975649993663], [0.2079933990007703, 0.20919818400034274, 0.20791745699898456, 0.21258805800061964, 0.20887654000034672, 0.2344626479989529, 0.25914750499941874, 0.2385604360006255, 0.21231734399952984, 0.2303511720001552, 0.2150512170010188, 0.20455508699888014, 0.21200713600046583, 0.2217860130003828, 0.2065824139990582, 0.21699849000106042, 0.21742069500032812, 0.20741409999936877, 0.2047027970002091, 0.20816684899909887, 0.2119529000010516, 0.20382182799949078, 0.21644120199925965, 0.20316118600021582, 0.22277316899999278, 0.20187972800158605, 0.2103706579982827, 0.22682281500055979, 0.24910898999951314, 0.21200372300154413, 0.20712155099863594, 0.20966365599997516, 0.20506365000073856, 0.21875590099989495, 0.23197076900032698, 0.21055208899997524, 0.21385690299939597, 0.22116878899942094, 0.21948915000029956, 0.2376783820000128, 0.2581802170006995, 0.2108094559989695, 0.21668419600064226, 0.21202240000093298, 0.2157805989991175, 0.20633275699947262, 0.20804870600113645, 0.2227622819991666, 0.21454519799954141, 0.2088337090008281], [0.2077058280010533, 0.20917680200000177, 0.2079231459993025, 0.21258097000099951, 0.20887782299905666, 0.23446114000034868, 0.25915125599931343, 0.23857996799961256], [0.20710325900108728, 0.20957113699842012, 0.20791534800082445, 0.21293032199901063, 0.20882286400046723, 0.2342029890005506, 0.25894249100019806, 0.23831429399979243, 0.21334659099920827, 0.22912408800038975, 0.21493408700007421, 0.20562453800084768, 0.2116415849995974, 0.2216851579996728, 0.20563134599979094, 0.2173362930006988, 0.21741273199950228, 0.20631657400008407, 0.20555011500073306, 0.20824930799972208, 0.2117628939995484, 0.2038415349998104, 0.21661834900078247, 0.20318547199894965, 0.22274741700130107, 0.20150995299991337, 0.21056529299858084, 0.22701175600013812, 0.24911526200048684, 0.21200401200076158, 0.2069543599991448, 0.20952537700031826, 0.2051446860004944, 0.21892498499983049, 0.23201715799950762, 0.21050470400041377, 0.21379037299993797, 0.2211115449990757], [0.2075779290007631, 0.20974990300055651, 0.20761637999930826, 0.21295944399935252, 0.2090468950009381, 0.23386105300050986, 0.2589450300001772, 0.23869084899888549, 0.21226977600053942, 0.23028449899902625, 0.2149204000015743], [0.20763645700026245, 0.2092665220006893, 0.20797574899916071, 0.21258954699987953, 0.20877332700001716, 0.2346076150006411, 0.25895315399975516, 0.23860406700077874, 0.21235349499875156, 0.23014866700032144, 0.2150216680001904], [0.20960319100049674, 0.20758324400048878], [0.2092037069996877, 0.20791520700004185, 0.21258840300106385, 0.20887946899892995, 0.2344638490012585, 0.25914537299831863, 0.23853073500140454], [0.20926230099939858, 0.20751414999904227, 0.21288394100156438, 0.2090118859996437, 0.2344636449997779, 0.2591437529990799, 0.23835190800127748, 0.21250892100033525, 0.2303568399984215, 0.21499863600001845], [0.20766949899916654, 0.21249780600010126, 0.20877491099963663], [0.20788076099961472], [0.20754830800069612, 0.21230492799986678, 0.20959376199971302, 0.23446383000009519, 0.25913872999990417, 0.23835805099952267, 0.2124965550010529, 0.2303469149992452, 0.21494326699939847], [0.2125235759995121, 0.2089792139995552, 0.23446299600072962, 0.2591457670005184, 0.23853383099958592, 0.21236109900019073, 0.2303195450003841, 0.2150262789982662, 0.20459423200009041, 0.21199624400105677, 0.2217990249991999, 0.2066000830000121, 0.21677318700130854], [0.21292789000108314, 0.20882091599924024, 0.23420637700110092, 0.2589290469986736, 0.23833348700100032, 0.2132750719993055, 0.22902054500082158, 0.2150476169990725, 0.20465954300016165, 0.2124154360008106], [0.21228497800075274, 0.20987768799932383, 0.23446664000039164, 0.25902302999929816, 0.238458885, 0.2123789580000448, 0.2304957819997071, 0.21433789100046852, 0.20507385500059172, 0.2119828819995746, 0.22205871199912508, 0.20566273800068302, 0.217533093999009, 0.217264178001642], [0.21222437700089358, 0.2097205039990513, 0.23446259699994698, 0.25902506400052516], [0.2089507010005036, 0.23381865800001833, 0.258944707999035, 0.23868002100061858, 0.21280501900037052], [0.208760561001327, 0.23445911799899477, 0.258947991000241, 0.2385991160008416, 0.2123613399999158, 0.23019562199988286], [0.2087799629989604, 0.23454841600141663], [], [0.2091219119993184, 0.23387468500004616, 0.25894581099964853, 0.2386939820007683, 0.21226738199948159, 0.23004052699980093, 0.21500288600145723, 0.20452507699883427], [0.213208138000482], [], [0.21240907500032336, 0.23032698499991966, 0.2150291420002759, 0.2045878939989052, 0.21182362800027477, 0.22197423500074365, 0.2065983079992293, 0.2167732560010336, 0.21764741100014362, 0.20732033799868077], [], [0.20620121100000688, 0.21227913099937723, 0.22139610500016715, 0.20703926699934527, 0.2163132690002385, 0.21741735900104686, 0.20862953199866752], [0.20498484400013695, 0.21202216900019266, 0.22198435899917968, 0.2067463730018062, 0.21658305199889583, 0.2176554319994466, 0.2077494020013546, 0.2048883939987718, 0.20792733800044516, 0.21255793800082756, 0.20333328299966524], [0.20460060599907592, 0.21195074299976113, 0.22197682000114582, 0.20642743999997037, 0.2169015519993991, 0.2176674180009286, 0.20672569499947713, 0.20532264100074826, 0.20824858299965854, 0.2117612839992944, 0.20383713000046555, 0.21662193900010607, 0.20317989199975273, 0.2227546579997579, 0.2015112589997443, 0.21074831900114077, 0.226830716999757, 0.24911104300008446, 0.21200372199928097, 0.20711984199988365, 0.20935047599959944, 0.2052681080003822, 0.21885159500016016, 0.23198477600089973, 0.2105336320000788, 0.2138600629987195, 0.22116022400041402, 0.21947824500057322, 0.23768126999857486, 0.25817646800169314, 0.210816442999203, 0.21641890699902433, 0.21124713300014264, 0.21682576800048992, 0.2063389430004463, 0.20805060699967726, 0.2227634169994417, 0.21428172500054643, 0.20879068900103448, 0.2300898679986858, 0.24941826800022682, 0.27586963900103, 0.21238814199932676, 0.2186175650003861, 0.22411556800034305, 0.21799415499845054, 0.19943227500152716, 0.2085084399986954, 0.21502343400061363, 0.23303888299960818, 0.25505874500049686, 0.28088162499989267, 0.23753673499959405, 0.2111114439994708, 0.20820746600111306, 0.207697656000164, 0.2064046249997773], [0.21205345499947725, 0.22132413200051815, 0.20704424099858443, 0.21630758399987826, 0.21741601300163893, 0.20834055299928878, 0.2044488640003692, 0.20841077699878952, 0.21259768500021892, 0.20371975600028236], [0.21204367300015292, 0.22181486499903258, 0.20649182600027416], [0.22152751000066928, 0.2063563850006176, 0.2169994139985647, 0.21741748200111033, 0.20742108299964457, 0.2046976290002931, 0.20816705899960652, 0.21195840499967744, 0.20381976200042118, 0.21643815400057065], [0.2217202499996347], [0.2067118949998985, 0.21677524400001857, 0.21765063500060933, 0.20673107500078913, 0.2053143960001762, 0.20825006999984907, 0.21176071499940008, 0.20383276199936518, 0.21662521200050833, 0.20317364699985774, 0.22276180700100667, 0.20151268799963873, 0.21075339799972426, 0.22682476899899484, 0.24910922200069763, 0.2120044750008674, 0.20712162499876285, 0.20934042600129033, 0.20527743299862777, 0.2188502740009426, 0.23197840200009523, 0.2105415259993606, 0.21385614599967084, 0.22116552100123954, 0.21948354999949515, 0.23767952699927264, 0.2581771610002761, 0.2108148280003661, 0.21641861599891854, 0.21226769800159673, 0.2158028559988452, 0.20633609300057287, 0.2080486419999943, 0.22276320899982238, 0.21427737699923455, 0.20880854800088855, 0.2300824260000809, 0.24941428300007829, 0.27586908900048, 0.2123956969990104, 0.21861008099949686], [0.2172602390000975, 0.21730527299951063, 0.20690302299954055, 0.205550636001135, 0.20824932599862223, 0.21176506700066966, 0.20380134100014402, 0.21665732499968726, 0.20311228200080222, 0.22282949399959762, 0.20139048199962417, 0.21064734699939436, 0.2268726490001427, 0.24928973500027496, 0.21199834300023213, 0.20696043799944164, 0.20953915500103903, 0.20513156599918148, 0.2187884880004276, 0.23216391099958855, 0.20978588500111073], [0.21627068599991617], [], [0.21575466899957974, 0.21728797899959318, 0.2093014910005877, 0.20413957600067079, 0.2084998109985463, 0.21244031400055974, 0.20376539199969557, 0.21631896200051415, 0.20310557599987078, 0.22228300599999784, 0.20232466999914323, 0.2105624740015628, 0.22633630599921162, 0.2486424069993518, 0.21321176499986905, 0.20653782900080842, 0.20934931800002232, 0.20611178100079997, 0.217367829000068, 0.2320000669988076, 0.2117239180006436, 0.21353421499952674, 0.22101539200048137, 0.21970380799939448, 0.2367039590008062, 0.2585327389988379, 0.2111862990004738, 0.21658280200063018, 0.2118452859995159, 0.21568029400077648, 0.2066120099989348, 0.2083695399996941, 0.22160539200012863, 0.2147811590002675, 0.20919256799970753, 0.2294992759998422, 0.24917396900127642, 0.27677963599853683, 0.21198489500056894, 0.21878211900002498], [0.20871127399914258, 0.20478120400002808, 0.2084244880006736, 0.2124062339989905, 0.20386633100133622, 0.2153836859997682, 0.2036752809999598, 0.22272269699897151, 0.20210664899968833, 0.21073227300075814, 0.2263467339998897, 0.24837325100088492, 0.21347364399844082, 0.20649384900025325, 0.20938228799968783, 0.20599095900070097, 0.21751076700093108, 0.23203592999925604, 0.21145640699978685, 0.21367222700064303, 0.2209757679993345, 0.21957160199963255, 0.23701305500071612, 0.25840129400057776, 0.2113334509995184, 0.21659618699959537, 0.21184634100063704, 0.21567136199882952, 0.20644611800162238, 0.20847062599932542, 0.22163969999928668, 0.21480945100120152, 0.20919066599890357, 0.2294497130005766, 0.24920173499958764, 0.276622416000464, 0.2117526040001394, 0.21918947899939667, 0.22358903299937083, 0.21777058299994678, 0.20095868800126482, 0.20778377299939166, 0.21448946199961938, 0.23293840900078067, 0.2550680429994827, 0.28073291200053063, 0.238321568000174, 0.21135407499969006], [0.2048409469989565, 0.20816713100066409, 0.21175942899935762], [0.20413826500043797, 0.2083803519999492], [0.20474893100072222, 0.20830443900013051, 0.21227145499869948, 0.2040917120011727, 0.21554604499942798, 0.20325485600005777, 0.22264773400092963, 0.20202026900005876, 0.21083199399981822, 0.22607323699958215], [0.20484080200003518, 0.20819391400073073, 0.21237716900031955, 0.2040845880001143, 0.21555833599995822, 0.2032643829988956, 0.2226351440003782, 0.20193921200007026, 0.2103145470009622, 0.22667315099897678, 0.24910614100008388, 0.2127989439995872, 0.20655844500106468, 0.20997467800043523, 0.2047815849982726, 0.21866057800070848, 0.2318284009998024, 0.2114055490001192, 0.21329298199998448, 0.221552459999657, 0.21908735500073817, 0.2376150449999841, 0.2584720239992748, 0.21114764699996158, 0.21667790100036655, 0.2114407500012021, 0.21598683099909977, 0.20629893799923593, 0.20794084500084864, 0.22247985700050776, 0.21486008899955777, 0.2088977570001589, 0.2296998950005218, 0.24913264499991783, 0.27668208599970967, 0.21177698700012115, 0.21858581499873253, 0.22409209000034025, 0.21790329000032216, 0.2004157489991485, 0.20754050000141433, 0.21494217599865806, 0.23321084300005168, 0.2550195630010421, 0.2807480529991153, 0.237658548001491, 0.21187565899890615, 0.20783914200001163, 0.2078293329996086, 0.2063290220012277, 0.20784502399874327, 0.20662589499988826, 0.2083739350000542, 0.2115580890003912, 0.22850112400010403, 0.2221634779998567, 0.21061477799958084, 0.23645250200024748, 0.20386294899981294, 0.22006519100068545, 0.22924046300067857, 0.20611158099927707, 0.21518415699938487, 0.22092968500146526, 0.21139397999832, 0.22865522600113763, 0.21075708599892096, 0.2072029200007819, 0.2258453680005914, 0.23899997399894346, 0.21211059500092233, 0.2110566329993162, 0.2266921860009461, 0.1991277259985509, 0.2126846570008638, 0.21866985700035002, 0.21249263699974108, 0.2099788579998858, 0.22565609299999778, 0.22617012499904376], [0.2047029579989612, 0.20840974600105255, 0.21247291199870233], [0.20423458400000527, 0.20839178799906222, 0.21256855700084998, 0.20371946199884405, 0.2160171100003936, 0.2033661250006844], [0.2048955490008666, 0.2079276740005298, 0.21189899799901468, 0.2038815270007035, 0.21647011899949575, 0.20321614100066654], [0.20842341899879102, 0.21241257499968924, 0.20371485900068365, 0.21553226399919367, 0.20367805200112343, 0.22232140400046774, 0.20246074599890562, 0.21075348799968197, 0.2262669330011704], [0.2079505829988193, 0.21189845700064325, 0.20381614500001888], [0.21244446899981995, 0.20371845699992264, 0.21553035699980683, 0.2036779280006158, 0.22232113599966397, 0.2021329519993742, 0.21065994700074953, 0.22662695399958466, 0.24851007600045705, 0.2133073869990767], [0.21229025700085913, 0.20408283599863353, 0.21554999300133204, 0.2032594969987258, 0.22264105999965977, 0.20193934700000682, 0.21031563600081427, 0.22667009600081656, 0.24910595299843408, 0.21280124400072964, 0.20655356499992195], [0.2125725469995814, 0.20333525500063843, 0.2163098599994555, 0.20327056200039806, 0.22262590399986948, 0.2017560170006618, 0.2103530749991478], [0.20333594499970786, 0.21636214700083656, 0.20328256399989186, 0.22249615699911374], [0.20333551600015198, 0.21631122100006905, 0.2032746290005889, 0.22262092399978428, 0.2017531700003019, 0.2103577519992541, 0.22682290299962915, 0.24910789299974567, 0.21264293800049927, 0.20667530299942882, 0.21000284500041744, 0.2046738090011786], [0.20372036600019783, 0.21601014099906024, 0.2033719450009812, 0.22238290600034816, 0.20231468999918434, 0.2105696809994697, 0.22633504800069204, 0.24865056999988155, 0.2132014420003543, 0.206545228998948, 0.20928435900168552], [0.20406949499920302, 0.21552984600020864, 0.2036307870002929], [0.2036524940012896, 0.2166225429991755, 0.2031684369994764, 0.22276687000157835, 0.20151305399849662], [0.2038235630006966, 0.21578525400036597, 0.20325726000010036, 0.2227246849997755, 0.2021109629986313, 0.21073058700130787, 0.2263470399993821, 0.24837093700080004, 0.2134776189996046, 0.2064970129995345], [], [], [0.2031124759996601, 0.22228410400020948, 0.20232013199893117, 0.21056515400050557, 0.22633553000014217, 0.24864704200081178, 0.2132062839991704, 0.20654167300017434, 0.2093471589996625, 0.20611196699974244, 0.21736659800080815, 0.23200366499986558, 0.2117252499992901, 0.21351939600026526, 0.2210204929997417, 0.21970505500030413, 0.2367053460002353, 0.25849858400033554], [0.2033765759988455, 0.222389918000772, 0.20230710499890847, 0.2105739810012892, 0.22633466799925372, 0.24865055900045263, 0.21319999499974074, 0.2065491289995407, 0.20928664799976104, 0.20611291800014442], [0.2223795150002843, 0.20192934300030174, 0.21084219600015786, 0.22661832499943557, 0.24853038400033256, 0.21328469199943356, 0.2063894140010234, 0.20972226499907265, 0.20547242800057575], [0.20291141800043988, 0.21065919200009375, 0.22662558299998636, 0.24851624699840613, 0.21329823400083114, 0.20637612899918167, 0.20971851800095465, 0.20556622699950822, 0.2178557669994916, 0.2317906620010035, 0.2115463930003898, 0.21328211299987743, 0.22146104799867317, 0.2195771880014945, 0.23714167599973734, 0.25841504799973336, 0.2113133149996429, 0.21657559999948717, 0.21189842600142583, 0.2156663909991039, 0.2064459720004379, 0.20846473799974774, 0.22164774100019713, 0.2148153510006523, 0.209183775999918, 0.22944788899985724, 0.24920201099848782, 0.2766241680001258, 0.21175293700071052, 0.2191136359997472], [0.2021078710004076, 0.21073169599912944, 0.2263444359996356, 0.24837939600001846, 0.2134664690001955, 0.2061751010005537, 0.2097124209994945, 0.20598755500031984, 0.21750881700063474, 0.23203724199993303, 0.21134958299990103], [0.2105178670008172, 0.2265985300000466, 0.24850606499967398, 0.21339533500031393, 0.20626249800079677, 0.2097150909994525, 0.20557942899904447, 0.21784790300080203, 0.23178696600007243, 0.21155189399905794, 0.2136782760007918], [0.21031143000072916, 0.22668351900028938, 0.2491063559991744, 0.21279403600055957, 0.2065661340002407, 0.2099763639998855, 0.20477458099958312, 0.21854677100054687, 0.23194743899875903, 0.21140135800123971, 0.21329584100021748, 0.22153652599990892, 0.21909614200012584, 0.23761384599856683, 0.2584802370001853, 0.21113831799993932, 0.2166857259999233, 0.2114319880001858, 0.21598182300112967, 0.20611086399912892, 0.20814082300057635, 0.2224817839996831, 0.21486283800004458, 0.20889121099935437, 0.22961184000087087, 0.24922478900043643, 0.2761442109986092, 0.21231338500001584, 0.2185836590015242, 0.2240938830000232, 0.2179038109989051, 0.20041292700079794, 0.20754364699860162, 0.2149431120014924, 0.23321012099950167, 0.2550195950007037, 0.280752863998714, 0.23765143000127864, 0.2118833509994147, 0.20776472499892407], [0.21065534299850697, 0.22633313000005728, 0.2483672739999747, 0.21348115100045106, 0.20655368299958354, 0.2092958869998256, 0.20608883500062802, 0.21744272700016154, 0.23202345100071398, 0.21172711399958644, 0.2134348929994303], [0.21042215099987516, 0.22659688900057517, 0.24848620600096183, 0.2134026730000187], [0.21026293099930626], [], [], [], [0.20657579699945927, 0.2099767729996529, 0.20476718800091476, 0.21855189199959568, 0.23195219300032477, 0.2113923769993562, 0.21330342600049335, 0.22097479299918632, 0.21964848400057235, 0.23750390200075344, 0.2585440639995795], [0.20987163800054986, 0.20480625500022143, 0.21866403099920717, 0.23195569000017713, 0.21076211699983105, 0.21387564600081532, 0.22098861699851113, 0.2194946620002156], [0.20969520499966166, 0.2049263670014625, 0.218523240999275, 0.23179936899941822, 0.2115364370001771, 0.2132857350006816, 0.2214488480003638, 0.21908043199982785, 0.23763875199983886, 0.2584347890006029, 0.21116428899949824], [0.2048867400008021, 0.21868562799863867, 0.23196534100134159, 0.21055538899963722, 0.21404497299954528, 0.22100629300075525, 0.21949293199941167, 0.23767636800039327, 0.2585650319997512, 0.21054503800041857], [], [0.20482194000032905, 0.21866447400134348, 0.23196048399950087, 0.21055904899913003, 0.21400790600091568, 0.2210070139990421, 0.21949280000080762, 0.23767562700049893, 0.25817940999877464, 0.21080954100034432], [0.20505964899894025, 0.21875957400152402, 0.2319742169984238, 0.21054731300137064, 0.21385612899939588, 0.22116771500077448, 0.21948667899960128, 0.23767850599870144, 0.25817884700154536, 0.2108123899997736, 0.21641913399980695, 0.2122811230001389, 0.21578731199952017, 0.2063343089994305, 0.20804952300022705, 0.22276157700071053, 0.2142704550005874, 0.20882117399924027, 0.23018608399979712, 0.2493045589999383, 0.27586898200024734, 0.21240029799992044, 0.2187076589998469, 0.22421202700024878, 0.21790687999964575, 0.19958042100006423, 0.2082798850005929, 0.21499408799900266, 0.23304276800081425, 0.25506217799920705, 0.2808923530010361, 0.2375306849990011, 0.21110291900004086, 0.2082110740011558, 0.20785934499872383, 0.2067622560007294, 0.20789115499974287, 0.20622895199994673, 0.20868644499932998], [0.20492039300006581, 0.2185113369996543, 0.23179393099962908, 0.2115421039998182, 0.21328448700114677, 0.22145492199888395, 0.21907659800126567, 0.23764398399907805, 0.25842332399952284, 0.21124946900090436], [0.21766467500128783, 0.2320365870000387, 0.21134779899875866, 0.21370636000028753, 0.22103503899961652, 0.21948350200000277, 0.23712874200100487, 0.25840806499945757, 0.21132498599945393, 0.21656570400045894], [], [0.2188558390007529, 0.2319943910006259, 0.21052582999982405, 0.213860907999333, 0.2211536310005613, 0.219461169999704, 0.23768226399988635, 0.25818384699960006, 0.21080975999939255, 0.21643111500088708, 0.21125394999944547, 0.2163857410014316], [], [0.21744336200026737, 0.23202665699864156, 0.2114657320016704, 0.21366617700005008, 0.22097893499994825], [0.21861040600015258, 0.23180604399931326, 0.2115323210000497, 0.213205640000524], [0.2173661010001524, 0.2320092959998874, 0.21172607300104573, 0.21351290799975686, 0.2210158109992335, 0.21947365300002275, 0.23692353799924604, 0.25850375900154177, 0.21123220200024662, 0.21659325399923546, 0.21184443200036185, 0.2156749409987242, 0.20651511300093262, 0.20843409900044207, 0.2216227520002576, 0.21479829799864092, 0.20919307800068054, 0.22947427200051607, 0.24918453799909912, 0.27670473500074877, 0.21205674100019678, 0.21879459499905352, 0.22331007499997213, 0.21790426400002616, 0.20109806199980085, 0.20778466900083004, 0.21449030799885804, 0.2329350300005899], [0.21196243499980483, 0.21331507700051588, 0.22097039199979918, 0.21964352299983148, 0.23750719199961168, 0.25854997300120885, 0.21118824899895117, 0.21663469200029795], [], [0.21340423099900363, 0.22097290900092048, 0.21948595100002422], [0.21347055600017484, 0.22096800799954508, 0.21963366499949188, 0.23751579500094522, 0.2585561529995175, 0.2106224729996029, 0.21719402600137983, 0.2114079650000349], [0.21321163100037666, 0.22153875100048026, 0.21908324099968013, 0.23761609499888436, 0.2584648490010295, 0.21115475799888372, 0.21667182100100035, 0.2118143930001679, 0.2157562329994107, 0.20634375299960084, 0.2084198100001231], [0.21343109400004323, 0.22103414199955296, 0.21949300600135757], [0.21388031199967372, 0.220986100999653, 0.21949204600059602, 0.23767732600026648, 0.25856184199983545, 0.2106172179992427, 0.21719349600061832, 0.21140806900075404, 0.21566971799984458, 0.20633017299951462, 0.20804900400071347, 0.22275682199870062, 0.21489245100019616, 0.20860834700033593, 0.2298162509996473, 0.2492811949996394, 0.2758712450013263, 0.2125174059983692, 0.2186462150002626, 0.22374308600046788, 0.21801265599970066, 0.2004750080013764], [0.2137050180008373, 0.22095436999916274], [0.2212343779992807, 0.23671054300029937, 0.25850171300044167, 0.21123482899929513, 0.21658707999995386, 0.21184525799981202, 0.2156772380003531, 0.20651589400040393, 0.20843379699908837, 0.22162220900099783, 0.21479249199910555, 0.20919355200021528, 0.22948488300062309, 0.2491781680000713, 0.2767120279986557], [], [0.21118290000049456, 0.21652853500017955, 0.20681938800044009, 0.20805648999885307, 0.22276649800005544, 0.21425704400098766, 0.20863474199904886, 0.23028281699953368, 0.24942088300122123, 0.27587073399990913, 0.2121639420001884, 0.2188446809996094, 0.22411406699939107, 0.21799714600092557, 0.19942163599989726, 0.20851347700045153, 0.21502497999972547, 0.2330346369999461, 0.2550569989998621, 0.2803634849988157, 0.23793213000135438, 0.2110975209998287], [0.21161869899879093, 0.21567627900003572, 0.20633073099998, 0.20804679499997292, 0.2227627020001819, 0.21489177700095752, 0.20860071499919286, 0.22981867300040904, 0.24928707999970356, 0.27587022300031094, 0.21240516000034404], [0.2117177010004525, 0.2157515050002985, 0.2063411780000024, 0.20795224600078654, 0.22234604899858823, 0.21482498000113992, 0.20890820099884877, 0.22970832600003632, 0.2492003349998413, 0.27662288900137355, 0.21175942700028827, 0.21858153399989533, 0.22422861299855867, 0.21777331500015862, 0.20048877200133575, 0.20744883899897104, 0.21494327100117516, 0.2332084579993534, 0.2550224690003233, 0.2807407339987549, 0.23815197400108445, 0.21138256700032798, 0.20784915900003398, 0.20782578699981968, 0.20632818699959898, 0.20784237000043504, 0.20664724400012346, 0.2083708909995039, 0.2115598959990166, 0.22850010600086534, 0.22215666900046926, 0.21062356699985685, 0.2364457929998025, 0.2038699059994542], [], [0.21576426199862908, 0.20623300900115282], [0.21566247200098587, 0.20629130099950999, 0.2085085729995626, 0.221763297000507, 0.21482019200084324, 0.20891287099948386, 0.22971007299929624, 0.24920437000037055, 0.27662292800050636, 0.2117543040003511, 0.21858160499868973], [0.2163935250009672, 0.2068087129991909, 0.20805091800139053, 0.22276566399887088, 0.214251116000014], [], [0.20704340799966303, 0.2075924060009129, 0.22312005299863813, 0.21431161500004237, 0.20869214500089583, 0.2302394660000573, 0.24946667500080366, 0.27587869899980433, 0.21215477899932011, 0.21885852800005523, 0.22411604700027965, 0.2180005890004395, 0.19931457599886926, 0.20860134000031394, 0.21502687800057174, 0.2329623810001067, 0.25505899999916437, 0.2803158130009251], [0.20788341499974194], [0.2084069829998043], [0.20837492200007546, 0.22160605600038252, 0.21478698200007784, 0.20919310299905192, 0.2294922270011739, 0.24917479399846343, 0.2767754190008418, 0.21198491900031513, 0.21878494299926388, 0.22338026299985358], [0.2084332539998286, 0.22162696399936976, 0.21480364600029134, 0.20919252900057472, 0.22945426299884275, 0.2492004209998413, 0.27662557600160653], [0.2227716360011982, 0.2142047540000931], [0.22235666600136028, 0.21482969499993487, 0.2089037499990809, 0.22970477000126266, 0.249124618998394, 0.276695466000092, 0.2117654860012408, 0.21858364699983213, 0.22422152899889625, 0.21777716600081476, 0.20042008199925476], [0.222489289000805, 0.21486819699930493, 0.20861317799972312, 0.22981540400178346, 0.24927984199894127, 0.2758743440008402, 0.2125171349998709], [0.20941387499988195, 0.23001070699865522, 0.24929593600063527, 0.2758683949996339, 0.2124018470003648, 0.2187110200011375, 0.2242331359993841, 0.2179036889992858, 0.20016468600078952, 0.2077339329989627, 0.2149512070009223, 0.23319955700026185, 0.25502433799920254, 0.28077875599956315, 0.23761465500138002, 0.21147275799921772, 0.20795691300008912], [0.2088283720004256, 0.22994903499966313, 0.24929088600038085, 0.27586916299878794, 0.21240432200102077, 0.21870982600012212], [0.22961559100076556, 0.2492283609990409, 0.27613503400061745, 0.21231819999957224, 0.21856653400027426, 0.2241147259992431, 0.2179040780010837, 0.2003525649997755, 0.2075798690002557, 0.21495118500024546, 0.23321007799859217, 0.2550181149999844, 0.28076591300123255, 0.23763527299888665, 0.21189717000015662, 0.20775248700010707, 0.20791310500135296, 0.20632964499964146, 0.20780780899985984, 0.20668254900010652, 0.20837617599863734, 0.21155666100094095, 0.22849807999955374, 0.22193791500103544, 0.21084382899971388, 0.2363871849993302], [], [0.22462395199909224, 0.21794265100106713, 0.2004074809992744, 0.20758965499953774, 0.2149514699995052, 0.2332090550007706, 0.2550185430009151, 0.280772154999795, 0.2376266779992875, 0.2119044989995018, 0.207744729001206, 0.20791234900025302, 0.20633248999911302, 0.2078147150004952, 0.20667450899964024, 0.20837789100005466, 0.21155580099912186, 0.22849355000107607, 0.22194792499976757, 0.21083949800049595, 0.23619965899888484, 0.2039886940001452, 0.22018014000059338, 0.22926771600032225, 0.20600447499964503], [0.20143876600013755, 0.20734779099984735, 0.21480924500065157, 0.23304588700011664, 0.25505918700037, 0.2807463569988613, 0.2381200660001923, 0.21134013400114782, 0.2082812879998528, 0.20827194299999974, 0.20558701399932033, 0.20822546300041722, 0.20672786999966775, 0.20809293799902662], [0.20016270000087388, 0.20759943499979272, 0.21473858500030474, 0.23318492699945637, 0.25502261700057716, 0.28072987499945157], [0.20774771099968348, 0.21495124400098575, 0.2330433589995664, 0.25517456300076446, 0.2807813979998173, 0.23753228100031265], [0.2075504610002099, 0.21494533099939872, 0.2332105990008131, 0.2550183179992018, 0.2807591670007241, 0.2376434950001567, 0.21189089399922523, 0.20775935300116544, 0.20791301200006274, 0.2063299419987743, 0.2077997980013606], [], [0.20752939199883258, 0.21469449300093402], [0.20829059800053074, 0.21499680699889723, 0.23304168000140635, 0.2550601650000317, 0.28089010099938605, 0.23752944899933937, 0.2111077080007817, 0.20820889300011913, 0.20769534799910616, 0.20651026400082628, 0.20831003099920054, 0.20622930700119468, 0.20868365899877972, 0.2115512750006019], [0.21448784600033832, 0.23294482299934316, 0.25506321899956674, 0.28074005500093335, 0.2381253450002987, 0.21133239899972978, 0.20846375399924, 0.20812128500074323, 0.20557870599986927, 0.2085196949992678, 0.2065476210009365, 0.20805062699946575, 0.21126672900027188, 0.22842605999903753, 0.2221255780004867, 0.21065737699973397, 0.23655110300023807, 0.20423083800051245, 0.21957484599988675, 0.22939692599902628], [0.21472639399871696, 0.23318080500030192, 0.25502267600131745, 0.280785681999987, 0.23811287399985304, 0.21134929199979524, 0.20786468599908403, 0.2085992009997426, 0.20565280900154903, 0.2077798909995181, 0.2065904099999898], [0.21474655099882511, 0.23318917000142392, 0.25502340699858905, 0.2807353990010597, 0.23817353499907767, 0.21136111300074845, 0.2078566559994215, 0.2078230839997559, 0.20632963200114318, 0.20783683499939798], [], [0.2113638520004315, 0.20835505700051726, 0.2080482959991059, 0.2056704679998802, 0.2084267579994048, 0.2068690410014824, 0.20810773399898608, 0.21091867300128797, 0.22842150499855052, 0.2221079680002731], [0.21111131100042257, 0.20820796800035168, 0.20770081599948753, 0.20640266800000973, 0.20819817300071009, 0.20639275899884524, 0.20859176900012244], [0.20772563599894056, 0.20743570500053465, 0.20676652699876286, 0.2078734650003753, 0.20645276499999454, 0.20853543100020033, 0.21157237999977951, 0.22833207199983008, 0.2220739880012843, 0.2108933290001005, 0.2362309579984867, 0.20396970000001602, 0.22018512400063628, 0.22922016300071846, 0.20542727899919555, 0.21585308700014139, 0.22084315500069351, 0.21155775399893173, 0.22745000600116327, 0.21177378999891516, 0.2072757799996907, 0.22594462400047632, 0.2391392530007579], [0.20839879699997255, 0.207722704999469, 0.20634147099917755, 0.20800333700026385], [0.20826229600061197, 0.20800416100064467, 0.20566105199941376, 0.20843686800071737, 0.20686178699907032, 0.20811342100023467, 0.21091608499955328, 0.22842189100083488, 0.22211219100063317, 0.21067319399844564, 0.23657652900146786], [0.20835743300085596, 0.2080494980000367, 0.20558290400003898, 0.20851563900032488, 0.20655377299954125, 0.2080443689992535, 0.21127144300044165, 0.228424595999968, 0.22212159899936523, 0.21066144900032668, 0.2365499429997726], [0.2082799640011217, 0.20558669499951066, 0.20822703399971942, 0.20672193599966704, 0.20786388899978192, 0.2115033410009346, 0.22849749499982863, 0.22214222199909273, 0.21063996800148743, 0.23642961099903914, 0.20425594300104422, 0.2196893779982929, 0.2293823850013723, 0.20766529299908143, 0.2135184279995883, 0.22107619500093278, 0.2112057479989744, 0.22870590400088986, 0.21087907900073333, 0.2074364099989907], [0.20813000399903103, 0.20557453500077827, 0.20852277999983926, 0.20654136700068193, 0.20802592699874367], [0.20565478800017445, 0.20778380500087223, 0.2065690599993104, 0.20837247199960984, 0.21155933999943954, 0.2285007710015634, 0.22216087499873538, 0.21061746400118864, 0.23645052899883012, 0.2038638300000457, 0.22006497900110844, 0.22923326199997973, 0.2065608049997536, 0.21478742699946451, 0.22108426799968584, 0.2112136300002021, 0.22868303299947002, 0.21075305700105673, 0.2075781410003401, 0.22546147599859978, 0.23917279800116376, 0.2119377599992731, 0.21119261000058032, 0.2265442299994902, 0.19912503300110984, 0.21268248399974254, 0.21865869799876236, 0.21250523399976373, 0.20998092200170504, 0.22596026499923028, 0.2259229779992893, 0.21348355800000718, 0.21166822099985438, 0.21000888500020665, 0.20684345600056986, 0.21867777099942032, 0.2402839309997944, 0.26335321400074463, 0.2887570719994983, 0.22390606600129104, 0.19924281999919913, 0.2148088789999747, 0.21769751800093218, 0.23155659399890283, 0.2584013790001336, 0.279754414999843, 0.21310124199953862, 0.22666401800051972, 0.22437117400113493, 0.2112680639984319, 0.228495744000611], [], [0.20633718999852135, 0.20782384700032708, 0.20647644400014542, 0.20852846299931116, 0.21157924200088019, 0.22832550900056958, 0.222057324999696], [0.2056606650003232, 0.20840617900103098, 0.20687317099873326, 0.2080615670001862, 0.21091763799995533, 0.22842319300070812, 0.2221174919995974, 0.21066663199962932, 0.23657901099977607, 0.2041907020011422], [0.20810203499968338, 0.2068871430001309, 0.20823014400048123, 0.21103023199975723, 0.22828395800024737, 0.22205647500049963, 0.2108318649989087, 0.23633360000167158, 0.20468352399984724, 0.2190289579993987], [0.2082246829995711, 0.20684886900016863, 0.2080916459999571], [0.20653657399998337, 0.20803202600109216, 0.21130520400038222, 0.2284283899989532, 0.22213076899970474, 0.21065248400009295, 0.23651627999970515], [0.20631728199987265, 0.20866287399985595, 0.21172053599912033, 0.22837362500104064, 0.2221342619995994, 0.21074388200031535, 0.2364266820004559, 0.20367356599854247, 0.22038575500118895, 0.22923033199913334, 0.20497898299981898, 0.21605626000018674, 0.2210933140013367, 0.21100741999907768, 0.22790704699946218, 0.2115097820005758, 0.20749679599975934, 0.2258960319995822], [0.20622167400142644, 0.2086449709986482, 0.21158620400092332, 0.22845980199963378, 0.22209103000022878, 0.21087962399906246, 0.23624472500159754, 0.20370119499966677, 0.22038416999930632, 0.2292679140009568, 0.20535482299965224, 0.2157381399993028, 0.22099849400001403, 0.2110574580001412, 0.2278520159998152, 0.2116145609998057, 0.20742186200004653, 0.2259781920001842, 0.23908615100117458, 0.211771290998513, 0.21131551600046805, 0.22558949499943992, 0.19972504200086405], [0.2063008510012878, 0.20821437599988712, 0.21155988899954536, 0.2284997699989617, 0.2221520250004687, 0.210628328999519, 0.23644126600083837, 0.2042426459993294, 0.21969335300127568, 0.22939322399906814, 0.20675165499960713], [], [0.2083855090004363, 0.21155777700005274, 0.2283247819996177, 0.22211908499957644, 0.21083442400049535, 0.23620885499985889, 0.20398268600001757, 0.22018160699917644, 0.22927295500085165, 0.20554187500056287], [0.208232085000418, 0.210774898998352, 0.22838941300142324], [0.20787150000069232, 0.2115042479999829, 0.22849755400056893, 0.22214826100025675, 0.210633410999435, 0.2364361830004782, 0.20424986399848422, 0.21969154399994295, 0.22938716400130943, 0.20765688099891122, 0.21352124599980016, 0.22107869499996013, 0.2112080930000957, 0.22869953300141788, 0.21075338299851865], [0.21132322300036321, 0.22845831099948555, 0.22213559100055136, 0.2106461940002191, 0.2364232380004978, 0.2042625220001355], [0.21077754899852152, 0.22839140300129657, 0.22214019399871177, 0.21073577200149884, 0.2364969239988568, 0.2042081910003617, 0.21949903200038534, 0.22943595700053265, 0.20760713899835537, 0.21352241400018102], [0.2282836779995705, 0.22206838999954925, 0.21072001200082013], [0.21227926299980027, 0.23608692400011932, 0.2046838989990647, 0.21914256800118892, 0.22937200299929827, 0.2076553810002224, 0.21389354900020408, 0.22058790299888642, 0.21142629499991017, 0.22854273800112423, 0.2119845359993633, 0.20685619700088864, 0.22507667999889236, 0.23869463499977428, 0.21257334200163314, 0.21167632999822672, 0.22646057100064354], [0.2107104970000364, 0.23646787399957248, 0.20468135200098914, 0.21902818499984278, 0.22943143399970722, 0.20760757899915916, 0.21393008199993346, 0.2206453530016006, 0.21139053199840419, 0.2285540460015909, 0.21177018399976077, 0.20679215800009842, 0.2252422329984256, 0.2385943330009468, 0.21281282500058296, 0.21168245899934846, 0.22643828299987945, 0.19874587699996482, 0.21245365600043442, 0.21850291199916683, 0.21252014600031544, 0.20998176300054183, 0.22595122799975798, 0.2260680470008083, 0.21340474199860182, 0.2116539910002757, 0.20994383600009314, 0.20685046700054954, 0.21876142200017057, 0.2401998810000805, 0.2628428169991821, 0.2885766840008728, 0.22316430299906642, 0.20067657599975064, 0.21310603600068134, 0.21819787499953236], [0.21073690299999726, 0.23639328199897136, 0.20369672200104105, 0.22038614399934886, 0.22920352800065302], [], [0.20466469299935852, 0.21970838100060064, 0.22939427900018927, 0.20674182699985977, 0.21444562999931804, 0.22108070800095447, 0.21121114299967303, 0.22869224900023255, 0.2107519349992799, 0.20757913300076325, 0.22545787899980496, 0.2395628760004911, 0.2118362889996206, 0.21092716000021028, 0.22661017799873662, 0.19903734900071868, 0.2126815749998059, 0.21865229200011527, 0.21251178800048365, 0.2099808769999072, 0.225959702000182, 0.2259181859990349, 0.2134938430008333, 0.21165865799957828, 0.21000855400052387, 0.206848046000232, 0.2186779959993146, 0.2402847119992657, 0.26365619900025195, 0.28849260400056664, 0.22392847499941126, 0.19917916300073557, 0.21491806599988195, 0.21759057599956577, 0.23155866699926264, 0.25840157700076816, 0.2797558710008161, 0.21310092299972894, 0.22666565500003344, 0.2243742629998451, 0.21125872999982676, 0.22861508499954653, 0.20824735600035638], [0.204272705999756, 0.21958186699885118, 0.22937663100128702, 0.20767011999851093, 0.2135198190007941, 0.22107182500076306, 0.2113904249999905, 0.22854335400006676, 0.21176888599984522, 0.20678566499918816, 0.22518417600076646], [0.22018910999941, 0.22922797600040212, 0.20541380699978617, 0.21569657400141296, 0.22100289699847053, 0.21103827400111186, 0.2278645160004089, 0.21162425100010296, 0.20751616099914827, 0.2259380899995449, 0.23904118300015398, 0.21188523400087433, 0.21116738299861026, 0.2255912870004977, 0.19983096800024214, 0.21293496299949766, 0.21775583800081222, 0.21324479000031715, 0.21002582700020866, 0.22591018299863208, 0.22629572400001052, 0.21316918699994858, 0.21171983500062197, 0.20906959400053893, 0.2065971569991234, 0.21969556600015494, 0.24003449399970123], [0.22006864300055895, 0.22924744000010833, 0.20609690099990985, 0.21519106499908958, 0.2209338230004505, 0.21139519600001222, 0.22760081399974297, 0.21165392600050836, 0.20732533400041575, 0.22585848499875283, 0.23894722500153875, 0.2121614719999343, 0.21101418699981878, 0.22669915199912793, 0.19914507000066806, 0.21268628100006026, 0.21868782700039446, 0.21247178699923097, 0.20987362599953485, 0.22578521100149374, 0.22618003799834696, 0.21321060300033423, 0.21200494000004255, 0.20982845700018515, 0.2064916670005914, 0.21919028400043317, 0.24029874599909817, 0.26321837000068626, 0.28855475499949534, 0.22408024600008503, 0.19883717499942577, 0.2153868280001916, 0.21714769400023215, 0.2320571820000623, 0.25816312300048594, 0.27992878899931384, 0.21277522899981705, 0.22692446000110067, 0.22292949299844622, 0.21231401300065045, 0.22892246000083105, 0.20801268899958814, 0.21286784800031455, 0.22687883999969927, 0.22374421099993924], [0.21906287999991036, 0.22933028300030855, 0.2076568859993131, 0.2138981429998239, 0.22058192500117002, 0.21142761800001608, 0.22854697999900964, 0.21198259700031485, 0.2068603309999162, 0.22542515700115473, 0.23887706799905573, 0.21203969599991979, 0.21167303999936848, 0.2265320700007578, 0.1989877180003532, 0.21221630000036384, 0.2185377609985153, 0.21253409100063436, 0.21047863000057987, 0.22539234400028363, 0.22598948299855692, 0.21343253200029721, 0.21185963599964452, 0.20980822300043656, 0.20690089100025943, 0.2190208200008783, 0.23992206399998395, 0.2634284609994211, 0.2884975670003769, 0.22392244299953745, 0.1996351899997535, 0.21439932599969325], [0.22025213799861376, 0.2292480380001507, 0.20536590800111298, 0.21573545299906982, 0.22100006300024688, 0.21104731800005538, 0.22785902299983718, 0.21162067099976412, 0.2074117419997492, 0.22598219200153835], [0.20705080700099643, 0.21457058699888876, 0.2210860560007859, 0.2112163950005197, 0.2286744839984749, 0.21075360200120485, 0.20757420799964166, 0.2254684929994255, 0.23886002099970938, 0.21225034500093898, 0.21118464299979678, 0.22654932899968117, 0.19912648900026397, 0.21268424799927743, 0.21866320200024347, 0.2124998079998477, 0.20997881000039342, 0.22595772200111242, 0.22592973899918434, 0.2134704830004921, 0.2116828029993485, 0.2100014759998885, 0.20643577000009827, 0.2190887400010979, 0.24028318799901172, 0.2631614729998546, 0.28855351700076426, 0.22407876599936571, 0.19946498799981782, 0.21476236099988455, 0.217241627000476, 0.23205951399904734, 0.25839836400155036, 0.2797494779988483, 0.21298913999999058, 0.22670650399959413, 0.2228727080000681, 0.21282720300041547, 0.2284961960012879, 0.20833464299903426, 0.2128560010005458, 0.22669177299940202, 0.2245774059992982, 0.19892964100108657, 0.21164445499925932, 0.20758964699962235, 0.20545439300076396, 0.22265359700031695, 0.2152034589998948, 0.2161193510000885, 0.21650609800053644, 0.2179178629994567, 0.20679334600026777, 0.208861306999097, 0.2068384710000828, 0.21106820800014248, 0.208480249000786, 0.2218051709987776, 0.22628380200148968], [0.20756102000086685, 0.21393767500012473, 0.22062935099893366, 0.21142141100062872, 0.2285358549997909, 0.2119518759991479, 0.20660455500001262, 0.2252427630010061], [0.20539552899936098, 0.21584454300136713, 0.2208396409987472], [0.20766242100035015, 0.21351912999853084, 0.22106874700148182, 0.21139033799954632, 0.22854795300008846, 0.21177198899931682, 0.20678919700003462, 0.2252391500005615, 0.23885402599989902, 0.21246860599967476, 0.21138086000064504], [0.21574583999972674, 0.22099245000026713, 0.21107429999938176, 0.22784544999922218, 0.21159840600012103, 0.2074407540003449, 0.2259688020003523, 0.23908451600073022, 0.21175773399954778, 0.21132144699913624, 0.22557901900108845, 0.1997320159989613, 0.21302275699963502, 0.21781219200056512, 0.21324691399968287, 0.21002925300126662, 0.22591284199916117, 0.22630475200094224, 0.2131479709987616, 0.2117336740011524, 0.20892409499901987, 0.20672426800047106, 0.21969163399990066, 0.23990535600023577, 0.2640222629997879, 0.2886662149994663, 0.2232523670008959, 0.19894771699910052, 0.21491669399983948, 0.21815496100134624, 0.23208841599989682, 0.25820746299905295, 0.27985504800017225], [], [0.21576016299877665, 0.22095222600000852, 0.21140105400081666, 0.2274569759993028, 0.21178718000010122, 0.2073310460000357, 0.22585732900006406, 0.23886643600053503, 0.21223964700038778, 0.21101597599954403, 0.2265758800003823], [0.21388651099914568, 0.22059673900002963, 0.2114247580011579, 0.22853972299890302, 0.21194976300103008], [0.21478472600028908, 0.22108599599960144, 0.21122110500073177, 0.22866637900006026, 0.2107543540005281, 0.20756586599964066, 0.22547865500018816, 0.2390176339995378, 0.21209301899943966, 0.21105774600073346], [0.21204434699939156, 0.22854048400040483, 0.21089000299980398], [0.22754102900034923, 0.2115408589997969, 0.20751413000107277, 0.22594090500024322, 0.23903697399873636, 0.21189393799977552, 0.2111614900004497, 0.22559117099990544, 0.19983517000036954, 0.21293841199985764, 0.21793139200053702], [0.21211795099952724], [0.20721389999926032, 0.22584246000042185, 0.23898283100061235, 0.2121267219990841, 0.2110144220005168, 0.22670697700050368, 0.19913686899963068, 0.21268686599978537, 0.2186814790002245, 0.21247955199942226, 0.2098760509998101], [0.20709204000013415], [0.2250805629992101, 0.23864910200063605, 0.21262638000007428, 0.2116799989998981, 0.2264524430011079, 0.19907866999892576, 0.2122138230006385, 0.218540371999552, 0.21252882900080294, 0.20984580499862204, 0.22594471400043403, 0.22606551500030037, 0.21341439100069692, 0.21164578799835, 0.20994183800030441], [0.210683892999441, 0.21093202399970323, 0.22654201300065324], [0.21140027599903988, 0.22646632000032696, 0.1989767409995693, 0.21222042400040664, 0.21853360299974156, 0.21253926800090994, 0.21048067299852846, 0.22538605100089626, 0.22598868900058733, 0.2134366009995574, 0.21185660199989798, 0.2098052170003939, 0.20690361999913875, 0.21902344500085746, 0.23992465099945548, 0.2631213280001248, 0.2887582900002599, 0.2239096769990283, 0.1996941670004162, 0.21435343399934936, 0.21761528500064742], [0.211683269999412, 0.2263492589991074], [0.2110189929990156, 0.22657431200059364, 0.19928988199899322, 0.21268511000016588, 0.21869512800003577, 0.21231303600143292, 0.2098210329986614, 0.22589864499968826, 0.22628159200030495, 0.21320354800081986, 0.21176923599887232], [0.22626501500053564, 0.19895137899948168, 0.21268234499984828, 0.21864604700022028, 0.21251765499982866, 0.2099814700013667, 0.22595688099863764, 0.226069386000745, 0.21339590699972177, 0.2116163909995521], [0.22669425400090404, 0.19912988299984136, 0.21268625099946803, 0.21867527299946232, 0.2124862029995711, 0.20997488500142936, 0.22566397199989296, 0.2261732019996998, 0.21321709299991198, 0.21200102799957676, 0.20983561399953032], [0.19900083799984714, 0.21280073300113145, 0.21887038099885103, 0.21210165699994832, 0.210023245001139, 0.22590639099871623, 0.22629062000123668, 0.21318259699910413, 0.21171232800043072, 0.209082920999208], [0.2126829139997426, 0.21870725299959304, 0.2122977670005639, 0.20983159200113732, 0.2259023469996464, 0.22628621399962867, 0.213193952000438, 0.21177657199950772, 0.20915821999915352, 0.20645290700122132, 0.21993161200043687], [0.21220969399837486, 0.2185429290002503, 0.21252190800078097, 0.20985346700035734, 0.225947355000244, 0.22606749099941226, 0.21340953700018872, 0.21165030100019067, 0.20994177499960642, 0.2069384379992698, 0.21872484200139297, 0.24025206499936758, 0.26301222599977336], [0.21227787200041348, 0.21845538900015526, 0.21252490799997759], [0.2185679699996399, 0.21251674099949014, 0.2099808969996957, 0.22595446000013908, 0.22606868200091412, 0.2134007959994051, 0.21165531699989515, 0.20994884399988223, 0.20684962500126858, 0.2186864199993579], [0.21251828899949032, 0.20987431600042328, 0.22571282399985648], [0.2100350979999348, 0.22568072700050834, 0.22662820299956365, 0.21269806700001936], [0.2254025920010463, 0.2259929470001225, 0.21342579199881584, 0.21163349900052708, 0.2099823970002035, 0.20689714299987827, 0.21874406300048577, 0.24025375900055224, 0.2630993809998472, 0.2886500989989145], [0.2137585680011398, 0.2118130500002735, 0.20992952099913964], [0.21339213099963672, 0.21162352499959525, 0.21000822499991045, 0.20684909500050708, 0.21868138600075326, 0.2402844609987369, 0.26293662399984896, 0.28853833500033943, 0.2233117180003319, 0.20046796099995845, 0.21332493999943836], [0.2097671060000721, 0.20632036899951345, 0.22004076700068254, 0.23976943100024073], [0.20981836299870338, 0.20685011000023223], [0.20914670399906754, 0.20645772200077772, 0.21992487600073218, 0.23990028399930452, 0.2640419359995576, 0.28874850000102015, 0.2239036369992391, 0.19842245099971478, 0.21565338400068867, 0.21715565399972547, 0.23206000299978768, 0.258386714000153, 0.27968569100085006, 0.2130788719987322, 0.226709729000504, 0.22287403200061817, 0.21255800600010843, 0.2287018059996626, 0.20833147699886467, 0.21268150600008084, 0.22690998400139506, 0.22394866099966748, 0.19953856699976313, 0.21164750900061335, 0.20679697899868188, 0.20549493500038807, 0.22338896099972771, 0.21523608400093508, 0.21582225199927052, 0.21634930100117344, 0.2181911149982625, 0.20689327400032198, 0.2078915260008216, 0.2074127870000666, 0.21124904399948718], [0.20989861700036272, 0.20685476700055005, 0.21873150799910945, 0.2402578569999605, 0.26309850700090465, 0.28852383499906864, 0.22414030100117088, 0.1993707829988125], [0.2096143899998424, 0.20596921099968313, 0.21990598199954547, 0.2402916869996261, 0.263092389999656, 0.28854269400108024, 0.22331975199995213, 0.19962130000021716, 0.21426850500029104, 0.2181247969983815], [0.20649459999913233, 0.2191971160009416, 0.24029576699831523, 0.2633488860010402, 0.28846369500024593, 0.22408220099896425, 0.19867825900109892], [], [0.21871588100111694, 0.24017609799921047], [0.2199099009994825, 0.24028295999960392, 0.2637649179996515, 0.2885059000000183, 0.22391554100067879, 0.19837404600002628, 0.21566752000035194, 0.2171295319985802, 0.23205870099991444, 0.25839567000002717, 0.27968110800065915], [0.21909480700014683, 0.24028374000045005, 0.2633752959991398, 0.28875740300100006, 0.2239004669991118, 0.1991987630008225], [], [0.22405678699942655, 0.19945357399956265, 0.21473494400015625, 0.2171520550000423, 0.23205870300080278, 0.2582773750000342], [0.22325071600062074, 0.19955435799965926, 0.21431725199909124, 0.21800471900132834], [0.1983181119994697, 0.21474848400066548, 0.21816249499897822, 0.2321966910003539, 0.25816305999978795, 0.27992253999946115, 0.21277972800089628, 0.226928500998838, 0.22293430200079456, 0.2121983500001079, 0.2290178349994676, 0.20804486000088218, 0.21274229099981312, 0.22702501099956862, 0.22373627600063628, 0.19944087299882085, 0.21176480800022546, 0.20694444000037038, 0.20564815000034287, 0.22328629399999045, 0.2153307490007137, 0.21591509699828748, 0.2163262140002189, 0.2179859280004166], [], [0.21717087000070023, 0.23205549500016787, 0.25816467899858253, 0.27992679300041345, 0.21277608899981715, 0.22692667100091057, 0.22293101099967316, 0.21221789899936994, 0.2290128740005457, 0.20802352099963173, 0.2127526830008719], [], [0.2268995989998075, 0.22291750600015803, 0.21254905800014967, 0.22871127799953683, 0.2082749250002962], [0.22662530799971137, 0.22297256700039725], [0.22671389199967962, 0.22287480700106244, 0.21255082899915578, 0.22871112299981178, 0.20832778700059862, 0.2125972260000708, 0.2269997660005174, 0.2236644869990414, 0.19981713600100193, 0.2116489059990272, 0.20653816900085076, 0.2056888989991421, 0.22330937600054312], [0.22692177799945057, 0.22295072300039465, 0.21299965999969572, 0.22849519600094936, 0.20839040899954853, 0.2128283250003733, 0.22667044700028782, 0.22464130299886165, 0.1988605020014802, 0.21164323899938609, 0.2078468059989973], [0.21089471300001605, 0.22874320200025977, 0.20800501300072938, 0.21287598099843308, 0.22696804299994255], [0.22850087599908875, 0.2082877480006573, 0.21257693600091443], [0.21412484400025278, 0.22669930899974133, 0.22448198399979447], [], [0.21282371699999203, 0.2266754590000346, 0.2245929349992366], [0.21264481999969576, 0.22689612400063197, 0.22395605600104318, 0.19953575799991086, 0.21164771399890014, 0.2075068829999509, 0.20536677800009784, 0.2228077090003353, 0.2152267879991996, 0.21609294100016996], [0.21281235900096362, 0.22726770999906876, 0.22261124400029075, 0.20040909499948611, 0.21188587100004952, 0.20686178400137578, 0.20571759599988582, 0.2231132009983412, 0.2155427920006332, 0.21582044299975678, 0.21626887900129077, 0.21787797399883857, 0.2069082800007891, 0.2083819309991668, 0.20741618600004585, 0.21125831000063044, 0.20818442500058154, 0.22214648699991812], [0.21267167299993162, 0.2270025510006235, 0.22365603999969608, 0.19982108099975449, 0.21165179099989473, 0.20755105500029458, 0.20524757000021054], [0.21254479800154513, 0.22722944999986794, 0.22372268899925984, 0.19945114300026034, 0.21176130999992893, 0.2084476950003591, 0.20518646399978024, 0.22222714999952586, 0.21534928300025058, 0.21691748800003552, 0.21519382199949177], [0.22424753199993575], [0.19964733800043177, 0.21176275899961183, 0.20799708500089764, 0.20501257099931536, 0.2228471720009111, 0.21536509599900455, 0.21627177399932407, 0.21582939000109036, 0.2178741280004033, 0.20691569599875947, 0.20883401300125115, 0.20734992299912847, 0.2111852070011082, 0.20841224099967803, 0.22188080299929425, 0.22620447900044383, 0.20559738600059063, 0.20402188299885893, 0.2213319769998634], [0.19905560400002287, 0.21164389600016875, 0.20694305500001065, 0.20537741599946457, 0.2234309260002192, 0.2152390330011258, 0.21587262399953033], [0.2113732819998404, 0.20824987900050473, 0.20521227799872577], [0.21193188699908205, 0.20837609900081588], [0.208096692998879], [0.20500923999861698, 0.2226290449998487, 0.2155692070009536, 0.21628882799996063, 0.21577568400061864, 0.2178909369995381, 0.20684003899987147, 0.20894217000022763, 0.20735247700031323, 0.21118563299933157, 0.20841280499917048, 0.22187873600159946, 0.22620474599898444, 0.2055960910001886, 0.20402218900017033, 0.22133392300020205, 0.321560739999768, 0.10290441200049827, 0.2294140519989014, 0.2498850890005997, 0.2733168479990127, 0.24997168000118108, 0.20803272999910405, 0.21014841200121737, 0.22235397599979478, 0.23944422000022314, 0.2194854999997915, 0.2069380299999466, 0.21672721799950523, 0.2058260079993488, 0.21611561500139942, 0.20081262500025332, 0.22816008999870974, 0.2511233290006203, 0.24492024599931028, 0.20700618299997586, 0.2226983950004069, 0.22951772799933678, 0.21381954900061828, 0.2368823809993046, 0.22435571100140805, 0.22041152000019792, 0.24007398999856377, 0.2592157529998076, 0.28738925800098514, 0.21843394300049113, 0.22041973199884524, 0.20378297900060716, 0.2212332069993863, 0.2314397200007079, 0.21101774300041143, 0.2288249260000157, 0.22784874599892646, 0.23929411599965533, 0.20103865500095708, 0.21477748899997096, 0.21583481699963158, 0.20651539100072114, 0.20659170699946117], [0.20549945200036746, 0.22338508800021373, 0.2152484110010846, 0.215822696000032, 0.2163431289991422, 0.21812740600034886], [0.20564627600106178, 0.22330172500005574, 0.21533880599963595, 0.21589827599927958, 0.21633058000043093, 0.2177441120002186, 0.2069184439988021, 0.2083738280016405, 0.20741229699888208, 0.21125665200088406, 0.20844556799966085], [0.2053482109986362, 0.22228466300111904, 0.2151957019996189, 0.21669903499969223, 0.21593384299922036, 0.2179190060014662, 0.20683408699915162, 0.20956163499977265], [0.20538108399887278, 0.22338031000072078, 0.2152179940003407, 0.21581048100051703, 0.2163560069984669, 0.21819498900003964, 0.20689773800040712, 0.20788648599955195, 0.20741351600008784, 0.21135607300129777, 0.20843412899921532, 0.22186780199990608, 0.22618743699968036, 0.2052556150010787, 0.2038523859991983, 0.22179108899945277, 0.32164162900153315, 0.10218364799948176, 0.22991087199989124, 0.2504273220001778, 0.27355709899893554, 0.24998064400097064, 0.2083992739990208, 0.20974147600099968, 0.22238758399907965], [0.2053090190001967, 0.22279661599895917, 0.21521061200110125, 0.21611651899911521, 0.21622177400058717, 0.21804995399907057, 0.20689964200028044, 0.20889900000111084, 0.2068431049992796, 0.21106885200060788, 0.20841223299976264], [], [0.21668776900150988, 0.21580867299962847, 0.218113151999205, 0.20668955099972663, 0.20933282700025302, 0.20683709700097097, 0.21106866199988872, 0.20848462499998277, 0.22180104299877712, 0.2263197990014305, 0.20544590600002266, 0.20402016600019124, 0.22145531499882054, 0.32141458000114653, 0.10314917999858153], [0.22275926200018148, 0.2152747680011089, 0.21623810399978538, 0.21601237600043532, 0.21771916399848124, 0.2070739560003858, 0.2086541730004683, 0.20734914499917068, 0.21118302500144637, 0.2084126390000165, 0.22188324899980216, 0.22620335999999952, 0.20559848099946976, 0.2040205680004874, 0.22144594800010964, 0.3214285979993292, 0.10290791999977955, 0.22941776500010747, 0.2500268229996436, 0.27332218300034583, 0.2499261180000758, 0.2080677049998485, 0.2100439780006127, 0.2223899420005182, 0.23938041599831195, 0.2197595290017489, 0.20674262499960605, 0.2170378319988231, 0.2054258040006971, 0.21638192499995057, 0.2008695059994352, 0.2278502440003649, 0.25112997200085374, 0.24492290199850686, 0.2070125240006746, 0.2227927149997413, 0.22939621600016835, 0.21390163199976087, 0.23680265100119868, 0.22454756699880818, 0.22029179200035287, 0.24005031500018958, 0.2592167530001461, 0.2873589289993106, 0.21846006400119222, 0.22061217000009492, 0.20390870199844358, 0.22101034100160177, 0.23132185099893832, 0.2111339470011444, 0.22871687299993937], [0.21574900399900798, 0.21684948899928713, 0.21792395200100145, 0.20717664400035574, 0.20740966399898753, 0.20758594000108133, 0.21122553299937863, 0.20841283600020688, 0.22187524199944164, 0.22620240499963984, 0.20546690600167494], [0.2158247030001803, 0.21633941300024162, 0.21812238299935416, 0.20685948900063522], [0.21562825300134136, 0.2180495679986052, 0.2068985830010206, 0.20897474400044302, 0.20741953899960208, 0.210596462000467, 0.2090224669991585, 0.22157469500052684, 0.22594350399958785, 0.2055311170006462, 0.20412084799863806, 0.2212860780000483, 0.3213742660009302, 0.10323123299895087], [0.2074322000007669, 0.20802813499904005, 0.20741040600114502, 0.21125423999910709, 0.2085545780009852, 0.22186107800007449, 0.22596883199912554, 0.2053147259994148], [0.2067949390002468, 0.20782817699910083, 0.2074124810005742, 0.21135989699905622, 0.20843172300010337, 0.22187281300102768, 0.22619796199978737, 0.20547659499970905, 0.20363763599925733, 0.22178869000163104, 0.32163135499831697, 0.10276932200031297, 0.22934375499971793], [0.2080458999989787, 0.20733209600075497, 0.21059085599881655, 0.20903714100131765, 0.22173586200005957, 0.22578342899942072, 0.2055219150006451, 0.20413453199944342, 0.2217566990002524, 0.3208960190004291, 0.10330881599838904], [0.2087827979994472, 0.20684637300109898, 0.21106979599971964, 0.20841246899908583, 0.22188656500111392, 0.2262859689999459, 0.2054983229991194, 0.20402000000103726, 0.22145305099911639, 0.321419321000576, 0.10307728999941901], [0.20685702099945047, 0.21107300900075643, 0.20841134900001634, 0.22188537299916788, 0.22620496399940748], [0.20709650800017698, 0.21057249899968156, 0.20960130200001004, 0.22117215000071155, 0.22578123099992808, 0.205812905998755, 0.2038466600006359, 0.2217724359998101], [0.20736299300006067, 0.21118884700081253, 0.20841269700031262, 0.221877914000288, 0.2262008439993224, 0.20559792600033688, 0.20402181200006453, 0.22133598599975812, 0.32156495100025495, 0.10290024899950367, 0.22934792100022605], [], [0.2107359780002298, 0.20842118300060974, 0.22180190600010974, 0.22631570699923031], [0.21122983599889267, 0.20841503300107433, 0.22187388699967414, 0.22620197399919562, 0.20546872300110408, 0.2036404729988135, 0.22178523000002315, 0.32162771500043164, 0.10279416400044283], [0.21060388799924112, 0.20840735199999472], [0.2211500409994187, 0.22579274700001406, 0.2055256300009205, 0.20412766299887153, 0.2212857000013173, 0.32137094599966076, 0.10329723399991053, 0.22947944599945913, 0.2496496389994718, 0.273522009001681, 0.2500276029986708], [], [0.221019813001476, 0.22574858099869743, 0.2058166090009763, 0.20384680700044555, 0.22208175899868365, 0.3206644830006553, 0.10327884099933726, 0.22939591300018947, 0.24944200000027195, 0.2733218890007265, 0.2498712529995828], [0.220974687999842, 0.22571686399896862, 0.20596258800105716, 0.2037644639985956, 0.2220322910015966, 0.3206667149988789, 0.10329366400037543, 0.22939283000050636, 0.24952372899861075, 0.2735242329999892, 0.24998029800008226], [0.22099547400102892, 0.2257309519991395, 0.20581820600091305, 0.2038495659999171, 0.2220787879996351, 0.32066493700040155, 0.1032843729990418, 0.22939453199978743, 0.2494745240001066, 0.2735114850001992], [0.2061305759998504, 0.20364062699991337, 0.2217877769999177, 0.32163667300119414, 0.1021894829991652, 0.2299152600007801, 0.25047324399929494, 0.2735236440003064, 0.25002272999881825, 0.20835776000058104, 0.20985427900086506, 0.22231163099968398, 0.23902849099977175, 0.21986044999903243, 0.20693839600062347, 0.21780613400005677, 0.20468789900041884, 0.2161264599999413, 0.20030974300061644, 0.2286985739992815, 0.2508101250004984, 0.24517001399908622, 0.20704837400080578, 0.2225782369987428, 0.22935476200109406, 0.21411379799974384, 0.2365587450003659, 0.22453195999878517, 0.2203904270008934, 0.2400228229998902, 0.25909607900030096, 0.28740134699910413, 0.21868309199999203, 0.22108654600015143, 0.20360577100109367, 0.22073738699873502, 0.2311512659998698, 0.21157651800058375], [0.20525576299951354, 0.2038511569990078, 0.22179319099996064, 0.32165388700013864, 0.10217038500013587, 0.22990877099982754, 0.25044607400013774, 0.27355232999980217, 0.24997957699997642, 0.20833052200032398], [0.20370392000040738, 0.22198672299964528], [0.2040237260007416, 0.22134491900033026, 0.32156852599837293, 0.10289428300166037, 0.22934456199982378, 0.25033262799843214, 0.27352247100134264, 0.25006101799954195, 0.2085611099992093, 0.21080675500161306, 0.22117651699954877], [0.20394705200124008, 0.2218691679991025, 0.3214332080005988], [0.20375820499975816, 0.22203995299969392, 0.3206657749997248, 0.10328946700064989, 0.22939275099997758, 0.24949342199943203, 0.2735587540009874, 0.2499801279991516, 0.2084067439991486, 0.2097393620006187], [0.203938737999124, 0.22141703099987353, 0.3214111060005962, 0.10321407599985832, 0.2295514670004195, 0.24971298899981775, 0.2735215350003273, 0.250059648999013, 0.20855857800052036, 0.21079853599985654, 0.2211575700002868], [0.22136657599912724, 0.32157364600061555, 0.10288307900009386, 0.229339550000077, 0.25032625699896016, 0.2735232420000102, 0.250025725001251, 0.20859886299876962, 0.21078007300093304, 0.22114309199969284], [0.22128848200009088, 0.32138074599970423, 0.10322350699971139, 0.2295583289997012, 0.24952837100136094, 0.2733227019998594, 0.25023284799863177, 0.208226218001073, 0.20979249099946173, 0.22247304499978782, 0.2390938320004352, 0.21975041800033068], [0.32066352400033793, 0.10327479099942138, 0.22939957400012645, 0.24944524300008197, 0.2733210019996477, 0.2498726899993926, 0.20804050600054325], [0.10441388199978974, 0.22927628499928687, 0.2500312700012728, 0.27344003100006375], [0.1021353199994337, 0.23000813200087578, 0.25049588100046094, 0.2733904189990426, 0.24988324399964768, 0.2080355750003946, 0.21015081199948327, 0.22234300300078758], [0.1020625539986213], [], [0.20783706499969412, 0.2101707930014527, 0.22220547199867724, 0.23949628199989093, 0.21985418100121024, 0.2072444869991159, 0.21768718699968304, 0.20453226300014649, 0.21642915600023116, 0.20101502900070045, 0.22772504100066726], [0.2095730380005989, 0.22239256300053967, 0.23909977999937837, 0.2198635889999423, 0.20681712000077823, 0.21696750199953385, 0.20556258999931742, 0.21618265399956726, 0.20076615400103037, 0.22819340499881946, 0.2508474410005874, 0.24516844900063006, 0.20705090800038306, 0.2225809899991873, 0.22934430100031022, 0.21403416899920558], [0.209790767999948, 0.22242003199971805, 0.23914643399984925, 0.21985733899964544, 0.2072421110005962, 0.21768886800055043, 0.20453386299959675, 0.21637332899990724, 0.20052112899975327, 0.22825607100094203, 0.25082111099982285], [0.21021054700031527, 0.22235224199903314, 0.23949845999959507, 0.21950741700129583, 0.2069192529997963, 0.21672112299893342, 0.20577693599989288, 0.2161519830006, 0.20084889800091332, 0.22808181700020214, 0.25062473099933413], [0.20966255600069417, 0.22225011499904213, 0.23900813000000198, 0.21986828400076774, 0.20681074599997373, 0.21696371899997757, 0.20557479899980535, 0.2161831079993135, 0.20026685899938457, 0.22858543900110817], [], [0.22244290799972077, 0.23909087600077328, 0.21981243299887865, 0.2066647740011831, 0.21704659099850687, 0.2056296860009752, 0.2162322629992559, 0.20091839599990635, 0.2277418680005212, 0.2511328450000292, 0.24506014500002493], [0.2078881100005674], [0.20663829099976283, 0.21703573299964773, 0.20562088800033962, 0.216232761998981, 0.2009220500003721, 0.22774511399984476, 0.25113495100049477, 0.24515814500045963, 0.20705906100010907, 0.222587049998765, 0.22931644600066647], [0.2067350310007896, 0.21692643300048076], [0.2169079529994633], [0.21688609500051825, 0.20550474700030463, 0.2161866549995466, 0.20092671699967468, 0.22791074499946262, 0.2509727260003274, 0.2451647870002489, 0.20705319099943154, 0.22258286900068924, 0.22934815299959155, 0.2140207720003673, 0.23667047699927934, 0.22454997200111393, 0.22038173799955985, 0.23991843899966625, 0.259226498001226, 0.2874078400000144, 0.21844521699858888, 0.2212167470006534, 0.20326065299923357, 0.22109180900042702, 0.23122273400076665, 0.21115228399867192, 0.23013464700125041, 0.22640905699881841, 0.23929559200041695, 0.20144239200089942, 0.21446340100010275, 0.21649025599981542, 0.20671443500032183, 0.20643864900011977, 0.20742772499943385, 0.22649905399885029, 0.2138078050011245, 0.21876650199919823, 0.19992375299989362, 0.2106357280008524, 0.21704476999912004, 0.20626016300047922, 0.20573178300037398, 0.20783718699931342, 0.2074156340004265, 0.2108616500008793, 0.22461057900000014, 0.24715919899972505, 0.2277084349989309, 0.21896011700118834, 0.20885535900015384], [], [], [0.2161281839998992, 0.20075775000077556, 0.22824502599905827, 0.25080884599992714, 0.2451707330001227, 0.20704840200050967, 0.22257970700047736, 0.22933081299925107], [0.21615258900055778, 0.20175491299960413, 0.22721047199956956, 0.25081241599946225, 0.24516848399980518, 0.2070493900009751, 0.22263426700010314, 0.2292917539998598, 0.21412115400016773, 0.23655220000000554, 0.2245371619992511, 0.22039317800044955], [0.21623379800075782, 0.20151005600018834], [0.20073400600085733, 0.2281034579991683, 0.250814270999399, 0.24516775099982624, 0.20705012700091174, 0.2226368840001669, 0.22928144899924519, 0.21413080000093032, 0.23654249500032165, 0.224544431999675, 0.2204596390001825, 0.2399449899985484, 0.2590885600002366, 0.2873951110013877, 0.21868426099899807, 0.22109270200053288, 0.20360982599959243, 0.2207314850002149, 0.2313485619997664], [0.2005152450001333, 0.22826127799999085, 0.2508170159999281, 0.24516559699986828, 0.20705221500065818, 0.2226364359994477, 0.22927373400125362, 0.21413780099828728, 0.23653580500104, 0.22455142099897785, 0.2204658090013254], [0.20150040499902389, 0.22723713999948814, 0.2509158610009763, 0.2450489219991141, 0.2074303930003225, 0.22231630699934612, 0.2292216810001264, 0.21414965000076336, 0.23652400900027715, 0.22463570499894558], [0.20082885199917655], [0.22718499400070868, 0.2508123049992719, 0.2451680390004185, 0.2070501960006368, 0.22258045299895457, 0.22933769100018253, 0.2141403799996624, 0.23653815900070185, 0.22455810999963433, 0.22038773799977207, 0.23991317600120965], [], [0.20733668499997293, 0.22228165399974387, 0.22921567900084483, 0.21415626099951623, 0.23651736099964182, 0.2247287320005853, 0.2204140859994368, 0.23984406900126487, 0.2590819509987341, 0.28736558800119383, 0.21888040399971942], [0.20692282900017744, 0.22277506399950653, 0.2293789060004201, 0.21391603099982603, 0.23678898199977993, 0.22455820600043808, 0.2202897369988932, 0.24005015799957619, 0.25921738800025196, 0.28735060000144586], [0.22262582199982717, 0.22934576199986623, 0.21392666899919277, 0.23681013399982476, 0.22453498100003344, 0.22072656199998164, 0.23984417900101107, 0.25908395599981304, 0.2873730440005602, 0.2188449289988057], [0.2225897280004574, 0.2293293500006257, 0.2139344160004839, 0.23680400899866072, 0.22454110000035143, 0.2202688319994195], [0.22232300699943153, 0.22922975400069845, 0.214143506000255, 0.23653039399869158, 0.22455813200031116, 0.22052442700078245, 0.23986593500012532, 0.2590865189995384, 0.2873875820005196, 0.2186853439998231], [], [], [0.22049546699963685, 0.2398515299992141, 0.25908315400010906, 0.28738132800026506, 0.2188411540009838, 0.22135469099885086, 0.2032104120007716, 0.22072367900000245, 0.23142658600045252, 0.21146006099843362, 0.2295871350015659, 0.2266908549991058, 0.23930991400084167, 0.2014590489998227, 0.21439289399859263, 0.21626386200114212, 0.20675020899943775, 0.20692228299958515, 0.20725697099987883, 0.22686523500124167, 0.21383545699973183, 0.21840067999983148, 0.19970644900058687, 0.2105973460002133, 0.21693926499938243, 0.20689262399901054, 0.20629438100149855, 0.20684768699902634, 0.2072276580001926, 0.21117600400066294, 0.22436795300018275, 0.24724475399852963, 0.22756344200024614, 0.22007794199998898, 0.2090565130001778, 0.2112503000007564, 0.21930020499894454, 0.24430761400071788], [0.2202935340010299, 0.24005356899942853, 0.2592163779991097, 0.2873700950003695, 0.21844888700070442, 0.22060820200022135, 0.20370139700025902, 0.22117329699904076, 0.23136981800053036, 0.21110679299999902, 0.22858295799960615, 0.22788423800011515, 0.2393556829993031, 0.20174351500099874, 0.2140561489995889, 0.21585855500052276, 0.2076113629991596, 0.20688518800125166, 0.20737688799999887, 0.22687109299840813, 0.21317613300016092, 0.21865521100153273, 0.19992426499993599, 0.21063126199987892, 0.21704252400013502, 0.20625370599918824, 0.20663089499976195, 0.20713102599984268, 0.2072289349998755], [], [0.2211997459999111, 0.2032767500004411, 0.22108939399913652, 0.2312337680014025, 0.21114380399922084, 0.2301251040007628, 0.2264174419997289, 0.23929349100035324, 0.20143800699952408, 0.21447580299900437, 0.2163659470006678], [0.22109537700089277, 0.20353395900019677, 0.22082855699954962, 0.23116632999881404, 0.21155910300149117, 0.22976646699862613, 0.22656466199987335], [0.22097620500062476, 0.20358308699906047, 0.22072761500021443, 0.23142917200129887, 0.2114564399998926, 0.22958862999985286, 0.22668838299978233, 0.23930275999919104, 0.20071060700138332, 0.21511907399872143], [0.22169978300007642, 0.20283285699952103, 0.22065627000120003, 0.23141716200007068, 0.2114942919997702, 0.2295630919998075, 0.2266907649991481, 0.23931755000012345, 0.20100109800114296, 0.21483857499879377, 0.21627107600033924, 0.20655564300068363, 0.20687241999985417, 0.20738530000016908, 0.22659543599911558, 0.2134545300013997, 0.2186563519990159, 0.1999209219993645, 0.21063318900087324, 0.21704195200072718, 0.2062586879983428, 0.20612023400099133, 0.20764800500001002, 0.2072324220007431, 0.21120889899975737, 0.22430316600002698, 0.24726520599870128, 0.22757736300081888, 0.21896417499920062, 0.20899045500118518, 0.21227129599901673, 0.2197530020002887, 0.24466553400088742, 0.23739236099936534, 0.2113044189991342, 0.2106796160005615, 0.2090319039998576, 0.2330360890009615, 0.2094423779999488, 0.2156850060000579, 0.23015398399911646, 0.21187243900021713, 0.21214759500071523, 0.20229983899844228, 0.2106092970007012], [0.22108200200091233, 0.20351986499917984, 0.22082550000050105, 0.23115865399995528, 0.21156939100001182, 0.2297635149989219, 0.2266757340003096, 0.23901300200122932, 0.2002930419985205, 0.21573592999993707], [], [0.20286095600022236, 0.22065762700003688, 0.23142264499983867, 0.21146351400057029, 0.22958787599964126, 0.22669145399959234, 0.23931361100039794, 0.20030285800021375, 0.2155436449993431, 0.21626622500116355, 0.20551859399893146, 0.206270869999571, 0.2083051469999191, 0.22660938200169767, 0.21395805599968298, 0.21804200499900617, 0.1998314020001999, 0.21064939000098093, 0.2177425760000915, 0.20630916699883528, 0.20525151800029562, 0.2075148479998461, 0.20737289099997724, 0.21170835600059945, 0.22445642799902998, 0.2466815610005142, 0.22836369200012996, 0.21884780800064618, 0.2084407829988777, 0.21217708500080334, 0.22027753799920902, 0.24504115600029763, 0.23732869000014034], [0.22101370800010045, 0.2313343360001454, 0.21112126499974693, 0.22871879499871284, 0.22784895000040706, 0.2392929079996975, 0.20076415699986683, 0.21515442400050233, 0.21664341500036244, 0.20534209399920655, 0.20632860300065659], [0.2208369309992122, 0.23117508600080328, 0.21129478499824472, 0.23000352600138285, 0.22654996500023117, 0.2391530969998712, 0.20184625999900163, 0.21405185100047674, 0.21650115599913988, 0.20676638900113176, 0.20689579799909552], [0.21166152200021315, 0.22977367599924037, 0.22656068700052856, 0.2391431959986221, 0.20095310100077768, 0.2149385569991864, 0.21650896400024067, 0.20586513800117245, 0.2064710529994045], [0.21154677499907848, 0.22959292599989567, 0.22668533400064916, 0.2392102789999626], [], [0.2266527629999473, 0.2397471409985883, 0.20020988000032958, 0.21518586500133097, 0.21627625699875352, 0.2060725770006684, 0.20628976199986937, 0.20798323800045182, 0.2265040879992739, 0.21381218600072316, 0.21804336899913324, 0.20038944400039327, 0.210684843999843, 0.21717130000070028, 0.20630067399906693, 0.20534713699998974, 0.2075156999999308, 0.20761720100017556, 0.2113984010011336, 0.22457453699826146, 0.2466857000017626, 0.22819596599947545, 0.21885221299999102, 0.20886601399979554, 0.21188145199994324, 0.2201961869996012, 0.24499473300056707, 0.23739584099894273, 0.21130953500141914, 0.21066310799869825, 0.20903819800150814, 0.2330385639997985], [], [0.2002413259997411, 0.21567359899927396, 0.2163251380006841, 0.20533995000005234, 0.20614324899906933, 0.20794777599985537, 0.22697131000131776, 0.21420858499914175, 0.2180679049997707, 0.19984132700119517, 0.2105294060002052], [0.21473803900153143, 0.21625829999902635, 0.20653781600049115, 0.20687937299953774, 0.20738016900031653, 0.226869997999529, 0.21317865200035158, 0.21865906700077176, 0.19991830099934305, 0.21063341399894853, 0.21704195000165782, 0.20625557999846933, 0.2066174890005641, 0.20714820800094458, 0.207230902999072, 0.2112131789999694, 0.22430560300017532, 0.24726663699948404, 0.2275749510008609, 0.21896263800044835, 0.2089932389990281, 0.21226566599943908], [0.21552306199919258, 0.21626929700141773, 0.20533248399988224, 0.20614912000019103, 0.2079425399988395, 0.22697514700121246, 0.214209634999861, 0.2180619199989451, 0.19984480300081486, 0.2105313779993594, 0.2174766299995099], [], [0.21488045399928524, 0.21650060600040888, 0.2058652970008552, 0.20654043099966657, 0.20789258200056793], [0.21394854899881466, 0.21580266400087567, 0.20756900599917572, 0.20688982600040617, 0.20737368300069647, 0.2268693309997616, 0.21317808799904014, 0.2186494780016801, 0.1999296689991752, 0.2106316400004289, 0.21704337799928908, 0.20643903400014096, 0.2065793149995443, 0.2069912059996568, 0.20726266500059864, 0.21117197000057786, 0.2243088089999219, 0.24726926400035154, 0.22757231299874547, 0.21902615100043477, 0.20895883400044113, 0.21233718899929954, 0.21964579300038167, 0.24387100900094083, 0.23772006099898135], [0.20631150799999887, 0.206160613000975, 0.2079185589991539, 0.227038781000374, 0.214208511999459, 0.218057674001102, 0.1998494639992714, 0.21020472000054724, 0.21777002799899492, 0.20638362400131882, 0.20561025200004224, 0.20671635599865112, 0.20782807800060255, 0.2112892080003803, 0.22510063299887406, 0.24664093899991713, 0.22857031600142363, 0.21859336899979098, 0.20842754299883381, 0.21187090600142255], [0.2072630559996469, 0.20588087199939764, 0.20798440399994433, 0.22650235000037355, 0.21380915400004596, 0.21876487200097472, 0.1999205369993433, 0.2104697609993309, 0.21716789600031916, 0.20629422700039868, 0.20535254099922895], [0.20555556200088176, 0.20615217399972607, 0.20793731000048865, 0.22697934899952088, 0.21420948500053782, 0.21806026400008705, 0.19984607699916523, 0.21037895100016613, 0.21758771100030572, 0.20639159200072754], [], [0.20628650800063042, 0.2079780349995417, 0.22650740000062797, 0.21381863999886264, 0.21804212400093093, 0.2003877419992932, 0.21068354099952558, 0.21717483600150445, 0.2063012290000188, 0.20534671299901675, 0.20745904700015672], [], [0.20627430599961372, 0.2083038589989883, 0.2266180610004085, 0.21395940900038113, 0.21803944000021147, 0.19983374000003096, 0.21064931199907733, 0.2177409739997529, 0.20631067100111977, 0.20525100200029556, 0.20745011199869623], [0.20691562499996508, 0.20726522999939334, 0.22686822100149584, 0.2131802539988712, 0.21871476100022846], [0.20807356100158358, 0.22654098899874953], [0.20771090000016557, 0.2265647469994292], [], [0.22663364300024114, 0.2139612480004871, 0.21803912599898467, 0.19983528299962927, 0.21064979299990227, 0.2174566230005439, 0.20654601500064018, 0.20528028899934725, 0.2074459699997533, 0.207384360001015], [0.2135020200003055, 0.2186565160009195, 0.19992220399944927, 0.21063511399916024, 0.21704251099981775, 0.206259755001156, 0.20573460099876684, 0.20783718900020176, 0.20740910099993926, 0.21086057700085803, 0.22461585199926049, 0.2471733239999594, 0.2276937070000713, 0.2189626870003849, 0.20892164600081742, 0.21236090299862553, 0.219625020001331, 0.24424004100001184, 0.23780478600019705, 0.2107576729995344, 0.21095754199996009, 0.20862736500021128, 0.23339226999996754], [0.21402486300030432, 0.21803847900082474, 0.19983913599935477, 0.21064381500036689, 0.21745369499876688, 0.20654947900038678, 0.20528023400038364, 0.20744450900019729, 0.20738563399936538, 0.21176718100105063], [0.21829620000062278, 0.19967252899914456, 0.2106180980008503, 0.21704349299943715, 0.2069045999996888, 0.20615495499987446, 0.20695063200037112, 0.20726151000053505, 0.21117311799935123, 0.2243202730005578, 0.24727392999920994, 0.22756926600050065, 0.21952453499943658, 0.20943078900018008, 0.21135811900057888, 0.22004446599930816, 0.24364427000000433, 0.23780427600104304, 0.2107649190002121, 0.2109543289989233, 0.2086269989995344, 0.23351920900131518, 0.2097375909997936, 0.21526319700024032, 0.23047361399949295, 0.2113899889991444, 0.21250890600094863, 0.2022723970003426, 0.21135467199928826, 0.2043169990010938, 0.21566321699901891, 0.22794087100010074, 0.21066563000022143, 0.21966524699928414, 0.21921708400077478, 0.2091278579991922, 0.20580091800002265, 0.21150303700051154, 0.21054626899967843, 0.21604326800115814, 0.20697502799885115, 0.2096916179998516, 0.2084298019999551, 0.20591398699980346, 0.21878311600085, 0.22675669800082687, 0.21499827799925697, 0.2369016720003856, 0.2543044039994129, 0.2079136730008031, 0.21279815999878338, 0.2215143600005831, 0.20580400200014992, 0.20544543500000145, 0.2074932079995051, 0.23067897799955972, 0.20544369900017045, 0.2148543580005935, 0.22438643399982539, 0.20854195299943967, 0.20629456500137167, 0.23447468799895432, 0.2194446989997232, 0.204998721001175, 0.20710869199865556, 0.2136342190005962, 0.2262005880002107, 0.20607997099978093, 0.20359134300088044, 0.21780751299957046, 0.21619712199935748, 0.21998478699970292, 0.20748498900138657, 0.20501490899914643, 0.20608342299965443, 0.21411681000063254], [0.19988258600096742, 0.21058851099951426, 0.21716997800103854, 0.2062983819996589, 0.20534804399903805, 0.20752066700151772, 0.20760822599913809, 0.21139833599954727, 0.22458084000027156, 0.24668805200053612, 0.22819295400040573, 0.21885149999980058, 0.20886763299859012, 0.21188198400159308, 0.22019445399928372, 0.24499409099917102, 0.23739759599993704, 0.21131210400017153, 0.21065385100155254, 0.20904373599842074, 0.2330970820003131, 0.20938186999956088], [0.19989112799885334, 0.21061965800072358, 0.21704232599950046, 0.20690694900076778, 0.20615907999854244, 0.2069504520004557, 0.2072628980004083, 0.21117230299932999, 0.2243161450005573, 0.24727247900045768, 0.22757039399948553, 0.21902727499946195, 0.20992172700061928, 0.2113682199997129, 0.2196514080005727, 0.24394597299942689, 0.23780241399981605, 0.210635932000514, 0.2109477939993667], [0.19981838000057905, 0.21057776299858233, 0.2171694530006789, 0.20629614400058927, 0.20535027199912292, 0.2077993240000069, 0.2078035890008323], [0.21051960499971756], [0.21068326600106957, 0.21718588399926375, 0.20630417299980763, 0.20525400699989405, 0.2075190730010945, 0.207504797999718], [0.21704888100066455, 0.20626188499954878, 0.20572641200124053, 0.2074117739994108, 0.20784175200060417, 0.2108712409990403, 0.22460515599959763, 0.2466785249998793, 0.22819009399972856, 0.21895484600099735, 0.20875051199982408], [0.21748042599938344, 0.20649185699949157, 0.20546887300042727, 0.20709741599966947, 0.2074878240000544], [0.20708243799890624], [0.2063126849989203, 0.20525379200080351, 0.20744734300023993, 0.2074521979993733, 0.21171832800064294, 0.22444941999856383, 0.24668344900055672, 0.22836421499960124, 0.21883877100117388, 0.20844666499942832, 0.21209987200018077], [0.20689294499970856, 0.20629378199919302, 0.20685003400103597, 0.20722773399938887, 0.2111749569994572, 0.22433044700119353, 0.24727633799921023, 0.2275650850006059, 0.22008133799863572, 0.20905202200083295, 0.21122053299950494], [0.20650268099961977], [0.20616665899979125, 0.20695082299971546, 0.20726350899894896, 0.2111719570002606, 0.22431277400028193, 0.24727020200043626, 0.2275713609997183, 0.2190269509992504, 0.2099122140007239, 0.2113822449991858, 0.2196467700014182, 0.24394388200016692, 0.23779898899920227, 0.21063084900015383, 0.21095313600017107, 0.20866535300046962, 0.23347793499851832, 0.209954555000877, 0.21497626599921205, 0.23067756599994027, 0.2107690900011221, 0.21301593499993032], [0.20685377499830793, 0.2072305370002141, 0.21117434300140303, 0.224325040999247, 0.2472746460007329, 0.22756779399969673, 0.22008313599872054, 0.20904802800032485, 0.2112233190000552, 0.22001740500127198], [0.2076561820013012, 0.20723396699941077, 0.21120189599969308, 0.2243045320010424, 0.24725880000005418, 0.22758489199986798, 0.21896307499991963, 0.20898689400019066, 0.21227877999990596, 0.21962906699991436], [], [0.20746088800115103, 0.20755643799930112], [0.20787573999950837, 0.20726968800045142, 0.21085931699963112, 0.22462105200065707, 0.2471783309993043, 0.22768798000106472, 0.21896178099996177, 0.2089287359995069], [], [0.20720247000099334, 0.21116461800011166, 0.22437808599897835, 0.24724008200064418, 0.22773659499944188, 0.2199210069993569, 0.20905685400066432, 0.21124407699971925, 0.22006981300000916, 0.24333562799984065, 0.2377911290004704, 0.21119555699988268, 0.2110825189993193, 0.20902613799989922, 0.23302898700057995, 0.20945720900090237, 0.21537668699966162, 0.2304578319999564, 0.21157258799939882], [0.20775671799856354, 0.21127579700078059], [0.20738401299968245, 0.21135901100024057, 0.22458813699995517, 0.24668830500013428, 0.22819056299886142, 0.21885270300117554], [], [0.21160783999948762, 0.22444580800038239, 0.2466805909989489], [0.21178134299952944, 0.22450413799924718, 0.24668319600095856, 0.22836680299951695, 0.2186025030005112, 0.20867454299877863, 0.21210263400098484, 0.22034042899940687, 0.24452498400023615, 0.23780667000028188, 0.21063968499947805], [0.21140056100011861, 0.22456488499847183, 0.24668115400163515, 0.2282048239994765, 0.21885071599899675, 0.2088589930008311, 0.2118819009992876, 0.22020329699989816, 0.2444488100009039, 0.23780215800070437, 0.2108995189992129], [0.2245163389998197, 0.24668099799964693, 0.22837307199915813, 0.2186005160001514, 0.20842886500031454, 0.21233828000003996, 0.22141981899949315, 0.24334844999975758, 0.23800443900108803, 0.21096752999983437, 0.21110229999976582, 0.2090088620007009, 0.23296667099930346, 0.20954818000063824, 0.21536544799892, 0.23046285400050692, 0.2115689160000329, 0.21246206300020276, 0.20230333799918299, 0.21117367000078957], [0.22461097499945026, 0.24717692299964256], [], [0.21993292799925257, 0.2090515880008752, 0.21124756199969852, 0.220063991000643, 0.2440068269988842, 0.23734119400069176, 0.21097314300095604, 0.2110907979986223, 0.2090196030003426, 0.2329688410009112], [0.20904617500127642, 0.21119918799922743], [0.20896337399972253, 0.21230529700005718], [], [0.2119410909999715, 0.22023494799941545, 0.2443864750002831, 0.23780516400074703, 0.21063767499981623, 0.21105995899961272, 0.20853090899981908, 0.23347810199993546, 0.20994588900066447, 0.21498505800082057, 0.2306698749998759], [], [0.21188037199863174, 0.22022428100171965, 0.24439877799886744, 0.23780724000062037, 0.2106379710003239, 0.2110668799996347, 0.20852459100024134, 0.2334773900001892, 0.20992187799856765, 0.21499309499995434, 0.23072859400053858, 0.21136434599975473, 0.2124410970009194, 0.2023367040001176, 0.21085054299874173, 0.2048338260010496, 0.21559624899964547, 0.22800960799941095, 0.21066448600140575, 0.219669250998777, 0.2192320430003747, 0.208992591000424, 0.20593232899955183, 0.21069183299914584, 0.21021693100010452, 0.2165818350003974, 0.2066733680003381, 0.2098062460008805, 0.20807181799864338, 0.20594743299989204, 0.2192922490012279, 0.22559244799958833, 0.21634678299960797, 0.237247484999898], [0.21960868700080027, 0.24422498300009465, 0.23780750799960515, 0.21063709800000652, 0.2110648960006074, 0.208527150000009, 0.233476604000316, 0.2100150729984307, 0.2157031040005677, 0.2301375070001086, 0.2118931530003465], [], [0.21097046800059616, 0.20866813599968737, 0.2334789720007393, 0.20996176699918578, 0.2149666929999512, 0.23068919999968784, 0.2099301390007895, 0.21334187899992685, 0.20263175500076613, 0.21106470599988825], [0.2111956150001788, 0.20842922699921473, 0.23337215600076888, 0.2097256329998345, 0.21527071300079115], [0.20872354899984202, 0.23348380999959772, 0.20989400600046793, 0.21595192200038582, 0.23012616000050912, 0.21197316500001762, 0.21204202300032193, 0.20229593599833606, 0.2103048190001573, 0.2058939670005202, 0.21507869500055676], [], [0.23304545100108953], [0.2333966030000738, 0.20989351400021405, 0.21500027000001865, 0.23072392999893054, 0.2113734900012787, 0.2124450829996931, 0.20232694799960882, 0.21100341599958483], [], [0.21568770900012169, 0.2304852809993463, 0.21138183900075092, 0.2124473499989108], [0.21505803299987747, 0.23070552200078964, 0.20982055099921126, 0.21254713800044556, 0.2034917660002975, 0.2111086989989417, 0.20464751000145043, 0.2154802609984472, 0.22837637400152744, 0.209886328999346, 0.22025715800009493, 0.21935818800011475], [0.21477134000087972], [0.21037124100075744], [0.2124639659996319, 0.20227348299886216, 0.21121207400028652, 0.20431173799988755, 0.2156616970005416, 0.227980841000317, 0.21061410899892508], [], [0.21244647200001054, 0.20261093999943114, 0.21116056900063995, 0.20453963699947053, 0.21570184499978495, 0.22815049400014686, 0.21006153800044558, 0.2200907679998636, 0.2193974439996964, 0.20902800600015325, 0.20583044500017422], [0.21249344200077758, 0.20225676500012923, 0.21057676899908984, 0.20509817700076383, 0.21566786899893486, 0.22793655300120008, 0.2106660749996081, 0.21966365699881862, 0.2192114790013875, 0.20913657199889713, 0.20579756100050872, 0.21150935900004697, 0.20915695499934372, 0.21667580299981637, 0.20644017400081793, 0.20991986300032295, 0.20825091799997608, 0.20592974899955152, 0.2192936949995783, 0.22548169900073844, 0.2163709699998435, 0.23753064800075663, 0.2542886309984169, 0.20800533100009488], [0.20209995900040667, 0.21058437600004254, 0.2050716769990686, 0.21560165700066136, 0.22800265499972738, 0.21066469300058088, 0.21966860799875576, 0.21922845400149527, 0.2089975319995574], [], [0.21069939600056387, 0.20489166999868758, 0.21567150300143112, 0.22793292599999404, 0.21066740300011588, 0.2200246389984386, 0.2188432670009206, 0.2091451460000826, 0.20579639899915492, 0.21151248200112605, 0.20993487200030359, 0.21620683999935864, 0.20709329700002854, 0.20926920700003393], [0.21080160000019532, 0.20464697500028706, 0.21560145299918076], [0.21094658900074137, 0.20447905999935756, 0.21570545699978538, 0.22814448100143636, 0.21006681699873297, 0.22008506699967256], [0.20507029100008367, 0.21548756999982288], [0.20447543999944173, 0.21569659300075728, 0.2281445270000404, 0.21006957099962165, 0.22018735600067885, 0.2192635479987075, 0.2090356470016559, 0.2059257159999106, 0.21069778299897735, 0.2109295749996818, 0.21643378000044322, 0.2069990340005461, 0.2091980209988833, 0.20834765100153163, 0.20572078499935742], [0.20550051600002917, 0.21554407800067565, 0.2283823569996457, 0.20988111900078366, 0.2198606989986729, 0.21977734800020698, 0.208810470001481, 0.2056361039994954, 0.21112534100029734, 0.2100999079993926], [0.20430927900088136, 0.2156588380003086, 0.22792950099938025, 0.2106690639993758, 0.22003610200044932, 0.21882506499969168, 0.20915258900095068, 0.2057951349997893, 0.21151431100042828, 0.2104996879988903, 0.21604523600035463, 0.2069710319992737, 0.20969015400078206, 0.20844270400084497, 0.2060746859988285, 0.21869482300098753, 0.2267792009988625, 0.21489599699998507, 0.23694274700028473, 0.25428069600093295, 0.20805723199919157, 0.21267479500056652, 0.22150126199994702, 0.20580043299924, 0.20544437799981097, 0.20749699100088037, 0.2308179920000839, 0.20530037899879972, 0.21509777900064364, 0.22414519999983895], [0.21525553499850503, 0.22790218699992693, 0.21072916699995403, 0.2199063070002012, 0.21881288599979598, 0.2091591349999362, 0.20579588700093154, 0.2115167920001113, 0.20999225599916826, 0.21643707300063397, 0.20699673899980553, 0.2092018690000259, 0.2083455360007065, 0.20599735100040562, 0.21895054099877598, 0.22544350899988785, 0.21641163300046173, 0.2372617729997728, 0.2542742580008053, 0.20805824099988968, 0.21267773099862097, 0.22176574700097262], [0.21508184599952074, 0.22769263800000772, 0.21066489599979832, 0.21966690299996117, 0.2192227070008812, 0.2091145209997194, 0.20580634500038286, 0.21069156900011876, 0.2102171679998719, 0.2165789089995087, 0.2066761639998731], [0.21012935299950186, 0.2193666100010887, 0.21894400000019232, 0.2099836380002671, 0.20495373099947756, 0.21141822800018417, 0.21026553000046988, 0.21616148699831683, 0.20698749800067162, 0.20965254499969888, 0.20789682800023002], [0.2196758090012736, 0.21920004899948253], [], [0.20531055799983733, 0.21141675900071277, 0.21026404299846035, 0.21616454000104568, 0.20699178599898005, 0.20920680300150707, 0.2083412979991408, 0.20634744400013005, 0.21860994800044864, 0.22587264600042545, 0.21597780799856992, 0.23726570200051356], [0.2056763939999655, 0.21097524699871428, 0.2102419060011016, 0.21658661299989035, 0.20666907399936463, 0.20980232900001283, 0.2080850639995333, 0.20594100400012394, 0.21929275900038192, 0.2254826120006328], [0.20522754000012355, 0.2111190469986468, 0.2098010730005626, 0.21645737000108056, 0.2070024189997639, 0.2091948629986291, 0.20829256200158852], [0.21114184200087038, 0.20980624399999215, 0.21645117200023378, 0.20688899800006766, 0.2093099939993408, 0.2082894369996211, 0.20555249000062759, 0.2192904460007412, 0.2256006459992932, 0.21634674899905804, 0.23750208300043596, 0.2542429719997017, 0.2080564920015604, 0.21262114699857193, 0.22180915500030096], [0.21090081600050326, 0.20999663200018404, 0.21616256500055897, 0.20698482599982526, 0.20965566499944543], [0.21092371199847548, 0.2103330530007952, 0.21659045900014462, 0.20666554099989298, 0.2096918410006765], [0.21065267599988147, 0.21603911300007894, 0.20698088599965558, 0.20969168999909016, 0.2084260110004834, 0.205869759000052], [0.20968607299982978, 0.21642854399942735, 0.20700156900056754, 0.2091958569999406, 0.20834764699975494, 0.2057187549999071, 0.21912883599907218, 0.22555628700138186, 0.2164113049984735, 0.23745610800142458, 0.2542083169992111, 0.20805447699967772, 0.21270742900014739, 0.2217426820006949, 0.20560771199961891, 0.20543177100080356, 0.20810093199906987, 0.23019532400030585, 0.20524406399999862, 0.21504116699907172, 0.2244567610014201, 0.20884622299854527, 0.20616336100101762, 0.2342396040003223, 0.2194142139996984, 0.20511258899932727, 0.20737665399974503, 0.21364116000040667], [0.2165940929990029, 0.2064200160002656], [0.21664052699998138, 0.2055624490003538, 0.2106447099995421, 0.20841352999923402, 0.2058030640000652, 0.2193949110005633, 0.2256338440001855, 0.21635525999954552, 0.23674396699971112, 0.25474436300100933, 0.2073903809996409], [0.2161033119991771, 0.20667641300133255, 0.20971656099936808], [0.2064587839995511, 0.20982216999982484, 0.20832972200150834, 0.20592803599902254, 0.2192973780001921, 0.22548569399987173, 0.2163684259994625, 0.23696788600136642, 0.2547746049986017], [0.20690309800011164, 0.20930194199900143, 0.2079014989994903], [0.20709379400068428, 0.2092661329988914, 0.20798642900081177, 0.2059545439988142, 0.2192914600000222, 0.2255982650003716, 0.2163473319997138, 0.2375422700006311, 0.25416188099916326], [0.20988508699883823, 0.20826545400086616, 0.20579937500042433, 0.21939039599965326, 0.2256247440000152, 0.21636456200030807, 0.23684742799923697], [0.20970003600086784, 0.20822350299931713, 0.20593512500090583, 0.21929368999917642, 0.2254810100002942, 0.21637055300016073], [0.2098484529997222, 0.2082466129995737, 0.20600729800025874, 0.21919126300053904], [], [0.20826034199853893, 0.2059208190003119, 0.21929759200065746, 0.22548197099968093, 0.21636912199937797, 0.23696877300062624, 0.2548325190000469, 0.20777972699943348, 0.21287972400023136, 0.22143984800095495], [0.20587598599922785, 0.21851478400094493, 0.22587655899951642, 0.2159713470009592, 0.23737112399976468, 0.25421784199897957, 0.20805533100065077, 0.2126264189992071], [0.20582229200044821, 0.21862858699932985, 0.22678326799905335], [0.21869311699992977, 0.22669546399993123], [0.21889101099986874], [0.2191813720000937, 0.22558011799992528, 0.21642612499999814, 0.23746029599897156, 0.254213432999677, 0.20805416800067178, 0.21269907799978682, 0.22174980099953245, 0.20560099199974502, 0.20544023100046616, 0.20797884599960526], [0.21860401300000376, 0.2268059580001136, 0.21483430500120448, 0.23714017099882767, 0.2542023830010294, 0.2080546979996143, 0.212713437000275, 0.22173691100033466, 0.20561357899896393, 0.20542656300131057], [0.21913130999928399, 0.22555845600072644, 0.21632851799950004], [0.21500871099851793, 0.23632697500033828, 0.2545130329999665], [], [0.21261886400134244, 0.22130381099850638, 0.20550280499992368, 0.20533850100036943, 0.2084457310011203, 0.23061208299986902, 0.2052001529991685, 0.21504868600095506, 0.22438123199935944, 0.2086748460005765, 0.20581662099903042], [0.21276401300019643], [0.21279086100003042, 0.22151173400015978, 0.20580713599883893, 0.20544671800053038, 0.20749364900075307, 0.2306791239989252, 0.20544447199972637, 0.2148609050000232, 0.2243750600009662, 0.20854788799988455, 0.2062946779988124, 0.2344731840003078, 0.21945113000037964, 0.20499547200051893, 0.20710505399983958, 0.21362932699958037, 0.22620183400067617, 0.20528589300010935, 0.20424367399937182, 0.2177692429995659, 0.21578039900123258, 0.22058701899914013, 0.2071477989993582, 0.20519481400151562], [0.21260187299958488, 0.22176395099995716, 0.20524572899921623, 0.20518958899992867, 0.20840580000003683, 0.2306866210001317, 0.2052361549995112, 0.21499610700084304], [0.2126867540009698, 0.221719421000671, 0.2056200600000011, 0.20571550599925104, 0.20783368999946106, 0.23029099099949235, 0.20511670900123136, 0.21503587900042476, 0.2244622629987134, 0.20915251600126794], [0.21258101700004772, 0.22150247899844544, 0.20580227000027662, 0.2054448950002552, 0.20749517799958994, 0.23081083800025226, 0.20530963300006988, 0.21484772599978896, 0.2243930430013279, 0.20854116000009526, 0.20629428999927768, 0.23447652499999094, 0.21943780800029344], [0.2060838950001198], [0.2051405309994152], [0.20527668000067933, 0.20536064599946258, 0.20840673000020615, 0.2306688930002565, 0.2052511849997245, 0.21491074799996568, 0.22439784400012286, 0.2086847589998797, 0.20708662899960473, 0.23415239400128485, 0.21940305499992974], [0.2054508170003828, 0.2083993489995919, 0.23018785400017805], [0.205328260000897, 0.20747094699981972, 0.23082075199999963, 0.20529390199953923, 0.2150997560001997, 0.2242595280004025, 0.20840652199876786, 0.20629297400046198, 0.23447724700054096, 0.21946658399974694, 0.20495546599886438], [], [0.20759575800002494, 0.2306786799999827, 0.2052343599989399, 0.21506454500013206, 0.2242179490003764, 0.20868537900059891, 0.2062995050000609, 0.23443097000017588, 0.21930145399892353, 0.20503474600081972, 0.20694043799994688], [0.20741952499884064, 0.23077081800147425, 0.20529044399881968, 0.2150980950009398, 0.22426738600006502, 0.20840014399982465, 0.20629287399970053, 0.23447952199967403, 0.2194606280008884, 0.20504080199862074], [0.23044784699959564, 0.2052457930003584, 0.21504850600103964, 0.2242756220002775, 0.20900227399943105, 0.2057052449999901, 0.2344771349999064], [0.20565467400047055, 0.21487362399966514, 0.2242242760003137, 0.2086922290000075, 0.20629407799970068, 0.23446644700015895, 0.2192582540010335, 0.20519454500026768, 0.20690449899848318, 0.213596438001332], [0.22506527000041388, 0.20884825800021645, 0.20570133600085683, 0.23459295199972985, 0.21951516999979503, 0.2051139270006388, 0.20685086299999966], [0.20918229999915638, 0.20611689200086403, 0.2344771479984047, 0.21945576000143774, 0.20508473199879518, 0.20696116799990705, 0.21363385100084997, 0.22620254600042244, 0.20525994399940828, 0.20424439099951996, 0.21777114600081404, 0.21577615800015337, 0.22059907800030487, 0.20713094399980037, 0.20525650899980974, 0.2061026649989799, 0.21411360199999763], [], [0.2063274280008045, 0.23415543699957198, 0.21940707700014173, 0.2051128860002791, 0.2073850050001056, 0.21374287999969965, 0.22546917199906602, 0.20522791000075813, 0.20423856799970963, 0.21777132700117363, 0.21577680999871518], [0.2342442690005555, 0.21942290200058778, 0.20511225200061745, 0.2069325709999248, 0.21346452299985685, 0.22620360499968228, 0.20522965300006035, 0.20423925399882137, 0.21777189200111025, 0.2157760549998784, 0.22062210100011725], [0.23441028500019456, 0.2195608900001389, 0.20453286900010426, 0.20695615299882775, 0.21413044600012654, 0.2249196140001004, 0.2065174540002772, 0.20347425900035887, 0.2184540130001551, 0.21570783099923574, 0.2201087590001407], [0.23425594899890712, 0.21948768800029939, 0.20481658000062453, 0.20700855299946852, 0.21381451900015236, 0.22491128600086085, 0.20651160499983234, 0.20375978399897576, 0.2181683390008402, 0.21570525899915083, 0.2202831550002884, 0.20680753300075594, 0.20498941499863577, 0.20676655500028573, 0.21459746900109167, 0.21682437900017248, 0.22113871699912124, 0.2076084800009994, 0.22550756599957822, 0.19707555399872945, 0.22050439800113963, 0.20673865099888644, 0.2115537019999465, 0.23138312500122993, 0.2264668169991637, 0.22311171700130217, 0.24335910899935698, 0.2511070460004703, 0.21239359799983504, 0.20983036500001617, 0.22181345500030147, 0.22284942799888086, 0.21049839099941892, 0.22158225000021048, 0.20400044600137335, 0.2059884289992624, 0.21343132500078354, 0.2335672169992904, 0.2119672860007995, 0.20763561199964897, 0.2201859790002345, 0.21384930800013535, 0.21709700799874554, 0.20944779999990715], [0.2053294730012567, 0.20682170699910785, 0.2138103930010402, 0.22646740899836004, 0.20571216999996977, 0.20395638400077587, 0.21776966800098307], [], [], [0.20684452399837028, 0.2135464540006069, 0.2262028540008032, 0.20605566999984148, 0.2035912779992941, 0.21780360699995072, 0.21620143200016173, 0.2199894889999996, 0.20747374600068724], [0.20676704000106838, 0.21450056299909193, 0.22620350500073982, 0.20516327299992554, 0.20419333899917547, 0.2175139240007411, 0.21604635599942412, 0.22128912200059858, 0.20618057799947564, 0.2055068379995646, 0.20608371200069087, 0.21416290699926321], [0.21359428499999922, 0.22539099900131987, 0.2051280379982927, 0.20419213000059244, 0.21751208299974678], [0.21373828600007982, 0.22645715500038932, 0.20512592200066138, 0.20427073999962886, 0.21754376500030048, 0.21597934599958535, 0.21991772699948342, 0.2068880620008713, 0.20573886199963454], [0.21356712099986908], [0.2134058299998287], [0.20573832400077663, 0.2039591169996129, 0.21776951200081385, 0.21583994200045709, 0.21956674799912435, 0.2082050299995899, 0.205137625000134, 0.20611359100075788, 0.21412848199906875, 0.21640108400060853, 0.22114173299996764, 0.20912434999991092, 0.22402184599923203, 0.197080009000274, 0.2205022280013509, 0.20787573799862002, 0.211444759999722, 0.23035878400150978, 0.22646655099924828, 0.2231040070000745, 0.24336538699935772, 0.25110500600021624, 0.2123953000009351, 0.20983063200037577, 0.22180657599892584, 0.22285967800053186, 0.2104943819995242, 0.2215824459999567, 0.20400947199959774, 0.20598960999996052, 0.21342900099989492, 0.2335546530011925, 0.21273913900040498, 0.20845075699980953, 0.21859808299996075, 0.21511912699861568], [0.2035931400005211, 0.21778266000001167], [0.2036912060011673, 0.21814560900020297, 0.21570431999862194, 0.22117899200020474, 0.2059232459996565, 0.20572171700041508, 0.20604007499969157, 0.2145728750001581, 0.21699116000127106, 0.22132391499872028, 0.207273444000748], [0.2037283669997123, 0.21859167200091179, 0.2156998359987483, 0.22008368400020117, 0.20655668700055685], [0.20408332499937387, 0.21768895899913332, 0.21572363500126812, 0.22114972999952442, 0.20593694600029266, 0.20573158299885108, 0.2060300120010652, 0.21456221500011452, 0.21699420499862754, 0.22132017600051768, 0.2073893920005503], [], [0.20419177199983096, 0.21751868299907073, 0.21598055000140448], [0.2175931949986989, 0.21592020299976866, 0.21971270700123569, 0.20775772199885978], [0.21755189999930735, 0.21597503399971174, 0.2209217890012951, 0.20589042199935648, 0.2057352030005859, 0.20602589299960528], [], [0.21638983099910547], [0.2157846400004928, 0.219699891998971, 0.20803885700115643, 0.20519445699937933, 0.20617607299936935, 0.2141191880000406, 0.2164568380012497, 0.2211457369994605, 0.20907295100005285, 0.2240394929995091, 0.1970629879997432, 0.22051395000016782, 0.207663440000033, 0.21107823300008022, 0.230731208999714, 0.22666215600111173, 0.22311505299876444, 0.24334796900075162, 0.2511136430002807, 0.21239192199936952, 0.20982899100090435, 0.2218281779987592, 0.22282290100156388, 0.21051554099904024, 0.221577956001056, 0.20389464799882262, 0.2060172599994985, 0.21348152800055686, 0.2336094630009029, 0.212315923999995, 0.20847535599932598], [0.20728986599897326, 0.20516689000032784, 0.20610701400073594, 0.21413987000050838, 0.21667118199911783, 0.22135951900054351, 0.20861770199917373, 0.22420184000111476, 0.1977377200000774], [0.20609610099927522], [0.20501897800022562, 0.20607643899893446, 0.21412274900103512, 0.2164994039994781, 0.22106248099953518, 0.2091122780002479, 0.2239736850006011, 0.19707007800025167, 0.2205064179997862, 0.20789952899940545, 0.21143241000027047, 0.2303349949997937, 0.22647363699979906, 0.22311744100079522, 0.2433504879991233, 0.2511096500002168, 0.21239232600055402, 0.20982942400041793, 0.22181943800023873, 0.22284221699919726, 0.21050310999999056, 0.22158089299955464, 0.2039056260000507, 0.20607404700058396, 0.21343179599898576, 0.23358226700111118, 0.2127483009990101, 0.20845367100082512, 0.2185834550000436, 0.21513656699971762, 0.21580571199956466, 0.2106979960008175, 0.20475432599960186], [0.2051387400006206, 0.2061079659997631, 0.2141339900008461, 0.2161104869992414, 0.22126443600063794, 0.20928361699952802, 0.2233741510008258, 0.19749907799996436, 0.22064178599976003, 0.2078841940001439], [0.20552506000058202, 0.2059814579988597, 0.2144160820007528], [0.20565607199932856, 0.20573508800043783, 0.2144059259990172, 0.2168179100008274, 0.2213335479991656, 0.2077781000007235, 0.2250546529994608, 0.19708886400076153, 0.22049944900027185, 0.2070540799995797, 0.21144036499936192, 0.2312334930011275, 0.2269384880000871, 0.22259869199842797, 0.24354727300124068, 0.2509402529994986, 0.21288034400095057, 0.2095394549996854, 0.22161608599890315, 0.22300541500044346, 0.21036085699961404, 0.22206012300011935, 0.20355836000089766, 0.20609595799942326, 0.21331190800083277, 0.23359978799999226, 0.21202509999966423, 0.2083718260000751, 0.2192923589991551, 0.21430704799968225, 0.21671123700070893, 0.2103552070002479], [0.20577099600086513, 0.21441361299912387, 0.21681352800078457, 0.22133466599916574, 0.2077707280004688, 0.2250670760004141, 0.19708399499904772, 0.22050069400029315, 0.20675195300100313, 0.2115547899993544], [0.206338562999008, 0.21377939800004242, 0.21651761700013594, 0.22132803299973602, 0.20878763899963815, 0.22404374100005953, 0.19709465600135445, 0.22049688500010234, 0.20785768199857557, 0.21144908200039936, 0.23042344100031187], [], [0.21423962200060487, 0.2168013989994506, 0.22133072900032857, 0.20778306899956078, 0.22504846599986195, 0.1970918070001062, 0.2204973850002716, 0.20705880300010904, 0.21144019799976377, 0.23123027799920237, 0.22694396500082803], [0.21408037599940144, 0.21619592500064755, 0.22131533999890962], [0.2141346970001905], [0.21412607399906847, 0.21628784099993936, 0.22119229500094661, 0.20910549699874537], [0.2168036420007411, 0.22105392099911114, 0.20749186400098552, 0.2251530930006993, 0.19761637400006293, 0.22052108199932263, 0.20675879100053862, 0.21155257999998867, 0.23113315399859857, 0.22667918500155793, 0.22311176799848909, 0.24328087300091283, 0.25118571299935866, 0.21238300400000298, 0.20983495800101082, 0.2218444649988669, 0.22264141000050586, 0.2106869449999067, 0.22147108299941465], [0.20882288799839444, 0.22483720099990023, 0.1970978200006357, 0.22049608999986958, 0.2070479220001289, 0.2114375020009902, 0.2313702529991133, 0.22689481800080102, 0.22248105899961956, 0.2435547149998456, 0.25093789099992136], [0.20876533000046038, 0.22400713299975905, 0.19785916900036682, 0.21978326499993273, 0.2077369020007609], [], [0.2080540539991489], [0.22397915399960766, 0.19721277499957068, 0.22036235900122847, 0.2078374550001172, 0.21145576999879268, 0.23057050200077356, 0.22689325399915106, 0.22247171100025298, 0.24356016400088265, 0.251085009000235, 0.2127218579989858, 0.20965721200082044, 0.22169852099978016, 0.2232182230000035], [0.22529699500046263, 0.1972132769988093, 0.22035225200124842, 0.20663943599902268, 0.21155349500077136, 0.23172210399934556, 0.22696184699998412, 0.2223817730009614, 0.24358629599919368], [0.1988150039996981, 0.2199254960014514, 0.2077422269994713, 0.21146307699928002, 0.23060275700117927, 0.22689574699870718], [], [0.22017900500031828, 0.2071739510010957, 0.21127504099968064, 0.23139352399994095, 0.22689435899883392, 0.2224596330015629, 0.2435727969987056, 0.2514629289998993, 0.2124887480003963], [0.22007193699937488, 0.20758194900008675, 0.21141932499995164], [0.20746343199971307, 0.21127735799927905, 0.2313938950010197, 0.2268939709992992, 0.22246484199968108, 0.2435679270001856, 0.25144998300129373, 0.21235772599902702, 0.20965830600107438, 0.22169192099863722, 0.22331174300052226, 0.20996904800085758, 0.22197827699892514, 0.20433452900033444, 0.20536228399942047, 0.2132593349997478, 0.233575809001195, 0.21203235199936898, 0.20835274700039008, 0.21943552300035662, 0.21418388699930802, 0.21671058500032814, 0.21037608400001773, 0.2040227479992609, 0.20858094200048072, 0.2151972459996614, 0.227661506000004, 0.21608377499978815, 0.20716596800048137, 0.1970807119996607, 0.21098937100032344, 0.20770963100039808], [0.2114396199995099, 0.23124287400059984, 0.22693348899883858, 0.22260794000067108, 0.24353712999982235, 0.2509463579990552, 0.2128698760006955, 0.20954630300002464, 0.22162299000046914, 0.22288565400049265], [0.21108598399951006, 0.23103205200095545, 0.2264653479996923, 0.22319194299961964, 0.24357894700006, 0.2519592919998104, 0.21211445399967488], [0.21098845300002722, 0.2309723770013079, 0.22691217299870914, 0.22263559500061092, 0.24351316499996756, 0.25096143699920503, 0.21239857300133735, 0.20983155499925488, 0.22180314700017334, 0.2228646999992634, 0.21048846600024262, 0.2215842790010356, 0.20401590199981, 0.20609106899973995, 0.21332484999948065, 0.23354559899962624, 0.2122975199999928, 0.2084991040010209, 0.21898906199930934, 0.2145969650009647, 0.21634624499893107, 0.21056069200130878, 0.20404080899970722, 0.20858837499872607, 0.21506874300030177, 0.22761338500095007, 0.21608474399909028, 0.20749476800119737, 0.19708693599932303, 0.2108135050002602, 0.207807849999881, 0.20393206399967312, 0.21283358599976054, 0.20816319200093858, 0.20697091900001396, 0.21336011899984442, 0.21197692299938353, 0.2327306419992965, 0.25157259900151985], [0.2114424080009485, 0.23037957599990477, 0.22692667299997993, 0.22261822300060885, 0.2435272979982983, 0.25095313300153066, 0.21239825799966638, 0.20990780300053302, 0.22172330699868326, 0.22287166400019487, 0.21048320999943826, 0.22158610400038015], [], [], [0.20955827399848204, 0.22163529099998414, 0.22287710400087235, 0.2104807149989938, 0.22165272300117067, 0.20393511799920816, 0.20609832599984657, 0.2133177790001355, 0.23361261399986688, 0.21259318800002802, 0.20814102400072443], [], [0.2215236290012399, 0.22338237300027686, 0.2099410609989718, 0.2216583419995004, 0.2039346800011117, 0.20609803299885243, 0.21331347700106562, 0.2336113490000571, 0.2126430469998013, 0.20844592200046463, 0.2185226719993807, 0.2151425960000779, 0.215800121999564, 0.21071451799980423, 0.20436708000124781, 0.20872462399893266, 0.21448701100052858, 0.22758455599978333, 0.21613255199918058, 0.20793641000091156, 0.19686286599971936, 0.2110635770004592, 0.20820965399980196], [], [], [0.2219754970010399, 0.2034900700000435, 0.20609556999988854, 0.21331250299954263, 0.23360627699912584, 0.21216437300063262, 0.2085023170002387, 0.2190147599994816, 0.2145676939999248, 0.21638378399984504], [0.20579723000082595, 0.20564218499930575, 0.2126366180000332, 0.23342269599925203, 0.2126932110004418, 0.20828918400002294, 0.2188886799995089, 0.21490566300053615, 0.21612691300106235, 0.2106031029998121, 0.20455215199945087, 0.20818950600005337, 0.21490432499922463, 0.22759266499997466, 0.21596816900091653, 0.20773955900040164, 0.19692131699957827, 0.21098319699922286, 0.2082444330008002], [0.20601473100032308, 0.21329564699954062, 0.23359216900098545, 0.2120347429990943, 0.2083622030004335, 0.21928943900093145, 0.21432127799926093, 0.2166998690008768, 0.21039381599985063, 0.20401979999951436, 0.20850989099926664], [0.20524582300095062, 0.21321815900046204, 0.23356832299941743, 0.21204195700011041, 0.2083436119992257, 0.2194327710003563, 0.21435159900102008, 0.21654435899836244, 0.21038762800162658, 0.20403452799837396, 0.20858721300101024, 0.21517490099904535, 0.22765926100146316, 0.2160794409992377, 0.2071915220003575, 0.19719734899990726, 0.21085634699920774, 0.207803616000092, 0.20392381400051818, 0.21195708899904275, 0.20893273200090334, 0.20709026599979552, 0.21324540800014802, 0.21204947799924412, 0.23273946800145495, 0.251580895999723, 0.27851612700033, 0.24129546999938611, 0.21042539500012936, 0.2096953010004654, 0.22565546099940548, 0.21156373499979964, 0.22088312599953497, 0.2224946930000442, 0.21494161100054043, 0.22753178700077115, 0.217571463999775, 0.21528559400030645], [0.20570551000128035, 0.21325883399913437, 0.23358332899988454, 0.2126098570006434, 0.20844078899972374, 0.21860328299953835, 0.21515239000109432], [], [], [0.21301023599880864, 0.2335108509996644, 0.21189298900026188, 0.20839909400092438, 0.21951214099863137, 0.2136979330007307, 0.2172083109999221, 0.20947587199952977, 0.20439517600061663, 0.2085975949994463], [0.21313337100036733, 0.23353934999977355, 0.21259354799985886], [0.21283836499969766, 0.23346140600006038, 0.21270535000076052, 0.2082996799999819, 0.21879792400068254, 0.2149929359984526, 0.21591388000160805, 0.21052592599880882, 0.20483664099992893, 0.2081997120003507, 0.21462702700046066, 0.2276535569999396, 0.21607475800010434], [0.21264273899942054, 0.23341567399984342, 0.21190578900132095, 0.20838446899870178, 0.2195115930007887, 0.21370165900043503, 0.2172063870002603, 0.2099248689992237], [0.21260660599909897, 0.2082975980010815, 0.21922331899986602], [0.2198026120004215, 0.21372226200037403, 0.21720645499954117, 0.2094706160005444, 0.20438723699953698, 0.20859844100050395, 0.21569911499864247, 0.22760576400105492, 0.21615596099945833, 0.20645262300058675, 0.19709178999983124, 0.21131961199898797, 0.2077416970005288, 0.20371573900047224, 0.21202995400017244, 0.20830190400010906, 0.2075482860000193, 0.21375215399893932, 0.2121286000001419, 0.2321107440002379], [], [0.21965626800010796, 0.21370443799969507, 0.21719064699937007, 0.20949321999978565, 0.20439533900025708, 0.20859627999925578, 0.2156834830002481, 0.22759887400025036, 0.21615330799977528, 0.2067408279999654, 0.196855599000628, 0.21129545599978883, 0.20773538399953395, 0.20371188600074674, 0.21223014399947715, 0.2082507289997011, 0.2074057530007849], [0.2146620029998303, 0.21657510499971977, 0.21036667999942438, 0.2040276490006363, 0.2085855419991276, 0.2152111600007629, 0.2276568050001515, 0.21607661899906816, 0.20716113700109418, 0.19708601599995745, 0.21097605700015265, 0.20779880800000683, 0.20391816399933305, 0.21196049299942388, 0.20865018900076393, 0.20735645999957342, 0.21324503499999992, 0.21205074499994225, 0.23266213900024013, 0.25167631799922674, 0.2784555160014861], [], [0.2105706359998294, 0.20406797400028154, 0.20851027500066266, 0.2140515070004767], [0.20419584000046598, 0.2085111609994783, 0.21552809800050454, 0.22756014200058416, 0.2161112729991146, 0.2066608120003366, 0.19738813799995114, 0.21102106400030607, 0.2074951989998226, 0.20370097900013207, 0.21234880100018927], [0.20404390399926342, 0.20861626000078104, 0.21562613300011435, 0.22764937299871235, 0.21611351600040507, 0.2066659760002949, 0.19700613699933456, 0.21117250000133936], [0.20482592900043528, 0.20821671100020467, 0.21467099499932374, 0.22764426300091145, 0.2161141670003417, 0.20773705600004178, 0.1968517539989989, 0.21105901100054325, 0.20825940900067508, 0.20359874699897773, 0.21252785599972412, 0.20805288399969868, 0.20729239000138477], [0.20435630999963905, 0.2086094240003149, 0.2148516759989434, 0.22763654500158736, 0.21611277999909362, 0.2076538060009625, 0.19686339299914835, 0.2110670370002481, 0.20797619599943573, 0.20345527800054697, 0.21284720099902188, 0.20808635400135245, 0.2069762829996762, 0.21342912100044487, 0.21192757499920845, 0.23272949700003664, 0.25203367799986154, 0.27803572099946905, 0.24135119800121174, 0.2107710849995783, 0.2098648890005279, 0.22518671800025913], [0.20840235600007873, 0.21558769600051164, 0.22764096100036113, 0.216113211999982, 0.20666324199919472, 0.1971542920000502, 0.21117777899962675, 0.20755733900114137, 0.2037054979991808, 0.21234138200088637, 0.20812997999928484], [], [0.21488529099951847, 0.22749867600032303, 0.216110416000447, 0.20764561099895218, 0.19686277499931748, 0.21106429700012086, 0.20820554200145125, 0.20340230199872167, 0.21272357100133377, 0.2080424289997609, 0.20697697299874562], [0.21566622400132474, 0.22753011399981915], [0.2151975439992384, 0.22749760600163427, 0.21596368699829327, 0.20759392200125149, 0.19681809800022165, 0.21109182199870702, 0.2079873660004523, 0.2034483179995732, 0.21284305100016354, 0.20810319600059302, 0.20697422699959134, 0.21342784000080428, 0.21191652599918598, 0.2327308889998676, 0.2520402390000527, 0.27803607399982866, 0.24127996200149937], [0.20792158200129052, 0.19707643299989286, 0.21100523099994462, 0.20750385300016205, 0.20405438799934927, 0.21212469300007797, 0.20853566199912166, 0.20744528300019738, 0.213246508001248, 0.21205784199992195, 0.23266192299888644, 0.25167820700153243, 0.2784462879990315, 0.2413889300005394, 0.21041383599913388, 0.20969618700110004, 0.22564755199891806, 0.21095460899960017, 0.2211669520002033, 0.22273710100125754, 0.21499599999879138, 0.2265304450011172, 0.2182037490001676, 0.21478988699891488, 0.23352378600066004, 0.21644161499898473, 0.2221430480003619, 0.20862076900084503, 0.20967254399874946, 0.20976922400041076, 0.21764782500031288, 0.1963110559991037, 0.2222104330012371, 0.22586303999923985, 0.22352071500063175, 0.20556668899916986, 0.23086747500019555, 0.21399613200082968, 0.3521859510001377, 0.07171196899980714, 0.2190546120000363, 0.21107977899919206, 0.21795118400041247, 0.2118290620001062, 0.22247395200065512], [], [0.20688961799896788, 0.19735175499954494, 0.2110132670004532, 0.20749990100011928, 0.20379209400016407, 0.2123550910000631, 0.20809582800029602, 0.20739402700019127, 0.2136651319997327, 0.2121413709992339, 0.23266158300066309, 0.2516804040005809, 0.2783835089994682], [0.196886875999553, 0.21108577500126557, 0.20799103599892987, 0.20344610800020746, 0.21283918300105142, 0.20811320299981162, 0.20697307099908357, 0.21342796800126962, 0.21190972399926977, 0.2327324369998678, 0.2520386159994814, 0.2780399210005271, 0.24126998800056754, 0.2104388129992003, 0.20994172300015634], [0.19698216199867602, 0.21080558500034385, 0.20803054300085932, 0.20396590800010017, 0.21199383699968166, 0.2083387179991405, 0.20671125400076562], [0.1968629629991483, 0.21129945800021233, 0.2077386809996824, 0.20371362100013357, 0.2120306580000033, 0.20829795099962212, 0.2075553670001682, 0.21375382900077966, 0.21213036500012095, 0.23220394199961447, 0.25202968399935344], [0.19708722299947112, 0.21081734700055677, 0.20780532400021912, 0.20392870999967272, 0.21195578799961368, 0.20893106400035322], [0.19685682899944368, 0.21105878200069128, 0.20825540099940554, 0.20359539600030985, 0.21252972100046463, 0.20805890299925522, 0.20707925699935004, 0.21386968300066656, 0.21149344299919903, 0.23289175600075396, 0.2517112179994001], [0.19692562700038252, 0.2109852800003864, 0.20824188100050378, 0.20360430399887264, 0.21252774200002023, 0.2080410100006702, 0.20739382700048736, 0.21363460199972906, 0.21166513499883877], [0.19702820800011978, 0.2107915110009344, 0.2083407640002406, 0.20344685099917115, 0.2128328449998662, 0.20812574900082836, 0.2069724649991258, 0.2134260560014809, 0.21190636699975585, 0.2327304339996772, 0.25164145099915913, 0.2784419580002577, 0.24127140500058886, 0.21043613399888272, 0.20993329500015534, 0.22553227900061756, 0.21074044300075911, 0.22116043200003332, 0.22273714799848676, 0.21500464900054794, 0.22652406000088376, 0.21808132200021646, 0.21472603999973217, 0.2337097179988632, 0.21622951599965745, 0.22193719999995665], [0.2110287879986572, 0.20749179700032983, 0.20370330500009004, 0.21234600500065426, 0.20819497499905992, 0.20738943800097331, 0.2136687139991409, 0.21213760600039677, 0.23265345899926615, 0.25168783300068753, 0.27831390199935413], [0.2110683400005655, 0.20797658399897045, 0.2034514990009484, 0.21284593499876792, 0.20809404800093034, 0.2069757600002049, 0.2134280949994718, 0.21192169599999033, 0.23273077300109435, 0.25203705099920626, 0.27803540000059, 0.24135107700021763, 0.210359876999064, 0.2102754150000692, 0.2251819749999413, 0.21129920400017, 0.22079589900022256, 0.22261948499908613, 0.21495562400014023, 0.22741662100088433], [0.21118486700106587, 0.20755480399930093, 0.20370858800015412, 0.21233322099942598, 0.20813618099964515, 0.20746681800119404, 0.2136730099991837, 0.21213509399967734, 0.2326401540012739, 0.25169591899975785, 0.27830899999935355, 0.24143691999961447, 0.20946231299967621, 0.21059580700057268, 0.22525098500045715, 0.21200543399936578], [0.21133310599907418, 0.20774563000122725, 0.20371937699928822, 0.21202849700057413, 0.20830815999943297, 0.20753917299953173, 0.21375081800033513, 0.21211947899973893, 0.2321140080002806, 0.2521496310000657, 0.2783124699999462], [0.21106000600047992], [0.2111779690003459, 0.20771825200063176, 0.2037100739999005, 0.2122387859999435], [0.21100078700146696, 0.2082406119989173, 0.2036017959999299, 0.21252628500042192, 0.2080473370006075, 0.207335951999994, 0.21366695199867536, 0.2115772659999493], [0.20754683000086516, 0.20388462899973092, 0.21205369999916002, 0.20831915600138018, 0.20702984899980947, 0.21408530699955008, 0.21163771799911046], [0.20391299099901516], [0.20345180700132914, 0.21282400599920948, 0.20814150300066103, 0.20697218699933728, 0.21336600500035274], [0.2037251780002407, 0.21202914499917824, 0.2083125850003853, 0.2070419169995148, 0.21408912200058694, 0.21175864500037278, 0.23249538099844358, 0.25226373200166563, 0.27831026799867686, 0.2415886369999498, 0.20945827700052178, 0.2105961479992402, 0.22514947700074117, 0.21162145500056795, 0.22113055199952214, 0.22276963600052113, 0.21482914999978675, 0.22670156799904362, 0.21798299600050086], [], [0.21235307000097237, 0.2081050500000856, 0.2073901929998101, 0.21366680699975404, 0.21213782399900083, 0.23266019400034565, 0.251683258000412, 0.2783767729997635, 0.24148495699955674, 0.20936763000099745, 0.21057668899993587, 0.22525721899910423], [0.21272377899913408, 0.2080516030000581, 0.20697657200071262, 0.21342922499934502, 0.211933914999463, 0.23291146900010062], [0.21253555600014806, 0.2080658949998906, 0.20707793700057664, 0.21386973199878412, 0.21148900499974843, 0.23289032400134602, 0.25171830199906253, 0.2780400629999349, 0.24145504500120296, 0.2106949839999288], [0.21232485900145548, 0.2085255940000934, 0.2074633369993535, 0.2131740839995473], [0.20861826799955452, 0.2069732350009872, 0.21325119699940842, 0.21204816399949777, 0.23274444400158245, 0.25157738599955337, 0.27852122699914617, 0.24128595100046368, 0.2104280719995586, 0.2096965860000637, 0.22568099700038147], [0.20746226899973408, 0.2131755880000128, 0.21214114500071446, 0.23266312099985953, 0.2516782860002422, 0.27843946400025743, 0.24140153400003328, 0.21040277400061314, 0.20970155099894328, 0.22563641700071457, 0.21088438900005713, 0.2211462119994394, 0.22277532999942196, 0.2150406880009541, 0.22651025199957076, 0.2180444929999794, 0.21473720200083335, 0.23372616799861134, 0.2162378400007583, 0.22191372899942508, 0.20901036100076453, 0.2097288019995176, 0.2097646279999026, 0.21768737099955615, 0.19631427400054235, 0.22220411700072873, 0.22586972799945215, 0.22352306900029362, 0.20547683099903225], [0.2069892509989586, 0.21335272100077418], [0.20736117800151987, 0.21323720500004129, 0.21205269599886378, 0.23266207199958444, 0.2516763070016168, 0.27845185799924366, 0.24137858200083429, 0.21042151899928285, 0.20969462399989425, 0.22565319199929945, 0.2109423620004236, 0.2211734240008809, 0.22273841300011554, 0.21498835300008068, 0.22653786599948944, 0.2183011990000523, 0.2149721320001845, 0.23326160099895787, 0.21644655900126963, 0.22213853399989603, 0.20862744999976712, 0.20965950400022848, 0.20977741800015792, 0.21762971199859749, 0.19630529999994906, 0.22221866300060356, 0.2258555129992601, 0.22351851100029307, 0.20557960500082118, 0.23087841999949887, 0.213974935000806, 0.3521997849984473, 0.07170155800122302, 0.21905743599927519, 0.21109301700016658], [0.2073033619999478, 0.21324024199930136, 0.21204960499926528, 0.23266341999988072], [0.21372343800067028, 0.21156375999999, 0.23277559999951336, 0.2517526130013721, 0.27835650499946496, 0.24108189799881075, 0.2107921630013152, 0.21007248899877595], [0.21334965100140835, 0.21188451899979555, 0.2329928769995604, 0.25175122099972214, 0.2780358020008862, 0.24123140799929388, 0.21044092100055423, 0.21017901499908476], [0.21395464099987294], [0.21363574099996185, 0.21165607399962028, 0.23266722100015613, 0.25174700999923516, 0.2783649500015599, 0.2411429939984373, 0.21076054500008468, 0.21009088100072404, 0.22453755599963188, 0.2114815130007628], [], [0.2133346470000106, 0.21188456699928793, 0.23300156500044977, 0.2517381079996994, 0.27803669400054787, 0.2413388959994336, 0.21077816700017138, 0.21021908299917413, 0.22489621200111287, 0.21125675899929774, 0.2207725339994795], [0.21148772900050972, 0.23288772799969593, 0.25172792699959246, 0.2780382800010557, 0.24128781299987168, 0.2107736580001074, 0.2098360159998265], [0.21197860699976445, 0.23273373399933917, 0.2515730529994471, 0.27852598000026774, 0.24127813000086462, 0.2104321560000244, 0.20969737599989458, 0.2257595829996717, 0.21062700000038603, 0.22096282199890993, 0.22228874400025234], [], [0.2106896860004781, 0.2097394019983767, 0.22521891500036872, 0.2106477930010442], [0.20936321999943175, 0.2105799710006977, 0.2252531469985115, 0.21139047700125957, 0.2209543239987397, 0.22228603600160568, 0.21552278299895988, 0.2266940240006079, 0.21799230400029046, 0.21452018399941153, 0.23380677599925548, 0.21641487300075823, 0.2218804820004152], [0.21075640299932275, 0.21009315999981482, 0.22484757900019758, 0.21061620600085007, 0.22118003600007796, 0.2227396830003272, 0.21497970699965663, 0.2265453449999768, 0.21850357800030906, 0.21483204399919487, 0.2332211320008355], [0.21005565900122747, 0.22522400799971365, 0.2112928930000635, 0.22096099099871935, 0.2223936260015762], [0.210467785000219, 0.22617362100027094, 0.2104426309997507, 0.22152756200011936, 0.22261929399974179, 0.21494911200170463, 0.22751442299886548, 0.21758632000091893, 0.21527774199967098, 0.23281775999930687, 0.21674805200018454], [], [], [], [0.2210748199995578, 0.22220577799998864, 0.2156755180003529, 0.22657869100112293], [0.22091496999928495, 0.2226405370001885, 0.21497178000026906, 0.2265508000000409, 0.2184999119999702, 0.21527012200022, 0.23286382999867783, 0.21649353400061955, 0.22210952999921574, 0.20849877500040748], [0.22079284899882623, 0.2226198860007571, 0.21496441599992977, 0.22684278199994878], [0.22273653499905777, 0.21502098400014802, 0.22651700599999458, 0.21804047000114224], [0.22752326199952222, 0.2182350189996214, 0.21528643700003158, 0.23284943500038935, 0.2167249140002241, 0.22193269200033683, 0.2085532660003082, 0.20954252099909354, 0.2099521710006229, 0.21804171999974642], [], [0.2266728989998228, 0.21804801500002213, 0.21473382099975424, 0.23356551799952285, 0.21639704900007928, 0.2219240570011607, 0.20804860799944436, 0.21054075500069303, 0.20922633599911933, 0.2184771610009193, 0.19628282499979832, 0.2222302430000127, 0.22584250799991423, 0.2235184869987279, 0.20592787500027043, 0.2302186930010066, 0.21428887999900326, 0.35221958399961295, 0.07168532900141145, 0.21884615699855203, 0.21092768000016804, 0.21843444600017392, 0.21147431200006395, 0.2224988449997909, 0.20691345500017633, 0.2126704680013063, 0.21826556099949812], [0.21567926600073406, 0.23326742300014303, 0.21644463499978883, 0.2221408400000655, 0.20862386199951288, 0.20966616599980625, 0.20977299200058042, 0.217716148999898, 0.19668914900103118, 0.22182440299911832, 0.22583624400067492, 0.22351748999972187], [0.21464629199908813], [0.2152703539995855, 0.23282746400036558, 0.21673871299935854, 0.2219178559989814, 0.20856129100138787, 0.2101081399996474, 0.20952014199974656, 0.2171750420002354, 0.1962537790004717, 0.2221544179992634], [0.21446742300031474, 0.23370900599911693, 0.21623233100035577, 0.22190763099933974], [0.21482755299985, 0.23322102899874153, 0.21644637700046587], [0.2335737710000103, 0.21639245400001528, 0.22193424100078118, 0.20802061299946217, 0.21056422699984978, 0.20922456100015552, 0.21782045699910668, 0.1964604920012789, 0.22237164299986034, 0.22598650899999484, 0.22353253300025244], [0.21688113499840256, 0.22178254600112268, 0.20898551299978863, 0.20967948900033662, 0.20976608399905672, 0.2182085090007604, 0.1965280200001871, 0.22210322099999757, 0.22544207600003574, 0.22401604299921019, 0.20555727099963406, 0.23013145700133464, 0.21423227499872155, 0.352952486000504, 0.0709167469995009, 0.21885595000094327, 0.21107158799895842, 0.21828275300140376, 0.21149473900004523, 0.22248369099906995, 0.20728594700085523], [0.21018991299933987, 0.20959269300146843, 0.2095247979996202, 0.2171801989989035, 0.19625001700114808, 0.22227584199936246, 0.22588215100040543, 0.2235264350001671, 0.2049542869990546], [0.2084063000002061, 0.20968599099978746, 0.209763873999691, 0.2182160140000633, 0.19652726800086384, 0.22209650199874886, 0.2254480000010517, 0.22401539899874479, 0.20555431100001442, 0.2301066300005914, 0.21419041599983757], [0.20854172100007418, 0.20955329000025813, 0.2098590530004003, 0.2176210399993579, 0.19681336900066526, 0.2217541270001675, 0.22578884499853302, 0.22374808800122992], [], [0.20951864600101544, 0.21739627299939457, 0.19681106799907866, 0.22175893200073915, 0.22578193600020313, 0.22378094699888607, 0.20584103100009088, 0.23044613300044148, 0.2138865960005205, 0.35225029600042035, 0.07169006499862007, 0.21907534300044063, 0.21112905600057275, 0.21803475100023206, 0.21183233999909135, 0.22237903400127834, 0.2076904329987883, 0.21295540800019808, 0.2178098950007552], [0.20926488700024493, 0.21844211900133814, 0.19624731199837697], [0.20980745399901934, 0.21850048800115474, 0.19648839499859605, 0.22205110899994907, 0.22537346399985836], [0.21736125999996148, 0.1963928630011651, 0.22232442299900868, 0.22596095799963223, 0.22360908500013466, 0.20484240600126213, 0.2314399599999888, 0.2139579260001483, 0.35183516399956716, 0.07223064800018619, 0.21901113300009456, 0.21093612699951336, 0.21777247399950284, 0.21206172700112802, 0.22252353399926506, 0.20682925099936256, 0.21273146600105974, 0.21817150999959267, 0.228804931999548, 0.20489595999970334, 0.21703166600127588, 0.20738919299947156, 0.21214063399929728, 0.20721503700042376, 0.21587772900056734, 0.21159185199940111, 0.22956266199980746, 0.21279239900104585, 0.231978732999778, 0.21509808199880354, 0.20305649300098594, 0.2036779789996217, 0.22141011699932278, 0.20623929500106897, 0.20861570099987148, 0.21023102199978894, 0.21153229199990164, 0.21729002500069328, 0.22536575800040737, 0.20460443899901293, 0.22762016100023175], [0.21824595100042643, 0.1965266890001658, 0.22208677399976295, 0.22545535899917013, 0.22401127699959034, 0.20555721500022628, 0.22998374700000568, 0.2143166639998526, 0.35302650700032245, 0.07092796399956569, 0.21876281200093217], [0.21748183099953167, 0.1962888699999894, 0.22222407100161945, 0.22584957799881522, 0.22351856600107567, 0.20558688299934147, 0.23094865799976105, 0.21389889599959133, 0.3522097550012404, 0.07169507599974168, 0.21906889199999569], [0.1965398299998924, 0.22206720899885113, 0.22547027400105435, 0.22370064799906686, 0.20586750200163806, 0.22986297799980093, 0.2144417589988734, 0.35268340000038734, 0.07125942300081078, 0.218718195999827, 0.21080419899953995], [0.19622458800040476, 0.22230230599961942, 0.22595103599996946, 0.22361106599964842, 0.20493790900036402, 0.23151044600126625, 0.2138266809997731, 0.351828430999376, 0.07221898500029056, 0.21909319999940635, 0.211064613000417, 0.21756039899992174], [0.19613378299982287, 0.22228470200025185, 0.22594364599899563, 0.22361151299992343, 0.20495016600034432, 0.2317108660008671, 0.21379424599945196, 0.35171692599942617, 0.07217806100015878, 0.21921976300109236, 0.2111271649991977, 0.21745159000056447, 0.21241280100002768, 0.22238238499994623, 0.20768304000011995, 0.21296376600002986, 0.21780346099876624, 0.2279621670004417, 0.20498541599954478, 0.21695025799999712, 0.20716485600132728, 0.21235536999847682], [0.22204527299982146, 0.22538153999994393, 0.2240154529990832, 0.20578282400128955, 0.23005438499967568, 0.21420673600005102, 0.35290919999897596, 0.07085598500088963, 0.21893111700046575, 0.21115981799994188, 0.21811781199903635], [0.22175208199951157, 0.2257973050000146, 0.2235589850006363, 0.20605527800034906, 0.23029334099919652, 0.214047796000159, 0.35223485399910714, 0.07166550400143024, 0.21899254999880213, 0.21108704800099076, 0.2181398229986371], [], [0.22402705700005754, 0.20588288999897486, 0.23031136900135607, 0.21402687599947967, 0.3522407340005884, 0.07165811199956806], [0.20633944800101744, 0.2302091420006036, 0.21413880699947185, 0.35222677499950805, 0.07167558500077575, 0.2189597569995385, 0.21087095999973826, 0.21838833299989346, 0.2115033530008077, 0.22247789699940768, 0.2069370709996292, 0.21266216600088228, 0.21879374799937068, 0.2281236720009474, 0.20500230099969485, 0.21693776000029175, 0.2083218929983559, 0.2112115449999692, 0.20895279200158257, 0.2149404309984675, 0.21093706600004225, 0.22957069400035834], [], [0.23004475899870158, 0.21411778299989237, 0.35295766000126605, 0.07090714399964781, 0.21888682499957213, 0.21118389399998705, 0.2181394069993985, 0.21155617700060247, 0.22252515199943446, 0.20736845900137268, 0.21229503599897726, 0.21860944000036397, 0.22816578099991602, 0.20495840200055682, 0.21697324399974605, 0.2086226589999569, 0.2108749250000983, 0.20911915800024872, 0.21504337300029874, 0.21067780399971525, 0.2296170979989256, 0.2127574520000053, 0.2317018960002315, 0.21555478800109995, 0.20303764500022226, 0.20339367099950323, 0.22141331899911165, 0.20655496000108542, 0.20969071199942846, 0.20937881200006814, 0.21120021900060237, 0.21712497299995448], [0.35371154400127125, 0.07094501599931391, 0.21876371600046696, 0.21094519500002207, 0.2185144199993374, 0.2113715460000094, 0.222488503999557, 0.2069278500002838, 0.21266515100069228, 0.21837085399965872, 0.228483270999277], [0.351708817999679, 0.07218231000115338, 0.2192013740004768], [0.3529014409996307, 0.07086692300072173, 0.21888587399917014, 0.21119695900051738, 0.218126048999693, 0.21156391200020153, 0.22252162000040698, 0.20737628799906815], [], [], [0.21125376300005883, 0.21819166300156212, 0.21153537600002892, 0.22246817799896235, 0.2069481660000747, 0.21265857099933783, 0.21880581400000665, 0.22807898900100554, 0.20484992599995167, 0.21703687400076888, 0.20828336899830902], [0.21780556900012016, 0.21198038100010308, 0.2224726529984764], [0.2128887790004228, 0.22237113699884503], [0.21180976899995585, 0.22238968400051817, 0.20740403799936757, 0.21256124100000306, 0.21833216699997138, 0.2280945430011343, 0.20496865799941588, 0.2169626930008235, 0.20831502599867235, 0.2111914289998822, 0.20886186999996426, 0.21492085499994573, 0.21092994600076054, 0.2297522900007607, 0.21276919199954136, 0.2316990139988775, 0.21554555500006245, 0.20345993600130896, 0.20307843099908496, 0.22161181100091198, 0.20626723599889374, 0.20958297500146728, 0.2093911649990332, 0.21111634299995785, 0.2173699619997933, 0.22539300199969148, 0.2048859580008866, 0.22716846799994528, 0.22937774099955277, 0.20721836800112214, 0.2118323569993663, 0.23025755799972103, 0.2491243120002764, 0.25722667099944374, 0.21224868100034655, 0.2126798659992346, 0.20880450399999972, 0.2169869400004245, 0.23938474300121015, 0.2325694579994888, 0.20827435699902708, 0.20855468100126018, 0.2174569809994864, 0.20692026899996563, 0.21505946800061793], [0.21188213899949915, 0.22243498399984674, 0.20695632199931424, 0.2126561050008604, 0.21880990200043016, 0.2280824739991658, 0.20487697399948956, 0.21703156200055673, 0.20741022100082773, 0.2121206699994218, 0.20721870600027614, 0.2159905689986772, 0.21148802600146155, 0.22951147599997057, 0.21267790399906517], [], [0.2118850740007474, 0.22252904499873694, 0.20731602200066845, 0.2122598519999883], [0.20774265799991554, 0.21228545299891266], [0.20747197099990444, 0.2122962630000984, 0.21860333400036325, 0.2280690819989104, 0.20500137800081575, 0.21701252999991993, 0.2086323209987313, 0.21082263500102272, 0.2090601340005378, 0.21517365899853758, 0.21064136700078961], [0.20764014099950145, 0.2129237449989887, 0.21791225800006941, 0.22784099400087143], [0.2123695409991342, 0.21827300100085267, 0.22808654899927205, 0.2049744659998396, 0.21695846900001925, 0.20832098299979407, 0.21119015300064348, 0.208866898999986, 0.21491187600076955, 0.21092676099942764, 0.22975572900031693], [0.2177982190005423, 0.22797016600088682, 0.2049794180002209, 0.2169556159988133, 0.20832612800040806, 0.21118879499954346, 0.208868486000938, 0.2149064389996056, 0.21092378399953304, 0.22979301400118857], [0.21833460299967555, 0.22810496099918964, 0.20496296300007089, 0.21696806799991464, 0.20783294800094154, 0.21166928399907192, 0.20763041000100202, 0.21556225899985293, 0.21146181899894145, 0.22979967600076634, 0.21276208000017505, 0.231699079999089, 0.21555360700040183, 0.2034497120002925, 0.20308237000062945, 0.22137671199925535, 0.2064967730002536, 0.20872954500009655, 0.20976059999884455, 0.21142545800103107, 0.21755883100013307, 0.22540249600024254, 0.2048289129998011, 0.22722338099993067, 0.22938373199940543, 0.20720890200027497, 0.21183472700067796, 0.23025811599836743, 0.2490808950005885, 0.2572756080007821, 0.21223957700021856, 0.212683368999933, 0.20880160099841305, 0.2169891590001498, 0.2393856449998566, 0.23256729200147674, 0.2082464790000813], [], [0.20495259200106375, 0.21697371899972495, 0.2086259589996189, 0.21084025100026338, 0.20904295400032424], [0.2171023150003748, 0.2069450719991437], [0.21678369400069641, 0.2079289430002973, 0.2117422749997786, 0.20753656799934106, 0.21543039300013334, 0.21143943599963677, 0.22992371800137335, 0.2130861539990292, 0.23133292800048366, 0.21562070099935227], [0.20872654099912324, 0.21110998199947062, 0.20894236599997384, 0.2149290960005601, 0.21093339800063404, 0.22965405600007216], [0.21213845599959313, 0.2071675030001643, 0.21593524499985506, 0.21160344300005818, 0.22953452000001562, 0.2126545930004795, 0.2321183829990332, 0.21510726800079283, 0.20304026600024372, 0.20355499099969165, 0.2215420760003326, 0.206235633999313, 0.20863176000057138, 0.2099186670002382, 0.2117964139997639, 0.21732272199915315, 0.22536643000057666, 0.2043432689988549, 0.2277179030006664, 0.22941644599995925, 0.20619257699945592, 0.21298905399999057, 0.2303802540009201, 0.24908908599900315, 0.2571242710000661, 0.21099298900116992, 0.2130287199997838, 0.20908170999973663], [0.21174653500020213, 0.20753366899953107, 0.21543925600053626, 0.2114407109984313, 0.22992253600023105, 0.21306712700061325, 0.23134572399976605, 0.21562439199988148, 0.2035977030009235, 0.20288642899868137, 0.2215968159998738], [0.21166486799847917, 0.2076438310014055, 0.2155670159991132, 0.2114672009993228, 0.22978348700053175, 0.21275434400013182, 0.23170404499978758, 0.2155554740002117, 0.20302880900089804, 0.20339953499933472, 0.2212968700005149], [0.21116551299928688, 0.2087184329993761, 0.21517294099976425, 0.2106503340000927, 0.22982524600047327, 0.21268207200046163, 0.23169778199917346, 0.21554334299980837], [0.21509454599981837, 0.21094324000114284, 0.22929354599909857, 0.2124646259999281, 0.23206675500114216], [0.21545038600015687, 0.21144239800014475, 0.2298016730001109, 0.2127654010000697, 0.231700328999068, 0.2155478860004223, 0.20345558000008168, 0.20308037600079842, 0.22138555499986978, 0.20649126500029524, 0.20872229499946116], [0.21558230799928424, 0.21140889799971774], [0.2116282360002515, 0.22954113900050288, 0.21248069399916858, 0.2322783960007655, 0.21511552799893252, 0.2030200210010662, 0.20356737899965083, 0.22155065600054513, 0.20622877499954484, 0.20861723699999857, 0.2098117990008177], [], [0.21150603699970816, 0.22950921499977994, 0.21266817200012156, 0.23211107200040715, 0.21510218000003078, 0.20304970700090053, 0.2035538309992262, 0.22153681499912636, 0.20623777900073037, 0.20872225200037064, 0.21022352900035912, 0.21150346899958095, 0.21717418700063718, 0.2253685419982503, 0.2052385420010978, 0.2268240199991851, 0.22942386000067927, 0.20618348700008937, 0.2128914459990483], [0.21321554599853698, 0.23171270700004243, 0.21509406299992406, 0.20306300800075405, 0.20368000700000266, 0.2214052819999779, 0.20624243500060402, 0.2101635629987868, 0.20938524000121106, 0.21111512199968274, 0.21696388899908925, 0.22536666300038632, 0.20565180599987798, 0.22656648399970436, 0.22954628899969975, 0.2059023910005635, 0.2129977839995263, 0.2303308950013161, 0.24908178199984832, 0.2571405179987778, 0.21098534400152857, 0.21292558499953884], [0.2036908050013153], [0.20359521400132508, 0.2028905829993164, 0.22159019299942884, 0.2064414950000355, 0.2078545740005211, 0.21022616600021138, 0.21151733899932879, 0.2176577059999545, 0.2253833630002191, 0.20442058600019664], [], [0.202918883998791, 0.22158352000042214, 0.20652778200019384, 0.20852882399958617, 0.209735078000449, 0.21149698599947442, 0.21744996100096614, 0.2253759519990126, 0.20481067000037, 0.22734531599962793, 0.2292875399998593, 0.20742817900099908, 0.21164556599978823, 0.23028184800023155, 0.24907930200060946, 0.25721267699918826, 0.21226315000058094, 0.21307427200008533, 0.20885785199970996, 0.21653623999918636], [0.20308771800046088, 0.22134170400022413, 0.20650814900000114, 0.20969788499860442, 0.20938153600036458, 0.21119617099975585, 0.21711944700109598, 0.225503960999049, 0.20528255399949558, 0.2267715739999403, 0.22939106600097148, 0.20688843599964457, 0.2121312350009248, 0.23025782900003833, 0.24908457699893916, 0.25728249399980996, 0.21221001900084957, 0.21269584999936342, 0.20855748900066828, 0.21716350299902842, 0.23946437599988712, 0.23256026600029145, 0.20821025500117685, 0.20866210099848104, 0.2174587720001, 0.2069161700001132, 0.21577075100140064, 0.19531297299909056, 0.20944326400058344, 0.2227056009996886, 0.21015893399999186, 0.21389443400039454, 0.21248098599971854, 0.2180454440003814, 0.22166954599924793, 0.2607747769998241, 0.2639800140004809, 0.2656539210001938], [0.22129993999988073, 0.20666707899908943, 0.2081593850016361, 0.21022828899913293, 0.2115236490008101, 0.21748524599934171, 0.22550040399983118, 0.20428978100062523, 0.22776947099919198, 0.2293986370004859, 0.20677354399958858], [0.22157202700145717, 0.2063883499995427, 0.20852124799966987, 0.21005556700038142, 0.21117900500030373, 0.2174524839992955, 0.22536917599973094, 0.2048169740010053, 0.2273463859983167, 0.22927993500161392], [0.22162367599958088, 0.20621243200002937, 0.20879763700031617, 0.21022416800042265, 0.21151075799934915, 0.21714312600124686, 0.22523797699977877, 0.2051997639991896, 0.22684497999944142, 0.22949686800166091], [0.20719275000010384, 0.20859835499868495, 0.20966738400056784], [0.20880668199970387, 0.20975669899962668, 0.21143242300058773, 0.21725593599876447], [0.20981531200050085, 0.21144028999879083, 0.21724808900034986, 0.22536535700055538, 0.2051777699998638, 0.2271451779997733, 0.22942457899989677, 0.20590238300064811, 0.21300018399961118, 0.23034885199922428, 0.24908854400018754, 0.25711807399966347, 0.21100145600030373, 0.21302885600016452, 0.2091504090003582, 0.21753461299886112, 0.2394642270010081, 0.23233275600068737, 0.2084864109983755, 0.20869450400095957, 0.21744488200056367, 0.20650764699894353, 0.21496874900003604, 0.19602626500090992, 0.20966060399950948, 0.2226109399998677, 0.21041572700050892], [], [0.20986409000033746, 0.2111188510007196, 0.2171736559994315, 0.22523554899999, 0.20523430300090695, 0.22709492899957695, 0.22941470300065703, 0.20590530699882947, 0.2130038630002673, 0.23034751900013362, 0.24908727500042005, 0.257112129998859, 0.2110082199997123], [0.21154572200066468, 0.2174935799994273, 0.22522901500087755, 0.20429251899986411, 0.22803934500007017, 0.22940699699938705, 0.20611457000086375, 0.21280284599924926, 0.2303444720000698, 0.249087733000124, 0.25710720300048706, 0.21113193999917712, 0.2128915209996194, 0.2091562880013953, 0.21753288400032034, 0.23941525599911984, 0.23233240000081423, 0.20849002499926428, 0.20867849599926558, 0.21745960699990974, 0.20649729300021136, 0.2142929820001882, 0.19669645800058788, 0.20966514499923505, 0.22260641800130543, 0.21040705399900617, 0.2135707409997849, 0.21250372000031348, 0.21834203400067054, 0.2218025789989042, 0.26078539400077716, 0.26397353999891493, 0.26451210900086153], [], [0.2068309459991724], [], [], [0.2057064979999268, 0.22630069499973615, 0.22947800899964932, 0.206066662000012, 0.21264329199948406, 0.23076513200066984, 0.24899884499973268, 0.25727043000006233, 0.21096056100032, 0.21292769600040629, 0.2090501789989503, 0.21768504200008465], [0.22682279899891, 0.22943768100049056, 0.20616798500122968, 0.21262281399867788, 0.23070995099988068, 0.24909985900012543, 0.25716134600043006, 0.21096745700015163, 0.21292555199943308, 0.2090545459996065, 0.21778642700155615, 0.23938266999903135, 0.23237959000107367, 0.20774101899951347], [0.22769583499939472, 0.22934179900039453, 0.20722469599968463], [0.22698663200026203, 0.22929425799884484, 0.2074576499999239, 0.21164548200067657, 0.23028485100076068, 0.24907618299948808, 0.2572060689999489, 0.21226300799935416], [0.2077330330012046, 0.21184255899970594, 0.2302574339992134, 0.24908273199980613, 0.25727895900126896, 0.2122285709992866, 0.212686880999172, 0.2085566630012181, 0.21716178600036073, 0.2394616399997176, 0.23256387099900167, 0.2082016090007528], [0.21165141299934476, 0.23027876600099262, 0.24908333599887555, 0.25721838800018304, 0.21225617700110888, 0.2126766299988958, 0.20924256600119406, 0.2165498819995264, 0.2393839289998141, 0.2325727730003564, 0.20826988499902654], [0.2122686889997567, 0.23025952500029234, 0.2490859179997642, 0.25728329100093106, 0.21164113799932238, 0.21317968500079587], [0.23063449899927946, 0.24908624599993345, 0.2571485850003228, 0.2109780379996664, 0.21292646100118873, 0.209080548998827], [], [0.21158363599897712], [], [0.2085517859995889, 0.2173766390005767, 0.2394451209984254, 0.23233507500117412, 0.20847719499943196, 0.20865987400065933, 0.2174513959998876, 0.20650332500008517, 0.21496336099880864, 0.1960284460001276, 0.2096627430000808, 0.22260878800079809, 0.21041349900042405, 0.21362019799926202], [0.20842097400054627, 0.2173436800003401, 0.2395111759997235, 0.23227299499922083, 0.2084663420009747, 0.2086839229996258, 0.21743832900028792, 0.20680829599950812], [0.21699071599869058, 0.2394525710005837, 0.23257556799944723, 0.208376558000964], [0.2171679570001288, 0.239466266000818, 0.23227268799928424, 0.20845862299938744, 0.20868754900038766, 0.21743367000090075, 0.2069319780002843, 0.2145424459995411], [], [0.20821973599959165, 0.2086614700001519, 0.2174286800000118, 0.2069424089986569, 0.21577570400040713, 0.194789192000826], [0.2089231589998235, 0.21754812800099899, 0.2063255350003601, 0.21587729699967895, 0.19522053499895264, 0.2096650880012021, 0.2226133860003756, 0.21019369699934032, 0.21435495500008983, 0.21134570699905453], [0.20868093900025997, 0.21747108299859974, 0.20633423600156675, 0.21492746899821213, 0.19618938600069669, 0.20966531500016572, 0.22260447600092448, 0.21024906699858548, 0.21383418500045082, 0.2123128330003965, 0.21834401999876718, 0.22173224500147626, 0.2609358549998433, 0.26397727000039595, 0.2643946849984786, 0.20936995000010938, 0.2096691650003777, 0.21456437300003017, 0.2153169209996122, 0.2232470890012337, 0.20380295899849443, 0.21569682500012277, 0.20929480999984662, 0.21571144000154163, 0.21049321399914334, 0.21306978100074048, 0.2188730919988302, 0.21156970000083675, 0.2294042069988791, 0.21200520400088863, 0.21672065900020243, 0.2149506810001185, 0.20076910799980396, 0.2100750980007433, 0.22109857899886265, 0.2223165510004037, 0.22586449799928232, 0.22869398800139606, 0.261422286999732, 0.282534639000005, 0.2346476780003286], [0.20847233399945253, 0.21752245700008643, 0.20767232100115507, 0.21332456299933256, 0.19707656799982942, 0.20944763500119734, 0.22263559099883423, 0.21071771800052375, 0.2126822070003982, 0.21312494099947799], [0.21772410300036427, 0.20630583699858107, 0.21437960100047349], [0.20673086999886436, 0.21620478099976026, 0.1947845930008043, 0.2096661640007369, 0.22260330300014175, 0.21025332899989735, 0.21424831799959065, 0.21190404200024204], [0.2076727519997803, 0.21325869000065723], [0.21594023599936918, 0.19478616600099485, 0.20965875199908623, 0.2226125500001217, 0.21051405999969575, 0.2139148260012007, 0.21202110499871196, 0.21834009800113563, 0.22180307599955995, 0.26077999399967666, 0.26397436000115704, 0.2645753249998961, 0.20916527999906975, 0.20967602800010354, 0.21456387800026278, 0.21531580999908329, 0.2233714610010793, 0.20449634199940192, 0.21541364900076587, 0.20907752299899585, 0.21674780100147473, 0.21013348499946005, 0.21301394600050116, 0.21842284699960146, 0.21111534199917514, 0.2294009739998728, 0.21219543000006524, 0.2166932750005799, 0.21478910500081838, 0.20133362899832719, 0.21057370100061235, 0.2202312310000707, 0.22211981600048603, 0.2258688189995155, 0.2289496470002632, 0.2611240539990831, 0.28252752700063866], [0.21425352599908365, 0.1965339939997648, 0.20937066199985566, 0.2227107070011698, 0.21071556599963515, 0.21289055299894244, 0.212931854000999, 0.21814805900066858, 0.22163405399987823, 0.26065936899976805, 0.2639795409995713, 0.2656955759994162, 0.20912662000046112, 0.20915157200033718, 0.21414830200046708, 0.2152582069993514, 0.22346410600039235, 0.20344468199982657, 0.21600623300037114, 0.20904580000023998, 0.21583594899857417, 0.21029098899998644, 0.2131834110005002, 0.21873438200054807, 0.21188308499949926, 0.2306775449997076, 0.2117183610007487, 0.21590431099866692, 0.2149318410010892, 0.20028484800059232, 0.21007323999947403, 0.22149628399893118, 0.22249938500135613, 0.22577442100009648, 0.22865115799868363, 0.26111896600014006, 0.2830430480007635, 0.23513414099943475, 0.2112275649997173, 0.20832115200028056], [], [0.19628016900060175, 0.20948690899967914, 0.22261153600084072, 0.21052271500047937, 0.2134459249991778, 0.2124884029999521, 0.21818784900096944, 0.22173224599828245, 0.26093375500022375, 0.2639763290007977, 0.2643935979995149], [0.19707252599982894, 0.20939342500059865, 0.22271263099901262, 0.21015244299996994, 0.21332804500161728, 0.21305423800004064, 0.21804691399847798, 0.2216605730009178], [0.19639787900086958, 0.20941048900021997, 0.22266537900031835, 0.21071548799955053, 0.2128503849999106, 0.21295828000074835, 0.21815691699885065, 0.2216304699995817, 0.2606948980010202, 0.26393990100041265], [0.20921058199928666, 0.22256235600070795, 0.21052535200033162, 0.21353480699872307, 0.21240065100028005, 0.2183189420011331, 0.2218015109992848, 0.26077713999984553, 0.2639762899998459, 0.264579020000383, 0.2102130240000406], [0.20937271300135762, 0.22270880299947748, 0.21015119799994864, 0.21386895000068762], [], [0.22238054099943838, 0.21048916099971393, 0.21349452899994503, 0.21244211700104643, 0.2183187419996102, 0.22180143799960206, 0.26077474799967604, 0.2639773930004594, 0.2645809290006582, 0.20910066199940047, 0.20967376800035709, 0.2145621339986974, 0.21531772800153703, 0.22334825599864416, 0.2036974940001528, 0.21569642800022848, 0.2092962050010101, 0.21570478199828358, 0.21049274100005277, 0.2130773520002549, 0.21886444899973867, 0.2116202870001871, 0.22940013600054954, 0.21219375600048807, 0.21668587800013484, 0.21479707099933876, 0.20072618300036993, 0.21007418800036248, 0.22115297399977862, 0.22230598199894303, 0.22587000200110197, 0.2288328430004185], [0.22266674599995895, 0.21071289199971943, 0.21271179900031711, 0.21309957599987683, 0.2181541499994637, 0.22163319600076647, 0.2606921759997931, 0.26394186799916497, 0.2656921779998811, 0.20908540100026585, 0.20919893300015246], [0.2112858669988782, 0.21323664400006237, 0.21293163700102014, 0.21804739899926062], [], [0.21336912200058578, 0.21813894200022332, 0.22180046699941158, 0.2607749840008182, 0.26397784700020566, 0.26517709299878334, 0.2085287950012571, 0.20967653899970173, 0.21481061399936152, 0.21525733199996466, 0.22346011900117446], [0.21301490999940143, 0.21804153900120582, 0.22162816899981408, 0.26069734699922265, 0.2644901319999917, 0.26511751300131436, 0.20912102699912793, 0.20929880599942408, 0.2140178260015091, 0.21544200099924637, 0.22337142099968332, 0.20359700900007738, 0.21579419000045164, 0.20900839199930488, 0.216714400001365, 0.20956646199920215, 0.21305245999974431, 0.21871949299929838], [0.21246637200056284, 0.2179300299994793, 0.22179813200091303, 0.26077436299965484, 0.26397907300088264, 0.2656517379982688, 0.2090640030000941, 0.20927227300126106, 0.21414791499955754, 0.21525920599924575, 0.223470097000245, 0.20426014500117162, 0.21541177399922162, 0.2090771750008571], [], [0.22168328599946108, 0.2608739440001955, 0.264089905000219, 0.26440443600040453, 0.20936110000002373, 0.20966732099986984, 0.21448867300023267, 0.21533848499893793, 0.22331078800016257, 0.20469026700084214, 0.21541428700038523, 0.20907913999872108, 0.21674433699990914, 0.20977668900013668, 0.2132634160007001, 0.21852069700071297, 0.2110154229994805, 0.22941241799890122, 0.2119806860009703, 0.21668280999983835, 0.2150180309999996, 0.2013835170000675, 0.21060078899972723, 0.21988149100070586, 0.22239481699944008, 0.22575066100034746, 0.22874353299994254, 0.26134111499959545, 0.2826460300002509, 0.23467661399990902, 0.2114484049998282, 0.2097267709996231, 0.20813715800068167, 0.2195702999997593], [], [], [0.20927936699990823, 0.21407275199999276, 0.21529767399988486, 0.22330488999978115, 0.20446912499937753, 0.21541231599985622, 0.2090769670012378, 0.21675044299990986, 0.2101342759997351, 0.21301248700001452, 0.218418765000024], [0.21420610600034706, 0.21522898700095539, 0.22337386999970477, 0.2036486529996182, 0.21569575899957272, 0.20929590400010056, 0.21588863500073785, 0.2103062599999248, 0.21308055900044565], [0.2159756950004521, 0.22337449800033937, 0.2038111329984531, 0.21564910100096313, 0.20907346499916457, 0.21663406300103816], [0.21526023399928818, 0.22328556200045568, 0.20407212200007052, 0.21568684299927554, 0.20900725700084877, 0.2167157280000538, 0.20956455699888465, 0.2130557440013945, 0.21907724700031395, 0.21125914299955184], [0.20501387799959048, 0.21541742500085093, 0.20907808799893246, 0.21674107000035292, 0.20969907700055046], [0.2040039980001893, 0.21565777999967395, 0.20900691899987578], [0.20345053099845245, 0.21568070300054387, 0.20929552000052354, 0.2158950779994484, 0.21029799600000842, 0.21317357000043557, 0.21874823799953447, 0.21183228300105839, 0.22922371499953442, 0.21239664499989885, 0.21649866299958376], [0.20299368100131687, 0.2159370970002783, 0.20886725499985914, 0.21655644000020402, 0.21049292699899524, 0.21292424199964444, 0.21904279600130394, 0.21162093699967954, 0.22940275899964035, 0.2120000169998093, 0.21673071599980176, 0.21494433199950436, 0.2004370780014142, 0.21014348499920743, 0.22136819300067145, 0.222310381999705, 0.2258696940007212, 0.228691712998625, 0.261265719000221, 0.2826423820006312, 0.2348245119992498, 0.2112827050004853, 0.20851958999992348, 0.20934398999997939, 0.21967665900046995], [0.2153943489993253, 0.20876313900043897, 0.21655713399923116, 0.21049581400075112, 0.21294451199901232], [0.21613105799951882, 0.20887414000026183, 0.2164881440003228, 0.21045587600019644], [0.2153791779983294, 0.20909886300069047, 0.2166715879993717, 0.2105223250000563, 0.21265319600024668, 0.21845609500087448, 0.21205659999941417, 0.22995962200002396, 0.2117267230005382, 0.21590924699921743, 0.21493471299982048], [0.21580494700174313, 0.2090083559996856, 0.216710802000307, 0.20957168499990075, 0.21304861399949004, 0.21872519200042007, 0.21258642399880046, 0.2299684919998981, 0.2117247160003899, 0.21590625600038038, 0.21493790800013812, 0.20028501199885795, 0.2100712490009755, 0.22170256299978064, 0.22227236300022923, 0.22577680100039288, 0.22865081899908546, 0.26111879299969587, 0.2830575450007018, 0.23511938999945414, 0.21144432900109678, 0.2082664619993011], [], [0.2094851279998693, 0.21620880299997225, 0.21051818700107106, 0.21265734100052214, 0.2184519789989281, 0.21205919699968945, 0.22995281900148257, 0.2117283529987617, 0.21623044800071511, 0.21464784599993436], [0.20904766300009214, 0.2158355899991875, 0.21029417800127703, 0.21317982499931531, 0.21873943600076018, 0.21186045200010994, 0.2306885929992859, 0.21163616599915258], [], [0.2095821260008961, 0.21304926199991314, 0.21872940699904575, 0.21257594100097776, 0.22998229899894795, 0.2117222489996493, 0.21590491100141662, 0.21492674999899464, 0.20029266900019138, 0.21007267800086993, 0.22161789999881876], [0.2130142669993802, 0.21843017600076564, 0.2110925219985802, 0.2294007620002958, 0.2121053139999276], [0.21335312999872258, 0.21853792399997474, 0.21139240900083678, 0.22932957599914516, 0.21228167899971595, 0.21660325700031535, 0.21503920500072127, 0.20063787800063437, 0.2108042639993073, 0.22039183400011098, 0.22232081599941012], [0.21265147699887166, 0.21846007800013467, 0.21130508399983228, 0.23068231800061767, 0.21171275800043077, 0.21590488400033792, 0.21493874399857305, 0.2009210370015353, 0.2105718610000622, 0.22035384199989494, 0.22247070699995675], [0.21305622099862376], [0.21126196899967908, 0.22935474699988845, 0.2121931299989228, 0.2164865610011475, 0.2149419939996733, 0.200820821999514, 0.21063164100087306, 0.22049890000016603, 0.22230854499866837, 0.22587092100002337, 0.22868899200148007, 0.26140066100015247, 0.28252868199888326, 0.23480761800055916, 0.2112130139994406, 0.20961714400073106, 0.2082433180003136, 0.2195753309988504, 0.2115402819999872, 0.23229048600114766, 0.2530196609986888, 0.2794969679998758], [0.210898053001074, 0.21649865200015483, 0.2147863989994221], [0.21633751599983952, 0.21494789099961054, 0.20012188500004413, 0.21004693700160715], [0.20192095099992002, 0.21048583800074994, 0.22073551600078645, 0.2221108509984333, 0.2258675339999172, 0.22895805500047572, 0.2611196710004151, 0.2826497219994053, 0.23468850900098914, 0.2112724389990035, 0.20952727000076266], [], [0.2001158889997896, 0.2100527010006772, 0.22164084100040782, 0.22231694699985383, 0.22566790299970307, 0.22894824099967082, 0.2611380950002058, 0.2826642050004011, 0.2346546179996949, 0.21210071600035008, 0.20764922399939678, 0.20943727300073078, 0.2197205140000733, 0.21136126499914099, 0.23239605399976426, 0.2528523210003186, 0.27957898400018166, 0.20996699500028626, 0.21083707099933235, 0.20853897199958737], [0.20113137800035474, 0.2105772020004224, 0.22029473399925337, 0.22230839700023353, 0.22566800099957618, 0.2289585350008565, 0.26111912399937864, 0.2826578799995332, 0.23464116300056048, 0.21125780799957283, 0.20969798599981004], [0.2104580889990757, 0.22034541300126875], [0.21079596399977163, 0.22040183100034483, 0.2223184600006789, 0.2256657620000624, 0.22894572299992433, 0.2611371479997615, 0.28266687399991497, 0.23508860199945047, 0.21166283000093244, 0.20869870399837964], [], [0.2100746739997703, 0.2215255060000345, 0.22241449399916746, 0.22584484300023178, 0.22866846100077964, 0.26111917499838455, 0.2826676660006342, 0.2351031710004463, 0.21164332599983027, 0.2076429949993326, 0.20943229900149163, 0.21972173399990425, 0.21154872699844418, 0.2322273560002941, 0.25284955900133355, 0.28002657999968505, 0.21004715299932286, 0.21109457300008216, 0.2083690880008362], [], [0.2212848759991175, 0.22214670900029887, 0.2257814780004992, 0.2286514419993182, 0.26113685200107284, 0.2830450669989659, 0.2351093449997279, 0.21144362300037756, 0.20830499099974986, 0.20930152900109533, 0.2190719119989808], [0.22631263400035095, 0.22875957999895036, 0.26108688700151106, 0.28266114500002004, 0.23465771900009713, 0.21123910399910528, 0.20850570000038715, 0.2093370029997459, 0.21974208599931444, 0.21132065799974953, 0.23230324700125493, 0.25302298099995824, 0.2795767240004352, 0.20985969199864485], [], [0.22581520399944566, 0.2286560440006724, 0.26111829099863826, 0.28266667900061293, 0.2355081709993101, 0.21123467500001425, 0.20871793600053934, 0.20836125599998923, 0.21972217000075034, 0.21151954499873682, 0.2322227130007377, 0.25285144400004356, 0.28001191200019093, 0.21005814300042402, 0.2109878809988004], [0.2084355829993001, 0.20866423000006762, 0.21974731400041492, 0.2120225130001927, 0.2319226580002578, 0.25330599599874404, 0.2795754440012388, 0.21069715299927338, 0.21063614200102165, 0.20849304999865126, 0.22186707900073088], [0.20977372099878266, 0.2080495019999944, 0.2195228569999017, 0.2116888270011259, 0.23214747999918472, 0.2530755380012124, 0.2796366909988137, 0.20989948900023592, 0.21082913700047357, 0.20820036599980085], [0.20854978799980017, 0.20917628300048818], [0.20828630899995915, 0.20934527300050831, 0.21907627400105412, 0.21146613800010527], [0.20840127400151687, 0.20865103599862778, 0.21974676300123974, 0.21138545899884775, 0.23238520199993218, 0.2528567330009537, 0.2795791200005624, 0.20996254499914357, 0.21083090399952198, 0.20853812700079288, 0.22247014599997783], [0.20923743099956482, 0.21968157999981486, 0.21152957699996477, 0.2322296060010558, 0.25284894200012786, 0.2800347909997072, 0.21004217799963953, 0.21109755500037863, 0.20850063299985777, 0.22203627999988385, 0.20982577399990987], [0.20970451399989543, 0.21908871999949042, 0.21146908400078246, 0.23223462699934316, 0.2528498360006779], [0.20811984699867025, 0.21971686800134194, 0.21136683499935316, 0.23239202200056752, 0.252854293999917, 0.2795787659997586, 0.20996546300011687, 0.21083463200011465, 0.20853804499893158, 0.22261419800088333, 0.2097997969995049, 0.21582585100077267, 0.23351282399926276, 0.2363739579996036, 0.1957494760008558, 0.20568792999983998, 0.21805071599919756, 0.21514762100014195, 0.22573265900064143, 0.21764986400012276, 0.20360678999895754, 0.20648063400039973, 0.21908598600020923, 0.20687647799968545, 0.2091139780004596, 0.20865576799951668, 0.21069359099965368, 0.2084491870009515, 0.22570728400023654, 0.219570876999569, 0.22964042400053586, 0.20385690500006604, 0.2156258369996067, 0.20877233300052467, 0.21112047799942957, 0.20783178099918587, 0.20776392300103907, 0.21423861699986446, 0.23146416999952635, 0.25392736200046784], [0.2194835010013776, 0.21147502299936605, 0.23223165899980813, 0.2528502440000011, 0.28003969400015194, 0.21003874899906805, 0.21109798900033638, 0.20850364800026, 0.2220353150005394, 0.20985455799927877, 0.21607926100114128, 0.23319935999825248, 0.236459386000206, 0.19672713700128952, 0.2042692260001786, 0.21862906599926646, 0.214832760999343, 0.225906997000493, 0.2174507599993376, 0.20361025300007896, 0.2073410650009464, 0.21847900099965045, 0.20573685300041689, 0.20945561799999268, 0.20898483599921747, 0.21069881400035229, 0.20844150700031605, 0.22571406099996238, 0.2202319810003246, 0.2295844889995351, 0.20417036700018798, 0.2160913570005505, 0.20849840699884226, 0.21001153300130682, 0.20785415599857515, 0.2071386050010915], [0.21247911200043745, 0.23231522199967003, 0.25328460700075084, 0.2795937489991047, 0.21061601700057508, 0.21069200199963234, 0.20833012299954135, 0.22203777600043395, 0.2100041579997196, 0.2160114739999699, 0.2331388610000431, 0.2370458260011219, 0.19619987099940772, 0.20379050799965626, 0.21906031900107337, 0.21480910499849415, 0.22603881700160855, 0.21742546899986337], [0.21154913899954408, 0.2321905249991687], [], [0.21113798400074302, 0.20844129800025257, 0.22221335299946077, 0.21015756099950522, 0.2160277450002468, 0.2332500140000775, 0.23691053400034434, 0.19619698700080335, 0.20417992699913157], [], [0.21078111899987562, 0.20870967600058066, 0.2224632230008865, 0.2099953219985764, 0.2158011740011716, 0.23345244899974205, 0.2364402319999499, 0.19575990199882654, 0.20485130200177082, 0.21844972199869517], [0.21099044000038703, 0.20841782999923453, 0.22221053000066604, 0.20967847000065376, 0.21598813099990366, 0.23337738199916203, 0.2363663819996873], [0.21064334199945733, 0.2083206080005766, 0.22203877100037062, 0.20999953499995172, 0.21601909899982275, 0.23313825599871052], [0.208290210000996, 0.2220410930003709, 0.2098324929993396, 0.2161167430003843, 0.23319622300004994, 0.2364548570003535, 0.19673933800004306, 0.20408965699971304], [0.20817831699969247, 0.22242580999954953, 0.20978451900009532, 0.21583750399986457, 0.2335169580001093, 0.23636841400002595, 0.19639351600017108, 0.20437472999947204, 0.21888461399976222, 0.21498910900118062, 0.22576683799888997, 0.21762548700098705, 0.20360791699931724, 0.20648190100109787, 0.21921191799992812, 0.2055443289991672, 0.2098035910003091, 0.20898832099919673, 0.2106933150007535, 0.208322603999477, 0.22582047499963664, 0.22021542900074564, 0.22950015400056145, 0.20371235299899126, 0.2155079830008617, 0.20909170000049926, 0.2103704969995306, 0.20781336700019892, 0.20712049499888963, 0.214864227000362, 0.23192020100032096, 0.25355856500027585, 0.22533069000019168, 0.2094056139994791, 0.20805260599991016, 0.21198489199923642, 0.2138079470005323, 0.21221902800061798, 0.2077053880002495, 0.20998568499999237], [0.22221565099971485, 0.20969685199997912, 0.21584639600041555, 0.23352074700051162, 0.2363668219986721, 0.19639514200025587, 0.20419521800067741, 0.2193986189995485, 0.21480382300069323, 0.226051790999918], [0.22217148799973074, 0.20963356900028884, 0.21585577899895725], [0.2165440620010486, 0.2331022739999753, 0.23645122999914747, 0.19641421400046966, 0.20502775099885184, 0.2183075690008991, 0.21485829199991713, 0.2258940680003434, 0.2174504060003528, 0.20361170399883122, 0.20667669300019043], [0.2160057710007095, 0.2331391909992817, 0.23704870599976857, 0.1962046000007831, 0.20447771799990733, 0.21836848000020836, 0.21481594599936216, 0.22591905700028292], [], [], [0.19621152699983213, 0.2044824669992522, 0.21835986700170906, 0.21482453399949009, 0.22591300400017644, 0.2175511200002802, 0.20350976499867102, 0.20734435899976233, 0.21847673600132111, 0.20729390599990438], [0.19632508299946494, 0.203990468999109, 0.21933606600032363, 0.2148435420003807, 0.22590022300028068, 0.21745051799916837, 0.203611319000629, 0.2067738339992502, 0.21890783400158398, 0.20531796399882296, 0.20941476699954364], [0.2043752650006354, 0.2188306329990155, 0.2150008490007167, 0.22588631600046938, 0.21745205199840711, 0.2036124980004388, 0.20667368800059194, 0.21902299499924993, 0.20571005800047715, 0.2096008989992697, 0.20898718900025415, 0.21069656899999245, 0.20831854100106284, 0.22581964299934043, 0.22023557399916172, 0.22949828500168223, 0.20397245299864153, 0.2152779959997133, 0.20906198500051687, 0.2103604189996986], [0.20514961399931053, 0.2185310210006719], [], [0.20520514300005743], [], [0.21804668599907018, 0.21500177900088602, 0.22575588099971355, 0.21763031500086072, 0.2036069999994652, 0.20648181800061138, 0.21921207099876483, 0.20728575900102442, 0.20892166100020404, 0.2088392149998981, 0.2106336659999215], [0.21881527600089612, 0.21496679299889365], [0.21862822899856837, 0.2150060410003789, 0.22569516099974862, 0.21762364900132525, 0.20360938099838677, 0.20666053000059037, 0.2190355799993995, 0.20581797100021504], [], [0.22614638499908324, 0.217460021000079, 0.2036102319998463, 0.20667090000097232, 0.21902631699958874, 0.20725578100064013, 0.2089112439989549, 0.20907227499992587, 0.2111398930010182, 0.20736968900018837, 0.22570432799875562], [0.20425152399911894, 0.20714052400035143, 0.21847664499910024, 0.20525806700061366, 0.20980034400054137, 0.20899171299970476, 0.21058298100069806], [0.2030473830000119, 0.20687474700025632, 0.21922282599916798, 0.2068328580007801], [0.20648681800048507, 0.2190914900002099, 0.2060134460007248, 0.2095859040000505, 0.2089860439991753, 0.21069781400001375, 0.20843740199961758, 0.22571781400074542, 0.21960443399984797, 0.22952611800064915], [0.20699429399974179, 0.21843946900116862, 0.20573258599870314, 0.20960948200081475], [0.20724667700051214, 0.21800035599881085, 0.20727804800117156, 0.2086975040001562, 0.2090151269985654, 0.2112331960015581, 0.2068597179986682, 0.22581641299984767, 0.22031252000124368, 0.22959776099924056], [0.21862793100081035, 0.20563081799991778, 0.20959211899935326, 0.2089855060003174, 0.2106984879992524, 0.20831914100017457, 0.22581708799953049, 0.22023514600005, 0.2294983690007939, 0.20426901599967096, 0.21506926300025953, 0.20899242800078355, 0.21044620199972996, 0.20793955999943137, 0.20695576099933533, 0.21478605800075457, 0.2319636320007703, 0.2535223300001235, 0.22544009999910486, 0.20929446599984658, 0.208055188999424, 0.21197019900137093, 0.21382634499968844, 0.212200922998818, 0.20799007900131983, 0.20987774700006412, 0.21367970099890954, 0.2247555949998059, 0.21403049400032614, 0.21556107700052962, 0.21793604800041066, 0.2123987909999414, 0.20652216099915677, 0.21343552700091095, 0.21193395199952647, 0.21423512699948333, 0.2069450630006031, 0.2241693949999899, 0.21572114099944883, 0.21899619600117148, 0.20399661800001923, 0.20963593399937963, 0.2203086079989589, 0.21596357000089483, 0.21974181400037196, 0.24046753800030274, 0.2621625800002221, 0.2603375019989471, 0.203902000999733, 0.2159800500012352, 0.23155738499917788, 0.20482448199982173], [0.2180647230015893, 0.20568304999869724, 0.2096041000004334, 0.2088284340006794, 0.21069755499956955, 0.20844347799902607, 0.225712466000914, 0.2202303039994149, 0.22959264800010715, 0.20416428899989114, 0.216098556000361, 0.20849950999945577, 0.21000275400001556, 0.20784824200018193, 0.20728211700043175, 0.2145200039994961, 0.2319110410007852, 0.25355838399991626], [0.21848579000106838, 0.2052787199991144, 0.20979313000134425, 0.20900260099915613, 0.2105834350004443, 0.20802920599999197, 0.2261454830004368, 0.2204136729997117, 0.22949784799857298, 0.20427214900155377, 0.21506787099860958], [0.20706770099968708, 0.20921358700070414, 0.2086594039992633, 0.21069510400047875, 0.20844722599940724, 0.22570957400057523, 0.2193750660007936, 0.22964591599884443, 0.20403063600133464, 0.21561554399886518, 0.2087659650005662, 0.21115418999943358, 0.2078374030006671, 0.2077507539997896, 0.2142362279992085, 0.23141954000129772, 0.25397610899926804, 0.22395535100076813, 0.21137792899935448, 0.20769147099963448, 0.2119559239999944, 0.2136740269997972, 0.21262260000003153], [0.2067986269994435, 0.2090906619996531, 0.20865409699945303, 0.21069349100071122, 0.20844807399953424, 0.2257073640012095, 0.21957410299910407, 0.22964351500013436, 0.20386068799962231, 0.2156261510008335, 0.20897047299877158], [0.2088135459998739, 0.2090502179999021, 0.21114972900068096, 0.20736163199944713, 0.22583045499959553, 0.21984093300125096, 0.22949857099956716], [0.20876020499963488, 0.20901993299958121, 0.21115775300131645], [0.20939041999918118, 0.20866658799968718, 0.2106956630013883, 0.2084460999994917, 0.22571037499983504, 0.22022963299968978, 0.2295951079995575, 0.2041621660009696, 0.21610094099924027, 0.20884509900133708, 0.2096547789988108, 0.2078427760006889, 0.20773215199915285, 0.21407666500090272, 0.23192818299867213, 0.2536331160008558, 0.22535887000049115, 0.20981872599986673, 0.2078008589996898, 0.21199920599974575, 0.21359887600010552, 0.2127094509996823, 0.20783730600123818, 0.20966225799929816, 0.21339237999927718, 0.22506773399982194, 0.21376844700171205, 0.21549196499836398, 0.21795500200096285, 0.21239074900040578, 0.20670716899985564, 0.21327108799960115, 0.2119333030004782, 0.21424751199992897, 0.20691962799901376, 0.22436585899959027, 0.21736845100167557, 0.21715246099847718, 0.20431358300083957, 0.2093627899994317, 0.220260957001301, 0.2159463499992853, 0.21974741799931508, 0.24060155600091093, 0.2620128039998235, 0.26062221599931945, 0.20396563000031165, 0.21577667299970926, 0.23142784800074878], [0.20840214800045942, 0.21063338100066176, 0.2084494979990268, 0.22570529199947487, 0.21997539800031518, 0.22924809600044682, 0.20386186399991857, 0.21562794700002996, 0.20907981299933454, 0.21111799900063488, 0.20748726300007547, 0.20777356699909433, 0.21423976700134517, 0.2314670819996536, 0.2539861049990577], [], [0.210577509000359, 0.20795520699903136, 0.22621744600110105, 0.22040553799888585, 0.22949970700028643, 0.20371869200062065], [], [0.20738438499938638, 0.22560055299982196, 0.21999100699940755, 0.22923659800107998, 0.20386110999970697, 0.21562707500015676, 0.20908903400049894, 0.2111177279984986, 0.20746941500146932, 0.20778133699968748, 0.2142404579990398], [0.22582303499984846, 0.21956520799903956], [0.22580714899959275, 0.21920438400047715, 0.229636797999774, 0.20478699500017683, 0.21610233299907122, 0.20884597300027963, 0.21011428500059992, 0.20789986399904592, 0.20789795100063202, 0.21395674999985204], [0.23022925299846975, 0.20361484100067173], [0.21659571399868582, 0.20878915600042092, 0.2091061820010509, 0.2084909309996874, 0.2074174249992211, 0.21486858200114511, 0.23208749599871226, 0.2531546940008411, 0.22581726299904403, 0.2087010459999874, 0.2084658120002132, 0.2113876130006247, 0.2135989199996402, 0.21208104600009392, 0.2078812370000378], [0.2152875480005605, 0.2090632019990153, 0.21052190000045812, 0.20792951899966283, 0.206961224999759, 0.21478337300140993, 0.23188897799991537, 0.2535994199988636, 0.22529355000006035, 0.20944117100043513], [0.2150696410008095, 0.20899779399951512, 0.20916099599890003, 0.20853924699986237, 0.20745153700045194, 0.21487515500120935, 0.2320518929991522, 0.25319147200025327, 0.22570537899991905, 0.20862327900067612, 0.20808238099925802], [0.20813071799966565, 0.21035171000039554, 0.20792299999993702, 0.20696739300001354, 0.21478038799978094, 0.23191944400059583, 0.2535693989993888, 0.22532788799981063, 0.20994998199967085, 0.20773145600105636], [0.21035520199984603, 0.20790294299877132, 0.20790141800171114, 0.21394678699834913, 0.23135268800069753, 0.2539597220002179, 0.2250348670004314, 0.21011554100005014, 0.20802074399944104, 0.21164942699942912, 0.21386519800034876, 0.21249503900071431, 0.2077354169996397, 0.21097817000008945, 0.21195762699971965, 0.22549388299921702, 0.21334090200070932, 0.21550096300052246, 0.21794801000032749, 0.21239394599979278, 0.206704884998544, 0.21327211800053192, 0.211933491000309, 0.21424626500083832, 0.2069238169988239, 0.224356679000266, 0.21555039600025339], [0.21002923199921497, 0.20786314600081823, 0.20712945999912336, 0.21467718900021282, 0.23191102999953728, 0.2535393310008658, 0.22543590999885055, 0.20986421199995675, 0.20780189800098015, 0.21200170500014792, 0.21350949899897387], [0.2080444550010725, 0.2071473750002042, 0.21486752799864917, 0.23185414200088417, 0.25338645900046686, 0.22528445899843064, 0.20955806500023755, 0.2081530270006624, 0.21137626999916392, 0.2136012090013537], [0.2078256370004965, 0.20712079899931268, 0.21486618400012958, 0.23192228600055387, 0.25354801600042265, 0.22533723299966368, 0.20940482900005009, 0.20805176899921207, 0.21199459200033743, 0.2137953710007423, 0.21222879299966735, 0.20708916600051452, 0.21059581299959973, 0.21378254999945057, 0.22483219700006885, 0.2138937910003733, 0.21553390100052638, 0.21805169300023408, 0.21236497099926055, 0.2065045370000007, 0.21352245699927153, 0.21193643800143036, 0.21407206399999268, 0.20714628499990795, 0.2241660449999472, 0.21572158100025263, 0.21899654699882376, 0.20366288700097357, 0.20941861499886727], [0.20839466999859724], [0.20807587200033595], [0.20694734300013806, 0.2147945910000999, 0.23193495200030156, 0.2535489379988576, 0.22534626200103958, 0.20938724699954037, 0.2080548310004815, 0.2119762759994046, 0.213817015001041, 0.2122111489989038, 0.20772310600113997], [0.21401618900017638], [0.21468265400108066, 0.2318970319993241, 0.2535546130002331, 0.22541324899975734, 0.20987970200076234, 0.20780189499964763, 0.21171716400021978, 0.21379924499888148, 0.21282054200128186, 0.20767851899836387], [0.21508166099920345, 0.23201623299974017, 0.2532328890010831, 0.22564808299830474, 0.20820559300045716, 0.20834054900115007, 0.21173800699943968, 0.21393607999925734, 0.2120374530004483, 0.20785509699999238, 0.21097675100099877, 0.21355882499847212, 0.22495401100059098, 0.21391831499931868, 0.21560923400102183], [], [0.22503469500043138, 0.2101152679988445, 0.20801871000003302, 0.2116595640000014, 0.2138557470007072, 0.21250235499974224, 0.20773520700095105, 0.210901673999615], [0.21040492899919627, 0.20801766099975794, 0.211669273001462, 0.21384424600000784, 0.2124394639995444, 0.20777715899930627, 0.21090659299989056, 0.211958414000037, 0.22530354400078068, 0.21342115600054967], [0.20981430700157944, 0.208055251998303, 0.21137117800026317, 0.21417946300061885, 0.2121525330003351, 0.20730643299975782, 0.21069252300003427, 0.21326389599926188, 0.22523904999980005], [0.2080882569989626, 0.2119905050003581, 0.2135973219992593, 0.21207875800064357, 0.20788157000060892, 0.2108157359998586, 0.21387977199992747, 0.22462353499940946, 0.21415992800029926, 0.21544116599943663, 0.21805941599996004, 0.2123610610015021], [], [0.20769640399885247, 0.21196223700098926, 0.2136081650005508], [0.21168462800051202, 0.21382826199987903, 0.2124550469998212, 0.207775770999433, 0.21074770499944862, 0.2118128620004427, 0.22558779000064533, 0.21328229199934867, 0.2156666499995481, 0.21788224400006584, 0.21246141899973736], [0.21182795200002147, 0.21379285299917683, 0.21282390499982284, 0.20751114100130508, 0.20993761099998665, 0.21336705499925301, 0.22484523599996464, 0.21394223700008297, 0.21542907000002742, 0.2180664160005108, 0.21240465600021707, 0.2064628369989805], [0.2137782760000846, 0.21224359400002868, 0.20702370700018946], [], [0.21381325500078674, 0.2121844630000851], [0.21367231299882405, 0.21264375499958987, 0.20777615800034255, 0.21072026399997412, 0.21163658800105623, 0.22578735899878666, 0.21290841300105967, 0.2159012949996395, 0.21783569299986993, 0.21262939699954586, 0.20629169800122327], [0.2075143879992538, 0.20971757199913554, 0.2137280870010727, 0.22470460799922876, 0.2141301610008668, 0.2154865249995055], [0.20773505400029535, 0.21089496500098903, 0.21199961499951314, 0.22526094900058524], [], [], [0.20987480100120592, 0.21368578100009472, 0.22475219599982665, 0.2140175240001554, 0.21556397799940896, 0.21793176900064282, 0.2124032929987152, 0.20642674900045677, 0.21352530799958913, 0.21193458900052065, 0.21406960700005584], [0.209660967999298, 0.21337790600045992, 0.22479099799966207, 0.21396209199883742, 0.2155624010010797, 0.21793339000032574, 0.2124004839988629, 0.20651628999985405, 0.21344019800017122, 0.2119337460007955, 0.2141736289995606], [0.21181472799980838, 0.2259809370007133, 0.21288680900033796, 0.2159226090006996, 0.21756758899937267, 0.21278077299939469, 0.2063999670008343, 0.21294920400032424, 0.2121137739995902, 0.21465286300008302, 0.206709692000004, 0.22447625499989954], [0.2117095599987806, 0.22555407500112779, 0.21328509599879908], [0.2128859910008032], [], [0.2137520599990239, 0.21550934900005814, 0.21794140600104583, 0.2123969690001104, 0.20670121599869162, 0.21327299299991864, 0.2119337620006263, 0.21424359299999196, 0.20693020500038983, 0.22434432199952425, 0.21555664700099442, 0.21899527599998692, 0.20399629899839056], [0.21562377199916227, 0.21779611199963256, 0.21262452399969334, 0.2064047500007291, 0.21286398899974301, 0.2125929180001549, 0.21423078299994813, 0.20687300899953698, 0.22435469900119642, 0.2157788629992865, 0.21875277099934465, 0.2038974960014457, 0.20892804699906264], [0.21499890399900323, 0.21787026000129117], [0.21834679399944434, 0.21237005600050907, 0.20650475199909124, 0.21271000600063417, 0.2125813950005977, 0.21422746399912285, 0.20708950799962622], [0.21258921699882194], [0.21278556499964907], [0.20729854599994724, 0.21327887500046927, 0.2119335899988073, 0.21424018700054148, 0.2069367100011732, 0.22417562899863697, 0.21571989400035818, 0.21899629899962747, 0.2039956130010978, 0.20963989899973967, 0.22030347699910635, 0.2159576220001327, 0.21974437100107025, 0.24047304899977462], [0.21289162399989436, 0.21215035400018678, 0.2146843810005521, 0.20663614699878963, 0.22422413599997526], [0.21267699000054563, 0.21259732200087456, 0.21423151700037124, 0.2066343689984933], [0.21194438699967577, 0.21407718299997214, 0.20714480800052115, 0.2241649099996721, 0.21571871599917358, 0.21900017100051627, 0.20366252799976792, 0.20941626199964958, 0.2207593180010008, 0.21606017999874894, 0.2193051780013775], [0.21423944700109132, 0.20664069299891707, 0.2245521450004162], [], [0.2066667889994278, 0.2243295419993956, 0.2173744000010629, 0.2171424879998085], [0.22423259099923598, 0.21571849300016765, 0.21874460700018972, 0.20389973199962697, 0.2094047300015518, 0.2207626639992668, 0.21608361300059187, 0.2191871169998194, 0.2409702400000242, 0.2622149439994246, 0.26019871000062267], [0.21708956899965415, 0.20366525999997975, 0.20941365900034725, 0.22075954100000672, 0.2160707540006115, 0.21929761499995948, 0.24088592899897776, 0.2621962869998242, 0.26029350600038015, 0.20392280899977777, 0.21596632200089516, 0.23145548199863697, 0.2046186610004952, 0.20708600600119098, 0.20904272599909746, 0.2094094629992469, 0.20871367500149063, 0.21355995500016434, 0.20645512099872576, 0.21105924699986645, 0.21578156800023862, 0.2092431380006019, 0.21007688099962252, 0.2104583910004294, 0.2049899159992492, 0.2071038909998606, 0.20989686900065863, 0.20594965899908857, 0.22154158700141124, 0.2177037349993043, 0.20462972200039076, 0.2188110749993939], [0.20460281499981647, 0.2093727300016326, 0.22068760499860218, 0.2160434030010947, 0.21937183599948185, 0.24082321599962597, 0.2621770240002661, 0.26032084100006614, 0.20390962300007232, 0.2159734130000288, 0.23155285400025605, 0.20468286100003752, 0.20694389500022226, 0.20903512699987914, 0.20940752000024077, 0.2089638229990669, 0.21332319599969196, 0.20726264000040828, 0.21015958899988618, 0.21588454400080082, 0.20882171799894422, 0.21039742399989336, 0.2102509070009546, 0.20492350699896633, 0.2071286130012595, 0.21004479399925913, 0.20574717199997394, 0.22150467100073, 0.2177421870001126, 0.2046549259994208, 0.21899321300043084, 0.21581963199969323, 0.24361676800072019, 0.2679540889985219, 0.2908569240007637, 0.2256870750006783, 0.22336637399894244, 0.2205577570002788, 0.20668878799915547], [0.20375854799931403, 0.2089837429994077], [0.20923499399941647, 0.22061292299986235, 0.21605182600069384, 0.21936633099903702, 0.24081960399962554, 0.26218481000069005, 0.26031087999945157, 0.20391409600051702, 0.2159700089996477, 0.2314534690012806], [0.20937076799964416, 0.22026345499944, 0.21595230999992054, 0.21974596200016094, 0.24059198199938692, 0.2620237780010939, 0.2603464879994135, 0.204176658000506, 0.21570388399959484], [0.20893920900016383, 0.2214983960002428, 0.21603523999874596], [0.22031577099915012, 0.2159714650006208, 0.2197358190005616, 0.24046687899863173, 0.2621694290010055, 0.2603311519997078, 0.20390441699964867, 0.21597667199966963, 0.23155664800106024, 0.20482654999977967, 0.20708939799988002, 0.20881715999894368, 0.2093632810010604, 0.20899507099966286, 0.21329045099992072], [0.22016328900099325, 0.21605669199925615, 0.21964610400027595, 0.24058709900054964, 0.26199636199999077, 0.26062362199991185, 0.20397201299965673, 0.21578617799968924, 0.23150331900069432, 0.2051819139996951, 0.20660743799999182], [0.2198437949991785], [0.21964789199955703, 0.24058092199993553, 0.2620034890005627, 0.2606237620002503, 0.2039684249994025, 0.21578276599939272, 0.23149885900056688, 0.20518288499988557, 0.20661535100043693, 0.20939883599930909, 0.20943471700047667], [], [0.20396201999938057, 0.21577111599981436, 0.23143458100093994, 0.2051974269998027], [], [0.2160239469994849, 0.23146794500098622, 0.20440025799871364, 0.20722019300046668, 0.20908813300047768, 0.2093012129989802], [0.20318786700045166, 0.20672337399992102, 0.20881882100002258, 0.20936206800070067, 0.20899993300008646, 0.21339329999864276, 0.20714901100109273, 0.2111163879999367, 0.21499456299898156, 0.2092245220010227, 0.21024579599907156, 0.210356577001221, 0.20519482899908326, 0.20675957599996764, 0.20997210400128097, 0.2059812929983309, 0.22156967900082236, 0.2175220659992192, 0.2051808380001603, 0.2191193850012496, 0.21547469799952523, 0.2431893709999713, 0.267995479000092, 0.2912200600003416, 0.2253680699996039, 0.22339966999970784, 0.22064784000031068, 0.20703580299959867, 0.217194152999582], [0.20615281500067795, 0.20951822999995784, 0.20927868199942168, 0.20877944200037746, 0.21407185600037337, 0.20636107700011053, 0.21072873699995398, 0.21507023599951935], [0.20697617199948581, 0.209032101000048, 0.20940866499950062, 0.20871979700132215, 0.21356179199938197, 0.20645039500050189, 0.21105574299872387, 0.21578445800150803, 0.20924183999886736, 0.21006505799959996], [0.20709521699973266, 0.20903582200116944, 0.20940646899907733, 0.20930559999942489, 0.21438835700064374, 0.2064066470011312, 0.2106403859997954, 0.21514752199982468, 0.2090763859996514, 0.21012471100038965, 0.2104206299991347], [0.20694850200015935, 0.2090327559999423, 0.20940625199909846, 0.20872404200054007, 0.21356198899957235, 0.20645005600090371, 0.21195545499904256, 0.21488317400144297, 0.2093388449993654, 0.21025428599932638, 0.21032367299994803, 0.205155941999692, 0.20685860100093123, 0.20986885700040148, 0.20607721699889225, 0.22156814000118175, 0.21752851199926226, 0.20517666900013865, 0.21912521100057347, 0.21546198099895264, 0.2431964750012412, 0.2679946829994151, 0.2912156969996431, 0.22537253700102156, 0.22340131399869279, 0.2206527440011996, 0.20703470399894286, 0.21718529099962325, 0.2292204400000628, 0.2075469110004633, 0.20582530399951793, 0.21247983600005682, 0.22449592300108634, 0.2072001859996817, 0.20796564900047088, 0.21387401799984218, 0.23522542799946677, 0.2402369430001272, 0.23509678499976872, 0.1998743509993801, 0.22112281100089604, 0.39904441600083373, 0.033637806998740416, 0.22055634000025748, 0.22382703199946263, 0.2204847780012642, 0.22512875199936389, 0.22646418300064397, 0.218751162999979, 0.2174296499997581, 0.20846874400012894], [0.20692328400036786, 0.20892578399980266, 0.2094072399995639, 0.20897070200044254, 0.2133172989997547, 0.20726657200066256, 0.21111936799934483, 0.21492161900096107, 0.20929878400056623, 0.2102542929987976, 0.2103230490010901], [0.20881489000021247, 0.20936688700021477, 0.20897201499974472, 0.21331505899979675, 0.20726929099873814, 0.21111784000095213, 0.21492156599924783, 0.20929793000141217, 0.21024967399898742, 0.21035519699944416, 0.20511672500106215], [0.20926247100032924, 0.2091788629986695, 0.20879717100069684, 0.21405800499996985, 0.20635933199991996, 0.20955482200042752], [0.20944528600011836, 0.20848587799991947, 0.21439282299979823, 0.20640605600056006, 0.2106342200004292, 0.21515595799974108, 0.20907123799952387, 0.21009426700038603], [0.20925988500130188, 0.20898579399909067, 0.2133959920010966, 0.2071460669994849], [0.20929077099935967, 0.20843187799982843, 0.21438404800028366], [0.20854683500147075, 0.21439391700005217, 0.20612501299910946, 0.21103215500079386, 0.21502634299940837, 0.20928852100041695, 0.21016314500047883, 0.210351683999761, 0.20521112499955052, 0.20673807599996508, 0.2099862769991887], [0.21341877000122622, 0.20660227499865869, 0.21064554000076896, 0.216202756999337, 0.2083039959998132, 0.21075939100046526, 0.20920655299960345, 0.2052829020012723, 0.20732789999965462, 0.20998163399963232, 0.20605980000073032, 0.22176080899953377, 0.2175003629999992, 0.20435783500033722, 0.2193388910000067, 0.2158561619999091], [], [], [], [0.2106346279997524, 0.21516872699976375, 0.20906507700055954, 0.21010000400019635, 0.21046280799964734, 0.20519808000062767, 0.20686801199917682, 0.20986633200118376, 0.2060718979992089, 0.2215658050008642, 0.21750557599989406], [0.2107440449999558, 0.2152168510001502, 0.20905949700136262, 0.2101047469986952, 0.21045782700093696, 0.20519180900009815, 0.2068800340002781, 0.20986552399881475, 0.20606273300109024, 0.22151385199867946], [0.209798559999399, 0.21625445400059107, 0.2082452149988967, 0.21074046100147825, 0.20921577099943534, 0.2052892730007443, 0.2073230109999713, 0.20998153899927274, 0.20605599299960886, 0.22176448100071866, 0.21749805099898367], [0.21560243499880016, 0.20909907900022517, 0.21011593600087508, 0.21038865199989232, 0.20525877599902742, 0.2068971570006397, 0.20986462799919536, 0.20605316900036996, 0.2214125120008248], [0.21618563000083668, 0.20855737399870122, 0.21047904600163747, 0.20940552499996556, 0.20521039300001576, 0.20763681399876077, 0.20973450500059698, 0.20603146699977515, 0.22156054799961566, 0.21755833800125401, 0.20456432499850052, 0.21915884500049287], [0.21530785399954766, 0.20900141099991743, 0.21011089900093793, 0.21038608199887676], [0.20948998700077937, 0.21009500499894784, 0.21025234700027795, 0.20511428999998316, 0.20716880500003754, 0.20989149100023496, 0.20570257700092043, 0.2217016809991037, 0.2175523030000477, 0.20464989399988553, 0.21899506500085408, 0.21582602799935557, 0.2436100560007617, 0.2679594820001512, 0.2909308439993765, 0.22570888699920033, 0.22348416700151574, 0.22060166399933223, 0.20650864699928206, 0.21756210300009116, 0.2291858710013912, 0.20863314899906982, 0.20609378399967682, 0.21179585100071563, 0.22443417399881582, 0.20577454500016756, 0.2087764560001233, 0.21509090700055822, 0.23449158699986583, 0.2403221950007719, 0.23535058299967204, 0.19882081499963533, 0.22132026100007351, 0.3997868730002665, 0.03297362199919007, 0.22116298800028744, 0.22326873400015756, 0.22020045099998242], [0.21053597799982526, 0.20905560299979697, 0.20528953100074432, 0.2077528310001071, 0.20986846800042258, 0.20604477399865573, 0.22156007200101158, 0.21755425199989986, 0.20423743999890576, 0.2193458220008324, 0.21597992699935276, 0.24370652100151347, 0.26776581999911286, 0.29074119299912127, 0.22600483700080076, 0.2232711710003059, 0.22069517499949143, 0.20639763200051675, 0.21789466299924243, 0.22918256900084089, 0.20845327700044436, 0.20603393300007156, 0.21197635299904505, 0.22443146700061334, 0.20592129199940246, 0.20811868000055256, 0.21554233899951214, 0.23468547800075612, 0.24023714199938695], [0.21048788400003104, 0.2090481159993942, 0.20529139900099835, 0.20775150899862638, 0.20987312800025393, 0.20603778499935288, 0.22155970400126535, 0.21755752699937148, 0.20423564500015345, 0.21934585500093817], [0.21019863200126565, 0.2103510010001628, 0.2052044259999093, 0.20674745599899325, 0.20998044600128196, 0.20597922999877483, 0.22157143000003998, 0.2175142539999797, 0.2051873809996323, 0.21911290300158726], [0.21212671899957058, 0.20914245499989192, 0.20529284000076586, 0.20732601300005626, 0.2099885979987448, 0.20613156400031585, 0.22174500599976454, 0.21752197800014983, 0.20434719300101278, 0.21923667400005797], [0.21040741500110016, 0.21024779599974863, 0.20459846700032358], [0.20450261900077749], [0.2052062679995288, 0.20762894000108645, 0.20975047599858954, 0.20603395600119256, 0.221559976998833, 0.21755869899971003, 0.2045623379999597, 0.21915679700032342, 0.21584474799965392, 0.24370559100134415, 0.26776996799890185, 0.29091694000089774, 0.22582700199927785, 0.22327453500111005, 0.2206777069986856, 0.20641788500142866, 0.2178957050000463, 0.2291630219988292, 0.20846178300052998, 0.20603269899947918, 0.21197978599957423, 0.224539522001578, 0.20579516899852024, 0.2081220010004472, 0.21571859499999846, 0.23450468900045962, 0.2403149179990578, 0.23534315600045375, 0.19867677100046421, 0.2215098950000538, 0.3996913430000859, 0.03275529199891025, 0.2214776159999019, 0.22317095500147843], [0.20498525199946016, 0.20711127499998838, 0.20989078999991762, 0.20570139500159712, 0.22170617299889273, 0.21755063499949756], [0.2071386129991879, 0.21004518400150118, 0.20574811299957219, 0.2215030850002222, 0.21774137399916071, 0.20442896699933044, 0.21920527100155596, 0.21575002499957918, 0.24370253300003242, 0.26794949199938856, 0.2907564779998211], [0.20699549699929776, 0.21001242600141268, 0.20574657199904323, 0.22150430500005314, 0.21774509699935152, 0.2046527890015568, 0.21899539299920434, 0.21582206899984158, 0.24361244899955636, 0.26795746500101814, 0.29086094000012963, 0.22579575099916838, 0.22348073400098656, 0.22060513799988257, 0.20650545500029693, 0.21756537099827256, 0.2291257200013206], [0.2096467310002481, 0.20624270999906003, 0.22157306900044205, 0.2175502800000686, 0.2042420529996889, 0.21934340500047256, 0.21597690300040995, 0.24370290899969405, 0.2677574179997464, 0.29074324300017906, 0.22592080799950054], [0.20986347799953364, 0.20593915700010257], [0.20989359199847968, 0.20570664400111127, 0.22169224800018128, 0.21755927499907557, 0.20465146800052025, 0.21899538999969081, 0.21582392399977834, 0.2436114579995774, 0.26795867800137785, 0.29086492199894565], [0.20575279300101101, 0.221504522000032, 0.21755839299839863, 0.20456390000072133, 0.2192243919998873, 0.21577770200019586, 0.24370336500032863, 0.2679404030004662, 0.29076144399914483, 0.22581324100065103, 0.22327400899848726], [], [0.20618749499953992, 0.22156373500001791, 0.21755187199960346, 0.20424056900083087, 0.21934365599918237, 0.2159782870003255, 0.24370754400115402, 0.26776119499845663, 0.2907423390006443, 0.22600262400010251, 0.2232697020008345, 0.22066141199866252, 0.2063964160006435, 0.21789350399922114, 0.2292071930005477, 0.20845197800008464, 0.2060291950001556, 0.21198159199957445, 0.22443500500048685, 0.2059072699994431, 0.20811319000131334, 0.2150375029996212, 0.2352261140003975, 0.24023753899928124, 0.2353090130000055, 0.1987587240000721, 0.22153090800020436, 0.39968976999989536, 0.03232529100023385, 0.2217466490001243, 0.2233490639991942, 0.21974843700081692], [0.22161493000021437, 0.21760590499980026, 0.2046768960008194, 0.2188776129987673, 0.21582537300128024, 0.24360887900002126, 0.26795916599985503, 0.29093676899901766, 0.2257055419995595, 0.22348539199992956, 0.22059489900129847], [0.2215733180000825, 0.21754993899958208, 0.2042431840000063, 0.21934327099916118, 0.2159695210011705, 0.24368994500036933, 0.2676751740000327, 0.2907650419983838, 0.22529315000065253, 0.22385841799950867, 0.22081057500145107], [0.22154398400016362, 0.21757947799960675, 0.20467644299969834, 0.21887291600069148, 0.2158259129992075, 0.2436078560003807, 0.2679593169996224, 0.29093870500037156, 0.22570439800074382, 0.22348628899999312, 0.22063603999959014, 0.2064553979998891, 0.2175607150002179, 0.22918583499995293, 0.2086344179988373, 0.20608999300020514, 0.2118056979998073, 0.22442565800156444, 0.2057753769986448, 0.20878293799978564, 0.2150853150014882, 0.2344903630000772, 0.2403234009998414, 0.23535208599969337, 0.19882597499963595, 0.22131565699964995, 0.3997846969996317], [0.20553857400045672, 0.2189957049995428, 0.21575089700127137], [0.20462104400030512, 0.21881507000034617, 0.2158251549990382, 0.24360753300061333, 0.267961130999538], [0.20443173400053638, 0.21920593799950439, 0.21573362200069823, 0.24370437300058256, 0.2677703619992826, 0.29092786200089904, 0.2258171459998266, 0.22327334299916402, 0.22067209300075774, 0.20642574799967406], [0.21931583200057503, 0.21505116400112456, 0.24362035599915544, 0.2679965320003248, 0.2908223189988348, 0.22570048200032033], [0.21915621500011184, 0.21585126100035268, 0.24370637699939834, 0.26776714300103777, 0.29073944199990365, 0.22600576799959526, 0.2232737600006658, 0.22068479900008242, 0.20640702899981989, 0.2178978929987352, 0.22917170300024736, 0.20845591299985244, 0.20603407599992352, 0.2119788720010547, 0.22442884399970353], [0.21913080000012997, 0.2154454400006216, 0.24320746600096754, 0.26799534899873834, 0.29119984399949317, 0.22538770100072725, 0.22340260000055423, 0.22061747599946102, 0.20682654600022943, 0.21727816999919014, 0.22932066200155532], [0.2192440959988744, 0.21504041200023494, 0.24362286600080552, 0.26799576399935177, 0.2908219029995962, 0.22576355999990483, 0.22340719100066053, 0.22062455699960992, 0.20681757200145512, 0.2172811479995289, 0.22928946299907693], [0.21558552799979225, 0.24362087299959967, 0.2679958299995633, 0.29082603999995627, 0.22570129500127223, 0.22348777299885114, 0.22063244700075302, 0.20672803199886403, 0.21734005400139722, 0.22930346700013615, 0.20770758899925568], [], [0.2233830509994732, 0.22067788200001814, 0.20637039600114804, 0.21758764599871938], [0.22347400699982245, 0.22034968699881574, 0.20676482100134308, 0.21757040299962682, 0.22913298099956592, 0.20834239599935245, 0.20593590200041945], [0.20770783000079973, 0.21707031699952495, 0.22934814200016262, 0.20707788099934987, 0.20624476600096386, 0.21201610199932475, 0.22489201099961065, 0.20712206600001082, 0.2081352719997085, 0.2138137590009137, 0.23512191199915833, 0.2399367460002395, 0.23550022000017634, 0.1999508170010813, 0.2211221999987174, 0.399032082001213, 0.03365689400015981, 0.22043268099878333, 0.2239555520009162, 0.22046951799893577, 0.22500408100131608, 0.22630431499965198], [0.20638797399988107, 0.21789333700144198, 0.22919253899999603, 0.20845127399843477, 0.20603240800119238, 0.21197697000025073, 0.2244333849994291, 0.20591626900022675, 0.2081176029987546, 0.21504576800180075], [0.2070353150011215, 0.21717358299974876, 0.22923347399955674, 0.20753168599912897, 0.20582840900169685, 0.21248185899821692, 0.2244981120002194, 0.20720190100109903, 0.20796619899920188, 0.2138534059995436, 0.23511231900010898], [0.21713748999900417], [0.21734332000050927, 0.2291515699998854, 0.20732205900094414, 0.20617748400036362, 0.21208007399945927, 0.2249020119998022, 0.2064498489999096, 0.20878088800054684, 0.2136747029999242, 0.23528108699974837, 0.23993843300013395, 0.23540928599868494], [0.21766556600050535, 0.22914053100066667, 0.20751857699906395, 0.20624683999994886, 0.21201568600008613, 0.2248887290006678, 0.2061444949995348, 0.2081238669998129, 0.2148095350003132, 0.2351172790004057, 0.23993860500013398], [0.21728482700018503, 0.2292938430000504, 0.20845638500031782], [], [], [0.20583473900114768, 0.21193205099916668, 0.22454429500066908, 0.20636728600038623, 0.2084766469997703, 0.21479363099933835, 0.2344972080009029, 0.24032054700001027, 0.2353451299986773, 0.1990604020011233, 0.22119606399974145], [], [0.21223131800070405, 0.22443844299959892, 0.20719778999955452, 0.20796501100085152, 0.21387661199878494, 0.23522544899969944, 0.2402379250015656, 0.23509610899964173, 0.20004763699944306, 0.22094881299926783], [0.2117476359999273, 0.2244859099992027, 0.20637225700011186, 0.20847393999974884, 0.2147938609996345, 0.234494000000268, 0.24032202399939706, 0.23534815600032744, 0.19905715999993845, 0.2213098270003684, 0.39947984799982805], [0.2245056409992685, 0.20577805300126784, 0.20810889299900737, 0.21513536600105, 0.2351146869987133, 0.24025839800015092, 0.23516326299977663, 0.1990366210011416, 0.22152732399990782, 0.39949345599961816, 0.03243194599963317, 0.2216454990011698, 0.22338420699998096, 0.2195861079999304, 0.2264585429984436, 0.22630246200060355, 0.21899622899945825, 0.21736334500019439, 0.20744748300057836, 0.2081261799994536, 0.21999014799985162, 0.20366180100063502, 0.21121332199982135, 0.21890085599989106, 0.20657858199956536, 0.2208133980002458, 0.20747510200089891, 0.2100111449999531, 0.2348409599999286, 0.19523698500051978, 0.21617372099899512, 0.21524712500104215, 0.20449121099954937, 0.21166049000021303, 0.2203336219990888, 0.22218376000091666], [0.20549626299907686, 0.2079713860002812, 0.213888541000415, 0.23522186399895872, 0.2401401730003272, 0.23515774900079123, 0.1999143909997656, 0.22112209599981725, 0.3990307229996688, 0.03365601000041352, 0.22044084099979955, 0.2239440499997727, 0.22047725599986734, 0.2250081610000052, 0.226421625000512], [], [0.2079824729989923, 0.21518410799944832, 0.23522720900109562, 0.24023678800040216, 0.23529727899949648, 0.1987622550004744, 0.22152916899904085, 0.3996990400009963, 0.032323153000106686, 0.22174901499965927, 0.22335117900001933, 0.21963881800002127], [], [], [], [0.21428119099982723], [], [0.23510122900006536, 0.19950078900001245, 0.22119476900115842, 0.3993522919990937, 0.03338078500019037, 0.2207231350002985, 0.22385638000014296, 0.22013961399898108, 0.22543179400054214, 0.22648593499980052, 0.21876654700099607, 0.21735162799996033], [0.23534148799990362, 0.19969991800098796, 0.22112975399977586, 0.3991316360006749, 0.033224578999579535, 0.22087024400025257, 0.22351141599938273, 0.22050004099946818, 0.225228180999693, 0.22785269199994218, 0.21752371399998083, 0.2174347440013662, 0.20833523999863246, 0.2077056320013071, 0.21972151899899472, 0.20421576500120864, 0.211160001999815, 0.21812832499927026, 0.207753770000636, 0.21966846599934797, 0.20840649300043879, 0.2097076959998958, 0.23458951000066008], [0.19989564099887502, 0.22119909100001678, 0.39929940100046224, 0.03343700000004901, 0.22049624399915047, 0.22408062300019083, 0.22013121800046065, 0.2253454799993051, 0.22608217600100033, 0.21913364799911506, 0.21740293699986069], [0.1986805020005704, 0.2215112699996098, 0.39969839100012905, 0.03252185599922086], [0.22112330699928862, 0.39912802100116096, 0.03356579200044507, 0.22061437099910108, 0.22377409500040812, 0.22046163199956936, 0.22520769299990206, 0.22698840799967002], [0.22118632099954993, 0.39916305700171506, 0.03356578499915486, 0.220932869000535, 0.22345699299876287, 0.2204558570010704, 0.22532511899953533, 0.2278559469996253, 0.21752243400078441, 0.21740621099888813], [], [0.22093233799932932, 0.39913489500031574, 0.0334309600002598, 0.22071826600040367, 0.22366374299963354, 0.22049207799864234, 0.2251708760013571, 0.2270849519991316, 0.21817428299982566, 0.2173533370005316, 0.20851962999950047], [0.033447249999881024, 0.22107411499928276, 0.22336299900052836, 0.22018641099930392, 0.2257729940010904, 0.22708930800035887, 0.2181720119988313, 0.21734157600076287, 0.2079927750000934, 0.207874379999339], [0.22060637100003078, 0.2237877480001771, 0.22014720900006068, 0.2254299579999497, 0.22649098599868012, 0.2187651590011228, 0.21745301299961284, 0.20808417499938514, 0.2075691400004871, 0.2198597000005975, 0.20413729599931685], [0.22171901699948648, 0.22317717500118306, 0.21981973899892182], [0.22118908199990983, 0.22350275600001623, 0.22016864699980943, 0.22576567499891098, 0.22707645800073806, 0.21811588299897267, 0.21742074500070885, 0.20794400900012988, 0.20790628800023114, 0.21965864800040436], [0.22104255999875022, 0.22520598400114977, 0.22646772699954454, 0.21875188299964066, 0.21743691099982243, 0.2082426300003135], [0.2196250559991313, 0.22652112600007968, 0.22709233599925938, 0.2180601130003197, 0.21741253400068672, 0.2072772729989083, 0.20858790900092572, 0.219777857999361, 0.20341702600126155, 0.2112288879998232, 0.21912342099858506, 0.20636048600135837, 0.22103267599959509, 0.207239629000469, 0.21000839499902213, 0.23495080700013204, 0.1959352960002434], [0.2279810970012477, 0.21789175999947474, 0.21733148699968297, 0.20726922600078979, 0.20867103499949735, 0.2198974509992695, 0.2032075020015327, 0.21123535900005663, 0.21912651299862773, 0.20635876800042752], [0.2264748689995031, 0.2187549720001698, 0.21744588000001386, 0.20847112299998116, 0.20719148500029405, 0.21985774600034347, 0.20436711699949228, 0.21129766700141772, 0.2180869489984616, 0.20778778300154954, 0.219642276999366], [0.21752442800061544, 0.21722168099950068, 0.20856163700045727, 0.20739301700086799, 0.21992363699973794, 0.20409238899992488, 0.2113182590001088, 0.2181299730000319, 0.20780672199907713, 0.2196151900006953, 0.20811359099934634], [0.20776930899955914, 0.20813179099968693, 0.22000259900050878, 0.20360696699935943, 0.21125686100094754, 0.21891181299906748, 0.20656568800040986, 0.22083633100010047, 0.20735930900082167, 0.21001521699872683, 0.23482233800132235], [0.20770855299997493, 0.20776748200114525, 0.21998603599968192, 0.20393666999916604, 0.2110648920006497], [0.20776380300048913, 0.2080209460000333, 0.21988040500036732, 0.20367803899898718, 0.21103633399980026], [0.20867570799964597, 0.21973459199944045, 0.20319793599992408, 0.21112214800086804, 0.21916604399848438, 0.2066814810004871, 0.22076397800083214, 0.2072996509996301, 0.2101376690006873, 0.23489519499889866, 0.19596007300060592, 0.2154729559988482, 0.21547020500111103, 0.2039460929991037, 0.21199349100061227, 0.22045318100026634, 0.22235289200034458, 0.18917329699979746], [0.20789696899919363, 0.21972182500030613, 0.20380540800033486, 0.2112909169991326, 0.2184071669998957, 0.2071712960005243, 0.2202588519994606, 0.20755328300037945, 0.21033075400009693, 0.23446665200026473, 0.19643733399971097], [], [0.20771818200046255, 0.21989316899998812, 0.2037354559997766, 0.2110923370000819], [0.2077953919997526], [0.2197923700005049, 0.2035939369998232, 0.211108293999132], [0.2198651710004924, 0.20361029900050198, 0.21122173000003386, 0.21890047599845275, 0.2065785290014901, 0.22080483499848924], [0.20453641099993547, 0.21101423899926885, 0.21867901100085874, 0.20717760899970017, 0.22025965499960876, 0.20754114600094908, 0.21033392000026652, 0.23446055199929106, 0.19592713400015782, 0.21547531500073092, 0.21546752699941862, 0.20510326499970688, 0.21084079700085567, 0.22045779600011883, 0.22325435299899254, 0.1891716259997338, 0.21111173900135327, 0.21027509199848282, 0.21489846400072565, 0.21196449899980507, 0.21681278700089024, 0.23367668299943034, 0.21019102900027065, 0.21214431999942462, 0.21363157400082855, 0.21017889099857712, 0.2180483299998741, 0.22149878200070816, 0.23574222999923222, 0.20940222200079006, 0.20845684699997946, 0.2127813490005792, 0.23102329900029872, 0.21489206799924432, 0.21788074299911386, 0.22551438900154608, 0.21965215599993826, 0.20978289199956635, 0.20864162699945155, 0.21445437600050354, 0.20785742400039453, 0.22203833299863618, 0.2167363230000774, 0.2115111570001318, 0.20800650300043344, 0.22100529999988794, 0.21633207699960622, 0.2147993270009465, 0.20626292599990848, 0.22924628900000243, 0.22922272499999963, 0.2606729159997485, 0.24576706799962267, 0.21197582900094858, 0.20978105399990454, 0.21583305599961022, 0.21573306800019054, 0.21819357799904537, 0.220135351000863, 0.21671037300075113, 0.2109591909993469], [0.21116379799968854, 0.21778246499889065, 0.2081000860016502, 0.21933779399842024, 0.20873064400075236, 0.20966914299970085], [0.21128118799970252, 0.21812167600000976, 0.20780158500019752, 0.21965083800023422, 0.20818707999933395, 0.20985453399953258, 0.23428712799977802, 0.19588051000027917], [], [0.21102700700066634, 0.21862811199935095, 0.20719249099965964, 0.2202424200004316, 0.207617341000514, 0.21032890899914491], [0.21105911700033175, 0.2188786959995923, 0.20694941699912306, 0.220513676000337], [0.21800202500162413, 0.2077267889999348, 0.219755008998618, 0.2081835469998623, 0.20997967700168374, 0.23396215199863946], [0.2081356999988202], [0.22018833699985407, 0.2076004800001101, 0.2103354169994418, 0.23422841200044786, 0.1960316779986897, 0.2155532739998307, 0.2151854510011617, 0.20544342799985316, 0.21077412200065737, 0.2203885929993703, 0.22329385299963178], [], [0.22077048800019838, 0.20715114400081802, 0.21024147299976903, 0.2348023149988876, 0.19599002600079984, 0.21553201300048386, 0.21518209099849628, 0.20426309700087586, 0.21197105099963665, 0.22037556400027825], [0.22030532500139088, 0.20751089999976102, 0.210435981000046], [0.20865674000015133, 0.20998209299978043, 0.2339550569995481, 0.19529065300048387, 0.21618528199905995, 0.21518484800071747, 0.20579270300004282, 0.21049795299950347, 0.22021844499977306, 0.22426665500097442, 0.18892045999928087, 0.21090997899955255, 0.21026178900137893, 0.2148894689998997, 0.21271409399923868, 0.21642361900012475, 0.2333217830000649, 0.21020962900001905], [0.21014105599897448, 0.2348870790010551, 0.19587882999985595, 0.2155325139992783, 0.21518046200071694, 0.20426838299863448, 0.21196413000143366, 0.22043346799910069], [0.20967805399959616, 0.234282063000137, 0.19595077600024524, 0.21542129699992074, 0.21546141999897372, 0.20557826399999612, 0.21037310900101147, 0.2204618270006904, 0.22392634199968597, 0.18885080399923027, 0.21088276500086067, 0.2109516549990076, 0.21420353699977568, 0.21301231300094514, 0.21620163999978104, 0.23328607700022985, 0.2102622620004695, 0.21201625999856333, 0.21363740600099845, 0.2104382830002578, 0.21791940499861084, 0.2216318050013797, 0.23537515899988648, 0.20973102599964477, 0.2082072680004785, 0.21275832499850367, 0.2310357420010405, 0.21489829900019686, 0.21780637799929536, 0.22551488099998096, 0.21967949200006842, 0.20991974100070365, 0.20894063099876803, 0.21404624000024342, 0.20793308700012858, 0.22197469099955924, 0.21672608700100682, 0.21152323000023898, 0.20807550599965907, 0.22091036200072267, 0.21637266799916688, 0.21475413000007393, 0.2064040360000945, 0.2291307310006232, 0.22922440899856156, 0.26060463200155937, 0.24576911799886147, 0.21197489500082156, 0.2097820929993759, 0.21576610100055404], [0.21013900799880503, 0.2348227680013224, 0.19633220799914852, 0.2147480359999463, 0.2154087470007653, 0.2050465609991079], [0.23480975900019985, 0.1959928280011809, 0.2155067079984292, 0.2151908790001471, 0.20427185000153258, 0.21194493499933742, 0.22039643800053454, 0.222341171998778, 0.18909938300021167, 0.21183376599947223, 0.21021074700001918, 0.21472959099992295], [0.1962436579997302, 0.21558176100006676, 0.21527439300007245, 0.205246822000845, 0.21145355999942694, 0.2201440190001449, 0.22284450699953595, 0.18949295499987784, 0.21095795899964287, 0.21025153100163152, 0.21480319399961445, 0.21222407700042822, 0.21680224599913345, 0.23369114299930516, 0.21006210500127054, 0.21223750399985875, 0.21342998999898555, 0.2103323030005413, 0.21769389700057218, 0.22184378400015703, 0.23606379999910132, 0.20906175100026303, 0.2085748909994436, 0.21268620200135047, 0.230578519998744, 0.21522418099993956, 0.21825148700008867, 0.22550740600127028, 0.21909114099980798, 0.20999866599959205, 0.2087818950003566, 0.2138123650001944, 0.20800435499950254, 0.2217542919988773, 0.21726482700069027, 0.21163111699934234, 0.20783660000051896, 0.22121840299951145, 0.21634950500083505, 0.21478926899908402, 0.20627884300120058, 0.2291173979992891, 0.22920052200061036], [], [0.21596924500045134, 0.21527602599962847, 0.20594442000037816, 0.2102871539991611, 0.22040626899979543, 0.2239676879999024, 0.18891859000177647, 0.21090603099946748, 0.2109424009995564, 0.21421200599979784, 0.2127061840001261], [0.2147576340012165, 0.2154120189989044, 0.20407186100055696], [0.21605527000065194, 0.2151553479998256, 0.20578613499856147], [0.21540898800049035, 0.21545831900039047, 0.20479901199905726, 0.21117554699958418, 0.22041936599998735, 0.22263917600139393, 0.18967908999911742, 0.21096159599983366, 0.21025349100091262, 0.21473662899916235], [0.20576775800145697, 0.2110629049984709, 0.22038038700156903, 0.22279264600001625, 0.1896726229988417, 0.21096696499989775, 0.2102568570007861, 0.21473564599909878, 0.2122887030000129, 0.216690388000643, 0.23382351500004006, 0.2096896849998302, 0.21256621099928452, 0.21346031700159074, 0.21032918699893344, 0.217705647000912, 0.22182115399846225, 0.23587601000144787, 0.20923419899918372, 0.2085332090009615, 0.21266769599969848, 0.23064131399951293, 0.2152201930002775, 0.21787981600027706, 0.2257443290000083, 0.21928056999968248, 0.20999080399997183, 0.20877910700073699, 0.21381707199907396, 0.20776055100031954, 0.2218820460002462, 0.217382541999541, 0.21123917700060701, 0.2082203149984707, 0.22100405700075498, 0.2165778840007988, 0.2146809609985212, 0.20628660900001705, 0.22918509600094694, 0.22921628400035843, 0.26079385799857846, 0.24590493100004096, 0.21197492700048315, 0.2096684110001661], [], [0.20471535200158542, 0.21143961499910802, 0.22021668600064004, 0.2230456969991792, 0.18920834200071113, 0.21145655999862356, 0.21027846700053487, 0.21473345999947924, 0.21228165400134458, 0.2166890959997545, 0.23382979000052728, 0.20968236399858142, 0.21256363600150507, 0.21347199299998465, 0.2100719999998546, 0.21794471300017904, 0.2218135719995189, 0.2358400379998784, 0.20930017099999532, 0.20853507199899468, 0.21264818600138824, 0.23052034299871593, 0.21536700100114103, 0.21772386100019503, 0.22583748499891954, 0.219338463000895, 0.20998585399865988, 0.2087795860006736, 0.2138124480006809, 0.2077713059989037, 0.2218664890006039, 0.21739810299914097, 0.21122357200147235, 0.20822610499999428, 0.22100870199938072, 0.21658898500027135, 0.2146773429994937, 0.20628109800054517, 0.22864176999974006, 0.22975274300006276, 0.26051035199998296, 0.24612034600068, 0.21136605299943767, 0.2102440859998751, 0.2158263090004766, 0.21541551500013156, 0.21832761199948436, 0.2198940960006439, 0.21728051499849244, 0.21090628599995398], [0.21058763099972566, 0.22022365600059857, 0.22363630899963027, 0.18929054799991718, 0.2109575340000447, 0.21025000299960084, 0.21480583300035505, 0.2122222010002588, 0.21680979399934586, 0.2336823910009116, 0.21007216399993922, 0.21222837399909622, 0.21343027900002198, 0.2103288390007947, 0.21769255499930296, 0.22185497899954498, 0.23565770000095654, 0.20945469599973876, 0.20857556100054353, 0.21269302399923617, 0.23057850599980156, 0.21522077299960074, 0.21758016400053748, 0.22584386500057008, 0.21942194999974163], [0.21050225799990585, 0.22015925099913147, 0.22411733100125275, 0.18870679099927656, 0.21084732800045458, 0.21095850599886035, 0.21418053500019596, 0.2117388660008146, 0.21668956199937384, 0.23382257599951117, 0.20969352700012678, 0.21256297699983406, 0.2134573140010616, 0.21033364399954735, 0.21769931500057282, 0.22182618799888587, 0.23598777300139773, 0.20968441999866627, 0.2082447630000388, 0.21272249499997997, 0.23103887800061784, 0.21488396300082968, 0.21790348699869355, 0.22550592799962033, 0.21958894800081907, 0.21017259099971852, 0.20877817000109644, 0.21398323299945332, 0.20792968699970515, 0.22199174600063998, 0.21671448499910184, 0.21184065099987492, 0.20777398999962315, 0.22088179000093078, 0.21637779299999238], [], [0.21188774000074773, 0.22042987500026356, 0.22236608200000774, 0.18925420199957443], [0.2104735590000928], [0.22355233900088933, 0.18949531599901093, 0.21095822300048894, 0.21025250099955883, 0.21480037100081972, 0.2122276949994557, 0.21669089299939515], [0.2228184550003789, 0.18917534399952274], [], [0.18870923899885383, 0.21083026800079097, 0.21097638199898938, 0.2141800260014861, 0.2132703829993261, 0.2159446770001523, 0.23328730499997619, 0.21076655999968352, 0.21189171799960604, 0.21327509500042652], [0.18885345099988626, 0.21088414100086084, 0.21094913100023405, 0.21420698299880314, 0.21301656500145327, 0.21619476299929374, 0.23324183200020343, 0.21030180100024154, 0.21202225100023497, 0.21363802199994097, 0.21038846899864438], [0.18875900599960005, 0.21084690499992575, 0.2109745819998352, 0.21418106499913847, 0.2132696910011873, 0.21594426999945426, 0.23328835599932063, 0.21076070800154412, 0.21188858399909805, 0.21328237499983516, 0.2104359380009555, 0.21791401199880056, 0.2216427420007676, 0.2353857699999935, 0.20970570799909183, 0.20824259000073653, 0.21271820400033903, 0.23103713099953893, 0.21489200699943467, 0.2178257890009263, 0.22551389199907135, 0.21965944200019294, 0.21006121200116468, 0.2088485029998992, 0.21400958899903344, 0.20793378800044593, 0.22198148600000422, 0.21672004299944092, 0.2118263920001482, 0.20778170000085083, 0.22089426099955745, 0.21637645599912503, 0.2147534010000527], [0.18871305599896004], [0.18920685000011872, 0.21146206299999903, 0.21027992400013318, 0.2147342389998812, 0.21217602499928034], [0.1891776350003056, 0.21168494099947566, 0.2102777479994984, 0.21473696100110828, 0.21216955999989295, 0.21680641399871092, 0.23383549500067602, 0.20968139300020994, 0.21208723800009466, 0.21392944999934116, 0.21008201199947507, 0.2178891690000455], [], [0.21170811399861122, 0.2102780460008944, 0.2147349610004312, 0.2121558239996375, 0.2166415319989028, 0.23399865300052625, 0.20968817500033765, 0.21207467199928942, 0.21394808600052784, 0.210089053000047, 0.21789353399981337, 0.22185436799918534, 0.23602366500017524, 0.20893975500075612, 0.2082067110004573, 0.2130556060001254, 0.23059923499931756, 0.21510560900060227, 0.2182710399993084, 0.22574192399952153, 0.21910898500027542, 0.20987079500082473, 0.2086422809989017, 0.21384656300142524, 0.20806204899963632, 0.2217467709997436, 0.21753785699911532, 0.21062078600152745, 0.2088207099986903, 0.220932256001106, 0.21653284300009545, 0.21482534799906716, 0.20561476300099457, 0.22907450200000312], [0.2109825940005976, 0.21025908699994034, 0.21473500600041007, 0.21228689099916664, 0.21668981699986034, 0.23382520100130932, 0.20968604199879337, 0.21256634699966526, 0.2134650240004703, 0.2101560610008164, 0.2178825129994948, 0.22181595899928652, 0.23587752700041165, 0.20924232000106713, 0.2085322429993539, 0.21266210899921134, 0.23063221400116163, 0.2152335350001522, 0.2178730750001705, 0.22574577999876055, 0.2192842770000425, 0.2099871330010501, 0.2087793699993199, 0.21381758700044884, 0.2077625599995372, 0.2218772739997803, 0.21738788599941472, 0.21123291200092353, 0.20822190500075521, 0.22100705199954973, 0.2165828369998053, 0.21467902599943045, 0.2062846509998053, 0.22864367400143237, 0.22975382099866692, 0.2607835850012634, 0.24591346999841335, 0.21197514200139267, 0.20967053299864347, 0.21578810500068357], [0.2109177099991939, 0.21025763200123038, 0.2148923509994347, 0.21272079899972596, 0.2164105899992137, 0.23333054400063702, 0.21020428900010302, 0.21213417100079823, 0.2136379539988411, 0.21039289100008318, 0.2179369180012145], [0.21022618000097282, 0.21454392899977393, 0.21429070699923614, 0.2159489189998567, 0.23328565399970103, 0.21076743900084693, 0.21189648499967007, 0.21333758699984173, 0.2103489550008817, 0.21791292499983683, 0.2216489479997108], [0.21013650600070832, 0.2150316480001493, 0.2119734799998696, 0.21681199799968454, 0.23368013199979032, 0.21018283100056578, 0.2121508599993831, 0.21362644399960118, 0.21010851500068384], [], [0.2162117389998457, 0.23353061099987826, 0.2101981159994466, 0.21213957500003744, 0.21363466200091352, 0.21030720799899427, 0.2179365299998608], [0.21618957399914507, 0.23324532700098644, 0.21028867200038803, 0.2120347349991789, 0.21363735100021586, 0.2103918539996812, 0.2179824520007969, 0.22162335099892516, 0.23531211000045005, 0.20976860900009342], [0.21303667400025006, 0.21349382100015646, 0.21007488400027796, 0.21794592599871976, 0.2218039689996658, 0.2361726520011871, 0.20878524299951096, 0.20819595899956767, 0.21305386800122506, 0.23059991799891577, 0.215097930000411], [0.2118185099989205], [0.21172236100028385, 0.2134566149998136, 0.21043953000116744, 0.21791493599994283, 0.2216378689990961, 0.23538921600083995, 0.2097098019985424, 0.2082054100010282], [0.21225084199977573, 0.2134324819999165, 0.2103340419998858, 0.21769586200025515, 0.22183127499920374, 0.2360705950013653, 0.20906939399901603, 0.20857192299990857, 0.21268199299993285, 0.23057840900037263, 0.21518591200037918], [0.21215784000014537, 0.21341428699997778, 0.2103259790001175, 0.21769137400042382, 0.2218613439999899, 0.23570014799952332, 0.2095184080008039, 0.20846141800029727, 0.21269913499963877, 0.2305808529999922], [], [0.21111146800103597, 0.2179366279997339, 0.22149683499992534, 0.23577173500052595, 0.20936488599909353], [], [0.21775408400026208], [0.21793483399960678, 0.22157384700039984], [0.21788722800010873, 0.2218109329987783, 0.2358593090011709, 0.20926917399992817, 0.2085325539992482, 0.21265518499967584, 0.2305213610015926], [0.22168576900003245, 0.2357298009992519, 0.2094237229994178, 0.20845804500095255, 0.21270550699955493, 0.23065281699928164, 0.2153377040012856, 0.21752819399989676, 0.22574751600041054, 0.21956723799848987], [], [0.20809887199902732, 0.21266672199999448, 0.23104111300017394, 0.2148768970000674, 0.21775413900104468, 0.22551740400012932, 0.21972581799855107, 0.21017911600029038, 0.20877657600067323, 0.21397975199943176, 0.20792797499962035], [0.20853237399933278, 0.21264921500005585, 0.23051797399966745, 0.21537382600035926, 0.21766333900086465, 0.2258558819994505, 0.21929765899949416, 0.21006376200057275, 0.20878006600105437, 0.21354443699965486], [0.20826144499915245, 0.21275030600008904, 0.23103188999994018, 0.2148723130012513], [0.20850133599924447], [0.2126743799999531, 0.23051826900154992, 0.2153770759996405, 0.2177779109988478, 0.22583385800135147, 0.2192092089990183, 0.21005372400031774, 0.2087822529992991, 0.2135440110014315, 0.2080634239991923, 0.22175438799968106], [0.2130509010003152, 0.23060437599997385, 0.21512067399999069, 0.2183147010000539, 0.22574130700013484, 0.21903355100039335, 0.2099003219991573, 0.20852717799971288], [0.23058113499973842, 0.21519683800033818, 0.2182799519996479, 0.22546164900086296, 0.21916361699913978, 0.20999461000064912, 0.20878087100027187, 0.21381615700011025, 0.2078824549989804, 0.2217621390009299], [0.21860221899987664, 0.22552021800038347, 0.2195441630010464, 0.2099016769989248, 0.2086237750008877, 0.2144839039992803, 0.20782101199984027, 0.22193894100018952, 0.21663525300027686, 0.21167028099989693, 0.2078190749998612, 0.22122469900023134, 0.21629337100057455, 0.21487423699909414, 0.20626461299980292, 0.22922352400019008, 0.22917168700041657, 0.26058340899908217], [0.2175151809988165, 0.22575791900089826, 0.2194351199996163, 0.21008658000027935, 0.20862870299970382, 0.21448655700078234, 0.20748178599933453, 0.22163681299934979, 0.2172510529999272, 0.21165519000169297, 0.20782548699935433, 0.22120037700005923, 0.21634633999929065, 0.21486597300099675, 0.2062688509995496, 0.22920704299940553, 0.22917344000052253, 0.2603085959999589, 0.2461150210001506, 0.21136840200051665], [0.21855478699944797, 0.20978113599994686, 0.20861999800035846, 0.21448104800037981, 0.20785853199959092, 0.22202730599929055, 0.21651116500106582, 0.21167328099909355, 0.20805453899993154, 0.22102340099991125, 0.2162632380004652], [0.20992812299846264, 0.21408956200139073, 0.20785395299935772, 0.22204687699922943, 0.21673129000009794, 0.21151642800032278, 0.2080031349996716, 0.22099915400031023, 0.21633338700121385], [0.20878644799995527, 0.21354958600022655, 0.2080637740000384, 0.2217495590011822, 0.21753197999896656, 0.21121366800070973, 0.20823140500033333, 0.22092567199979385], [0.2089382909998676, 0.21405527500064636, 0.20793119199879584, 0.2219728740001301, 0.216729646001113, 0.21151844799896935, 0.2080728660002933, 0.2209215740003856, 0.2163681780002662, 0.21475624699996843, 0.20626265999999305, 0.22925140099869168, 0.22922333200040157, 0.26000702700002876, 0.24619219899977907, 0.2112484110002697, 0.21035452900105156, 0.21583441399889125, 0.21541715300008946, 0.2183321390002675, 0.21977637199961464], [0.2088497640015703, 0.2140152659994783, 0.2079348690003826, 0.221977182000046, 0.2167227179998008, 0.21152688799884345], [], [0.2087783879997005, 0.21398893799960206, 0.20793153200065717, 0.22198690199911653, 0.21671741800128075, 0.21183317599934526, 0.20777790899956017, 0.2208879469999374, 0.21637723500134598, 0.21480113699908543, 0.2064882819995546, 0.2289996700001211, 0.22922312999980932, 0.260626797000441, 0.24584720300117624, 0.21189016599964816, 0.2106008760001714, 0.2152325209990522, 0.21567582500028948, 0.21803620100035914, 0.22013717699883273, 0.21678238500135194, 0.21172208200005116, 0.22836227500010864, 0.23692672399920411, 0.21118676799960667], [0.2134603890008293, 0.20809050999923784, 0.22179981599947496, 0.21739280300062092, 0.21077609500025574, 0.20882229900053062, 0.22094296799878066, 0.21653592900111107, 0.21482223800012434, 0.20561262899900612, 0.2289676939999481], [0.207485254999483, 0.22163591900061874, 0.21725435000007565, 0.21164814099938667, 0.2078280019995873, 0.22120832500149845, 0.21634570899914252, 0.2147927999994863], [0.2079543809995812, 0.22174305699991237, 0.21725942000011855, 0.21164078500078176, 0.20783216500058188, 0.22121361699828412, 0.21634676100075012, 0.21479053599978215, 0.20627859399974113, 0.22914802100058296, 0.22924364900063665], [0.22145032300068124, 0.21717756499856478, 0.2116599529999803, 0.20782424800017907, 0.22119290900081978, 0.21634674699998868, 0.21487146399886115, 0.20626565500060678, 0.2292155070008448, 0.22917340399908426, 0.26031232999957865, 0.24611176400139811, 0.2119629739991069, 0.2096853849998297, 0.21578645200133906, 0.2154154229992855, 0.21850863399959053], [0.221939573999407], [0.22142034799981047, 0.21715388699885807, 0.21166450700002315, 0.20782228100142675, 0.22118742899874633], [0.22174987300059001, 0.2172756700001628, 0.21161489299993264, 0.20784824600013962, 0.22122049999961746, 0.21635497699935513, 0.21478628399927402, 0.2062780210017081, 0.22910954500002845, 0.2292043339984957, 0.26113477000035346], [0.2126049950002198, 0.20779025599949819, 0.2209020110003621, 0.2163738929993997, 0.21475335499962966, 0.20654207799998403, 0.22899869700086128, 0.22922390699932294, 0.2606244290000177, 0.24576682800034177, 0.2119742419999966, 0.20978254600049695, 0.21583664599893382, 0.21568812900113699, 0.21820008699978644, 0.22013256100035505, 0.21671771999899647, 0.21095570900070015, 0.22896895699886954, 0.23690714500116883, 0.21125784600008046, 0.22517456599962316, 0.2421420720002061, 0.2779878679993999], [0.2115076330010197, 0.20800739099831844, 0.22101414400094654, 0.21632809999937308, 0.2148012910001853, 0.20626317899950664, 0.22924003200023435, 0.22922144400035904, 0.2606539320004231, 0.2457717519992002, 0.2119755100011389, 0.20978130999901623, 0.2157663030011463, 0.21577553599854582, 0.21821175800141646, 0.22013397399859969, 0.21672495400162006, 0.21094980799898622, 0.2289677640001173, 0.2369085129994346, 0.21125294900048175, 0.2251752590000251, 0.24214862500048184, 0.2779865439988498, 0.2962260480016994, 0.20027848499921674, 0.21874629900048603, 0.22538876499856997, 0.213531581001007], [0.20882413300023472, 0.2209720720002224, 0.21653490900098404, 0.21482234699942637, 0.20553721800024505, 0.2288478499995108, 0.2301405939997494, 0.26080540499970084, 0.2461075549999805, 0.2119730000013078, 0.209675027999765, 0.21578724199935095, 0.21541525900101988], [], [0.22103467899978568, 0.2162646400010999, 0.21487455799979216, 0.2062649159997818, 0.22923173799972574, 0.22916989700024715], [0.21676812399891787, 0.21467766400019173, 0.2056167370010371, 0.22915310700045666, 0.22974497499853896], [0.20705619899854355, 0.2291267330001574, 0.22922366300008434, 0.260560164000708, 0.24578121400008968, 0.21197346699955233, 0.20977647899962903, 0.21576512700085004, 0.21556077700006426, 0.21836153199910768, 0.21965046700097446, 0.21718866099945444, 0.21104067899977963, 0.22896516600121686, 0.23690491399975144, 0.21081378199960454, 0.22507269699963217, 0.2426725709992752, 0.2779840890016203, 0.2961523029989621, 0.2003697590007505, 0.2187454639988573, 0.22541147100128, 0.21341371199923742, 0.23306008700092207, 0.23651963099837303, 0.21358274800149957, 0.23063824599921645, 0.2223819850005384, 0.21393356299995503, 0.23056040200026473, 0.20775279400004365], [0.2062151560003258], [0.2287792309998622, 0.229751500999555, 0.2611258220003947], [], [0.22898251299920958, 0.22980300299968803, 0.2610401309993904, 0.24577559499994095, 0.21197374800067337, 0.20978088499941805, 0.21576650200040604, 0.21555944200008526, 0.21836082300069393], [0.22911584000030416], [], [0.21007583800019347, 0.21514740899874596, 0.2156855800003541, 0.21875005000038072, 0.21951118200013298, 0.21671208599946112, 0.2117443090010056, 0.22835873999974865], [0.20990144899951702, 0.21578862500064133, 0.21541561400044884, 0.21850911900037318, 0.2197851239998272, 0.21719921699877887, 0.2110272950012586, 0.22896569399927102, 0.23689608600034262, 0.21081703299932997, 0.22500752999985707], [0.21511040400037018, 0.2156613639999705], [0.21609788199930335, 0.21836980100124492, 0.2196544319995155, 0.21719355399909546, 0.21103466500062495, 0.22896615600075165, 0.23690042899943364, 0.210815554999499, 0.22506811499988544, 0.24267389899978298, 0.2779832560008799, 0.2960369609991176], [0.21566429299855372, 0.2180433700013964, 0.22013667600003828, 0.21670395799992548, 0.21103512399895408, 0.22888339500059374, 0.23690590300066106, 0.21126041199931933, 0.22517328299909423, 0.2421386390014959, 0.2781136649991822, 0.29609098699984315, 0.20043612600056804, 0.21862607000002754, 0.22534730900042632, 0.213657823000176, 0.23281479599972954, 0.23672112099848164, 0.21340089800105488, 0.23070965800070553], [0.21847269000136293, 0.21977967599923431, 0.217304960000547, 0.21100028599903453, 0.22909815000093658, 0.2369315039995854, 0.21059992899972713, 0.2249164690001635, 0.24306325900033698, 0.27798258399889164, 0.29604568400100106, 0.2003325080004288, 0.2188681159987027, 0.2254213450014504, 0.2133365319987206, 0.2330053810001118, 0.23664957400069397, 0.21347102300023835, 0.23072440599935362, 0.22242566400018404, 0.21390711099957116, 0.23061951300041983, 0.2069520620007097, 0.21409126899925468], [0.22005873800117115, 0.21674575299948629, 0.2117333990008774, 0.22835866999957943, 0.2369267559988657, 0.2112457910006924, 0.22493978800048353, 0.24213375199906295, 0.2781259350012988, 0.29716689699853305, 0.1993616159998055, 0.218614969000555, 0.22539074999986042, 0.21362127999964287, 0.23279206400002295, 0.23679900700153667], [0.2197888819991931, 0.2171871970003849, 0.21089934799965704, 0.22910330500053533, 0.23739126100008434, 0.21124933300052362, 0.22493313799895986, 0.24213263599995116, 0.2781309260008129, 0.29724823200012906], [0.21952195700032462, 0.2167194700014079, 0.21173823499884747, 0.22835987500002375, 0.2369264419994579, 0.21124855500056583, 0.22493533499982732, 0.24213304499971855, 0.27812872800132027, 0.2971721409994643], [0.21673857600035262, 0.21094590999928187, 0.22896579900043434, 0.23690803600038635, 0.21081198699903325, 0.22507429100005538, 0.24267105599938077, 0.27798632900157827, 0.2961561359988991, 0.20036609599992516, 0.21874627500073984, 0.2253996420004114, 0.21342272399851936, 0.23291420399982599], [0.21220335900034115, 0.22836571500010905, 0.2369310800004314, 0.21118414599914104, 0.22502508499928808, 0.24213532400062832, 0.27812427199933154, 0.2971533920008369, 0.19937292199938383, 0.21861855700080923, 0.22539473799952248, 0.21361127400086843, 0.23279688000002352, 0.23680626599889365, 0.2133470690005197, 0.23079903399957402, 0.22246748500037938, 0.21409028299967758, 0.2302680060001876, 0.2078801919997204, 0.21324914900105796, 0.217332970998541, 0.20854662300007476, 0.21487347500078613, 0.223971953999353, 0.23441880100108392, 0.21117768799922487, 0.20718547599972226, 0.2055195620014274, 0.20591346199944383, 0.2099418739999237, 0.21428096700037713], [0.2109984720009379, 0.2288623379990895, 0.23690442600127426, 0.2112600359996577, 0.2251737120004691, 0.2421367819988518, 0.2781210499997542, 0.2966250610006682, 0.19989993099989078, 0.2186208799994347, 0.22534000300038315], [0.22842350900100428], [], [0.2110949130001245], [0.22490704799929517], [0.22517250099917874, 0.24216459799936274, 0.27798340000117605, 0.296161245998519], [], [0.21822572499877424, 0.22545343400088314, 0.21348336200026097, 0.23279092200027662, 0.23682941799961554, 0.2133058669987804, 0.23080343800029368, 0.22240925200094352, 0.21402734500043152, 0.23020572699897457, 0.20782474800034834], [0.21862878300089506, 0.22535601199888333, 0.21364299500055495, 0.2328210770010628, 0.23651680699913413], [0.21874928400029603, 0.225427880001007, 0.21340219499870727, 0.232937477001542, 0.23664446299881092, 0.21357918300054735, 0.23063360299966007, 0.22278182099944388, 0.21409490000041842, 0.2302714300003572, 0.20867521800028044], [], [0.213388483000017, 0.2329424929994275, 0.236643627000376, 0.21347471399894857], [], [0.21339868100039894, 0.23062029099855863, 0.22269312200114655, 0.2140338339995651, 0.23020372599967232, 0.20794638600091275], [0.2133408560002863, 0.23079175400016538, 0.2224820350002119, 0.21408212299866136, 0.23016077500142273], [0.21438632699937443, 0.23027371900025173, 0.20781905600051687, 0.2134441420002986, 0.21719851799934986, 0.20807032599986997, 0.21514677999948617, 0.22424906300147995, 0.23444934699909936, 0.21115950500097824, 0.20707122899875685], [0.21402367299924663, 0.23021280400098476, 0.20782241799861367, 0.21343903500019223, 0.2171912190005969, 0.2080823269989196, 0.21514860000024782, 0.22424798600150098, 0.23444478399869695, 0.21115967799960345, 0.2071433760011132], [0.20558823499959544, 0.21397109099962108, 0.2171830309998768, 0.20713480899939896, 0.21591155500027526, 0.22437258700119855, 0.23457301599955827, 0.21081248699920252, 0.20684841300135304, 0.20628577999923436, 0.20592527199914912, 0.2099452040001779, 0.21427084800052398, 0.21882017999996606, 0.20816385800026183, 0.22400029900018126, 0.2213974739988771, 0.20711078800013638, 0.21059174800029723, 0.22835900300015055, 0.2064200910008367, 0.20686279599976842, 0.20542404299885675, 0.21736746300121013, 0.22413763300028222, 0.20366959199964185, 0.21507652099899133, 0.21189548300026217, 0.21714189300109865, 0.21438114299962763, 0.20538463899902126, 0.206444036000903, 0.22206529600043723, 0.21726672099975985, 0.21419577400047274, 0.198656074999235, 0.21102228999916406, 0.21854678400086414, 0.20942432199990435, 0.22621001299921772, 0.21712453000145615, 0.22264842000004137, 0.2045597420001286, 0.23127063299943984, 0.20237781300056668, 0.20886091999818746, 0.2057794680004008, 0.2082699960010359, 0.21163953699942795, 0.22068096200018772, 0.2526447529999132], [], [0.213641115999053, 0.21721161100140307, 0.20769747199847188, 0.21540743000150542, 0.22429966299932858, 0.23454122399925836, 0.21081004700135964, 0.20716306999929657, 0.20680821499990998, 0.20596741000008478, 0.21004126600018935, 0.21408995099955064, 0.21937977600100567, 0.2079741939996893, 0.22370941499866603, 0.22052941400033887, 0.2082073230012611, 0.2099676889993134, 0.22803142500015383, 0.20719581599951198, 0.20686916799968458, 0.20580317500025558, 0.2166096809996816, 0.22387930800141476, 0.20537170999887167, 0.21345267800097645, 0.21249244099999487, 0.21659032899879094, 0.21457236600144824, 0.2063286419997894, 0.20556877399940277, 0.22230915900036052, 0.2172235969992471, 0.21478433800075436, 0.1983980570003041, 0.21045313899958273, 0.21841080299964233, 0.20972070499919937, 0.2260685020009987, 0.21842082799958007, 0.2212173600000824], [0.21254785000019183, 0.21731956499934313, 0.20855693200064707, 0.21486767799979134, 0.22397060000002966, 0.23442125499968824, 0.21169417499913834, 0.20674146700002893, 0.2056374070016318, 0.20581283699902997, 0.21051121500022418], [0.21251956700143637, 0.21728423300010036, 0.2085660659995483, 0.21486360999915632, 0.22396975599986035], [], [0.2135425589985971, 0.21717846900173754, 0.20770780599923455, 0.21540330400057428, 0.22430101499958255], [0.21333231300013722, 0.21717575200091233, 0.20809145699968212, 0.2151481649998459, 0.22424788799980888, 0.23444591800034686, 0.21115682799973, 0.20718586099974345, 0.2063906350012985, 0.20597310899938748], [0.20836185999905865], [0.20712605100015935, 0.21584824599995045, 0.22408086999894294], [0.20800029800011544], [], [0.2070974769994791, 0.2158985140013101, 0.22437936899950728, 0.2345028839990846, 0.210806027000217, 0.20681323499957216, 0.206321839001248, 0.20592316100010066, 0.20986491099938576, 0.21419668899943645, 0.21888148600010027], [0.20853227299994614, 0.2148820849997719, 0.223976233999565, 0.234416291999878, 0.21117445500021859, 0.20719516499957535, 0.20619927100051427, 0.20602143900032388, 0.21005352099928132, 0.21408437600075558, 0.21940617600012047, 0.20795690100021602, 0.22365281999918807], [0.2154137460001948, 0.22430177600108436, 0.23453944900029455, 0.21081178299937164, 0.20716891499978374, 0.20681229600086226, 0.20595917899845517, 0.21004407800137415, 0.2140883419997408, 0.21938721299920871, 0.2079680040005769, 0.2237093379990256, 0.2205235920009727, 0.20820693299901905, 0.20997068600081548, 0.22801516000072297, 0.20721298299940827, 0.20686859200031904, 0.20572642200022528, 0.21665673299867194, 0.22390572500080452, 0.20535569099956774, 0.21345655900040583, 0.21249658600027033, 0.2165853429996787, 0.21456734700041125, 0.20633377299964195, 0.20557035599995288, 0.22186082100051863, 0.21764972999881138, 0.21482399399974383, 0.19835334700110252], [0.21504741700118757], [0.22398270799931197, 0.2344174429999839, 0.2111552059996029, 0.20721758200124896, 0.2055990409990045, 0.2058958170000551, 0.20993878500121355, 0.2143895999997767, 0.2198898869992263, 0.2078303580001375, 0.2235626420006156], [], [0.2070282410004438, 0.20573981499910587, 0.20592427400151792, 0.2099452319998818, 0.21427600199967856, 0.21891894299915293, 0.2087209889996302, 0.22354503700080386, 0.2212351039997884, 0.20732854200105066, 0.21038570899872866, 0.2285241000008682, 0.20626483199885115, 0.20693182100148988, 0.2057575499984523, 0.2170826190013031, 0.22402117199999338, 0.20405127800040646, 0.21466546999909042, 0.21194079800079635, 0.21710007499859785, 0.21467584499987424, 0.20544504700046673, 0.20615297699987423, 0.22215389800112462, 0.21715139299885777, 0.214297742000781, 0.19859059199916373], [0.20675281900003029, 0.20624871800100664, 0.2060399329984648, 0.21034561500164273, 0.21381567699972948, 0.21927469999900495, 0.20798421600011352, 0.2237107710006967, 0.2206497759998456], [0.2072268020001502, 0.20593034099874785, 0.2058947610003088, 0.21042192000095383], [0.20522711900048307, 0.20589719700001297, 0.209939096999733, 0.2143846470007702, 0.21989877699888893, 0.2076228940004512, 0.22353558500071813, 0.22157261299980746, 0.2070067669992568, 0.21036746100071468], [0.20681941799921333, 0.20595035100086534, 0.21004762899974594, 0.2140866770005232, 0.21939574099997117, 0.20796278299894766, 0.2237064510009077, 0.22052939099921787, 0.20809058700069727], [0.20554592500047875, 0.20591216199863993, 0.20994478900138347, 0.21427974399921368, 0.21915667000030226, 0.20848230800038436, 0.2235388819990476, 0.22124339000038162, 0.20733409300009953, 0.21036891099902277, 0.22868864000156464, 0.20608387799984484, 0.2069332069986558, 0.20586022800125647, 0.21714257299936435, 0.22387440800048353, 0.2040580709999631], [0.20572194499982288, 0.2059180739997828, 0.20994437300032587, 0.21427913299885404, 0.21891354900071747, 0.20872425400011707, 0.22354215499944985, 0.2212340559999575, 0.20733970199944451, 0.21037287800027116, 0.22854039300000295], [0.205949862000125, 0.21030438399975537, 0.21381964499960304, 0.2192671370012249, 0.20799021099992387, 0.22371001799911028], [0.2058177409999189, 0.2105054059993563, 0.21385482299956493, 0.21982839600059378, 0.20783959199980018, 0.22367273500094598, 0.22096815899931244, 0.2077391090006131, 0.21009407499877852, 0.22847787700084154, 0.20609970099940256], [0.20545945699996082, 0.21050829800151405, 0.21376571399923705, 0.21982386099989526, 0.2079336749993672, 0.22358598400023766], [0.21018712999830313, 0.21408047000113584, 0.21941727800003719, 0.20795022299898847, 0.22365131100013969, 0.2207239279996429, 0.20789597500152013, 0.21008988199901069, 0.2284133800003474, 0.2066713139993226, 0.2070674719998351, 0.2056287940013135], [0.2104662229994574, 0.21413140299955558, 0.2194369530006952, 0.20794348299932608, 0.2236493229993357, 0.2207264960015891, 0.2078959139998915, 0.210092971999984, 0.22839266899973154, 0.20668096900044475, 0.20700954299900332], [0.2139822319986706, 0.21983838000051037, 0.20783460799975728, 0.22366683700056456, 0.22087583000029554], [0.21381308699892543, 0.21928244100126904, 0.2079796689995419, 0.22371006700086582, 0.22056000099837547, 0.20818090900138486, 0.2099642409993976, 0.22822397900017677, 0.20725127299920132, 0.20662142600122024, 0.20580376399993838, 0.21660992899887788, 0.2238733020003565, 0.20579651800107968, 0.21313843199823168, 0.2134706000015285, 0.2157090729997435, 0.21442206599931524, 0.20632554000076198, 0.2058077929996216, 0.22210976399946958, 0.21716168599959929, 0.21480461400096829, 0.1988249639998685, 0.21011898799952178, 0.21830747999956657, 0.21013847200083546, 0.22569042000031914, 0.21839336700031708, 0.2212344210001902, 0.20476629399854573, 0.23176943600083177, 0.20230459099911968, 0.20860033500139252, 0.20607506599844783, 0.20859559400014405, 0.21059392800088972, 0.22089783199953672, 0.25226876700071443, 0.21351858799971524, 0.20762006000040856, 0.20811605800008692], [0.2078395749995252, 0.22335286399902543, 0.22117464800066955, 0.20788856400031364, 0.2100949989999208, 0.22826256100051978, 0.20631433599919546, 0.2072335650009336, 0.20577387499906763, 0.21692314500069187, 0.22386268499940343, 0.20471284800078138, 0.21404337099920667, 0.21261525599948072, 0.21651081900017743, 0.21456385900091846, 0.20542439199925866, 0.20625485900018248, 0.22203130699926987, 0.21739929800060054, 0.21438394600045285, 0.19898673500028963], [0.20811092300027667, 0.2240714299987303, 0.22131672200157482, 0.20711512899833906, 0.21058594300120603, 0.22849842499999795, 0.20628413600024942, 0.2069309919988882, 0.20577036800023052, 0.21707111400064605, 0.2240307899992331, 0.2039787459998479, 0.21475273800024297, 0.21193923600003473, 0.21710006000103022, 0.21467952799866907, 0.20528996299981372, 0.20626582200020493, 0.22206496800026798], [0.22355248299936648, 0.22124831800101674, 0.20712112500041258, 0.21058364599957713, 0.22852608199900715, 0.20625993000066956, 0.2069311249997554, 0.20576277899999695, 0.21707580600013898, 0.2240261860006285, 0.2039884739988338], [0.2087195399999473, 0.21014601299975766, 0.22786678800002846, 0.20720432000052824, 0.20685999499983154, 0.20562113800042425, 0.21655987999838544, 0.2238623870016454, 0.20580802399854292, 0.21313677400030429, 0.2134798420011066], [0.207640739999988, 0.21003634000044258], [0.21009320899975137, 0.22856695799964655, 0.2060352700009389, 0.20693458999994618, 0.20607790899885003, 0.21692984100081958, 0.2238672139992559, 0.20470149500033585, 0.21405030800087843, 0.2120932969992282, 0.21691954000016267], [0.21009597900047083, 0.22823262699967017, 0.20634872700065898, 0.20713096299914469], [0.22707296699991275, 0.20783021100032784, 0.2066473449995101, 0.20582756799922208], [0.20582606400057557, 0.20687397899928328, 0.20572349200119788, 0.216661356998884, 0.22391050300029747, 0.20517301000109, 0.21362948499881895, 0.2125034330001654, 0.21657802700065076, 0.21446818999902462], [0.2066596609984117, 0.20557967000058852, 0.2165605959999084, 0.22385631399993144, 0.20581373200002417, 0.21313654100049462, 0.21357331800027168], [], [0.2056190900002548, 0.2165602229997603, 0.22386751399972127, 0.2058025499991345, 0.2131373190004524, 0.21347542200055614, 0.2157057900003565, 0.2144215759999497], [0.20571788899906096, 0.21678082600010384, 0.22391356000116502, 0.20516922699971474, 0.21352314599971578], [0.21642762400006177, 0.22375304200068058, 0.20581876899996132, 0.21313600500070606, 0.2136368429983122, 0.21551403400007985, 0.21448266500010504, 0.20624619299996994, 0.20580630100084818, 0.22211118399900442, 0.21715635800137534, 0.21480889299891714, 0.1988238760004606, 0.2101233110006433, 0.2182991329991637, 0.21015132399952563, 0.2256857400006993, 0.2183872519999568, 0.2212321940005495, 0.2049828939998406, 0.2316100070001994, 0.20225552499869082, 0.2085943590009265, 0.2061306430005061, 0.20875080699988757, 0.21043716100029997, 0.22088619299938728, 0.2525206899990735, 0.21326975600095466, 0.20830201900025713, 0.20771577599953162, 0.21093203800046467, 0.214421823999146, 0.23026496400052565, 0.20797276700068323, 0.2203083799995511, 0.23374596099893097, 0.22751565300131915], [0.21776964200034854, 0.2237084420012252, 0.20582574399850273, 0.21313453200127697, 0.2136437199987995, 0.21550994800054468, 0.21448705299917492, 0.20623883600092086, 0.2058083939991775, 0.22211018500092905, 0.2171510150001268], [0.21702347400059807, 0.2239977609988273, 0.20405562599989935, 0.21466359100122645, 0.21211013100037235, 0.21693070999936026, 0.21467448099974717, 0.20544721700025548, 0.20614920700063522, 0.2221553959989251, 0.21714550700016844, 0.2145397860003868, 0.19900540799972077], [0.21661143100027402, 0.22388605099877168, 0.20536384700062627, 0.21345468999970763, 0.21249317100046028, 0.2165886969996791, 0.2145709619999252, 0.20633035200080485, 0.20556882900018536, 0.22229476299980888, 0.2172121479998168], [0.21686261200011359, 0.2238469219992112, 0.20506453500092903, 0.2136923759990168, 0.21262331099933363, 0.2165082280007482, 0.21455847499964875, 0.20542520100025286, 0.20625864300018293, 0.2220260819995019, 0.21739372199954232, 0.21439023700077087, 0.1990288689994486], [0.21726189900073223, 0.22403641500022786, 0.20387652299905312], [0.21681452600023476, 0.22383217299829994, 0.2050715900004434, 0.21368602999973518, 0.21262528500119515, 0.21650862999922538, 0.21455688000060036, 0.20542455299982976, 0.20626053200066963, 0.22202481999920565], [0.2054879869992874, 0.21352773100079503, 0.2126267870007723, 0.21650767599930987], [0.21320411300075648, 0.21243499699994572, 0.21659204599927762, 0.214573413000835, 0.20632764199945086, 0.20556887199927587], [0.21313975300108723, 0.21267819099921326, 0.2163354430012987, 0.21457359499981976, 0.20632689499871049, 0.2058079620001081, 0.22210783599985007, 0.21717584500038356, 0.21479372199974023, 0.19882246800079884, 0.21011483700021927, 0.2183250729995052, 0.20974210699932883, 0.22607145500114711, 0.2183925970002747, 0.22125176899862709, 0.20475158200133592, 0.23177709099945787, 0.20228684699941368, 0.20862259100067604, 0.2060764369998651, 0.2085147470006632, 0.21068298799946206, 0.22088864599936642, 0.25227779200031364, 0.21350920199984103, 0.20762393400036672, 0.20806101400012267], [0.2144769330006966, 0.21209364400056074, 0.21692249799889396, 0.21469548499953817, 0.2054262279998511, 0.20614722500067728], [], [], [0.21571626699915214, 0.21442772199952742, 0.20632690000093135, 0.20580770400010806, 0.22210927400010405, 0.21716813700004423, 0.21479877999991004, 0.19882474499900127, 0.21011559600083274, 0.2183171799988486, 0.2101178750017425, 0.22570327699941117, 0.21838430400021025, 0.22125138099909236, 0.2047591310001735, 0.23177268000108597, 0.20229694899899187, 0.2086102249995747, 0.2060763120007323, 0.20852376299990283], [], [0.20641579999937676, 0.20610391199988953, 0.2220887080002285, 0.2176580790001026, 0.2140962049998052, 0.19902830200044264, 0.21045912299996417, 0.21820354299961764, 0.20947833600075683, 0.22630874499918718, 0.21880223900006968, 0.22086387400122476, 0.20501731099830067, 0.231636234000689, 0.20200929100064968, 0.20894167499864125, 0.20611244100109616, 0.20780455299973255, 0.21149812499970722, 0.2206559999995079, 0.25256517300113046, 0.21231546299895854, 0.2085599160000129, 0.20756669799993688, 0.21172494000165898, 0.21347853099905478, 0.23067258400078572, 0.20847825999953784, 0.22013695199893846, 0.23208666300160985, 0.22950488199967367, 0.22508120800011966, 0.2147313169989502, 0.20700549600041995, 0.21375144599915075, 0.2295632960012881, 0.23534390999884636, 0.2137972840009752, 0.22424910600057046, 0.22169338799903926, 0.238995428000635, 0.2134435259995371, 0.2064967490005074, 0.20844077000037942, 0.22550004799995804, 0.20907655199880537, 0.2246023139996396, 0.21035058100096649, 0.21137560799979838, 0.2159811820001778, 0.21821153400014737, 0.22142498299945146, 0.20827342600023258, 0.221368282000185, 0.2105241549998027, 0.21471331999964605, 0.2328423359995213, 0.25290495800072677, 0.24685511099960422, 0.20833783300076902, 0.20791521399951307, 0.2258194200003345, 0.22187209500043537, 0.21715560899974662, 0.2333178089993453, 0.20104451599945605, 0.2112278820004576, 0.21153730399964843, 0.21944685700145783, 0.22164313299981586, 0.23898898500010546, 0.26431078399946273, 0.2881966040004045, 0.308884494999802, 0.214494496000043, 0.2246193979990494, 0.22697964400140336, 0.22210689899839053, 0.21931366400167462, 0.20922034299837833, 0.23278333000052953, 0.22533888799989654, 0.21131522600080643, 0.20532290600021952, 0.20879714999864518, 0.21527834100015752], [0.20528527300120913, 0.2062714940002479, 0.22206496999933734, 0.21724411099967256, 0.21435499400104163, 0.19860377599979984, 0.2109425779999583, 0.21851863600022625, 0.20944795299874386, 0.22620525300044392, 0.21712384999955248, 0.22264069300035771, 0.20457396900019376, 0.23127553700032877, 0.2023709080003755, 0.20885319399894797, 0.20588068300094164, 0.2082519420000608, 0.2116522159994929, 0.22059685999920475, 0.25270169699979306, 0.21150474200112512, 0.20855306799967366, 0.20790887300063332, 0.21197147000020777, 0.2127597059989057, 0.2313961500003643, 0.20876892100022815, 0.21987082099985855, 0.23236323700075445, 0.22920881399841164, 0.22544917300001543, 0.21412362699993537], [0.2054129539992573, 0.22198542099977203, 0.217634459000692, 0.21487797200097702, 0.19835728199905134, 0.2105073149996315, 0.21836927500044112], [0.20615859499957878, 0.2221499400002358, 0.21710171199993056], [0.2057217010005843, 0.22204209299889044, 0.21764151900060824, 0.21487090099981287, 0.19836269799998263, 0.2105000139999902, 0.2183760150001035, 0.20931651200044143, 0.22632870499910496, 0.21862742099983734, 0.2211715670000558], [0.20589027899950452, 0.22207247400001506, 0.21764882000024954, 0.21419043199966836, 0.1989614550002443, 0.21043570100118814, 0.21819633299855923, 0.20948633199986944, 0.22644924000087485, 0.21865413900013664, 0.22087036799894122], [0.2221103520005272, 0.21718480500021542, 0.21478849099912622, 0.1988178940009675, 0.21011710899983882, 0.21833321600024647, 0.2097342889992433, 0.226072331000978, 0.2184000779998314, 0.2212509359997057, 0.20474532799926237, 0.23178103600002942, 0.20226775999981328, 0.20864329500000167, 0.20607687800111307, 0.2085042329999851, 0.21069121999971685, 0.22087985799953458, 0.25228797900126665, 0.21349594200000865, 0.20763115899899276, 0.20806413399986923, 0.21123223200083885, 0.21368072000041138, 0.23086715699901106, 0.2081753740003478, 0.22015141699921514, 0.23237553800026944, 0.22893408600066323, 0.22508340999957, 0.21527334500024153, 0.20712293699943984, 0.21352098700117494, 0.22939405299985083, 0.2355279409985087, 0.21340240100107621, 0.22414428499905625, 0.22175966699978744, 0.23900847000004433, 0.21335145400007605, 0.20682713800124475, 0.20866288899924257, 0.22573575299975346, 0.2084013750009035], [0.22186641699954635, 0.21760879099929298], [0.2157838629991602, 0.19837234000078752, 0.21048816700022144, 0.21838273599860258, 0.20931061600094836, 0.22633005600073375, 0.21863897499861196, 0.22117064600024605, 0.20482977200117602, 0.23178423499848577, 0.2017577730002813, 0.20894047399997362, 0.20611138400090567, 0.2078022099994996, 0.21149028500076383, 0.22067047199925582, 0.25255081599971163, 0.2123286919995735, 0.20856002800064743, 0.20809622399974614, 0.21119280899984005, 0.21348240500083193, 0.23067226599960122, 0.20846880600038276, 0.22014899799978593, 0.23219983600029082, 0.22936863100039773, 0.22507448499891325, 0.21473813000011432, 0.20708759300032398, 0.2137004579999484, 0.22954809200018644, 0.23534283799926925, 0.21380913800021517, 0.2242269739999756, 0.2217076850010926, 0.23899559199890064, 0.21342580800046562, 0.20651339699907112, 0.2084351580015209, 0.22556687599899305, 0.20899674700012838, 0.22460035199947015, 0.21035172400115698, 0.21171724499981792, 0.2156398419992911], [0.21409340299942414, 0.19903022600010445, 0.21041931900072086, 0.21823284799938847, 0.20945612099967548, 0.2263064740000118, 0.2187807160007651, 0.22090617499998189, 0.20501542300007713, 0.23164281599929382, 0.20194149700000708], [0.21437650400002894, 0.19898953300071298, 0.21053152599961322, 0.21824370400099724, 0.20944927599884977, 0.22630539100100577, 0.21864483899844345, 0.22099745600098686, 0.20475900000019465, 0.23187038600008236, 0.20190639199972793], [0.19901174799997534, 0.2104095349986892, 0.21841263500027708, 0.209467348000544, 0.2262983410000743, 0.21727118299895665, 0.22239582499969401, 0.2045788100003847, 0.23128139700020256, 0.20236565599952883], [0.19857701100045233, 0.21038409999891883, 0.21818815900041955, 0.2094921770003566], [0.19896775000052003, 0.21039573199959705, 0.21822219099885842, 0.2094637430000148, 0.22630790200128104, 0.21877519599911466], [0.1988084839995281, 0.21038183600103366, 0.21821192700008396, 0.20947132899891585, 0.2263093130004563, 0.21880598000097962, 0.22086099999978615, 0.2050159859991254, 0.23163956600001256, 0.20200051400024677, 0.20894582999972044, 0.20611357500092709, 0.20780523999928846, 0.21150198900068062, 0.22064902300007816, 0.25257179499931226, 0.21230787599961332, 0.20855666500028747, 0.20757415400112222, 0.21172355099952256, 0.21347543699994276, 0.2306688739990932, 0.20848600400131545, 0.22013201600020693, 0.23206455299987283, 0.22952986899872485, 0.22508878300141077, 0.21472284699848387, 0.20699939699989045, 0.21375736300069548, 0.2295650010000827, 0.23534284100060177, 0.2137008869995043], [0.21034449900071195, 0.21834091499840724, 0.2097269830010191, 0.2260730309990322, 0.2184082710009534, 0.22124838799936697, 0.20474092500080587, 0.2317846579990146, 0.20175711900083115, 0.20914935499968124, 0.2060842640003102, 0.2084905270003219, 0.21070341399899917, 0.2208645990012883, 0.2523027439983707, 0.21337506600139022], [0.21068951499910327, 0.21842599299998255, 0.20945909200054302, 0.22629234099986206, 0.21703548400000727, 0.22263889600071707, 0.20457711999915773, 0.23127963899969473, 0.20236615300018457, 0.20894676799980516, 0.2059570210003585, 0.20814992700070434, 0.21161321999898064, 0.2206089660012367, 0.25276693499836256, 0.21178967200103216, 0.20834929599914176, 0.20778792000055546, 0.212023522999516, 0.2128581770011806, 0.2314278630001354, 0.208517220999056, 0.2198964729996078, 0.23235074500007613, 0.2292190230000415, 0.22542156000054092, 0.2142670020002697, 0.2067563529999461, 0.21369345299899578, 0.22974783000063326], [0.21825943600015307, 0.20944338199842605, 0.2263026450000325, 0.21857880200150248], [], [0.22597640700041666], [0.22151102099996933, 0.20482694200109108, 0.23170044899961795], [0.22090391799974896, 0.20473234100063564, 0.23186685299879173, 0.20197716500115348, 0.20901909099848126, 0.20611783800086414, 0.2078049400006421, 0.21151162999922235, 0.2205102709995117], [0.2056717880004726, 0.23158282400072494], [0.2315681489999406, 0.201995313000225, 0.20894076399963524, 0.20611278300020786, 0.20780242799992266, 0.2114936870002566, 0.22066369700041832, 0.25255795100019895, 0.21232228799999575, 0.2085603199993784, 0.20756166799947096, 0.2117279209996923, 0.2134814400014875, 0.23067144099877623, 0.20847406100074295, 0.22014250400025048, 0.2320865009987756], [0.23187750299985055, 0.2019025680001505, 0.2086762799990538, 0.20644824500050163, 0.20786818099986704, 0.21139406499969482, 0.2206291560014506, 0.25274509899827535, 0.21218161000069813, 0.20851336499981699, 0.2074629470007494], [0.23164880999866, 0.2019353539999429, 0.20901741700072307, 0.2061164419992565, 0.20780514900070557, 0.2115068639996025, 0.22063654100020358, 0.2525857040000119, 0.2122205470004701, 0.20850652899935085, 0.20766628999990644], [0.2312581960013631, 0.20246485999996366, 0.20881895999991684, 0.20595728599982976, 0.2082940869986487, 0.21146060000137368, 0.22061488299914345, 0.2527619640004559, 0.21180104199993366, 0.20834516899958544, 0.20778909100044984], [0.20191742000133672, 0.2086815900001966, 0.20613106499877176, 0.20812332999958016, 0.21144923800056858, 0.220620100000815, 0.25275704199884785, 0.21180986699982896, 0.20834363600079087, 0.20790342600048461, 0.2120094589990913, 0.21273890399970696], [0.20759378599905176, 0.20863828100118553, 0.2108135799990123, 0.220649658000184, 0.2523971930004336, 0.21328154199909477, 0.2082952300006582, 0.20781289899969124, 0.2108931399998255, 0.21443211200130463, 0.23018793999835907, 0.20800775500174495, 0.22026796999853104, 0.23373929000081262, 0.22758293299921206, 0.2248845780013653, 0.21555273499870964, 0.20707985199987888, 0.21347990600042976, 0.22920104399963748], [0.2061206090002088, 0.20780725599979633, 0.2115141250014858, 0.22050670699900365, 0.2527317660005792, 0.21221187499941152, 0.20850761600013357, 0.2076715189996321, 0.21177589200124203, 0.2134705379994557, 0.23061327299910772], [0.20595611299904704, 0.20815503499943588, 0.21162017900132923, 0.22060342799886712, 0.25268782900093356, 0.211717657999543, 0.2084960920001322, 0.20779019399924437, 0.2120231770004466, 0.2128575759998057, 0.2313659720002761], [0.20594913599961728, 0.20777507300044817, 0.21148567300042487, 0.22067667699957383, 0.2525436689993512, 0.21233483700052602, 0.20856031500079553, 0.20810162300040247, 0.21118747999935295, 0.2134832270003244, 0.23067100299886079, 0.20846387600067828, 0.22018265999940922, 0.23217560699958995, 0.2293633890003548, 0.225068249999822, 0.2147442140012572, 0.20708998299960513, 0.21369981200041366, 0.2295458199987479, 0.2353436490011518, 0.21380915800000366, 0.22422081100012292, 0.2217133409994858, 0.23899707099917578, 0.2134169050004857, 0.2065197829997487, 0.20843624300141528, 0.22557154199967044, 0.20899104299860483, 0.22459986800095066, 0.21035245600069175, 0.21172421999835933, 0.21574149200023385, 0.21808030400097778, 0.22142888999951538, 0.20848104700053227, 0.22118634399885195, 0.210529571000734, 0.21470290000070236, 0.23284139099996537, 0.25291384699994524, 0.2468539729998156, 0.20839825099938025], [0.20627087599859806, 0.2078292460009834, 0.2115187719991809, 0.22050476000003982, 0.25273746700077027, 0.2121996699988813, 0.20851000000038766, 0.2076779400013038, 0.21177220699973986, 0.21346632099994167, 0.2306176490001235, 0.20849510299922258], [0.2079819230002613, 0.21121197399952507, 0.2206377729999076, 0.2525302770009148, 0.21303038400037622, 0.20808561899866618, 0.20792887800052995, 0.2113104090003617, 0.21357797099881282, 0.2305120800010627, 0.20863685199947213], [0.2078737470001215, 0.21140351199937868, 0.22062298400123836, 0.252751828998953, 0.21181829200031643, 0.208635521999895, 0.20769546300107322, 0.211950999999317, 0.21340675200008263], [0.20857861100012087, 0.21056869700078096, 0.2209043790007854, 0.25226088099952904, 0.21352678499897593, 0.2076168889998371, 0.20830953500080795, 0.21101107300091826, 0.21364261699818599, 0.23085660000106145], [0.20816947200000868, 0.21162948199889797, 0.22059964900108753, 0.2526935099995171, 0.21169973599899095, 0.20850037200034421, 0.20779285000025993, 0.21202149400050985, 0.21285521899881132, 0.23125383600017813], [0.2112480260002485, 0.22063300000081654, 0.2525363250006194, 0.21302185299828125, 0.20808885299993563, 0.20793342100114387, 0.21130539799924009, 0.213578230001076, 0.23051199499968789, 0.20864033799989556, 0.22017033799966157, 0.23196915300104592, 0.22935851499823912, 0.2250426670016168, 0.21477007700013928, 0.20752863999950932, 0.21341570500044327, 0.22952032499961206, 0.23537549399952695, 0.21366489300089597, 0.22417749399937748, 0.22173712400035583, 0.23900211999898602, 0.21338534599999548, 0.20680101000107243, 0.20866027099873463, 0.2257290940015082, 0.20839919799982454, 0.2247087849991658, 0.2103237020000961, 0.21160694299942406, 0.2157418550013972, 0.21804444699955638, 0.22156450200054678, 0.208590144999107, 0.2214037140001892, 0.21030470699952275, 0.21452638400114665, 0.2328418409997539, 0.2529839210001228, 0.2467709749998903, 0.20899805599947285, 0.20754526500059, 0.22564525899906585, 0.22161456100002397, 0.2171571840008255, 0.2333216730003187, 0.20152409599904786, 0.21179654200022924, 0.21091813599923626, 0.21913097700053186, 0.22181650099992112, 0.23870257800081163, 0.26430550899931404, 0.2881964259995584, 0.3088805930001399, 0.21449428500091017, 0.2246231560002343, 0.22697922399856907, 0.22210683200137282, 0.21931341499839618, 0.20922033900023962, 0.2327802130002965, 0.22530463200018858, 0.21132520900027885, 0.2053349790003267, 0.20879484599936404, 0.2152895119997993, 0.20622570799969253, 0.20666934300061257, 0.2119977080001263, 0.21180585000001884, 0.2208901079993666, 0.24233614500008116, 0.2207603000006202, 0.23580668000067817, 0.21438951399977668, 0.2306136819988751, 0.21805953700095415, 0.22008987799927127, 0.2168491169995832, 0.3923200930003077, 0.04954434399951424, 0.21652311100115185, 0.22597996299919032, 0.24569908100056637, 0.21790346700072405, 0.21716138199917623, 0.21656326899937994, 0.23739013200065529, 0.23034925100000692, 0.2258256410004833, 0.21278827499918407, 0.21300499599965406, 0.20796846600023855, 0.202816339000492, 0.20459474199924443, 0.21409342100014328, 0.20876763399974152, 0.2157274810015224, 0.2334125139987009], [], [0.2104369869994116, 0.2208820600008039, 0.2525180479988194, 0.213270732001547, 0.20761365399994247, 0.20830928499890433, 0.2110121590012568, 0.2136438329998782, 0.23089921399878222, 0.20811387700086925, 0.22016382800029533], [0.2206651899996359, 0.2524040389998845, 0.21327535999989777, 0.20829955299996072, 0.20781408900074894, 0.21089113000016368, 0.214377907999733], [0.21379116299976886, 0.20777226700010942, 0.20806693299891776, 0.21122960000138846, 0.2135393579992524, 0.23097224900084257, 0.2082021239984897, 0.2201398560009693, 0.2319571919997543, 0.22935855399919092, 0.22503067100115004, 0.214780628999506, 0.2075321280008211, 0.2136404599987145, 0.2293910570006119, 0.2354162230003567, 0.21350971500032756, 0.22417040599975735, 0.2217435629991087, 0.23900342600063595, 0.21337652600050205, 0.20680759899914847, 0.2086626170003001, 0.22573060899958364, 0.2084013670009881, 0.22470453799905954, 0.21032750099948316, 0.21160406099988904, 0.2157414740013337, 0.21803596599966113, 0.2215666100000817, 0.2086929559991404, 0.22228249500039965, 0.20966893799959507, 0.21429936100139457, 0.2327450949997001, 0.2531983669996407, 0.24655586200060498, 0.2090018679991772, 0.20774314899972524, 0.22544244500022614], [0.21168071800093458], [0.20809689099951356, 0.20793890500135603, 0.21130054499917605, 0.21357832300054724, 0.23051352299989958, 0.2086423439995997, 0.22015901200029475, 0.23197872699893196, 0.2293579500001215, 0.22505042600096203, 0.2147637529997155, 0.20752779500071483, 0.21341596099955495, 0.22939497500010475, 0.23542031000033603, 0.21371179999914602, 0.22420801900079823, 0.22172574199976225, 0.23899943600008555, 0.21340095499908784, 0.20678808500088053, 0.20819617199958884, 0.2255744419999246, 0.2089905689990701, 0.22459764500126767], [0.2084619270008261], [0.20804421400134743, 0.2112946599991119, 0.21336525100014114, 0.2306698989996221, 0.2084580120008468, 0.22019142899989674, 0.23217360799935705, 0.22936112200113712, 0.2250614519998635, 0.2147523519997776, 0.20708927200030303, 0.2136995279997791], [0.2077272919996176, 0.2109303950001049, 0.21364341600019543, 0.23089676699964912, 0.20811006300027657, 0.2202902469998662, 0.23376239699973667, 0.22740269799942325, 0.22508029200071178, 0.2152694659998815, 0.20713071799946192], [0.20769740300056583, 0.2119536390000576, 0.21283477100041637, 0.23131130900037533, 0.2085069119984837, 0.2199099870013015, 0.23234614600005443, 0.22922042999925907, 0.22540828899946064, 0.21428698300042015, 0.20686830200065742, 0.213709255998765, 0.23010499800147954, 0.23535326399905898, 0.21346014499977173, 0.22447571600059746, 0.22180977599964535, 0.23898422400088748, 0.21306189599999925, 0.20567982200009283], [0.21101148900015687, 0.2136423489992012, 0.2308611419994122, 0.20817521800017857, 0.2201565320010559, 0.23390364300030342, 0.22740256399993086, 0.22507898499861767, 0.21527440899990324, 0.20712622700011707, 0.21371376600109215, 0.2292053479995957, 0.235636498000531, 0.213664515000346, 0.223772426999858, 0.22180513499915833, 0.23898010099946987, 0.21333353299996816, 0.20684020000044256, 0.2088148460006778, 0.2256381320003129, 0.2085563769996952, 0.2246996849989955, 0.21038470300118206, 0.21166268500019214, 0.2159810209996067, 0.2174321599995892, 0.22157099499963806, 0.2087769900008425, 0.22221980500034988, 0.20968357599849696, 0.2144758170015848, 0.2325424179998663, 0.2532057319986052, 0.24654604100032884, 0.20907986299971526, 0.20764950800003135, 0.2255230959999608, 0.21944809399974474, 0.21906913300153974, 0.23328982800012454, 0.20209977000013168, 0.21145428499949048, 0.21086510799977987, 0.21940493900001456, 0.22153737000007823], [0.21122503799961123, 0.21354142999916803, 0.23095720099991013, 0.2082200010008819, 0.22013266199974169, 0.23196301400093944, 0.229358840999339, 0.22503645500000857, 0.2147742899996956, 0.2075312920005672, 0.21341496799868764, 0.22952836400145316, 0.23536899799910316], [0.2108894400007557, 0.21437828299895045, 0.2302608190002502, 0.2079729880006198], [0.2117671230007545, 0.21345948499947554, 0.23062697100067453, 0.2085009620004712, 0.21992009299901838, 0.2323421800010692, 0.2292207270002109, 0.22539974199935386, 0.21429805899970233, 0.2068727330006368, 0.21371143899887102], [0.23027114099932078, 0.2079744140010007, 0.22030082199853496, 0.2337527770014276, 0.2275138139993942, 0.22496866199981014, 0.21554536999974516, 0.20708308100074646, 0.21347728299951996, 0.22920164700008172, 0.23563562299932528, 0.21366979200138303, 0.2237595259994123, 0.2218141100001958, 0.23897875999864482, 0.21332490800159576, 0.20702266599982977, 0.2086897199988016, 0.22562403899974015, 0.20872405400041316, 0.22555450100117014], [0.23087319000114803, 0.20817690900003072, 0.22014667199982796, 0.23236463899957016, 0.22894743899996683, 0.22508659400045872, 0.21472405699933006, 0.207532940999954, 0.21364125400032208, 0.229392679000739, 0.2354207829994266], [0.2305182150012115, 0.20841123199897993, 0.22019764600008784, 0.23217235899937805, 0.22935936500107346, 0.22505642400028592, 0.21475883899984183, 0.20708977699905518, 0.21376488100031565, 0.2294630930009589, 0.23534364999977697], [0.22072260799905052, 0.23207663200082607, 0.2292203500001051, 0.22539283500009333, 0.21445338199919206, 0.20672838899918133, 0.21380069900078524, 0.22999878700102272, 0.23534860299878346, 0.21352290399954654, 0.22456947000137006, 0.2216656199998397, 0.23898675899908994, 0.2133745370010729, 0.206522677999601, 0.20848705599928508, 0.22537860400007048, 0.20786799500092457, 0.22595299699969473, 0.21017334699899948, 0.21091443600016646, 0.21652219200041145, 0.21831773399935628, 0.22110504800002673, 0.20815165500061994, 0.22167000599984021, 0.2101037060001545, 0.2148596799997904], [], [0.22720655700140924, 0.22510257700014336, 0.21446561699849553, 0.20672334800110548, 0.21380784000029962, 0.22999897599947872, 0.23534571200070786, 0.21352874299918767, 0.22455617199921107, 0.22167571800127917, 0.23898870700031694, 0.21335968599851185, 0.2065414900007454, 0.2084748449997278, 0.22537963300055708, 0.20812354599911487, 0.22569513300004473, 0.21017252800083952, 0.21091814799910935, 0.2165202460000728, 0.2183084759999474, 0.22110853800040786, 0.20815866799966898, 0.2216693980008131, 0.21010386499983724, 0.2152011260004656, 0.23285576099988248, 0.25279253400003654, 0.24668190599913942, 0.20856256400111306, 0.20776985999873432, 0.22608264300106384, 0.21981185899858247, 0.2190978400012682, 0.2332991299990681, 0.2009644230001868, 0.21144058299978497, 0.21109092400001828, 0.21976181399986672], [0.21480711899857852, 0.20655962400087446, 0.2140722399999504], [0.20712086699859356, 0.21352116500020202, 0.22939404800126795, 0.2355257219987834, 0.21340513299946906, 0.22415066200119327, 0.22175452500050596, 0.2390069159991981, 0.21335907399952703, 0.20682104800107481, 0.20866279099936946, 0.22573381199981668, 0.20840095799940173, 0.22470109599998978, 0.21040972500122734, 0.2118063540001458, 0.21590540599936503, 0.21757532300034654, 0.22156971799995517, 0.20870004599964886, 0.2222975629993016, 0.2096904550016916, 0.21439178999935393], [], [0.21396099199955643, 0.22956947100101388, 0.23534300699975574, 0.21369323100043403, 0.22437627799990878, 0.2216909670005407, 0.23899173599966161, 0.21345364700027858, 0.20648801599963917, 0.20844486799978768, 0.22549280099883617, 0.20908067100026528, 0.2246047720000206, 0.21035071500045888, 0.2113644969995221, 0.2159908869998617, 0.2182185310011846, 0.22141948999887973, 0.20799425299992436, 0.22156839900162595, 0.21007254699907207, 0.21522094400097558, 0.23284678799973335, 0.25279589999991003, 0.24697469499915314, 0.20833786000002874, 0.20766067300064606, 0.22607969999990019, 0.22185513399927004, 0.21715921600116417, 0.23332549899896549, 0.2008335620012076, 0.21144240499961597, 0.21153556799981743, 0.2194547250001051, 0.22163921799983655, 0.2389835399990261, 0.2643009280000115, 0.28819465300148295, 0.30882244299937156], [0.21406933300022501, 0.22970279100081825, 0.23534484999981942, 0.2135301009984687, 0.22454701900096552, 0.22168237100049737, 0.23899200499909057, 0.21346200100015267, 0.2064785260008648, 0.2084470899990265, 0.22538137800074765], [0.21341832899997826, 0.22939554500044324, 0.23541565400046238, 0.21371784299844876, 0.22421488000145473, 0.22171987899855594, 0.23899830800110067, 0.21340842899917334, 0.20652574900123, 0.2084365289993002, 0.22557351300019945, 0.2089906309993239, 0.22459895400061214, 0.21035195799959183, 0.21172728999954415, 0.21574561600027664, 0.2180663729996013, 0.22156025700132886, 0.20837719900009688, 0.2211831730000995, 0.21071870499872603, 0.21453006299998378, 0.2328412290007691, 0.2529818829989381, 0.2467701000005036, 0.20877798500077915, 0.20755261500016786, 0.22573631399973237, 0.21968580599968845, 0.21909670400054893, 0.23330500399970333, 0.20149476699953084, 0.21158010500039381, 0.211170377999224, 0.21925756700147758, 0.22178546699979051, 0.23837293399992632, 0.2645891109987133, 0.28818598100042436, 0.3084974200010038, 0.2143834849994164, 0.2251392840007611, 0.2267225839987077], [0.2137026380005409, 0.22955480000018724, 0.2353424589982751, 0.21380503800173756, 0.22423609199904604, 0.22170002699931501, 0.23899648400038132, 0.21343483199962066, 0.20650482900055067, 0.2084366239996598, 0.22550450600101613], [0.22938490400156297, 0.23536966999927245], [], [0.21366790199863317, 0.22418809000009787, 0.22173078000014357, 0.2390011429997685, 0.21339311800147698, 0.20679491099872394, 0.20865806700021494, 0.22572570800002723, 0.20839541100031056, 0.22471717699954752, 0.2102132520012674], [0.2134110580009292, 0.22415755099973467, 0.2217484949997015, 0.23900511600004393, 0.21336745799999335, 0.2068140579995088, 0.2086630880003213, 0.2257325150003453, 0.20840107199910562, 0.22470239700123784, 0.21032978799848934], [0.21365255000091565, 0.22379317099876062, 0.22176615799980937, 0.23901128000034078, 0.21334205099992687, 0.20683334200111858, 0.20881537099921843, 0.22563651200107415, 0.2084907079988625], [], [0.2076156319999427, 0.20819971799937775, 0.225572926001405, 0.2089907299996412, 0.22459753700059082, 0.21035282199954963, 0.21172909999950207, 0.21574445000078413, 0.21805928599860636, 0.2215622740004619, 0.20857314400018367, 0.22118043299997225, 0.21053152999957092, 0.21452788799979317, 0.23284200100169983, 0.2529840509996575, 0.2467700999986846, 0.20878925800025172, 0.2075443579997227, 0.22573092600032396, 0.21972735500094132, 0.21907438099879073, 0.23329531400122505, 0.20148598499872605, 0.21157691799999157, 0.21117707600024005, 0.21924854800090543, 0.22179773599964392, 0.23862450900014665, 0.26435135599967907, 0.2881899889998749, 0.3086494590006623], [0.20604024199928972, 0.20896152699970116, 0.2253768360005779, 0.2078694789997826, 0.22595681399980094, 0.21017406200007827, 0.21090945200012357, 0.21652545300094062, 0.21832766399893444, 0.22110303600129555, 0.20814202099973045, 0.22167147399886744, 0.2100995500004501, 0.21486023400029808, 0.23321318399939628, 0.2527790530002676, 0.2466944620009599, 0.20856196699969587, 0.2076871970002685], [0.2064692580006522, 0.20845280499997898, 0.22537901800023974, 0.20920582699909573, 0.2246106590009731, 0.2103488409993588, 0.21076122500016936, 0.2165184900004533, 0.2182935170003475, 0.22117907499887224], [0.20900969000103942, 0.2253773499996896, 0.20787790099893755, 0.2259678120008175, 0.21017255100014154, 0.2108217919994786], [0.20878513000025123, 0.22563652300050308, 0.20856062100028794, 0.22469861499848776, 0.2105901660015661, 0.21145535199866572, 0.21598196800005098, 0.21745354599988787, 0.22154125400084013, 0.2087802850001026, 0.22222496999893337, 0.20967666900105542], [0.20869285800108628, 0.22562288500012073, 0.2085601709986804, 0.22567125000023225, 0.20962355700066837, 0.21144914899923606, 0.21598314200127788, 0.21744836699872394, 0.22153958400122065], [0.22571834200061858, 0.2084090770003968, 0.22471298799973738, 0.21021945899883576, 0.21173038900087704, 0.21574369500012835, 0.21805191599924, 0.22156339200046204, 0.2085814299989579, 0.22139320000133011, 0.2103170059999684, 0.21452768400013156, 0.23284183699979621, 0.2529844239998056, 0.24677022799914994, 0.20879575000071782, 0.2075401790007163, 0.225728960998822, 0.219748339999569, 0.21906985800160328, 0.23328425499857985, 0.20147951200124226, 0.211573224998574, 0.21127146000071662, 0.21915392200025963, 0.2218051119998563, 0.23862335000012536, 0.2643503090002923, 0.28819278399896575, 0.3087473610012239, 0.21411357800025144, 0.22514515900002152, 0.22697750399856886, 0.22211146900008316, 0.2193191639998986, 0.20881742799974745, 0.23296546600067813, 0.22542222599986417, 0.2110384610004985, 0.20472907300063525, 0.20938219599884178, 0.21557138900061545, 0.20629057699989062, 0.20619236499987892, 0.2125390769997466, 0.21182179400057066, 0.2204570590001822, 0.24100675499903446, 0.22178813900063687, 0.23643608800011862, 0.21430479700029537, 0.23052223199920263, 0.21810183200068423, 0.21979115700014518, 0.21674027299923182, 0.39238766900052724, 0.04995851999956358, 0.21658295199995337, 0.22591386800013424, 0.24579283099956228, 0.21778583800005435, 0.21732982499997888, 0.21626832299989474, 0.23754646000088542], [0.22563366400027007, 0.20849122700019507, 0.22477505999995628, 0.2102065009985381, 0.21179930600010266, 0.21591611800067767], [0.2245340989993565, 0.20988368899998022, 0.2108860749995074, 0.2168314989994542, 0.21836193300077866, 0.22110209099992062, 0.20810291199995845, 0.221653040000092, 0.21003695100080222, 0.21498166699893773, 0.233156656000574], [0.22555436999937228, 0.20959977299935417, 0.21144448700033536, 0.21598543599975528, 0.21744020600090153, 0.22159015999932308, 0.20872101799977827, 0.2222311340010492, 0.2097362919994339, 0.2144058550002228, 0.2325390089990833, 0.2532049420005933, 0.24654628499956743], [0.20876467400012189, 0.21076339800129062, 0.21651907799969194, 0.2183007309995446, 0.22111069300081], [0.21082363599998644, 0.21664170499934698, 0.21834049700009928, 0.22110074400006852, 0.20812849100002495, 0.22167185699981928, 0.2100045700008195], [0.2116668809994735, 0.21597692100112909, 0.21744432800005598, 0.22157138299917278, 0.20870166399981827], [0.21627769699989585, 0.2182293860005302, 0.22121692399923631, 0.2081853220006451, 0.22156892099883407, 0.21007640000061656, 0.21521906400084845, 0.2328461929992045, 0.25279519600007916, 0.2469688679993851, 0.20825449699987075], [0.2155131130002701, 0.21798038400083897, 0.22156794900001842, 0.20869678799863323, 0.22229021300154272, 0.2096997079988796, 0.21438073399986024, 0.23264557600123226, 0.2532031229984568, 0.24654827199992724, 0.2090025070010597], [], [0.22171673100092448, 0.2083716769993771, 0.22118474200033234, 0.21071731699885277, 0.21453103300154908, 0.2328419079985906, 0.25297648800005845, 0.2467756100013503, 0.20845663499858347, 0.20786700100143207, 0.22574217499823135, 0.2196842800003651, 0.21909571000105643, 0.23331078299997898, 0.2014917479991709, 0.21158429900060582, 0.21116180900025938, 0.21926745699965977, 0.2216618219990778, 0.2384536460012896, 0.2646028449998994, 0.2880692709986761], [0.2090806079995673, 0.2211877360005019, 0.21052791599868215, 0.21470678100013174, 0.23284139499992307, 0.25291077600013523, 0.2468556889998581, 0.2083348610012763], [0.22137237300012202, 0.21051343499857467, 0.21472450200053572, 0.23284387000057905, 0.2527980109989585], [0.22157213100035733, 0.2100814449986501, 0.21521362700150348, 0.23284769400015648, 0.25279467799919075, 0.24687597599950095], [0.22106353599883732], [0.20925575599903823, 0.21453563199975179, 0.2328416529999231, 0.25291371599996637], [0.21502461999989464, 0.23317095499987772], [0.214286391999849, 0.23273502299889515, 0.2532011910006986, 0.2465521220001392, 0.20900112299932516, 0.20774343599987333, 0.22551908800051024, 0.21919215399975656], [0.21429538799930015, 0.23274660900096933, 0.2531901829988783, 0.2465631979994214, 0.2090017490008904, 0.20774266800071928, 0.22544440499950724, 0.22163302700027998, 0.21715521999976772, 0.23331385999881604, 0.2015181480001047], [], [0.2083858269998018, 0.2078734099995927, 0.22619529300027352, 0.22188997400007793, 0.21716051700059325, 0.2333297239983949, 0.20039823100159992, 0.2115830709990405, 0.21130039300078352, 0.21979488599936303, 0.22176313399904757, 0.23904911300087406, 0.2642957900006877, 0.2881939959988813, 0.30881772700013244, 0.21456837900041137, 0.22462868500042532, 0.2269806209988019, 0.22210720400107675, 0.2193131120002363, 0.20881951999945159, 0.23296676199970534], [0.20749409800009744, 0.2254900780008029, 0.2213570769999933, 0.217174884999622, 0.2333356500002992, 0.20204006600033608, 0.211448145999384, 0.21087063699997088, 0.21940291999999317, 0.22161735500048962, 0.23847453499911353], [0.20750066100117692, 0.22561856299944338, 0.2216349549998995, 0.2171692499996425, 0.23333376000118733, 0.20142879800005176], [0.22618630600118195], [0.2256611350003368, 0.22167127300053835, 0.21716338099940913, 0.23333281000122952, 0.20140030199945613, 0.21156927599986375], [0.22574998299933213, 0.21965538800031936, 0.21909776299980877, 0.23332882300019264, 0.20150144699982775, 0.21103994300028717, 0.21153830599905632, 0.2194327900015196, 0.22165281799971126, 0.23840134400052193], [0.2254315489990404, 0.22005987200100208], [0.22559555399857345, 0.21954314400136354, 0.2190960459993221, 0.23331834800046636, 0.2017072670005291, 0.2118014839998068, 0.2109135819991934, 0.2191403500000888, 0.22181193200049165, 0.23824502299976302, 0.2645032549989992], [0.2170107170004485, 0.23335463299918047, 0.20076327300012053, 0.21150690799913718, 0.21127959500154248, 0.21977275099925464, 0.22177162200023304, 0.23835450299884542, 0.26453972200033604, 0.28828839900052117, 0.30857523799932096, 0.21423616799984302, 0.22523618700142833, 0.2268676539988519, 0.22221995099971537], [0.20156745799977216, 0.2110474470009649, 0.21153619100005017, 0.21944124699984968, 0.22164725699985866, 0.23831344199970772, 0.2645422839996172], [0.21146658300131094, 0.21085852399846772, 0.21940468700086058, 0.22153990100014198, 0.23824008799965668, 0.26460993600085203, 0.28817785999854095, 0.30849881500034826, 0.214382801001193, 0.22503487399990263], [0.2113314199996239], [0.211155917000724, 0.219279999999344, 0.22165735800081166, 0.23850862499966752, 0.26453639099963766, 0.2880699300003471, 0.30862593700112484, 0.21437976399829495, 0.2250384369999665, 0.22685620200172707, 0.22232358799919893, 0.21941213500031154, 0.20857586999954947, 0.2331784060006612, 0.22544618000029004, 0.21050352599922917, 0.205224442999679, 0.20924895300049684, 0.21550024799944367, 0.20654054900114716, 0.20589570199990703, 0.2126349720001599, 0.21202507699854323, 0.22022240899968892, 0.2412220130008791, 0.22178789300050994, 0.236436049999611, 0.2141926690001128], [], [0.21084816199982015, 0.2193641400008346, 0.2216234319985233, 0.23851433500021813, 0.2642919210011314, 0.2881941759987967, 0.3087551179996808], [0.2194715969999379, 0.22163492100116855, 0.23862227700010408, 0.264596465998693, 0.2881891420001921, 0.3084960600008344, 0.2143843529993319, 0.22514378400046553, 0.22681762799948046, 0.22220326699971338], [0.2214608699996461], [], [0.2251316069996392, 0.2269795800002612, 0.22210881099999824, 0.21931526499975007, 0.20881811000072048, 0.23296665499947267, 0.2254127010000957, 0.21104661100071098, 0.2052691879998747, 0.20903498400002718, 0.21542631099873688], [], [], [0.22233692800000426, 0.2195700369993574, 0.20847575500010862, 0.2332621300010942, 0.22547304399995483, 0.21047471000019868, 0.20522679100031382, 0.209261804999187, 0.2155093580004177, 0.20574739299991052, 0.20654555200053437, 0.21132181499888247, 0.21279882700036978, 0.22086093699908815, 0.24122009300117497, 0.22178731299936771, 0.2364407229997596, 0.21364237700072408], [0.20888929799912148, 0.2329751760007639, 0.22543108599893458, 0.21067757700075163, 0.20506302299872914, 0.20924806600123702, 0.21549406699887186, 0.20595163100006175, 0.20648292999976547, 0.21132399000089208, 0.21269894999932148, 0.2208600860012666, 0.2412216949996946, 0.22178949999943143, 0.23643581199939945, 0.21429168300164747, 0.2303642659990146, 0.21827422299975296, 0.2197825310013286, 0.2167441029996553, 0.3923870689995965, 0.04996281000057934, 0.2165364979991864, 0.2258199660009268], [0.23277737899843487, 0.22531831700143812, 0.21132348499850195, 0.20533057900138374, 0.208792318999258, 0.2152961060000962, 0.20616297400010808], [0.2111595740007033, 0.2047428059995582, 0.20924801500041212, 0.21555946099942958, 0.206279636000545], [0.21130068100137578, 0.20533266199890932, 0.20879475600122532, 0.21528508699884696, 0.20579211299991584], [0.21097177999945416, 0.20524547999957576, 0.20903460299996368, 0.21548795700073242, 0.20616018799955782, 0.20624839500123926, 0.21249073599938129, 0.21181145400078094, 0.22086481199949048, 0.24234042199896066, 0.22014122000109637], [], [0.20895556599862175, 0.215484305001155, 0.2068588969996199, 0.20562302600046678, 0.2127017969996814, 0.21181677099957597, 0.22030491000077745, 0.2410999339990667, 0.22168963100011752, 0.23643662900030904, 0.2143099519998941], [0.20869273000062094], [0.21559007500036387, 0.20657085200036818, 0.20571175599980052, 0.21282139799950528, 0.2120279600003414, 0.22013137500107405, 0.24122747000001254, 0.22177836799892248, 0.23645487500107265, 0.21350408699981926, 0.23110174099929282, 0.21831345099963073, 0.2198318869996001, 0.21676563900109613, 0.3923835900004633, 0.049973919998592464, 0.2163567140014493, 0.2260006299984525, 0.2459318830005941, 0.21779184400111262, 0.21709983099935926, 0.21620884999902046, 0.2378154670004733, 0.23050616299951798, 0.22543215100085945, 0.2125864610006829], [0.21543624100013403, 0.20566838499871665, 0.20679446699978143, 0.21116019900000538, 0.21254997300093237, 0.22111452699937217, 0.24264225600018108, 0.22014884800046275, 0.23643339599948376, 0.21437253800104372, 0.23047169899837172], [0.20634328000051028, 0.20671518500057573, 0.21140632899914635, 0.2123533440008032, 0.2214132850003807, 0.24233744599951024, 0.22042727699954412, 0.23612456199953158, 0.21438437700089708, 0.23061155100003816, 0.21807579199958127, 0.2200330470004701, 0.21689674200024456, 0.39231452499916486, 0.049552720000065165, 0.21653525799956697, 0.22589528300159145, 0.24578842499977327, 0.21790254499865114, 0.21716730200023449, 0.21654680800020287, 0.23739538500012713, 0.23035330200036697, 0.22582041900022887, 0.21279232999950182, 0.21300367799995001, 0.20764907900047547], [0.20696418099942093], [0.20664329099963652], [0.20540774300025078, 0.21302472699971986], [0.20644448200073384, 0.2112880539989419, 0.212756292999984, 0.22084589400037657, 0.2412206380013231, 0.22178776299915626, 0.2364383709991671, 0.21374062600079924, 0.23094815900003596, 0.2182092120001471], [0.20615980899856368, 0.21216598200044245, 0.21178920800048218, 0.22071732099902874, 0.2423362650006311, 0.22075946800032398, 0.23580592799953592, 0.21439257800011546], [0.2054017249993194, 0.21303487899967877, 0.21171192700057873], [0.20631663699896308, 0.21221850400070252, 0.21203225399949588, 0.22058540100078972], [0.21102360599979875, 0.21270314200046414, 0.22084294600063004, 0.24122153600001184, 0.22178682699995989, 0.2364366539986804, 0.21374877600101172, 0.23088911199920403, 0.21822616700046638, 0.21985986099934962, 0.2167502299998887, 0.39238318000025174, 0.049968305000220425, 0.21634696100045403, 0.22600918199896114, 0.24593484900105977, 0.21778846599954704, 0.21710052100024768, 0.2162158859991905, 0.23781529600091744, 0.23050176600008854, 0.22543811399918923], [], [0.21235798799898475, 0.22114128100110975, 0.2425884069998574, 0.2201411049991293, 0.23643069100035063, 0.21438392799973371, 0.2306038120004814, 0.2178821870002139, 0.22014750000016647, 0.21696570299900486, 0.39230942300127936, 0.049564037999516586, 0.2165439950003929, 0.22588508899934823, 0.24578782599928672, 0.2178980920016329, 0.21718445499936934, 0.21627990500019223, 0.23766150899973582, 0.23035598199930973, 0.2258108740006719, 0.2127999690001161, 0.2130018719999498, 0.20764901400070812, 0.20295725500000117, 0.20406852599990088, 0.21476143499967293, 0.20848080100040534, 0.21583882899903983, 0.23359363700001268, 0.20222129899957508, 0.21574423200036108, 0.23529301999951713, 0.2114552740004001, 0.21288783099953434], [0.21246781800073222, 0.22142826699928264, 0.24232863100041868, 0.2201425820003351, 0.23643147999973735, 0.21438227599901438, 0.23054374800085498], [0.21179055599895946, 0.22031115100071474, 0.2426451100000122, 0.22014623999893956, 0.2364316940002027, 0.21437849600079062, 0.23042593100035447, 0.2180869879994134, 0.2198006960006751, 0.21673690999887185, 0.392391369001416, 0.049954099999013124, 0.21657566099929682, 0.22592131100100232, 0.24578954599928693, 0.21778660500058322, 0.21732351100035885, 0.21628023700031918, 0.23765661299876228, 0.2303612850009813, 0.22553537099884124], [0.22040820300026098], [0.2208926799994515, 0.23581792500044685, 0.21438762499928998, 0.23061272099948837, 0.21806648500023584, 0.2200379210007668, 0.216896567000731, 0.39231796999956714, 0.04954853900017042, 0.21652836199973535, 0.22590227900036552], [], [], [0.231347178998476, 0.2180227830012882, 0.2201015729988285, 0.21684292100144376, 0.39235837399974116, 0.04950399299923447, 0.2165165110000089, 0.22599201500088384, 0.24569435800003703, 0.217902251999476, 0.21726301499984402], [0.22031883300041954, 0.21642575099940586, 0.39239323299989337, 0.0499498000008316, 0.2165692169983231, 0.22592852200068592, 0.24578902999928687, 0.21778624800026591, 0.21731666500090796, 0.21662501900027564, 0.23738808099915332, 0.23034783600087394, 0.2258255739998276], [0.22002824999981385, 0.21689830800096388, 0.3923112989996298, 0.04955908599913528, 0.2165388779994828, 0.22589038200021605, 0.24578684700099984, 0.21790381699975114, 0.21717309999985446, 0.21628896599941072], [0.3925444870001229, 0.049991378999038716, 0.21637924000060593, 0.22598007899978256, 0.24592947800010734, 0.21780113199929474, 0.21710022499974002, 0.21606028200039873, 0.23795016599979135, 0.23051569100061897, 0.2253077490004216, 0.21271301199885784, 0.213392018000377], [0.3920022850015812, 0.04981224199946155, 0.21656087699921045], [0.049570584000321105, 0.21655006599939952, 0.22588291900137847, 0.24578880699846195, 0.21778744400035066], [], [0.2259037410003657, 0.2458014669991826, 0.21778694900058326, 0.217332993999662, 0.21598659200026304, 0.23781697800041002, 0.23049917800017283, 0.22552978699968662, 0.21264267900005507, 0.2133478939995257, 0.20648219299982884], [], [0.2167011729998194], [], [], [0.2142361729984259, 0.20796710000104213, 0.20264518200019666, 0.2045579360001284, 0.2140638349992514], [0.21300244700069015, 0.20651204900059383, 0.20371552999858977, 0.20415014600075665], [0.2133401249993767, 0.20647475000077975, 0.20347077199949126, 0.2041710539997439, 0.2150464299993473, 0.20844640100040124, 0.21562348999941605, 0.23378986400166468, 0.20226413099953788, 0.21538510599930305, 0.23438733700095327], [0.20305153899971629, 0.20410651699967275, 0.21475809100047627, 0.20848737199958123, 0.2156814129994018, 0.23363360000075772, 0.2022198369995749, 0.21592849800072145, 0.2352179650006292], [0.20283111199933046, 0.2040583889993286, 0.2147431270004745, 0.20849502199962444, 0.21569028200065077, 0.2336242420005874, 0.2022135019997222, 0.21593913799915754, 0.23527194100097404, 0.2112164069985738, 0.21301219500128354, 0.210675951999292, 0.20903198899941344, 0.22972813300111738], [], [0.20263988400074595, 0.2045552019990282, 0.21407587400062766, 0.20877310700052476, 0.21574561299894413, 0.23351115399964328], [0.20425058499859006, 0.21444963400062989, 0.20876173299984657, 0.21571943500021007, 0.2334198379994632, 0.2022016370010533, 0.21576100699894596, 0.23529113500080712, 0.21143739800027106, 0.21302683799876831, 0.21036998300041887], [0.20405552100055502, 0.21508777499911957], [0.20396950199938146, 0.21471124700110522, 0.20905217099971196, 0.2157575450000877, 0.2335722520001582], [], [0.21449026700065588, 0.20844306999970286, 0.215847085999485, 0.23358744799952547, 0.2022153600009915, 0.21574837200023467, 0.23529403899919998, 0.21144803300012427, 0.2129929130005621, 0.21035910999853513], [0.21476591999999073, 0.20834512800138327, 0.2156972009997844, 0.23361807499895804, 0.20220895999955246, 0.21594632100095623, 0.23527445000036096], [0.2150828920002823, 0.20849878899934993, 0.2156664539998019, 0.23364847700031532, 0.2021629840000969, 0.21547439200003282, 0.2355397070004983], [0.21489769499930844, 0.20848162900074385, 0.21567569999933767, 0.2336385029993835, 0.2021569839998847, 0.21548229500149318, 0.23562838499856298], [0.216757977999805, 0.23342114899969602, 0.20222872399972402, 0.2157664800015482, 0.23551222699825303, 0.21121265900001163, 0.2132857070009777, 0.21056052099993394, 0.20872084199982055, 0.2296214220004913, 0.25249750500006485, 0.27659332499933953, 0.23005781900064903, 0.21510914600003161, 0.21143372699953034, 0.20632086399928085, 0.22943740300070203, 0.25022286300009], [0.21565547499994864, 0.23366113100018993, 0.20217199899889238, 0.2154612600006658, 0.23553602100037097, 0.21151495699996303, 0.21290168199993786, 0.20936543099924165], [0.21582581599977857, 0.23360566100018332, 0.2021660089994839], [0.21530473699931463, 0.23375027000111004, 0.20229399500021827, 0.21575451099852216, 0.23529276300178026, 0.21144305799862195, 0.21300470400092308, 0.21038834499995573, 0.20899524299966288], [0.21631169299871544, 0.23523485199984862, 0.2112998049997259, 0.21300178600176878, 0.21044712599905324, 0.20914721799999825, 0.22980595599983644, 0.252512430999559, 0.2767176030010887, 0.2299358829986886, 0.21499520600082178, 0.21085346399922855, 0.20674634400165814, 0.22958391099928122, 0.2502949190002255, 0.23990951099949598, 0.20459261900032288, 0.20838726100009808, 0.20653591900008905, 0.2081316029998561, 0.22614045499904023, 0.21772025100108294, 0.20433511500050372, 0.21618432299874257, 0.23180620899984206, 0.2115138190001744, 0.2074157010010822, 0.2313204219990439, 0.20421755099960137, 0.21109101100046246, 0.22959873800027708, 0.20796950300064054, 0.20709496599920385, 0.21089000900065002, 0.22893727199880232, 0.24918511400028365, 0.21870321099959256, 0.20875154600071255, 0.2284808479998901, 0.2155409780007176, 0.212590981998801, 0.20529780600008962, 0.2256857240008685, 0.22304058900044765, 0.206800044999909], [0.21544602699941606, 0.23567480000019714, 0.21130885999991733, 0.2129884240002866, 0.2094049739989714, 0.21019265799986897, 0.22980107900002622, 0.25251445200046874, 0.27661572599936335], [0.21565418600039266], [0.21581573000003118, 0.23528848400019342, 0.2111302209996211, 0.21302333600033307, 0.21066466999945987, 0.20903850300055637, 0.22990434199891752, 0.25251252300040505, 0.2765814930007764, 0.23010437799894135, 0.21505256199998257], [0.2138531860000512, 0.2105640730005689, 0.20871883899962995, 0.22967641800096317, 0.2525078669987124, 0.2765851260010095, 0.2300424139993993, 0.2151170840006671, 0.2113834110004973, 0.20610772999862093, 0.2296021110014408, 0.25026692999927036, 0.24000123599944345, 0.20475896000061766, 0.20844639700044354, 0.2084276339992357, 0.20577855800001998, 0.22624491100032174, 0.21799282800020592, 0.2041001369998412, 0.21601716300028784, 0.23343739799929608, 0.2098849070007418, 0.20756430300025386, 0.23122298599992064, 0.20415441799923428, 0.21126681399982772, 0.22959557400099584, 0.20784313299918722, 0.20705479299977014, 0.21161620800012315, 0.22847960900071485, 0.2492455069987045, 0.21907403500154032, 0.20875866199821758, 0.2283155720015202, 0.21498876300029224, 0.21293113799947605], [0.2127720579992456, 0.21059438699921884, 0.20904291100123373, 0.2298151830000279, 0.2523907559989311], [], [0.20902634600133752, 0.22972936399855826, 0.2525106680004683, 0.2767234290004126, 0.22997446099907393, 0.21493000800001028, 0.21086037700115412, 0.20674487900032545, 0.2295801019990904, 0.25028788300005544, 0.23991162600032112, 0.20460195200030284, 0.2083833249998861, 0.20878809500027273, 0.20611747699877014, 0.2262623850001546, 0.2173660110001947, 0.2057899150004232, 0.21505833499941218, 0.23288485200100695, 0.21041482699911285, 0.20752039100079855, 0.23198037299880525, 0.20323770899994997, 0.21172131999992416], [0.20903337900017505, 0.22973971799910942, 0.2525101610008278, 0.2767226859996299, 0.22992848600006255], [0.2100273850010126, 0.22965513599956466, 0.2526619809996191, 0.2766176050008653, 0.22990552599912917, 0.2151724790001026, 0.21040345400069782, 0.20703479399890057, 0.2297014420000778, 0.25028945300073246, 0.2398847249987739], [0.2090497659992252, 0.2296851980008796, 0.25250549699921976, 0.2765866890003963, 0.23005029799969634, 0.21511354600079358, 0.21137355499922705, 0.20611230100075772, 0.229601372999241, 0.25021480900068127], [], [0.21486836099938955, 0.2108576880000328, 0.2068254000005254, 0.22949612499905925], [0.21208460299931176, 0.20617207000032067, 0.22943445700002485, 0.250255154000115, 0.23995197399926838, 0.2047687890008092, 0.20877842200025043, 0.2080791029984539, 0.20587849900039146, 0.22623492200000328, 0.21791574400049285, 0.20481311199910124, 0.21555058200101485, 0.23321579599905817, 0.20997327999975823, 0.20765035900149087, 0.23116980399936438, 0.20405462400049146, 0.21171335100007127, 0.22911830999873928, 0.20795609800006787, 0.20727935900140437, 0.21128660199974547, 0.228761038999437, 0.24897764900015318, 0.21903425399978005, 0.2087785250005254, 0.22831934599889792, 0.2149593950016424, 0.21414484399974754], [0.2108717869996326, 0.20659789800083672, 0.22960835099911492, 0.25022939600057725, 0.2398294150007132, 0.2046064429996477, 0.20838342599927273, 0.20878998999978648, 0.20587976400020125, 0.22614047000024584], [0.20675131999996665, 0.229589857000974, 0.25030397799855564, 0.23990590799985512, 0.20458271900133695, 0.20839429899933748, 0.20653302800019446, 0.20867164399896865, 0.22634715600179334, 0.21689980099836248], [], [], [0.20656884300115053, 0.22960386500017194, 0.25022207599977264, 0.2398263989998668, 0.2046128250003676, 0.20838210699912452, 0.20878737699968042, 0.20595960700120486, 0.22623243999987608, 0.21780449299876636, 0.20430439099982323, 0.2160056259999692], [0.2294451180005126, 0.25022905799960427, 0.23999989999902027, 0.20476280100047006, 0.20844632100124727, 0.20842067699959443, 0.2060086940000474, 0.22627299799933098, 0.21773610600030224, 0.20586916899992502, 0.21490604499922483, 0.23278781900080503, 0.21046361799926672, 0.20731024900123884, 0.2320049840000138, 0.20318249999945692, 0.21182796500033874, 0.22889787599888223, 0.20900720999998157, 0.2064785700003995, 0.21102977100053977, 0.22847996699965734], [], [0.2047232120003173, 0.2081653870009177, 0.20874713999910455, 0.20608738500050094, 0.22627119999924616, 0.21765218600012304, 0.20595134799987136, 0.21473206600057893, 0.23281629099983547, 0.21039791899966076, 0.2075077389999933, 0.23200007300147263, 0.20319713999924716, 0.21181589600018924, 0.22880021600030886, 0.20890352499918663, 0.2066262040007132, 0.21065143899977556, 0.2287666629999876, 0.24919108699941717, 0.21906497100098932, 0.20857426099973964, 0.22847269999874698, 0.21543667100013408, 0.21419966200119234, 0.20450648599944543, 0.22525190899978043, 0.2228665490001731, 0.20799581100072828, 0.20329976900029578, 0.2235267849991942, 0.20521838899912836, 0.22844603300109156, 0.21700375500040536, 0.2199192359985318, 0.21935093700085417], [0.20468225200056622, 0.20815108499846247, 0.20874099000138813, 0.20593846599876997, 0.22623328500048956, 0.21783775900075852, 0.2042713239989098, 0.21611585699974967, 0.23312074200111965, 0.21007678899877646, 0.20755744900088757], [0.20820607700079563, 0.20875439699921117, 0.20608410900058516, 0.22626870999920357, 0.21764650200020697, 0.2056920680006442, 0.21493299499888963, 0.23284646600041015, 0.2104164270003821, 0.20751148700037447, 0.23199205299897585, 0.20321415400030673, 0.2118020649995742, 0.22880809200069052, 0.20889192600043316, 0.20661059399935766, 0.21068642499994894, 0.2287691330002417, 0.24918692599931092, 0.2186552359999041, 0.2087774810006522, 0.22859892199994647, 0.215527161000864, 0.21415148199957912], [0.20840927999961423, 0.2062488139999914, 0.20859422800094762, 0.22623341799953778, 0.21739389100002882, 0.20471082000040042, 0.21600845299872162, 0.23158602300100029, 0.211737985999207, 0.2075568150012259, 0.23130425599993032, 0.20407832599994435, 0.2116049460000795, 0.22898723099933704, 0.20808618999944883], [0.20844687499993597, 0.2084393490004004, 0.2058908330000122, 0.22623437499896681, 0.217887751001399, 0.20422364299884066], [], [0.208708044998275, 0.20640698800161772, 0.22628299899952253, 0.21728558699942369, 0.20603108500108647, 0.21491658199920494, 0.2325287589992513, 0.2112136530013231, 0.20680729599916958, 0.23225704499964195, 0.20292806200086488], [0.20846101499955694, 0.20638182900074753, 0.22628488000009384, 0.2173005259992351], [0.20843997500014666, 0.22619449800004077], [0.20823417700012214, 0.2262781339995854, 0.21697721000055026, 0.2063430279995373, 0.2149150830009603, 0.2324602109983971, 0.21127928700116172, 0.20681178599988925, 0.23206205799942836, 0.2031291359999159, 0.21183749200099555, 0.22864760999982536, 0.20926388999941992, 0.20646089799993206, 0.2102415090012073, 0.22893597799884446, 0.24918381099996623, 0.21869392299959145, 0.20875582600092457, 0.22848080800031312, 0.21588615299879166, 0.21420073100125592, 0.20508160999997926, 0.22489025499999116, 0.22265869399961957, 0.2080720920002932, 0.2037623309988703, 0.22303387400097563, 0.2055981020002946, 0.22799913499875402, 0.21696743200118362, 0.22007525799926952, 0.2200863769994612, 0.23677251300068747, 0.2063002190006955, 0.21517365699946822, 0.23447796700020263, 0.23496594199968968, 0.20817376999912085, 0.21355023800060735, 0.23085299200101872, 0.2576184599984117, 0.2668753510006354, 0.2940229249998083, 0.21345936600118876, 0.23192175199983467], [0.20871648600041226, 0.22623601799932658, 0.21739918899947952, 0.20469979500012414, 0.21601308599929325, 0.23158212000089407, 0.21174103900011687, 0.20755941099923803, 0.23130058300012024, 0.20408832599969173, 0.2112541290007357], [0.2261336499996105, 0.21770115700019232, 0.20587728499958757, 0.21491166499981773, 0.232782266999493, 0.21046231200125476, 0.20730946399999084, 0.2320054939991678, 0.20317642400004843, 0.21183310599917604, 0.22889646000112407, 0.20901047900042613, 0.20647304299927782, 0.21103605499956757, 0.22875152400047227, 0.2489577910000662, 0.21906742399914947, 0.20876964300077816, 0.22831803199915157, 0.21528029100045387, 0.21414428299976862, 0.20449052000003576, 0.2252524560008169, 0.22288587100047152, 0.20807278099891846, 0.20324709200031066, 0.22351615099978517, 0.20555073200011975, 0.2280829419996735, 0.2169913159996213, 0.22003267700165452, 0.22001604699835298, 0.23689723999996204, 0.206113924001329, 0.21536407199891983, 0.2344795580011123, 0.23496491399964725, 0.2081292940001731, 0.21355706499889493, 0.23113142600050196, 0.2578837700002623, 0.2666230289996747, 0.29512715300006676, 0.2123624320011004, 0.2320452949988976, 0.20952453300014895, 0.2205435239993676, 0.2394980460012448], [0.20578455299983034, 0.21555931399961992, 0.23313731199959875, 0.2100521860011213, 0.2076483869986987, 0.23117031900073925, 0.2040615509995405, 0.2117028600005142, 0.2290061700005026, 0.2080677409994678, 0.20725808099996357], [0.20592747499904362, 0.21507121800095774, 0.2312783439992927, 0.21190919800028496], [0.21494038200034993, 0.23284309299924644, 0.2104161910010589, 0.20751442899927497, 0.2319872080006462, 0.20322503500028688, 0.21179091799967864, 0.22881556500033184, 0.20888195499901485, 0.20662341299976106, 0.2106755320000957, 0.2287746630008769, 0.24918345200057956, 0.21866372099975706, 0.20877304799978447, 0.22848465199967904], [0.2147350750001351, 0.23281685999972979, 0.21039798300080292, 0.20750930299982429, 0.2319964489997801, 0.20320512400030566, 0.21180895199904626, 0.22880376200009778, 0.208897980999609, 0.20660243700149294], [0.21580078700026206, 0.23317794799913827, 0.21001225500003784, 0.20764208400032658, 0.23117657299917482, 0.20407003500076826, 0.2116211470001872], [0.21076155900118465, 0.20731623499887064, 0.23200215399992885, 0.20318960599979619, 0.21182200600014767, 0.2287976190000336, 0.20890553200115392, 0.20662331499988795, 0.21065438099867606, 0.2287668790013413, 0.24919302899979812], [0.2065583420007897, 0.23218110999914643, 0.20295378499940853, 0.21178898900143395, 0.22874594399945636, 0.2091680159992393, 0.20645254500050214, 0.210926150000887, 0.22848467099902336, 0.24923897799999395, 0.21891941700050666], [], [0.23202945199955138, 0.2028896089996124], [0.2312254140015284, 0.2041685949989187, 0.21122982000088086, 0.22958512999866798, 0.20785786800115602, 0.20707821999894804, 0.21161939800003893, 0.22848118500041892, 0.2492418900001212, 0.21907903899955272, 0.20848589100023673], [], [0.20410314000037033, 0.21122376899984374, 0.2294466809998994, 0.20799423099924752, 0.20706425100070192, 0.21111304099940753, 0.22878115599996818, 0.24918307600091794, 0.21866951799893286, 0.20876983299967833, 0.22848252699986915, 0.2154773420006677, 0.2128982009999163, 0.2054488690009748, 0.22524351099855267, 0.22303479200127185, 0.20692113699988113, 0.2038847399999213, 0.22395682699971076, 0.20454412199978833, 0.2289275879993511, 0.21575466300055268, 0.22158390399999917, 0.21933988199998566, 0.2371802489997208], [0.20313951000025554, 0.21183282300080464, 0.2289095689993701, 0.20900101799998083, 0.20646528100041905, 0.21113255999989633], [], [0.2095977299995866, 0.2062237890004326, 0.21025691100112454, 0.2289248309989489, 0.2491816170004313, 0.21868670599906181, 0.2087605659999099, 0.2288038440001401, 0.21558138000000326, 0.21421544100121537, 0.2051435079993098, 0.22536317999947642, 0.2222259469999699, 0.20837638300145045, 0.20336800899895024, 0.22302584899989597, 0.2056023590012046, 0.22799695699904987, 0.21694440400096937, 0.22007870000015828, 0.22010533699904045, 0.2367648529998405, 0.20631024700014677, 0.21556520699959947, 0.23410532100024284, 0.23493288999998185, 0.20844449200012605, 0.21354912700007844], [], [0.2064594749990647], [0.20726387700051419, 0.21080971799892723, 0.2289968000004592, 0.2491874530005589, 0.21860098199977074, 0.20880678399953467, 0.22850037300122494, 0.21559109699956025, 0.21242884899947967, 0.20543823300067743, 0.22562375300003623, 0.223112626999864, 0.20678586599933624, 0.20360430999971868, 0.224271597000552, 0.20462539499931154, 0.22881236300054297, 0.21588111100027163, 0.22161493999919912, 0.21932238500085077, 0.23717805900014355, 0.20582575799926417], [0.21052675799910503, 0.22889831199972832, 0.24918390100174292, 0.21867620999910287, 0.20876591900014319, 0.22848191099910764, 0.21568307900088257, 0.2141468209993036, 0.2043741300003603, 0.22536829199998465, 0.22291140600100334, 0.20790427199972328, 0.2034166869998444, 0.22338943899922015, 0.20535696800106962, 0.22844722299851128, 0.21700441100074386, 0.21992311500071082, 0.2193458029996691, 0.23769752999942284, 0.20611003900012292, 0.2153724260006129, 0.23447662800026592, 0.2348678189991915, 0.2082131040006061, 0.21356361499965715, 0.23100461600006383, 0.25762406600006216, 0.2668768359999376, 0.2941291699989961, 0.21333529000003182, 0.23197345700100414, 0.20926788199903967, 0.22041301799981738, 0.23989573400103836, 0.22338856299938925, 0.21085199600020132, 0.22813038999993296, 0.20854868900096335, 0.22018414499871142, 0.24307917800069845, 0.24428920399986964], [], [], [0.22848798300037743, 0.24923724600012065, 0.21892920500067703, 0.2085803029985982, 0.22847123900100996, 0.21559050799987745, 0.21421205799924792, 0.20514343400100188, 0.2252896560003137], [], [0.2087471060003736, 0.22848101099953055, 0.21592330500061507, 0.21419686599983834, 0.2050798330001271, 0.2248835179998423, 0.22266237499934505, 0.20807189399965864, 0.2037581519998639, 0.2230385729999398, 0.2055363250001392], [0.20847343099922, 0.22830365099980554, 0.21587548100069398, 0.2142053190000297, 0.20508144499945047, 0.22489613800098596, 0.22265737799898488, 0.2080687260004197], [0.2284438560000126, 0.2153040470002452, 0.2130524879994482, 0.20529613299913763, 0.2252426410013868, 0.22303394699883938, 0.20725309900080902, 0.20363638299932063, 0.223898141999598, 0.2045396850007819, 0.22893209299945738, 0.2158674760012218, 0.2214344389994949, 0.21934716000032495, 0.23728852800013556, 0.20581028800006607, 0.21587971699955233, 0.23421353099911357], [0.22835670200038294, 0.21561814099914045, 0.21420892599962826, 0.20514245600134018, 0.22516254699985438], [0.2130761300013546, 0.20503229199857742], [0.21414122100031818, 0.2043755049999163, 0.2253675120009575, 0.22276543000043603, 0.20803690999855462, 0.20342975000130537, 0.22338907699850097, 0.20535555400056182, 0.2284483370003727, 0.2160572909997427], [0.21414185799949337, 0.20448708500043722, 0.2252523499992094, 0.22287194700038526, 0.20800230100030603, 0.20329109500016784, 0.22353550099978747, 0.20542838999972446], [0.2141910390000703, 0.20449944099891582, 0.2252519450012187, 0.2228695149988198, 0.20800043100098264, 0.20329449100063357, 0.2235315339985391, 0.20542457700139494, 0.22823392499958572, 0.21700042799966468, 0.2199178060000122], [0.2044849849989987, 0.22525331900033052, 0.22288835200015455, 0.20725107600082993, 0.20408129599854874, 0.2234801040012826, 0.2053857769988099, 0.22827320900069026, 0.21567484899969713, 0.22140854400095122, 0.21936335399914242, 0.23774952900021162, 0.20535640600064653, 0.21588085399889678, 0.2347216890011623, 0.23462033899886592, 0.20732503299950622, 0.21453994600051374, 0.23133007400065253, 0.257882754000093, 0.26662338499954785, 0.29420028800086584, 0.2132483859986678, 0.23208634399998118, 0.20935704200019245], [0.20467205299974012, 0.22531505599908996, 0.22289247600019735, 0.20725228800074547, 0.20397670899910736], [0.20442686600108573, 0.22523811899918655, 0.22288735899928724, 0.20724843300013163, 0.20408903600036865, 0.2234748419996322, 0.2053872570013482, 0.2284414559999277, 0.2155036209987884], [0.20507418700071867, 0.2248811419995036, 0.2226670930012915, 0.20807073599826253, 0.2036490180016699, 0.22311321099914494, 0.2055521050006064, 0.22808068099948287, 0.21697898800084658, 0.22003609399871493], [], [0.2248721249998198, 0.22264011100014613, 0.20810554000127013, 0.20373549299984006, 0.22302787700027693, 0.20560244399894145, 0.2279962370012072, 0.2169517319998704, 0.22007806199871993, 0.22009892400092212, 0.236767708998741, 0.2063074100005906, 0.21556299500116438, 0.23408106399983808, 0.23496357899966824, 0.20844268699875101, 0.21349655100129894], [0.2251989020005567, 0.22286838599939074, 0.20746191199941677, 0.20389886100019794, 0.22347122300016053, 0.20539018400086206, 0.2284467150002456, 0.2155647189993033], [0.22534123700097553, 0.22267579199979082, 0.20807141099976434, 0.20363819700105523, 0.22312394499931543, 0.20555197300018335, 0.22808018999967317, 0.21698690800076292, 0.22003476499958197, 0.22003306099941256], [0.22535317000074429, 0.22219800499988196, 0.20837658299933537, 0.20337081300021964, 0.22302342700095323, 0.20560437200037995, 0.22799645399936708, 0.21693699400020705, 0.22007929299979878, 0.22011252400079684], [0.22525228900121874, 0.2228632269998343, 0.20790451699940604], [0.22245450199989136, 0.2080261060000339, 0.20369794500038552, 0.2230300810006156, 0.20560304100035864, 0.2279967279991979, 0.21695831299985002, 0.22007662200121558, 0.22009268699912354, 0.23676960299962957, 0.20630571600122494, 0.21555335499942885, 0.2340932610004529, 0.23496506699848396, 0.20817094600170094, 0.21355096899969794], [0.2228067590003775, 0.20744181100053538, 0.2040384809988609, 0.22339167000063753, 0.20535045100041316, 0.22845131499889249, 0.21562128200093866, 0.22121763399991323, 0.21938119799960987, 0.2377528130000428, 0.20571425500020268, 0.21559441299905302], [0.22276985800090188, 0.2074261170000682, 0.204039529999136, 0.22339129300053173, 0.2053533439993771, 0.22844927700134576, 0.2160572909997427, 0.22089582399894425, 0.21933872800036625, 0.2376989530002902, 0.2060326939990773], [0.20765821600070922, 0.20390129900079046, 0.22347130099842616, 0.205389370001285, 0.22844496699872252, 0.2155650010008685, 0.22131599599924812, 0.2193687899998622, 0.2377523619998101, 0.20535225100138632, 0.2158823419995315, 0.234724740999809, 0.234615630000917, 0.2075361899987911, 0.21444143200096732, 0.23121744899981422, 0.25788490000013553, 0.266621030999886, 0.2942067499989207, 0.2132433580009092, 0.2320846580005309, 0.20943550399897504, 0.22019650199945318, 0.23983891400166613, 0.22346165699855192, 0.21114995000061754, 0.2279301670005225, 0.20866307500000403, 0.2200164499990933, 0.24301948900028947, 0.24438499899952149, 0.21349468100015656, 0.21775989399975515, 0.22022303500125417, 0.20427050899888854, 0.21247820800090267, 0.2086872290001338, 0.2091172109994659, 0.22451067399924796, 0.21359452700016845, 0.22695657999975083, 0.2507873100003053, 0.24346132500068052], [0.20324986099876696, 0.22351593000166758, 0.20554626800003462, 0.22808885099948384, 0.21699552800055244, 0.21999568100000033], [], [0.2036384299990459, 0.22390059000099427, 0.2045418649995554, 0.22892956800023967, 0.21575077600027726], [], [0.2233933919997071, 0.20535084099901724, 0.22845006399984413, 0.215619611000875, 0.2212280189996818, 0.21937527299996873, 0.2377533390008466, 0.20535039399874222, 0.2158812890011177, 0.23472690000016883, 0.23461395599952084], [0.22395869799947832, 0.2045500690001063, 0.22892123999918113, 0.21576392499991925, 0.2215938350000215, 0.21933283399994252, 0.23717655200016452, 0.2059364060005464, 0.21587955199902353, 0.2342091270002129, 0.2351585200012778, 0.20724269799939066, 0.21461124400047993, 0.23143781999897328, 0.2578852309998183, 0.2666216990000976, 0.2942099980009516, 0.21328801599884173, 0.23203043400098977, 0.20944303099895478, 0.2201960960010183, 0.2398353890002909, 0.22346580799967342, 0.21114675200078636, 0.2279298609992111, 0.20866300799934834, 0.22006426799998735, 0.242996540000604, 0.24435966000055487, 0.2134965959994588, 0.21775527499994496, 0.22022969799945713, 0.20426256700011436, 0.21249120799984667, 0.20868517000053544, 0.20911408299980394, 0.22451226700104598, 0.2135918669991952, 0.22694960000080755, 0.2507955499986565, 0.2436546980006824, 0.2211071189994982, 0.20687788400027785, 0.20802260900018155, 0.20793518800019228, 0.21345754499998293, 0.22256102400024247, 0.24687478200030455, 0.26811635899866815, 0.23629639899991162, 0.22754056600024342, 0.21173934699982055, 0.2262300120000873, 0.2081232300006377, 0.21427736800069397, 0.2148237439996592, 0.2284590589988511, 0.21000447500045993, 0.20522831800008134, 0.20951397200042265, 0.2181777139994665, 0.2093857060008304, 0.21857585899851983, 0.2028108020003856, 0.2225630650009407, 0.2273384170002828, 0.21962740199887776, 0.22796184599974367, 0.21069224799975927, 0.21595553400038625, 0.21289122800044424], [0.2236135130006005, 0.2045148329998483, 0.22893259400007082, 0.21586909399957221, 0.2214231150010164, 0.21935256500000833, 0.2377312440003152, 0.20537322999916796, 0.21587976000046183, 0.2347031760000391, 0.23463800999888917, 0.2073240830013674, 0.21455056400009198, 0.2313254569999117, 0.25786629899994296, 0.26663624299908406, 0.29413152800043463, 0.21333480099929147, 0.2319675280014053, 0.20927142799882859, 0.22042213200074912, 0.23989263499970548, 0.22338980099993933, 0.2108596590005618, 0.22814094800014573], [0.22304362900104024, 0.20553646699954697, 0.22807777500020165, 0.2169744789989636, 0.22007163099988247, 0.22007808499984094, 0.23677906900047674, 0.20611236600052507, 0.21536236999963876, 0.23447955799929332, 0.23496546800015494, 0.20817951900062326, 0.2135490300006495, 0.2308421379984793, 0.25761468400014564, 0.2668702450009732, 0.29401960900031554, 0.21340114600025117, 0.23191678799958027, 0.20941839999977674, 0.22039390999998432, 0.23989595199964242, 0.22339803099930577, 0.2105765070009511], [0.22828775999914797, 0.21567648600102984, 0.22141447799913294, 0.21935733999998774, 0.2377444869998726, 0.20536189999984344, 0.21588031999999657, 0.23471515600067505, 0.234625794000749, 0.2073256819985545, 0.21454436000021815, 0.23132769800031383, 0.25787729200055765, 0.2666270669997175, 0.294134796000435], [0.21965836299932562, 0.21930655600044702, 0.23718821900001785, 0.20581606199993985, 0.21601544700024533, 0.23411668900007498, 0.23525671000061266, 0.20716600499872584, 0.21463603700067324, 0.23126173600030597, 0.25731880399871443, 0.26713467000081437], [0.2205531149993476, 0.23736247000124422, 0.2061115879987483, 0.21536668500084488, 0.2344781529991451, 0.23487028300041857, 0.20820577800077444, 0.21356519099936122, 0.23111070300001302, 0.2578851790003682, 0.2666207900001609, 0.2945316709992767], [0.21933371600061946, 0.23770038000111526, 0.2057141799996316, 0.21570768899982795, 0.23455687999921793, 0.2347545100001298, 0.20783015999950294], [0.20774997700027598, 0.21530678099952638], [0.21547118899979978, 0.23446098800013715, 0.23475101599979098, 0.20783009700062394, 0.21406995899997128, 0.23117059800097195, 0.2578838019999239, 0.2666218079993996, 0.29510642800050846, 0.21238193999852228, 0.23205603800124663, 0.2095218569993449, 0.22041723400070623, 0.2396274219991028, 0.22373821400105953], [], [0.21559628899922245, 0.2346743760008394, 0.23469388599914964], [], [0.20813795899994147, 0.213554343999931, 0.23112961600054405, 0.25788291599928925, 0.266623088000415, 0.2951192840009753, 0.21237050199852092, 0.2320509580004, 0.20952192799995828, 0.22042109500034712], [0.20822092699927452, 0.2135651520002284, 0.2309993150010996, 0.25762180099991383, 0.266876780999155, 0.29402554700027395], [0.21407954799906292, 0.23115243400025065, 0.257885996999903, 0.2666212780004571, 0.29451972100105195, 0.21298292299979948, 0.23202082199895813], [0.21355075199971907, 0.23112492700056464, 0.25788292700053717, 0.2666244789998018, 0.2951555620002182, 0.21233356799893954, 0.2320403810008429, 0.20952647400008573, 0.22055388399894582, 0.2395599219998985, 0.2237121850012045], [], [0.21456217199920502, 0.2312414850002824, 0.25755068400030723], [0.2135483199999726, 0.23080438699980732, 0.2574438909996388], [], [0.22109150400137878, 0.2395548949989461, 0.22346592900066753, 0.2111475839992636, 0.22792862899950705, 0.20866317600120965, 0.22006865799994557, 0.24299318900011713, 0.24435736200030078, 0.2134973469983379, 0.2177515860003041, 0.22023641000123462, 0.20434383799874922, 0.21253434600112087, 0.20856005499990715, 0.2091152789998887, 0.22451251599886746, 0.21359000200027367, 0.22694171800139884, 0.2508049919997575], [0.22041322699988086, 0.23952115300016885], [0.22028853700066975, 0.2398414599992975, 0.22338942799979122, 0.21086353400096414, 0.22824875299920677, 0.2084732389994315, 0.2201802850013337, 0.24302377899948624, 0.2443912620001356, 0.21350502699897334, 0.2176168130008591], [0.2115498410003056, 0.2279439360008837, 0.208475505000024, 0.22018130399919755, 0.24302177800018399, 0.24439084100049513, 0.21344669599966437, 0.21761822299959022, 0.22030082200035395], [0.21086162599931413, 0.22783342500042636, 0.20871012899988273, 0.22002324200002477, 0.24299181499918632, 0.24435508500027936, 0.21349882899994554, 0.21788152400040417, 0.22010754300026747, 0.20433931600018695, 0.21254423500067787, 0.20855551899876446, 0.2091146260008827, 0.22451438200005214, 0.21358790900012536, 0.22693520299981174, 0.2512729350000882, 0.2431850859993574, 0.22109178299979249, 0.20726233999994292, 0.20769149800071318, 0.20808246699925803, 0.21354387100109307, 0.2223788669998612, 0.24681555399911304], [0.21115654300047026, 0.22793000899946492, 0.20847686200067983, 0.22018380900044576, 0.24301991299944348, 0.24438915499922587, 0.2134881440015306, 0.2177105880000454, 0.22028587099885044, 0.20428290000018023, 0.21235547300057078], [0.207323902999633, 0.2200193289991148, 0.2430187890004163, 0.24438631100019848, 0.2134929240000929, 0.21771529899888264], [0.2198771149996901, 0.24296072800098045, 0.24435232399991946, 0.21349955400000908, 0.21788174799985427, 0.220110868998745, 0.20433195999976306, 0.212711913000021, 0.20840789700014284, 0.20920485100032238, 0.2244656170005328, 0.21356453899898042, 0.22691362600016873], [0.21979844400084403, 0.24293800599843962, 0.24435039600029995, 0.21350209100091888, 0.2178783179988386, 0.22011458599990874, 0.20432502400035446, 0.21272030900036043, 0.20840533299997333, 0.20920734500032268, 0.22446438899896748, 0.21356301500054542, 0.2271535310010222], [], [], [0.22045287500077393, 0.20401239799866744, 0.21274113999970723, 0.20874656200066966, 0.2089379139997618, 0.2247221140005422, 0.21366501199918275, 0.22697472400068364, 0.2507600219996675, 0.24346992200116802, 0.22133665000001201, 0.20675673999903665, 0.20770914599961543, 0.20760378600061813, 0.21404544200049713, 0.22271704000013415, 0.24687409199941612, 0.2679271079996397, 0.23651001200050814, 0.22753332200045406, 0.2117380139989109, 0.2262199300002976, 0.20815164300074684, 0.21427189399946656, 0.21482104899951082, 0.22845867199976055, 0.20976038400112884, 0.20534858599967265], [0.21363623599972925, 0.20841332099917054, 0.2091155180005444, 0.2245154480006022, 0.21358750999934273, 0.2269272989997262, 0.2512936980001541], [0.21246461299961084], [0.21192384800087893, 0.20893923999938124, 0.20940923799935263, 0.22423387600065325], [0.21266721199936, 0.2087214530001802], [], [0.20830097699945327, 0.20927869899969664, 0.2247280840001622], [0.2089397169984295, 0.22471898500043608, 0.2136600020003243, 0.22698569299973315, 0.250638818999505, 0.24357878000046185, 0.22138750100020843, 0.20677265000085754], [0.22451126700070745, 0.21359971600031713, 0.2269655899999634, 0.2507756689992675, 0.2434638270005962, 0.2212954999995418, 0.20662987099967722, 0.20782697100003134, 0.2076000640008715, 0.21405037099975743, 0.22261431200058723], [0.22446709299947543, 0.21356755899978452, 0.22692011300023296, 0.251382893000482, 0.24307586699978856, 0.2210833389999607, 0.20779465300074662, 0.20724965699992026, 0.20802145000016026, 0.21353702600026736, 0.22238062499855005], [0.22586223300095298, 0.2511570290007512], [], [0.20806989199991222, 0.20709528800034605, 0.20802364500013937, 0.213535413999125, 0.22245176400065247, 0.24684156500006793, 0.2676958629999717], [0.20785700200030988, 0.20807476000118186, 0.2132983499996044, 0.2225542919986765, 0.24687602200174297, 0.26811816999907023, 0.23629344700020738, 0.227545404999546, 0.2117382850010472, 0.2262342109988822, 0.20810889200038218], [0.20725913800015405, 0.20801806000054057, 0.21353986999929475, 0.22237901800144755, 0.24692441599836457, 0.26798967700051435, 0.2362911250002071, 0.2275522079999064, 0.21184417000040412, 0.22630742699948314, 0.20815700099956302, 0.21427008499995281, 0.2148954260010214, 0.22819003599943244, 0.21104911700058437, 0.2051230269989901, 0.20886349500142387, 0.21816350399967632, 0.20975517599981686, 0.2181904739991296, 0.20262359400112473, 0.2227177099994151, 0.228513041000042, 0.2182533199993486, 0.22825533600007475, 0.21082407900030375], [0.2074885770016408, 0.21409095499984687], [0.20793390799917688, 0.21329662600146548, 0.22272303799945803, 0.24687491899931047, 0.268053535000945], [], [0.2223820520011941, 0.24681819399847882, 0.2681170910000219, 0.23629179100134934, 0.22754949099908117, 0.2117387439993763], [0.22282747300050687, 0.24700343199947383, 0.26792647799993574, 0.2365193339992402, 0.22729393300141965], [], [0.22481340800004546, 0.20817305000127817, 0.21427302399933978, 0.21488711299934948, 0.22819081000125152, 0.21104779799861717, 0.2048016330008977, 0.2091070940005011, 0.2180308459992375, 0.20983860200067284, 0.21831422499963082, 0.20261348500025633, 0.22271777800051495, 0.22725219799940533, 0.21949636499994085, 0.22826761699980125, 0.21083299900055863, 0.21583640599965292], [0.21482952400037902, 0.21462367999993148, 0.22846207399925333, 0.21000479100075609, 0.20522464599889645, 0.20951407700158597, 0.21817891099999542, 0.2093851449990325], [], [0.21435127800032205, 0.21481128899904434, 0.22846518299957097, 0.209671069000251, 0.20538838900029077, 0.20967077999921457, 0.21819352200145659, 0.20896890800031542, 0.21885782299978018, 0.2028266170000279, 0.22234113000013167], [0.21436486299899116, 0.21460781200039492], [0.2153377319991705, 0.22820002300068154, 0.21104230499986443, 0.2046378730010474, 0.2092314940000506, 0.21806109299905074, 0.209487715999785, 0.21847308600081305, 0.20280509599979268, 0.22271088600064104, 0.2271934099990176, 0.21957480600030976, 0.22824412599948118, 0.21081823200074723, 0.21574615399913455], [0.20859442800065153, 0.2052325929998915, 0.20951864999915415, 0.21817759700024908, 0.20938218499941286, 0.21857715700025437, 0.20281157600038568, 0.22230189900074038, 0.22759246900022845, 0.21964248699987365, 0.2279523409997637, 0.20973421099915868, 0.21685910999985936, 0.2128056830006244, 0.2139711960007844, 0.21285037899906456, 0.22608487800061994, 0.2169212310000148, 0.22207098699982453, 0.22945325399996364, 0.22500512999977218, 0.21453828700032318, 0.2282804339993163, 0.24701878400082933, 0.2716735049998533, 0.29481962699901487, 0.2362108420002187, 0.2083396250000078, 0.2110336149999057, 0.21331582400125626, 0.20439767199968628, 0.20453135099887731, 0.21223450300021796, 0.21923942000103125], [0.2047060840013728, 0.20948121699984767, 0.21811542300019937, 0.2094875120001234, 0.21847556200009421, 0.2028063999987353, 0.22257925499980047], [], [0.20519897499980289, 0.2095048660012253, 0.21818034699936106, 0.20948176300043997, 0.21846366099998704, 0.2028095490004489, 0.22257185699891124, 0.22735279600055947, 0.21959731899914914, 0.22796938400097133, 0.2108928809993813], [0.20960754899897438, 0.21827310500157182, 0.2089096569998219, 0.21881381699859048], [0.20923863099960727, 0.21806189600101789, 0.20948977499938337, 0.21844034000059764, 0.2028070979995391, 0.22257643100056157, 0.22735683700011577, 0.21958303399878787, 0.22797745900061273, 0.21093963199928112, 0.21569224199993187, 0.21295552999981737, 0.21475263200045447, 0.21185848700042698, 0.2260941990007268, 0.21691093199842726, 0.2222929120016488, 0.229247970999495, 0.22498813200036238], [0.20964486499906343, 0.2181812600010744, 0.20897356099885656, 0.21885934000056295, 0.20282510600009118], [0.209107356999084, 0.21803370600173366, 0.20948669599965797, 0.21847256699948048, 0.2028071099994122, 0.2227148860001762, 0.22719024900106888, 0.2195668249987648, 0.22825905600075203, 0.21080824099954043, 0.21585591599978216, 0.2127304860005097, 0.21468028600065736, 0.2119477679989359, 0.22600606600099127, 0.216908930999125, 0.22230283099997905, 0.22923749599976873, 0.22510767400126497, 0.21437830600007146, 0.22830583299946738, 0.24700820399993972, 0.2716766909998114, 0.294829235999714, 0.2361816690008709, 0.20891030699931434, 0.2105896400007623, 0.21385937400009425], [0.2181709830001637, 0.2097527700007049, 0.21819710099953227, 0.20261808800023573, 0.22271811099926708, 0.22851387900118425, 0.21825701299894718, 0.22824666300039098, 0.21082939199914108, 0.21590296100112027, 0.21284172599916928, 0.2144770470004005], [0.20988762999877508, 0.21828057800121314, 0.20280631899913715, 0.2226520670010359], [0.20969837300071958], [0.21853118800027005], [0.20324301299842773, 0.22225659300056577, 0.22780674999921757, 0.21942231100001663, 0.2281361650002509, 0.20958928700019896, 0.21701347700036422, 0.2125961849997111, 0.21394497599976603, 0.21200812000097358, 0.22682208100013668, 0.21690547300022445, 0.2223555900000065, 0.2293291930000123, 0.22513043899925833, 0.21445796800071548, 0.22799607900014962, 0.24726123899927188, 0.2716854810005316, 0.29483242399874143, 0.2361514710009942, 0.20796662399880006, 0.21072117400035495], [], [0.22251333199892542], [0.21816263499931665, 0.22794138499921246, 0.20972441300000355, 0.2168663740012562, 0.2126054349992046, 0.21393720800006122, 0.21208260000094015, 0.22682276100022136, 0.2168267149991152, 0.22235619599996426, 0.22944616799941286, 0.22502106400133925, 0.2144378199991479], [0.22845193700050004], [], [0.21556813999995939, 0.21277657199971145], [0.21561969600043085, 0.21293559699915932, 0.21471919400028128, 0.21186228099941218], [0.21552337800130772, 0.21295101099894964, 0.2147110639998573, 0.21185672400133626, 0.22609085499971115, 0.21691419200033124, 0.22218182199867442], [0.21313104799992288, 0.21376432699980796, 0.21269073999974353, 0.22637020100046357, 0.21669196800030477, 0.22235498800000641, 0.22945066600004793, 0.2250136129987368, 0.21448682400114194, 0.22795634499925654, 0.24735445199985406, 0.27156361500055937, 0.29483169599916437, 0.236249294001027, 0.20799478299886687, 0.21100266100074805, 0.21359530100016855], [0.21285918300054618, 0.21468880400061607, 0.21194465000007767, 0.22600168699864298, 0.21690977599973849, 0.22229940300167073, 0.22924095599955763, 0.22510407299887447, 0.21439026799998828, 0.22829727300086233, 0.24701193100008823, 0.2716768640002556, 0.2948266629991849, 0.23618903399983537, 0.20890161200077273, 0.2105912469996838, 0.21385207800085482, 0.20374165899920627, 0.20453583400012576, 0.21265613499963365, 0.21897869699932926], [0.21183403299983183, 0.2260366039990913, 0.216970379000486, 0.22207438300029025, 0.22945324600004824, 0.22500729199964553, 0.21454386199911823, 0.22827231700102857, 0.24702155500017398, 0.27166835199932393, 0.2947176990001026], [0.21277070999894931, 0.22623927400127286, 0.21696454899938544, 0.22208141599912778, 0.22945122200144397, 0.22501054299937095, 0.2145493699990766, 0.22826475000147184, 0.24702349099970888, 0.27156459399884625], [], [0.22637670600124693, 0.2166957099998399, 0.22235559599903354, 0.22945009700015362, 0.22501630700025999, 0.21449046700035979, 0.227943232999678, 0.24725815199963108], [], [0.2293818280013511, 0.22498941699996067, 0.21453042999928584, 0.22828918699997303, 0.24701373999960197, 0.2716762830004882, 0.2948248379998404, 0.23619881100057682, 0.20834854500026267, 0.21103416999903857, 0.21331341699988116, 0.20411389200125996, 0.20403378299852193, 0.21302265300073486, 0.21929288499995891, 0.20678623099956894, 0.20650025100076164, 0.22436105799897632, 0.20439413800158945, 0.22132461099863576, 0.20836344700001064, 0.21475822800130118, 0.2088034839998727, 0.2141487449989654, 0.19763088600120682, 0.20801983499950438, 0.20416249299887568], [0.2291941380008211, 0.22509830899980443, 0.21450607100086927, 0.2281783069993253], [0.2285777050001343, 0.24704187600036676, 0.2715634649994172, 0.29483559300024353, 0.2363413910006784, 0.20832753700051398, 0.210811847999139], [], [0.22792773299988767, 0.2473401309998735, 0.27156420100072864, 0.29483306799920683, 0.2362364759992488, 0.20800728900030663, 0.21100127800127666], [0.20798200799981714, 0.2109972549988015, 0.21359694200145896, 0.20404107799913618, 0.20427178899990395, 0.21238669299964386, 0.2198301780008478, 0.20678165999925113, 0.20648861700101406, 0.2245042590002413, 0.20446888199876412, 0.22104656500050623, 0.2084446469998511, 0.2148969539994141, 0.208442114000718], [0.2081548619989917, 0.2109433639998315, 0.21350608300053864, 0.20421393499964324, 0.2040322560005734, 0.21257282399892574, 0.21957542800009833, 0.20695250800054055, 0.20641428800081485], [0.2088431540014426, 0.21055809499921452, 0.21394888199938578, 0.203629401001308, 0.20473692700034007, 0.21260727099979704, 0.2189381809985207, 0.20718208400103322, 0.20649802499974612, 0.22403864999978396, 0.20454896000046574], [0.21063452399903326, 0.21325111200167157, 0.20462812899859273, 0.20529566000004706, 0.2112499860013486, 0.21928764199947182, 0.2086291399991751], [0.21047646599981817, 0.21394022999993467, 0.2043584680013737, 0.20491152099930332, 0.2116953309996461, 0.21893445500063535, 0.20846019800046633, 0.20565599699875747, 0.22362533600062307, 0.20470956499957538], [0.2109046040004614, 0.21349683100015682, 0.2045385539986455, 0.20500394800001231, 0.21127587200135167, 0.21956375599984312, 0.20821977400009928, 0.20594749099836918, 0.22362631000032707, 0.20505464800044138, 0.22060262400009378], [0.21059647600122844, 0.21324354599892104, 0.2050567320002301, 0.20487412600050448, 0.21126273700065212, 0.21927619599955506, 0.2086534459995164, 0.20550559799994517, 0.22365758399973856, 0.20482507700035057, 0.22071115399921837, 0.20872986800168292, 0.21486900099989725, 0.20916372099964065, 0.21421461600039038, 0.19691009599955578, 0.2086898019988439, 0.20568126500074868, 0.20724372199947538, 0.20764713500102516, 0.21938623599999119, 0.21512145599990617, 0.21822099999917555], [0.2109026639991498], [0.2133199270010664, 0.204399073998502, 0.2044353110013617], [0.20514910199926817, 0.20528305000152614, 0.21120822800003225, 0.2192474809999112, 0.20865059700008715], [0.2045247539990669, 0.2048349960004998], [], [], [0.2046035090006626, 0.21107201899940264, 0.21928144699995755, 0.20875700900069205, 0.20585628700064262, 0.22302624999974796, 0.20514747800007171], [], [0.20443264399909822, 0.2118069780008227], [0.20452316800037806, 0.21183461600048759, 0.21970285999850603, 0.20706405200144218, 0.2070017159985582, 0.22371376100090856, 0.2047749110006407, 0.220733593998375, 0.2089639570003783, 0.21476568800062523], [0.2131748299998435, 0.218952362998607, 0.20667342900014773, 0.20692216899988125, 0.22416328000144858, 0.20416594499874918, 0.22134351600107038, 0.2083369859992672, 0.2149144390004949, 0.20872165999935532], [], [0.21261270499962848, 0.2189413530013553, 0.20717383499868447, 0.20650085400120588, 0.22404085000016494, 0.20443819199863356, 0.22106541900029697, 0.2086336800002755, 0.2148634069999389, 0.20894187200065062, 0.21442775200011965, 0.19691670700012764, 0.20862223099902621, 0.20440288800091366, 0.20855693699922995, 0.20732697200037364, 0.2197648940000363, 0.21510475699869858, 0.21823811600006593, 0.21166578600059438, 0.21383285999945656, 0.2298633760001394, 0.23032703300123103, 0.21191891899979964, 0.2273540089991002, 0.21171121500083245, 0.2141330590002326, 0.21786617199904867, 0.3814412520005135, 0.030406690000745584, 0.22149921199888922, 0.21714561299995694, 0.20564928500061797], [0.21271083100145916, 0.2189393199987535], [0.21899447699979646, 0.20671620899884147, 0.20691155800159322, 0.224155793999671, 0.20418558799974562, 0.22134034800001245, 0.20834454500072752, 0.21476074999918637, 0.20880214600038016], [0.20754164999925706, 0.20679778100020485, 0.22371283800021047, 0.20477073499932885, 0.22088676200110058, 0.20881160099997942, 0.2148589369990077, 0.2087255650003499, 0.21442218700030935, 0.1971058669987542, 0.20818748500096262, 0.20465420199980144, 0.20861175400023058, 0.20720344300025317, 0.21991766999963147, 0.21519248299955507, 0.21802376800042111, 0.21188212000015483, 0.2138346259998798, 0.22979707900049107, 0.23040597399995022, 0.21174998700007563, 0.22751021699878038, 0.2108879870011151, 0.214308180999069, 0.21699527100099658, 0.38178319100006775, 0.03127975699862873], [0.20884810000097787, 0.20565603199975158, 0.22323870500076737, 0.20514943599846447, 0.220570065001084, 0.20894965200022853, 0.21587973900022916, 0.20871323499886785, 0.21360443999947165, 0.19755226200140896, 0.20816607699998713, 0.2055161809985293, 0.2072453820001101, 0.20765758300149173, 0.2193433049997111, 0.2153335370003333, 0.21816295200005698, 0.2122608579993539, 0.21326181199947314, 0.23005152400037332, 0.23009310099951108, 0.21211277400107065, 0.2271581969998806, 0.21078748699983407, 0.21419464199971117, 0.21699088999957894, 0.38179391199992097, 0.03214295600082551, 0.22069663399997808, 0.21717798300051072, 0.20610868799849413, 0.21295872500013502, 0.21439653299967176, 0.21296324400100275, 0.21789278500000364, 0.21147639999981038, 0.21452210499955982, 0.22288586899958318, 0.242256150000685, 0.2669753789996321, 0.23782430600113003, 0.21467428599862615, 0.21425721800005704, 0.2351666419999674, 0.31525458800024353, 0.09747634000086691, 0.22225352999885217, 0.24368503000005148, 0.21195438200084027, 0.2102628279990313, 0.20573764800064964, 0.21464124700105458, 0.23445318899939593, 0.22138114699919242, 0.20849788499981514, 0.2122390840013395, 0.20981947600012063, 0.22211946199968224, 0.22785075699903246, 0.24527629000112938, 0.2731468189995212, 0.27211158700083615, 0.21986845299943525, 0.23109750900039217, 0.20546141500017256, 0.20953357399957895, 0.21291639899936854, 0.22520744699977513, 0.21700300100019376], [0.2055645820000791], [0.2058482129996264, 0.22327979799956665, 0.20490505800080427, 0.22061205399950268, 0.2089145419995475, 0.21596965200114937, 0.20860994499889784, 0.21359817099983047, 0.19755207500020333, 0.20816744200055837, 0.20551409700055956, 0.20726570899932995, 0.20764232799956517, 0.2193364049999218, 0.21534029000031296, 0.21815634700033115, 0.21226763499907975, 0.2143540249999205], [], [0.20595943499938585, 0.22401005999927293, 0.2046668220009451, 0.22084343799906492, 0.20862246199976653, 0.21486884300065867, 0.2090011649997905, 0.2143443870008923, 0.19692214699898614, 0.2086234640009934], [0.22368037900014315, 0.20481206200020097, 0.22071456499907072, 0.20898537300126918, 0.2147622529992077, 0.20883961800063844, 0.21391407899864134, 0.19761362100143742, 0.2081950109986792, 0.20457267700112425], [0.22324327000023914, 0.2049610769990977, 0.2205874909996055, 0.20893421300024784, 0.21588691100077995], [0.2048580150003545, 0.2206605249994027, 0.20882093900036125, 0.21492336899973452, 0.208875240999987, 0.21392003599976306, 0.19761580900012632, 0.2080768360010552, 0.20455504699930316, 0.20878145200003928, 0.20722782800112327, 0.21994230299969786, 0.215052616000321], [0.2211542429995461, 0.20835316800003056, 0.21481843699984893, 0.2085094129997742, 0.21379323200017097], [0.22098898200056283, 0.2086191719990893, 0.21486726200055273, 0.20894106100058707], [0.2159759189999022, 0.20949089799978537, 0.2137649930009502, 0.19688427899927774, 0.20870024299983925], [0.21475503300098353, 0.20880623599987302, 0.2135788899995532, 0.19770589899962943, 0.20850942700053565, 0.20414535999952932, 0.2082127899993793, 0.2079134290015645, 0.22006452200002968, 0.21522676099993987, 0.21816490799938038, 0.21177218400043785, 0.21397116799926152, 0.22969260299942107, 0.2283607170011237], [0.21476265199999034, 0.20884028899854457, 0.2139161890008836, 0.1976149109996186, 0.20820122199984326, 0.20448210500035202, 0.2087508410004375, 0.20722583399947325, 0.21992880899961165, 0.21517753100124537, 0.2179732979984692], [0.2149580479999713, 0.2094829279994883, 0.21374825400016562, 0.19749320600021747, 0.20813249999991967, 0.20557352299874765, 0.2072430420012097, 0.20765235599901644, 0.21937440700094157, 0.21530707599958987, 0.21808084400072403, 0.21194016499975987, 0.21364781899865193, 0.22974242100099218, 0.23041490099967632, 0.21210764100032975, 0.22715785000036703, 0.21045446700009052, 0.2137349329987046, 0.21766909200050577, 0.3817926190004073, 0.03212231999896176, 0.22056524500112573, 0.21735226300006616, 0.20619144800002687, 0.21296151699971233, 0.2143970260003698, 0.2129620050000085, 0.2178903000003629, 0.21132113399835362, 0.2146602740012895, 0.2228760689995397, 0.24209434700060228, 0.2671591789985541, 0.23715963100039517, 0.2151570490004815, 0.2143717300004937, 0.23499262499899487], [0.20872243100166088, 0.21361392499966314, 0.19755332400018233, 0.20810020499993698, 0.20555849599986686, 0.20724994800002605, 0.2076559779998206, 0.21935812199990323, 0.21531910299927404, 0.21809753500019724], [0.21357324100063124, 0.19769963500039012, 0.20848577799915802, 0.20417014300073788, 0.20815279899943562, 0.20789957600027265, 0.22014670299904537, 0.21521758200105978, 0.21818798599997535, 0.21174819499901787, 0.2139743890002137, 0.2290995240000484], [0.21451086600063718, 0.19692290899911313, 0.2081781550004962, 0.20466769999984535, 0.20871195300060208, 0.20709556299880205, 0.21991155500109016, 0.21519954799987318, 0.21801821400003973, 0.21188777499992284, 0.21383354299905477, 0.22979665100137936, 0.2304066509987024, 0.21176114500121912], [0.21422224699927028, 0.1969050879997667, 0.20869178300017666, 0.20431826999993064, 0.20855218100041384, 0.20746907700049633, 0.21961506099978578, 0.21511073599867814, 0.21823287100050948, 0.2116713619998336, 0.21383143599996401], [0.2139248499988753, 0.1976177460001054, 0.20800570800020068, 0.2044281119997322, 0.20862689400019008, 0.20736275300077978, 0.21995577400048205, 0.2152278679986921, 0.21813174199996865, 0.21193834200130368, 0.21383681899897056, 0.22979719700015266, 0.2303992550005205, 0.21073755599900323, 0.2283779860008508, 0.211877652000112, 0.21369631800007483], [0.2144340890008607, 0.1969134689989005, 0.20817077300125675, 0.20467529699999432, 0.2087148899991007, 0.20709053900100116, 0.2199054550001165], [0.1976417930000025, 0.20847972199953801, 0.20415327299997443, 0.2088575010002387, 0.2073913590011216, 0.2199627789996157, 0.21522719899985532, 0.2181451289998222, 0.2117932019991713, 0.21396956300122838, 0.22970611900018412], [], [0.19729355199888232], [0.19688020500143466, 0.20866374199977145], [0.2080516020014329], [0.20810089699989476, 0.2055612599997403, 0.20724464600061765, 0.20765517799918598, 0.21936590100085596, 0.21531348999997135, 0.21807403599996178, 0.2119492519996129, 0.21364400099992054, 0.22974298299959628], [], [], [0.2044834879998234], [0.20447904499997094, 0.20875068500026828, 0.2072269000000233, 0.21993549800026813, 0.21516524399885384, 0.21798726300039561, 0.2119614109997201, 0.2138347479994991, 0.2297963230012101, 0.23040548999961175, 0.21074843799942755], [0.20551919399986218, 0.20724236299975018, 0.20765665600083594, 0.2193504570004734, 0.21532734199900005, 0.21816759499961336, 0.21188940899992303, 0.21362668000074336, 0.23004636900077458, 0.23009952099891962, 0.21211116500126082, 0.2271589159990981, 0.21065762000034738, 0.21430475099987234, 0.21699371599970618, 0.3817878469999414, 0.03202396100095939, 0.22079513299831888, 0.21721903100115014, 0.20609484699889435, 0.21296119700127747, 0.21439409899903694, 0.21296478000112984, 0.21789186599926325, 0.2114686109998729, 0.21454471000106423, 0.22287131599841814, 0.2422143359999609], [0.2046659939987876, 0.2087090300010459, 0.2070864729994355, 0.21996637800111785, 0.21512842799893406, 0.21824410699991859, 0.21166218300095352, 0.21383325699935085, 0.22979605900036404, 0.23040912299984484, 0.21185084999888204, 0.227397563001432, 0.21161525899879052, 0.21370249800020247, 0.21823696300089068, 0.38124011999934737], [0.2072527030013589, 0.20744027999899117, 0.21959917599997425, 0.215115971999694, 0.21822759700080496, 0.21167674400021497], [0.20870452200142608, 0.20720599699961895, 0.2199235249991034, 0.21518524299972341, 0.21802883600139467, 0.21186166199913714, 0.21383309900011227, 0.22979843400025857, 0.23040342499916733, 0.21074621200023103, 0.22837776800042775], [0.2084809240004688, 0.20745244699901377, 0.2200082970011863, 0.21505045300000347, 0.21812568200039095, 0.2119053789992904, 0.21384387599937327, 0.22978941300061706, 0.23039771000003384, 0.2107311790005042, 0.22826354399876436], [0.20863117299995793, 0.2073665819989401, 0.21995875200082082, 0.21522805499989772, 0.21813782299977902, 0.21180339400052617], [0.20750189300088095, 0.21996702300020843, 0.21522800799903052, 0.21815322100155754, 0.21178401799988933, 0.2139717859990924, 0.22970176899980288, 0.23049173999970662, 0.21059747000072093, 0.2283838219991594, 0.21134114600135945], [0.20723010199981218, 0.21994970299965644, 0.21505023300051107, 0.21811903699926916, 0.2119388560004154, 0.21383322099973157, 0.2297980319999624, 0.23040286099967489, 0.21074128899999778, 0.2283793839997088, 0.21191024600011588], [0.21977678100120102, 0.2151002399987192, 0.2182393300008698, 0.211665990000256, 0.21383218599839893, 0.2297981070005335], [], [0.21600384499834036, 0.21809024000140198, 0.2117317299998831, 0.2138289859994984, 0.22974885000076029, 0.2303229899989674, 0.21192200199948275, 0.22734986400064372, 0.21148085499953595], [0.21277731000009226, 0.21365338600116957, 0.22974458600037906, 0.23040949499954877, 0.21183811999981117, 0.22734763500011468], [0.2118872820010438, 0.21362844400027825, 0.23001425300026312, 0.23012716499943053, 0.21211161099927267, 0.22715802300081123, 0.21084762799910095, 0.2141535290011234, 0.2169912139997905, 0.3817920450001111, 0.031986313999368576, 0.22079472100085695, 0.2172256539997761, 0.20608724799967604, 0.21296291699945868, 0.21439558200108877, 0.21296264699958556, 0.21789226900000358, 0.21146170999963942, 0.21455836099994485, 0.22286433599947486, 0.24206309700093698, 0.2671826890000375, 0.23781431899988092, 0.21459325499927218, 0.21432169699983206, 0.23515517600026214, 0.3153073619996576, 0.09718074700140278, 0.2224121399995056, 0.24379950000002282, 0.2118461659993045, 0.2103941980003583, 0.20573894300105167, 0.21464307899987034, 0.23441044399987732, 0.2213514609993581], [], [0.21194339100111392, 0.21364013600032195, 0.22979691499858745, 0.23034457900030247, 0.21210878900092212, 0.2271600859985483, 0.2104662690016994, 0.2141618709993054, 0.21730496899908758, 0.38177541900040524, 0.0320634110012179, 0.22077099199850636, 0.21724277200155484, 0.20609434499965573, 0.21296251300009317, 0.21439519500017923, 0.21296183300000848, 0.21789218499907292, 0.21131983600025706, 0.21470589399905293, 0.2228603200001089, 0.2420694900010858, 0.26717599400035397, 0.2372158540001692, 0.21512584099946253, 0.2143520499994338, 0.23499819400058186, 0.3154773699989164, 0.09702648800157476, 0.2222802039996168, 0.24393847699866456, 0.21197832800135075, 0.21042847199896642, 0.20574153200141154, 0.21464246499999717, 0.23441698199894745, 0.22135311199963326, 0.20858011200107285, 0.21223786199880124, 0.20982221200029016, 0.222124175999852, 0.22785000200019567, 0.24527083500106528, 0.27314714299973275, 0.2721094369990169, 0.21986730600110604, 0.23099036199891998, 0.2055781190010748, 0.20953132399881724, 0.21291039600146178, 0.2240820499991969, 0.2177709940006025, 0.23551561199928983, 0.2576354890006769, 0.2411847069997748, 0.2231364629988093, 0.21031232700079272, 0.2266277849994367, 0.22656615400046576, 0.2025570149999112, 0.20945011799994973, 0.22574795199943765, 0.21910318800109962, 0.21108227399963653, 0.206183226999201, 0.20596382800067659], [0.2291180109987181, 0.22996768600023643, 0.21211386300092272, 0.22715825500017672, 0.2112475429985352, 0.21378531000118528, 0.21709575599925302, 0.3819591560004483, 0.0318480259993521, 0.2208285460001207, 0.21702986499985855, 0.20623167200028547, 0.21285978400010208, 0.21437763600079052, 0.21296208999956434, 0.21789360699949611, 0.2114796780006145], [0.21245637700121733, 0.22715877500013448, 0.21150765799939109, 0.214175584998884, 0.21787102700000105, 0.3812509190011042, 0.03081423699950392, 0.22129422800026077, 0.21715854200010654, 0.2058132519996434, 0.21235180999974546, 0.21488557100019534, 0.21306884499972512, 0.21716014800040284, 0.21191346699924907, 0.21478250800100795, 0.2228672519995598, 0.24211581400049909, 0.2669743059996108, 0.23736026200094784, 0.2162154149991693, 0.21384790900083317, 0.2344684989984671, 0.3155167960012477, 0.09826238099958573, 0.22197033100019326, 0.24345992199960165, 0.21187221299987868, 0.20994415700079117, 0.20586966199880408, 0.21464379200006078, 0.2344285690014658, 0.22135657199942216, 0.2071664420000161, 0.21354427999904146, 0.20966101800149772, 0.22231702099998074, 0.22783246299877646], [0.2275193909990776, 0.211813195999639], [0.22736052199979895, 0.21165420199940854, 0.2141839420000906, 0.2178679579992604, 0.3812481109998771, 0.030602839000493987, 0.221501153000645, 0.21715155600031721, 0.20563588699951652, 0.21248829899923294, 0.21488420500099892, 0.21306615200046508, 0.21716222099894367, 0.21191280899984122, 0.2147815879998234, 0.22278208500028995], [0.21492956000111008, 0.21842356100023608], [0.2140568049999274, 0.2172757719999936, 0.3817789750009979, 0.03099902999929327, 0.22182973000053607, 0.21723452599871962, 0.20469727599993348, 0.2132827109999198, 0.21508511000138242, 0.21187401399947703], [], [0.2177183519997925, 0.3814017300010164, 0.029978102998938994, 0.2219255529998918, 0.21714001700092922, 0.20486302300014358, 0.2129843759994401], [0.21731524300048477, 0.381771939999453, 0.031337618000179646, 0.22134255600030883], [0.38080958899990947, 0.031232306000674726, 0.22145371599981445, 0.2170398930011288, 0.2054701599990949, 0.21277958300015598, 0.21490420299960533, 0.21306798300065566, 0.21715765099907003, 0.21191662599994743, 0.21478179200130398, 0.2227711809991888, 0.24218152700086648, 0.26703897299921664, 0.23728144599954248, 0.216236022000885, 0.2138214259994129, 0.23457620500084886, 0.31530784299866355, 0.09785205800108088, 0.22228102699955343, 0.24365385199962475], [0.2169650920004642, 0.3817930940003862, 0.03149525799926778, 0.2214605750014016, 0.21705081399886694, 0.20546232800006692, 0.21277823300079035, 0.21490601000004972, 0.2130656720000843, 0.21715487300025416, 0.21192151199829823, 0.21478260799995041, 0.22275840300062555, 0.24219549699955678, 0.26703745300073933, 0.23728269899947918, 0.2156070950004505, 0.21426771600090433, 0.23476178699820593, 0.31529740300175035, 0.09783352499835019, 0.2222656880003342, 0.24367665800127725, 0.21195904899832385, 0.2092126850002387, 0.20594059399991238, 0.21503812999981164, 0.23459198300042772, 0.22145755000019562, 0.20659360900026513, 0.21404941500077257, 0.20911882799919113, 0.22289155299949925, 0.22777777300143498, 0.24538939999911236, 0.2730271559994435, 0.2719626939997397, 0.21988064700053656], [], [0.030393892999200034, 0.22188782800003537, 0.21702149100019597, 0.20477149600083067, 0.21317588799865916, 0.21508743900085392, 0.2130727099993237, 0.2167828229994484, 0.21231499200075632, 0.21478043199931562, 0.22236337499998626], [0.22097157999996853], [0.22069574099987221, 0.21718681499987724, 0.20610232199942402, 0.21295973999986018, 0.2143949520013848, 0.2129630769995856, 0.21789341799922113, 0.21147334300076182, 0.21453217700036475, 0.22287905899975158, 0.24225740099973336, 0.26697257599880686, 0.23782251400007226, 0.2146624270008033, 0.21424799499982328, 0.235150350999902], [0.22096071600026335, 0.2172549330007314, 0.2060458279993327, 0.21236131300065608, 0.21488545799911662, 0.21306690799974604, 0.2171603070000856, 0.21191308500056039, 0.21478296100031002, 0.2228613610004686, 0.24206433299877972], [0.2056479950006178, 0.21278063399950042, 0.21490784699926735, 0.2130636730016704, 0.21714873599921702, 0.21193026599939913, 0.21478071700039436, 0.22246243699919432, 0.24239141500038386, 0.2671391920011956, 0.23728143999869644, 0.21558362300129374, 0.2142520389988931, 0.23479428599966923, 0.3149564220002503, 0.0978668400002789], [0.20612728300147865, 0.21282895999866014, 0.2143772400013404, 0.21296266599892988, 0.2178941729998769, 0.2115839470006904, 0.2143852280005376, 0.2230545689999417, 0.24214448999919114, 0.26693618100034655, 0.23782222899899352], [0.2130649930004438, 0.21399735500017414, 0.2132892939989688, 0.21756702800121275, 0.21159193399944343, 0.2143705279995629, 0.22306298700095795, 0.24214162899988878, 0.2673461710000993, 0.23748988799889048, 0.2152984069998638, 0.2137956220012711, 0.23506398199970135, 0.3156306399996538, 0.0975564079999458, 0.22198957600085123, 0.2434642049993272, 0.21187624800040794, 0.21037543400052527, 0.2056078029982018, 0.21463013800166664, 0.23444647299947974, 0.22137270900020667, 0.2085038519999216, 0.21224740499928885, 0.20981437000045844, 0.22210534400073811, 0.22784878199854575, 0.24540498399983335, 0.2730219550012407, 0.27211476899901754, 0.22036563100118656, 0.23070417499911855, 0.20546906900017348, 0.20947040300052322, 0.21284929099965666, 0.22520869599975413, 0.217118644999573, 0.23504015000071377], [0.21299060999990616, 0.21505401700051152, 0.21306691500103625, 0.2167819309997867], [0.2128628340014984, 0.21437895799863327, 0.21296227700076997, 0.21789235799951712, 0.21147812600065663, 0.21451431800051068, 0.22304648799945426, 0.24211165999986406], [0.21298958499937726, 0.2149125300002197, 0.21306462599932274, 0.21713831000124628, 0.211939397999231, 0.214780055999654, 0.22245759600082238, 0.2424036319989682, 0.2671322340011102, 0.23728059399945778, 0.21639522800069244, 0.213857435999671, 0.23438280099981057, 0.31488098800036823], [0.2125011429998267, 0.2148844960011047, 0.21306673199978832, 0.21716136199938774, 0.21191309300047578, 0.21478260599906207, 0.2227759960005642, 0.24217141599910974, 0.26704313500158605, 0.23728227599895035], [0.2144008870000107, 0.21296645700022054, 0.2171588060009526, 0.21191384599842422, 0.21478139700047905, 0.2228724400010833, 0.2421101619984256, 0.2669763990015781], [0.21687398700123595, 0.212489702998937, 0.21463157500147645, 0.22237492899876088, 0.2426438460006466, 0.2671518940005626, 0.2372809979988233, 0.21571555599985004, 0.21426285600136907, 0.23455845699936617, 0.3148765839996486, 0.09846038800060342, 0.2222609589989588, 0.24367916300070647, 0.21195661099955032, 0.20918034100031946, 0.2059387860008428, 0.21503877699979057, 0.2346098689995415, 0.2214484430005541, 0.2065932959994825, 0.2132755629991152, 0.2095937470003264, 0.2227474160008569, 0.22823078900000837, 0.2453690900001675, 0.27267187899997225, 0.27232786499916983, 0.2198836500010657, 0.23158885199882207, 0.2044755509996321, 0.2092716860006476, 0.21323611700063339, 0.22409778099972755], [0.2168757130002632, 0.2123379839995323, 0.21461821100092493, 0.22251685399896814, 0.2425430920011422, 0.2671193049991416, 0.23727885100015556, 0.21634890700079268, 0.21382713699858868, 0.23435158299980685, 0.3148800190010661], [0.2167850139994698, 0.2123158260001219, 0.21477643000071112, 0.22236393700040935, 0.242529088000083, 0.26712773100007325, 0.23727851399962674, 0.21637393799937854, 0.2137936350009113, 0.23435943699951167], [0.21132542400118837, 0.21466555999904813, 0.22287379400040663, 0.24210231300094165, 0.2670924999983981], [0.21422561000144924, 0.2230509749988414, 0.24213895200045954, 0.2673633009999321, 0.23748291099946073, 0.21531431800030987, 0.2138642930003698, 0.23496761100068397, 0.31563533799999277, 0.09761766199881095, 0.22241260500049975, 0.24302225800056476, 0.2123671879999165, 0.21012453799994546, 0.20567002299867454, 0.21441923600104928, 0.23433358799957205, 0.22169932200085896, 0.20867933399858885, 0.2118929450007272], [0.22370177000084368, 0.24211775999901874, 0.2669786740007112, 0.23782462800045323, 0.21531393700024637, 0.213818475998778, 0.2349615300008736, 0.3156780899989826, 0.0971007730004203, 0.22227632499925676, 0.24365517200021714, 0.21196041500115825, 0.21022225699925912, 0.20573517800039554, 0.21464131900029315, 0.23445301799984009, 0.2213781390000804, 0.20849918400017486, 0.21224102700034564, 0.209818526998788, 0.22211440600040078, 0.22784990400032257, 0.24528278099933232, 0.2731464660009806, 0.2721142589998635, 0.22035437199883745, 0.23065135100114276, 0.20541284999853815, 0.209533792000002], [0.2228613019997283, 0.2420779969997966, 0.26716975800081855, 0.23715522199927364], [], [0.21488943599979393, 0.2143133419995138, 0.2349839990001783, 0.3154832250002073, 0.09713073499915481, 0.22220447000108834, 0.24392467100005888], [0.21381659200051217, 0.2345903189998353, 0.3149705249998078, 0.09811913799967442, 0.22214150999934645], [0.31554370500089135, 0.0978747029985243, 0.22227196300082142, 0.24359784999978729, 0.21195154300039576, 0.20925387900024361, 0.20594109299963748, 0.21503836599913484, 0.23459933500089392, 0.22145217999968736, 0.20659334400079388, 0.2140415599988046, 0.20913315800135024, 0.2225376269998378], [0.31557408399930864], [0.09827497500009486, 0.22196423700006562, 0.2434624249999615, 0.2118743050014018, 0.20993737099888676, 0.2058705370000098, 0.21464944999934232, 0.2344331090007472, 0.22135875899948587, 0.20686227300029714, 0.21384095400026126, 0.20966311099982704, 0.22232178800004476, 0.2277377049995266, 0.24542579599983583, 0.27314185200157226, 0.2718481769989012, 0.2200549190001766, 0.23141721100000723, 0.20526264699947205, 0.20936895500017272, 0.2130351129999326, 0.22367980600029114, 0.21819422999942617, 0.23551326300002984, 0.2579602430014347, 0.24121018400001049, 0.22311652799908188, 0.21114357999977074, 0.22583400900111883, 0.2264508839998598, 0.20424364199971023, 0.20788057199933974, 0.2255814640011522, 0.2193112699987978, 0.21205664000081015, 0.20474586700038344], [0.09815929400065215, 0.22239928999988479, 0.24380680699869117, 0.21184748400082754, 0.2093310330001259, 0.2058399620000273, 0.2150625840004068, 0.2346520849987428, 0.22134418400128197, 0.20667519499875198, 0.21286168500046188], [0.2219072320003761], [0.2223882530015544, 0.24338133799938078, 0.21196689499993226, 0.20880178600054933, 0.20618869299869402, 0.21486075600114418, 0.23444962199937436, 0.22136849299931782, 0.20673264900142385, 0.2139171679991705, 0.20910686500064912], [0.2098775359991123, 0.20978573499996855, 0.2061885519997304, 0.21486012400055188, 0.2344424050006637, 0.2213654890001635, 0.2067471319987817, 0.21391135300109454, 0.20919597499960219, 0.22278576799908478, 0.22776596400035487, 0.24540153599991754, 0.2731269630003226, 0.2718525349991978, 0.2199829850014794, 0.23123241000030248, 0.20514910199926817, 0.20966531500016572, 0.2128414420003537, 0.22384966999925382, 0.2182823750008538, 0.2355011559993727, 0.257732883999779, 0.24118761899990204, 0.22313156400014122, 0.21030451799924776, 0.22664427800009435, 0.2265094370013685, 0.2026324639991799, 0.20944610300102795, 0.22575874799986195, 0.21899649199986015], [0.2095969909987616, 0.20574587200098904, 0.21464236400061054, 0.23442267399877892, 0.22135523300130444, 0.20718491999832622, 0.21353273300155706, 0.20965758099919185, 0.22231405499951506, 0.22789726799965138, 0.24526099500144483, 0.2731426829996053, 0.2720909420004318, 0.21981877599864674], [0.20587936700030696, 0.21465612999963923, 0.23443655099981697, 0.2213623790012207, 0.2068516549988999, 0.2138451150003675, 0.20956949699939287, 0.22238983500028553, 0.22775865500079817, 0.24541437500010943, 0.2731382889996894, 0.27184735700029705, 0.21998854499906884, 0.23140693100140197, 0.2053233589995216, 0.2093802629988204, 0.21279856200089853, 0.22390423300021212, 0.2181970839992573, 0.2355116660000931, 0.2578425610008708, 0.24118218399962643, 0.22327773500001058, 0.21095724099905055, 0.22588827800063882], [0.20567981000021973, 0.21441291100018134, 0.23433874500005913, 0.22136965100071393, 0.20867437000015343, 0.21207247099846427, 0.20981241300069087, 0.2221012760001031, 0.22784728899932816, 0.24541817300087132, 0.2730168429989135, 0.2721155710005405, 0.22036973499962187, 0.23071588099992368, 0.2054972980004095, 0.20943887400062522, 0.21285267199891678, 0.22350759800065134, 0.21819537699957436, 0.23551307300112967, 0.25809628299975884, 0.2411337369994726], [0.20561550300044473, 0.2146322209991922, 0.23444942199967045, 0.22137529400060885, 0.20850140000038664, 0.21224483699916163, 0.20981552400007786, 0.2221098450008867, 0.22784952399888425, 0.24529023300055997], [0.20582137100063846, 0.21501866099970357, 0.23466152099899773, 0.2213774440006091, 0.2065998079997371, 0.21405212200079404, 0.2091096149997611, 0.22289528100009193, 0.22777047399904404, 0.24539540600017062, 0.27304265199927613], [0.2144668279997859, 0.23434818100031407, 0.22137147699868365, 0.20850584800064098], [0.21485860999928263, 0.2344628989994817, 0.22137220800141222, 0.20660799199868052], [], [0.20659353700102656, 0.21326960299847997, 0.20944499800134508, 0.2223219280003832, 0.22875976599971182, 0.2453827099998307, 0.27255320400036, 0.2724455069983378, 0.2198817170010443, 0.23153551799987326], [0.20837700800075254, 0.2120596349996049, 0.20980918299937912, 0.2220979450012237, 0.22784620999846084, 0.24575826700129255, 0.2726838639991911, 0.27211709400035033, 0.22037097599968547, 0.23082414400050766, 0.20538161500007845, 0.20943697999973665], [0.21230726299836533, 0.20957977600119193, 0.22231043399915507, 0.2279016070006037, 0.24526076300026034, 0.2731449069997325, 0.2721014559992909, 0.2198662830014655, 0.23144442800003162, 0.2051470119986334, 0.2093751810007234, 0.21304520999910892, 0.22367017299984582, 0.21819317100016633, 0.23551435900117212, 0.2580832530002226, 0.24170680599854677], [0.2138498280000931, 0.20956320599907485, 0.22240237700134458, 0.2277615679995506, 0.2454073859989876, 0.2731341220005561, 0.27184834299987415, 0.21998825400078204, 0.23141225699873758, 0.20532565100074862, 0.20937651399981405, 0.21279718299956585, 0.22390076100055012, 0.21820200600086537, 0.23550835799869674, 0.2578451019999193, 0.2411815020004724, 0.22327680600028543, 0.21095075799894403, 0.22589553400030127, 0.2264834770012385, 0.2038097429995105, 0.20835327900022094, 0.22565526200014574, 0.21928791199934494, 0.21124528399923292, 0.2055152030006866, 0.20613679900088755, 0.2089563889985584, 0.203818214000421], [0.21189405100085423, 0.20968675299991446, 0.22209466499953123, 0.22784493300059694, 0.24577709099867207, 0.27267237300111447, 0.2721179050004139, 0.22037280699987605, 0.2308193979988573, 0.20537685199997213, 0.20947165600045992, 0.2128151680008159, 0.22520545099905576, 0.21713775900025212, 0.23521240999980364, 0.25779640400105563, 0.24178228799974022, 0.22254167499886535, 0.21102138000060222, 0.22583371300061117, 0.22644280399981653, 0.2042935489989759, 0.2083325240000704, 0.22515285600093193, 0.2192446930002916, 0.21215189899885445, 0.20530879299985827, 0.20623571100077243, 0.2084699120005098, 0.2040413319991785, 0.21408248499938054], [0.20899527599976864, 0.22260927900060778, 0.2282159979986318, 0.24537618500107783, 0.27267563299938047, 0.27232734199969855, 0.2198829460012348, 0.23162283099918568], [0.22212976199989498, 0.22785128300165525, 0.24526492499899177, 0.2731445250010438, 0.27210846999878413, 0.21986579100121162, 0.2309911899992585, 0.20558763799999724, 0.2095275749998109, 0.21290426400082652, 0.22407763099909062, 0.21777973999996902, 0.2355156800003897, 0.25762853900050686, 0.24118546199861157, 0.2231346320004377, 0.21030875600081345, 0.22663585699956457, 0.22649957800058473], [0.22232731400072225, 0.2277388569982577, 0.2454191750002792, 0.2731414690006204, 0.27184662299987394, 0.21998944600090908], [0.22253500500119117, 0.22815911799989408, 0.2453821959989, 0.2726786370003538], [0.22825121599998965, 0.24536051900031453, 0.27266578700073296, 0.27233156399961445, 0.21988520400009293, 0.23158185899956152, 0.20446613800049818, 0.20927058999950532, 0.21323744499932218, 0.22410613500142063, 0.21840679999877466, 0.23523930500050483, 0.25820896699951845, 0.241184313001213, 0.22326916299971344, 0.21018265500060807, 0.22662669799865398, 0.22655874200063408, 0.20343759000024875, 0.20869440199930978, 0.22568402100114326, 0.21927074899940635, 0.21096438799941097, 0.20498285000030592, 0.20644199900016247, 0.20876076000058674, 0.20373166499848594, 0.21491262300150993, 0.21378622699921834, 0.20841696400020737, 0.22164428699943528, 0.21512512899971625, 0.21315268100079265, 0.21313474800081167, 0.2173860679995414, 0.20683759399980772, 0.2080601329998899, 0.20953553300023486, 0.20754132699948968, 0.20687469400036207, 0.20802393200028746, 0.20894205500007956, 0.22809894499914662, 0.22498793700106035, 0.25624776399854454, 0.2827047840000887, 0.3020421820001502, 0.22945248799987894, 0.2197670770001423, 0.2170391510007903, 0.21044613499907427], [], [0.20319976800055883, 0.20976120399973297, 0.21285187099965697, 0.2238566530013486, 0.21828154799914046, 0.2353174370000488, 0.2582706160010275, 0.24105152999982238, 0.2232791169990378, 0.2111439000000246, 0.22583333399961703, 0.22645456900136196, 0.20424601899867412, 0.20787634000043909, 0.22558976599975722, 0.21930405600141967, 0.2120490149991383, 0.2042876889991021, 0.20623071100089874, 0.20914839599936386, 0.20357650200094213, 0.2145665280004323, 0.21410546699917177, 0.20806720499967923, 0.22176083700105664, 0.21630967799865175, 0.21231597699988924, 0.21283400200081815, 0.2175437490004697, 0.20776445199953741], [0.2045851490001951, 0.20973726000011084, 0.21285582199925557, 0.2238518619997194, 0.21828342000117118, 0.23531908999939333, 0.25839523499962525, 0.24169649400027993, 0.22264190100031556, 0.2110265850005817, 0.2258346749986231, 0.22644675500123412, 0.204242213998441], [0.2094419459990604, 0.2128464460001851, 0.22520810199966945, 0.21712950100118178, 0.23514783499922487], [0.20936540300135675, 0.2127890359988669, 0.22392410700012988, 0.2181950340000185, 0.23551290599971253, 0.25782393100053014], [0.20966974700058927, 0.2128409639990423, 0.2238501259998884, 0.21828272099992319, 0.23532007399990107, 0.2580183190002572, 0.24118488200110733, 0.22327853299975686, 0.2101768020002055, 0.22662323099939385, 0.22655216900056985, 0.20345007499963685, 0.2086941220004519, 0.22567327700016904, 0.21927702999892063, 0.21096407500044734, 0.20547567100038577, 0.20647370900042006, 0.20896136199917237, 0.20352292399911676, 0.21457454900155426, 0.21417073799966602, 0.20874642899980245, 0.2211700789994211, 0.216165722000369, 0.2123119450006925, 0.21282990899999277, 0.21753509500013024], [0.20931307399951038, 0.21318573000098695], [0.2094405679999909, 0.21282573200005572, 0.22567123699991498, 0.21713366199946904, 0.2352076520000992, 0.25744261300133076, 0.24118370399992273, 0.22337985499871138], [], [0.2093778470007237, 0.21279727399996773, 0.22383509799874446], [0.21278708800127788], [0.21319324400064943, 0.22420055399925332, 0.2182791270006419, 0.23531230599837727, 0.2583639750009752], [0.21296547600104532, 0.2239951129995461, 0.21828042600100162, 0.2353151129991602, 0.25795047900101054, 0.24119413299922599, 0.22313697000026878, 0.21016591399893514, 0.22677246700004616, 0.22653385500052536, 0.20260944599976938, 0.20939233700119075, 0.2257921289983642, 0.21902576400134421, 0.2107095310002478, 0.205660617999456, 0.2065337809999619, 0.20893412999976135, 0.20376635200045712], [0.2168873619993974, 0.23530192699945474, 0.25769010100157175, 0.24118237899892847, 0.223270759001025, 0.21017271499840717], [], [0.21158816300157923, 0.22583499699976528, 0.22635085499859997, 0.20382040300137305, 0.2083479859993531, 0.2256491490006738, 0.21929330799866875, 0.21124808200147527, 0.20551944599901617], [0.22591278099935153, 0.2264920190009434, 0.20345569399978558, 0.20869609299916192, 0.22566463200018916, 0.21928313500029617, 0.21096260199919925, 0.20654656900114787, 0.20596779699917533, 0.20874689499942178, 0.2037047680005344, 0.21430907200010552, 0.21438843900068605], [0.20391481300066516], [], [0.2093848109998362, 0.22573307899983774, 0.21911392000038177, 0.21108844199989107, 0.2053748700000142, 0.2063455419993261, 0.20888646800085553, 0.20383523999953468, 0.21457843399912235, 0.21400160500161292], [0.20787615600056597, 0.22559855100007553, 0.21929937000095379, 0.21124941099878924], [0.22515325899985328, 0.21925317900058872, 0.21214938199955213, 0.20471553100105666, 0.2059699619985622, 0.20917031600038172, 0.20367427299970586, 0.21436456199990062, 0.21440351700039173, 0.20859223499974178], [0.21194591099992977, 0.20499215299969364, 0.2063413270007004, 0.20904115200028173, 0.2036757249989023, 0.21458235400132253, 0.21409690200016485, 0.20807852399957483, 0.22164410299956216, 0.2152365229994757, 0.21345670499977132], [0.2109636410004896, 0.20657456899971294, 0.20598385800076358, 0.20874525899853325, 0.2037075719999848, 0.21430477400099335, 0.21438838699941698, 0.20863094400010596, 0.22147550500085345, 0.2155823329994746, 0.21256087700021453], [], [0.20532900299986068, 0.2062399300011748, 0.2084740159989451, 0.20368809100000362, 0.2144218430003093, 0.21435190000011062, 0.20853395099948102, 0.22148984100022062, 0.2155795090002357, 0.2127777599998808], [0.20532961399840133, 0.20644245100083936, 0.20877635900069436, 0.20373677099996712, 0.21406557599948428, 0.21446023899989086, 0.20830532099898846, 0.2218375130014465, 0.21516862599855813, 0.21315961400068772, 0.21314085599988175, 0.2174013029998605, 0.20647109700075816, 0.2080982919997041, 0.20957380899926648, 0.20782536700062337, 0.20687584699953732, 0.2080238750004355, 0.20893641300062882, 0.22810025099897757, 0.22498988100051065, 0.2562168330005079, 0.2825962539991451, 0.3020999029995437, 0.22956120000162628, 0.21914509599992016, 0.21755107399985718, 0.21021843400012585], [0.2063530229988828, 0.20888761700007308, 0.20383625900103652, 0.2145793859999685, 0.2139973449993704, 0.2081958630005829, 0.22164345099918137, 0.21512703400003375, 0.2135604940012854, 0.2129203159984172, 0.21751949800091097, 0.20711516499977733, 0.20757317000061448, 0.20952890799890156, 0.20790734500042163, 0.2066532520002511, 0.20820269000068947, 0.2089319369988516, 0.22771615400051815, 0.2251227619999554, 0.2559458569994604, 0.28259080899988476], [0.20623452099971473, 0.20901964400036377, 0.20367183499911334, 0.21458598999925016, 0.21410200400168833, 0.20807148799940478, 0.22164752899880114, 0.2164309800009505, 0.2123164849999739, 0.21284097600073437, 0.21751297199989494], [], [0.20874560300035228, 0.2037110519995622, 0.21430339200014714, 0.2143867920003686, 0.2086359539989644, 0.22146837800028152, 0.21558411099977093, 0.21256395800082828, 0.21276242699968861], [0.20896522600014578, 0.20352687899867306, 0.2145700470009615, 0.21410604499942565], [0.20870351399935316, 0.20369012800074415, 0.21431325999947148, 0.21445244899950922, 0.2085438409994822, 0.2214822260011715, 0.21558162699875538, 0.2125928230016143, 0.21277408899914008, 0.21728534099929675, 0.2080894120008452, 0.20737379499951203], [0.20870387100148946, 0.20371617999990121, 0.21491805400000885, 0.21378372399885848, 0.20841493400075706, 0.22164406099909684, 0.2151257240002451, 0.21322762400086503, 0.21323554599985073, 0.21728586199969868, 0.20682547999967937], [0.20354131500062067, 0.21489779199873738, 0.21399172600104066, 0.2082024060000549, 0.2216438969990122, 0.21512550999977975, 0.21327875300084997], [0.2036643199990067, 0.2141414210000221, 0.2143976900006237, 0.2083673010001803, 0.22181647099932889, 0.21519670500128996, 0.21316042699982063, 0.2130848340002558, 0.2174702839984093, 0.20644605600136856, 0.20810449399868958, 0.20957290700062003, 0.20782455600055982, 0.20687682899915671, 0.20802425100009714, 0.20887294100066356, 0.22815862899915373, 0.22499250700093398, 0.2561700690002908, 0.28262018199893646, 0.30199274200094806], [0.2035799040004349, 0.21456343600038963, 0.21410306899997522, 0.20807012499972188, 0.22164967200114916], [0.2038316729995131, 0.21436416399956215, 0.21407782700043754], [0.2036323659995105, 0.21490896600153064, 0.21398396999938996, 0.20821190400056366, 0.22164170499854663, 0.21512718200028758, 0.21328021100089245, 0.21321639599955233, 0.21752525299962144, 0.2067057250005746, 0.20787811599984707, 0.20960912500049744, 0.20790668999870832, 0.20651466800154594], [], [0.21435000599922205, 0.2141263630001049, 0.20874207599990768, 0.22117270000126155], [0.21430401500037988, 0.2143820239998604, 0.208643760999621, 0.22146030099975178, 0.21558697000000393, 0.21230639500026882, 0.21282767000047897], [], [], [0.2137988160011446, 0.20842220799931965, 0.22164507299930847, 0.21512211500157719, 0.21315497499927005, 0.21313792299952183, 0.21739023000009183, 0.20682086300075753, 0.20806855099908717, 0.20947016500031168], [0.21407894899857638, 0.2089364570001635, 0.22153042500031006, 0.2155934630009142, 0.21230757599914796, 0.21282865700050024, 0.2175642969996261, 0.20807666600012453, 0.20709971500036772, 0.2103506709991052, 0.20717254200098978], [0.2211731499992311, 0.216165596000792, 0.21231418499883148, 0.2128310509997391, 0.2175403319997713, 0.2081051560016931, 0.20712216299943975, 0.20954050500040466, 0.20747402499910095, 0.20655731499937247, 0.20817848900151148, 0.20900262299983297, 0.2283076860003348, 0.22444642199843656, 0.2561089240007277, 0.2829421789992921, 0.30179603600117844, 0.22968042100001185, 0.2196491140002763, 0.21696281299955444, 0.21089898100035498, 0.22625028199945518, 0.22924962199977017, 0.21534722999967926, 0.21398916100042698, 0.21536489900063316, 0.21311583999886352, 0.23651778400017065, 0.21079901600023732, 0.21448989199961943, 0.2279954160003399, 0.2041130929992505, 0.21185580500059586, 0.21021818699955475, 0.21289772400086804], [0.22160035299930314, 0.21560746200157155, 0.2123095619990636, 0.21282905400039454, 0.2175658639989706, 0.208070183000018, 0.20710963800047466, 0.2099323849997745, 0.20748790000106965, 0.20715620099872467, 0.20792550700025458], [0.22165016300095886, 0.21512311100013903, 0.2131558330002008, 0.21314034599890874, 0.21739403200081142, 0.206698427999072], [0.21266701000058674, 0.21272909700019227, 0.21745467099935922, 0.20808344699980807, 0.20709255800102255, 0.2103597200002696, 0.20728254699861282, 0.20734327399986796, 0.20762483300131862, 0.20939722799994342, 0.2271763219996501, 0.22457869599929836, 0.2558692479997262, 0.28291525800159434], [], [], [0.21301258899984532, 0.21692348100077652, 0.20807952799987106], [0.21308632900036173, 0.21744455199950607, 0.20681780700033414, 0.2080167820004135, 0.20954171400080668, 0.20753821699872788, 0.2068728780013771, 0.20841661699887482, 0.20882691699989664, 0.22784247900017363, 0.22498488800010819], [0.21270628700040106], [0.21321293299843092, 0.21726990700153692, 0.2069006570000056, 0.20792757099843584, 0.20954334100133565], [0.2088842109988036, 0.20713913200052048, 0.20896778799942695, 0.20803908000016236, 0.20655768800133956, 0.20818019099897356, 0.2089973279998958, 0.22775913400073478, 0.22498111799905018, 0.2561121500002628, 0.2829284330000519, 0.30180925599961483, 0.2296792289998848, 0.21959925300143368, 0.21702735199869494, 0.21088198899997224, 0.22624908800025878, 0.22924468699966383, 0.2153675250010565, 0.2139799819997279, 0.21535731100084377, 0.21313604399983888, 0.23649526099870855, 0.21082459799981734, 0.21448602000054962, 0.22756739199940057, 0.20454109199999948, 0.2117292870007077, 0.21034898499965493, 0.21286805500130868, 0.20959046699863393, 0.23276519200044277, 0.20343475300069258, 0.21027418199992098, 0.238693813998907, 0.21898353400138149, 0.20641906899982132, 0.21448388899989368, 0.2119618429987895, 0.21475825800007442, 0.2126097620002838, 0.20719738300067547, 0.21804963399881672, 0.2396808930006955, 0.2662894860004599, 0.24578927899892733, 0.21003612400090788, 0.21620533399982378, 0.21976703499967698, 0.20380104899959406, 0.2117356690014276, 0.21481591999872762, 0.2132002990001638, 0.2185372730000381, 0.2159479050005757, 0.21991835100016033, 0.20557520399961504, 0.21121450099963113, 0.20636809400093625, 0.21890354599963757, 0.20517271400058235, 0.2183504209988314, 0.20939286800057744, 0.22320895099983318, 0.21685538299971086, 0.21620983100001467, 0.2139602469997044, 0.21315715000127966, 0.21044978799909586, 0.23002893699958804, 0.18568307399982587, 0.21669146600106615, 0.22984699199878378, 0.20914142200126662, 0.207160099000248, 0.20653487500021583, 0.2144218119992729, 0.2330723079994641, 0.2526930830008496, 0.2640791119993082, 0.2113766950005811, 0.20780906499931007, 0.20770814699972107, 0.2261189609998837, 0.21808895400135953, 0.2118862179995631, 0.20950592500048515], [0.20681092199993145, 0.20797945999947842, 0.20935830400048872], [0.20682932300042012, 0.20788089699999546, 0.2096034400001372, 0.20745944500049518, 0.20687374800036196, 0.20841748399834614, 0.20883326700095495, 0.22783419000006688, 0.2251138199990237, 0.25614424500054156, 0.2827243140000064, 0.3020119169996178, 0.22967251100089925, 0.21960433999993256, 0.21704958100053773, 0.2104853719993116, 0.22662090899939358, 0.22916140199959045, 0.215461479001533, 0.21398978399884072, 0.21523847400021623], [], [0.20807493000029353, 0.20740902199941047, 0.21013898700039135, 0.20716010599971924, 0.2073406880008406, 0.20762589900004969, 0.20939477100000659, 0.22717512599956535, 0.2245771739999327, 0.25569172100040305, 0.2827147119987785, 0.30203661599989573, 0.22945413400157122, 0.21976958799859858, 0.21701063300133683, 0.21166396999979042, 0.22540260599998874, 0.22871534200021415], [0.20748227100011718, 0.20896375300071668, 0.20790654999836988, 0.20665265900061058, 0.2082018170003721, 0.2089330599992536, 0.227717298999778], [0.20757724500072072, 0.20952923799995915, 0.20790656199824298, 0.20665305600050488, 0.20820543999980146, 0.20892547400035255, 0.22772032600005332, 0.2251227460001246, 0.2558936149998772, 0.28261794699938037, 0.3020936220000294, 0.2295274870011781, 0.21913924100044824, 0.21756094599913922, 0.21086006500081567, 0.22606184799951734], [], [0.20936015999905067, 0.20776399900023534, 0.2068759100002353, 0.2080240360010066, 0.20893857099872548, 0.2281007990004582, 0.22498855800040474, 0.2562336270002561, 0.2826979179990303, 0.3019764809996559], [0.21035668600052304], [0.20749028399950475, 0.20671514600144292, 0.20787974399900122], [0.20717753899953095, 0.20709061799971096, 0.2080007000004116, 0.2092382250011724, 0.2272791489995143, 0.2246227479990921, 0.25579357300011907, 0.2827236789999006, 0.3020132520014158, 0.2296759659984673, 0.21960145500088402, 0.2170431609993102, 0.2114853889997903, 0.22562914199988882, 0.22916669900041597, 0.21544761900076992, 0.21399555899915867, 0.21535096000116027, 0.21302811399982602], [0.20680534799976158, 0.20774411099955614, 0.2099392660002195, 0.22730714600038482, 0.22462030600036087, 0.25580853399878833, 0.2827205840003444, 0.30252148900035536, 0.22929076299988083, 0.21964964700055134, 0.21695403599915153, 0.21138110700121615, 0.22577923399876454], [0.20656052000049385, 0.20818134299952362, 0.20893411799988826], [0.2065215389993682, 0.20834516499962774, 0.20883364700057427, 0.22783145399989735, 0.22512170300069556, 0.25618532199951005, 0.2829374939992704, 0.3017998630002694, 0.22967910800070968, 0.21964632699928188, 0.2169739410001057, 0.21046962199943664, 0.22667087300033018, 0.2292481719996431, 0.21535649600082252, 0.21398416699958034, 0.2153616220002732, 0.21309487100006663, 0.23649859199940693, 0.21082454600036726, 0.21448560300086683, 0.22756907499933732, 0.20394724099969608, 0.21232082000096852, 0.2097625930000504, 0.2127235230000224, 0.21035956499872555, 0.23276005099978647], [], [0.20821349199832184, 0.208831136000299], [0.20792802300093172, 0.20985686499989242], [], [0.20864317499945173, 0.22803107000072487, 0.22498648100008722, 0.25624539599994023, 0.28270603899909474, 0.3020422730005521, 0.22945264400004817, 0.21976908199940226, 0.2170286140008102, 0.21053530599965598], [0.20985413800008246, 0.22727926900006423, 0.22462275399993814, 0.2556993970010808, 0.2827040529991791, 0.302038812000319, 0.2294273940005951, 0.219143381998947, 0.21755095600019558, 0.211769004999951, 0.22526997500062862], [0.22726026700001967, 0.22483569300129602, 0.2559958709989587, 0.28270760600025824, 0.30204335800044646, 0.2294527729991387, 0.21977016500022728, 0.21702028300023812, 0.21104767399992852, 0.226008126999659, 0.2286381900012202], [0.22717852599998878, 0.22458073099915055, 0.25579145600022457, 0.28272260800076765, 0.30201372999908926, 0.22967880200121726, 0.2195996419995936, 0.21703559100023995, 0.21149735899962252, 0.22562648600069224, 0.229169855998407], [], [0.2196051080009056, 0.2169718910008669, 0.2106474789998174, 0.22636674599925755, 0.2286374949999299, 0.21610854400023527, 0.2139882489991578, 0.21523435300150595, 0.21302947199910705, 0.2367370160009159, 0.21048268499907863], [0.21705516799920588, 0.21168962199953967, 0.22532361400044465, 0.22863241900085995, 0.2154560399994807, 0.21447418699972332, 0.21488130199941224, 0.21336051100115583, 0.23548123900036444, 0.21187453099992126, 0.2138143249994755, 0.22819426800015208, 0.2058742989993334, 0.2106074660005106, 0.21105367699965427, 0.21326815499924123, 0.2083541760002845, 0.23288039500039304, 0.20400549000078172, 0.21021381499849667, 0.23823910800092563, 0.2194734580007207, 0.20634804899964365, 0.21455013000013423, 0.21187417799956165, 0.2127011049997236, 0.21328208200066, 0.20759523999913654, 0.21855468499961717, 0.2398507760008215, 0.26576048099923355, 0.24640168900077697, 0.209460570000374, 0.2167123460003495, 0.21926878499834856, 0.2053719710002042, 0.21118590200057952, 0.21421919699969294, 0.2150285839998105, 0.2161279440006183], [0.21083025199914118, 0.22662164500070503, 0.22863692399914726, 0.21611469200070133, 0.21398365700042632, 0.21523529099977168, 0.2130285620005452, 0.23673504999896977, 0.2104862560008769, 0.2138668139996298, 0.22814103400014574], [0.21161529299934045, 0.2253781039999012, 0.2287717180006439, 0.21592541899917705, 0.2139918660013791, 0.21523600399996212, 0.21314318799886678, 0.2366253649997816, 0.21059239900023385, 0.21468973300034122, 0.22757492299933801, 0.2056162620010582, 0.21085559699895384, 0.21117578899975342, 0.21293547700042836, 0.20906927000032738, 0.23236446000009892, 0.20366769599968393, 0.21088566000071296, 0.23779953899975226, 0.21936880000066594], [0.22619824100002006, 0.22868402799940668, 0.21591623700078344, 0.21399664700038556, 0.21523833500032197, 0.2131505939996714, 0.23661582199929398, 0.2105983550009114, 0.21468750399981218, 0.227574561999063, 0.20448319900060596], [], [0.2154808060004143, 0.21398393100025714, 0.2152389900002163, 0.21315459499965073, 0.23661060700032976, 0.21060130600017146, 0.21468895399993926, 0.22757161699883, 0.20540489999984857], [0.21402019500055758, 0.21474028400007228, 0.21342574099980993, 0.23541827500048385, 0.21188175499992212, 0.21386677299960866, 0.22814149300029385, 0.20535606399971584, 0.211126525000509, 0.2109136330000183], [0.2143935469994176, 0.23637432899886335, 0.21113113000137673, 0.2141546799994103, 0.22899414600033197, 0.20449282600020524, 0.21040719499978877, 0.21120933599922864, 0.21193636800126114, 0.21009947399943485, 0.23234674900049868, 0.20334244199875684, 0.2112024329999258, 0.23785407000104897, 0.21933935999913956, 0.2065975180012174, 0.21418687899858924, 0.21186686600049143, 0.2145204009993904, 0.2126091850004741, 0.20762189000015496, 0.21793771400007245, 0.2394507879998855, 0.26623177799956466, 0.2457872100003442, 0.2105406970003969, 0.21582179399956658, 0.21967685100025847, 0.20391167600064364, 0.21156998299920815, 0.21495712700016156, 0.21306726600050752, 0.21860712299894658, 0.21591944200008584, 0.22005444500064186, 0.20631841400063422, 0.21054930699938268, 0.20620126199901279, 0.21931220300029963, 0.2059680020011001, 0.21770648999881814], [0.21302784699946642, 0.23534230800032674, 0.21188389700000698, 0.21386877099939738, 0.22813839400077995, 0.20582190300046932, 0.21066357899871946, 0.21099630299977434, 0.21327953299987712, 0.20854269200026465, 0.23272270600136835, 0.2039677099983237, 0.21094041900141747, 0.23759195399907185, 0.21961328200086427, 0.20619611399888527, 0.21451712300040526, 0.2119580880007561, 0.21270328999889898, 0.21363472499979252, 0.20735889000025054, 0.2184950780010695, 0.23978010799874028, 0.265934658000333, 0.24616145900108677, 0.20957843599899206, 0.2165809079997416, 0.21936550000100397, 0.20525031099896296, 0.2111776319998171, 0.21423937800136628, 0.21523882799920102, 0.2163888560007763, 0.21619745599855378, 0.2198701200013602, 0.20630855099989276, 0.2108940359994449, 0.20622155599994585, 0.21892841500084614, 0.2062569319987233, 0.2175905940002849, 0.20993594600076904, 0.22259509799914667, 0.21706934400026512, 0.21584953800083895, 0.21312841100007063, 0.21352325799853134, 0.21056388600118225, 0.22992535099911038, 0.186514872000771, 0.21652452200032712, 0.22967340299874195, 0.210315984000772, 0.20599294199928408, 0.2069233140009601, 0.2141962589994364, 0.23324069500085898, 0.2526422419996379, 0.2637729979996948, 0.2124821580000571], [0.21093441099947086, 0.214489328000127, 0.22757042800003546, 0.20515675000024203, 0.211109754998688, 0.21067958000094222, 0.21273816199936846, 0.20940821099975437, 0.2327710780009511, 0.20358796599975904, 0.210210408000421, 0.23860173100001703, 0.21904947199982416, 0.20643172199925175, 0.21454824900138192, 0.21187482899949828, 0.21454772499964747, 0.21276792500066222, 0.20718799399946874, 0.218054924000171, 0.23962750799910282, 0.26634007900065626, 0.24579231499956222, 0.2096522450010525, 0.2165004959988437, 0.21983658700082742, 0.204047344999708, 0.2116656279995368], [0.22750356100004865, 0.20551261800028442, 0.21067291899998963, 0.2109877629991388, 0.2132861240006605, 0.20854370100096276], [0.20382952599902637, 0.2111324670004251, 0.21053226799995173, 0.21325189500021224, 0.20940214899928833, 0.2323564840007748, 0.203494157998648, 0.2102120780000405, 0.2386492890000227, 0.21899696800028323], [], [0.2054550279990508, 0.2106691190001584, 0.21097828100027982], [0.21169587899930775, 0.2105182400009653, 0.2128629050002928, 0.209532943999875, 0.23278975199900742, 0.20346995900035836, 0.21027361800042854, 0.23861116300031426, 0.21906869600024947, 0.2063539779992425], [], [0.2123310240003775, 0.2095830489997752, 0.21273076699981175, 0.2108427879993542, 0.2323445410002023, 0.2029402879998088, 0.21035367800141103, 0.2391118399991683, 0.2187656469996, 0.20579376600107935, 0.21493860199916526], [0.21155398199880437, 0.21030504000009387, 0.21297677500115242, 0.20990503599932708, 0.23238092099927599, 0.20340625000062573, 0.21025548100078595, 0.23868930299977364, 0.21898400699865306, 0.2064261900013662, 0.2144801849990472], [], [0.20923845399920538], [0.2129505760003667, 0.20857245000115654, 0.23278367999955663, 0.2036869809999189, 0.21094671500031836, 0.2377226869994047, 0.21946815000046627, 0.20663749699997425, 0.21417313599886256, 0.2118700840001111, 0.21395680900059233, 0.21241677400030312, 0.20736273900001834], [0.2129340459996456, 0.20856394600014028, 0.23277747700012696, 0.20369013300114602, 0.21095292099926155, 0.23775337699953525, 0.21942546300124377, 0.20664127099917096, 0.2141798110005766, 0.21186815399960324, 0.21429946500029473], [], [0.21324278400061303, 0.20940300099937303, 0.23273250900092535, 0.2034453010001016, 0.21035518600001524, 0.23866467100015143, 0.21921435999865935, 0.2057875629998307, 0.21504118200027733, 0.21115213200027938], [], [0.20953140299934603, 0.23279979400103912, 0.20318441499875917, 0.21035562900033256], [0.2078416179992928, 0.23274536300050386, 0.20413875200028997], [], [0.21042670400129282, 0.2388163399991754, 0.21898923099979584, 0.20511576300123124, 0.21564616199975717, 0.21116303099915967, 0.21407696300047974, 0.21363269399989804, 0.20735577199957334, 0.2183936370001902], [0.21020933900035743, 0.2385705609995057, 0.21908498100128782, 0.20643014599954768, 0.2145445189999009, 0.2118788059997314, 0.21417146400017373], [0.21035839800060785, 0.23896081699967908, 0.21880736799903389], [0.2102706349996879, 0.23861745200156292, 0.21906758499972057, 0.2062413759995252], [0.23772058199938328, 0.21950646199911716, 0.20619052500114776, 0.2145170309995592, 0.21195271100077662, 0.2127453319990309, 0.21364094199998362, 0.20735521800088463, 0.21849768399988534, 0.23974109899972973, 0.26583252799900947], [0.2063018649987498, 0.21494640600030834, 0.2111323799999809, 0.2156254120000085, 0.21281114399971557, 0.20697364500119875, 0.21826340400002664, 0.23964124499980244, 0.26631060799991246, 0.24580633400000806, 0.20958944999983942], [0.20618506199934927, 0.21451853300095536, 0.21187404000011156], [0.21470606500042777, 0.21116598499975225, 0.213673917000051, 0.21336333900035243, 0.207615965999139, 0.21839980600088893, 0.23990156599938928, 0.2658184119991347, 0.24628445200141869, 0.2094684839994443], [0.21523277100095584, 0.21113406400036183, 0.2152773839989095, 0.2124282189997757, 0.20735843799957365, 0.2185006740000972], [0.214175733999582, 0.21185872000023664, 0.21451631399941107, 0.21263370800079429, 0.20760221700038528, 0.2179473689993756, 0.2394369049998204, 0.2662381270001788, 0.24578628900053445, 0.21053892799864116, 0.21582247400147025, 0.219698304999838, 0.20503038199967705, 0.21082538799964823, 0.21456131900049513, 0.2149836160006089, 0.21669024799848557, 0.21591610300129105, 0.22007743399990431, 0.20629563699912978, 0.21055160200012324, 0.20630263600105536, 0.21921080099855317, 0.20597448500120663, 0.2177844339985313, 0.2096323530004156, 0.22258739000062633, 0.21743855500062637, 0.21547300999918662, 0.21385084000030474, 0.2137609599994903, 0.209834008001053, 0.23049444899879745, 0.1860162089997175, 0.21636521900109074], [0.2155293520008854, 0.21113992599930498, 0.2140946260005876], [0.21411050899951078], [0.21476876199994877, 0.21259766399998625, 0.2071766140015825, 0.21806401399953756, 0.2396339459992305, 0.26632849400084524, 0.24579678199916088, 0.20965083600094658, 0.2165013039993937, 0.2193626360003691, 0.2043079619998025, 0.2117458920001809, 0.2147421369991207, 0.2132659569997486, 0.21835035200092534, 0.21612712100068165, 0.2199185919998854, 0.20558442199944693, 0.21121279199905985, 0.20637068900032318, 0.2189046680014144, 0.20517038599973603, 0.21835091799948714, 0.20939406400066218, 0.2232095429990295, 0.21685407500081055, 0.2158855620000395, 0.21386800700020103, 0.2133856599994033, 0.21055751499989128, 0.23004603200024576, 0.18573047999962, 0.21670294199975615, 0.22984967100092035, 0.20906764800020028], [0.2137952850007423, 0.213310752000325], [], [0.20706218899977102, 0.21830755199880514, 0.2396601640011795, 0.26594715799910773, 0.24615610200089577, 0.20958611700007168, 0.21657961799974146, 0.21936461999939638, 0.2052435069999774, 0.21116797200011206], [0.2069686710001406, 0.21826485800011142, 0.2396499379992747, 0.26595522800016624, 0.24615559999983816, 0.20958645999962755, 0.21658253500027058, 0.21936239900060173, 0.20524103099887725, 0.2111978650009405, 0.2143231840000226, 0.21524932099964644, 0.21636133799984236, 0.21614270499958366, 0.21983845800059498, 0.20629150599961577, 0.21089033099997323, 0.206213569999818, 0.21893396100131213, 0.2062611809997179, 0.21759010999994643, 0.20993629899930966, 0.2225908350010286, 0.21742424999865761, 0.21549156900073285, 0.21314540400089754, 0.21352325999941968, 0.21056445700014592, 0.22991229299987026, 0.18651198800034763, 0.21652964699933364, 0.22967313200024364, 0.21031452100032766, 0.2060554689996934, 0.2068703259992617], [0.2177393120000488, 0.2396012659992266], [0.2179402370002208, 0.23965164500077663, 0.2662929729995085, 0.24578907400064054, 0.21036782000010135, 0.21594879799886257, 0.21970766699996602, 0.2035831960001815, 0.21186098200087145, 0.21499483899970073, 0.21299802999965323, 0.21867365499929292, 0.2159300670009543, 0.21991854999942007, 0.20544751700072084, 0.21042460199896595, 0.20713845899990702, 0.21888336099982553, 0.20522874100061017, 0.21834892300103093, 0.20939945099962642, 0.22321375499996066, 0.21684993899907568, 0.2158325820000755, 0.21447650600021007, 0.21337112199944386, 0.21020246400075848], [], [0.21594886999992013, 0.21971023199876072, 0.2040174140001909, 0.2117161420010234, 0.21468240200010769, 0.21315575199878367, 0.21852080500138982, 0.21594062499934807, 0.2199182379990816, 0.2059214710006927, 0.21095335000063642], [0.21582313500039163, 0.2196779610003432, 0.20359749599992938, 0.2118472659985855, 0.21499450400006026, 0.2130054690005636, 0.21866736099946138, 0.21592558400152484, 0.21991740299927187, 0.2054586089998338, 0.21042198199938866, 0.20713687100032985, 0.21888244600086182, 0.20522993299891823, 0.2183508920006716, 0.209397512000578, 0.22321263999947405, 0.21685103299932962, 0.21583133800049836, 0.2144773060008447, 0.2133739479995711, 0.2102303789997677, 0.23042336300022725], [0.21621158299967647, 0.21976800300035393, 0.204929732999517, 0.21099103899905458], [0.20590081099908275, 0.21083598200129927, 0.21414720000029774, 0.21538988299835182, 0.21624039900052594], [0.20483445600075356], [0.21119774100043287, 0.21473005500047293, 0.2140887069999735, 0.21758451599998807, 0.21591171599902736, 0.22007862200007366, 0.20572425099999236, 0.21102403099939693, 0.20622676700077136, 0.21888657199997397], [0.21150492499873508, 0.21467328700055077, 0.21315031599988288, 0.2185217370006285, 0.21593511999890325, 0.219918859000245, 0.20592655000109517, 0.21102101799988304, 0.20623188599893183, 0.21889145100067253, 0.2059587339990685], [0.2117251399995439, 0.2150124350009719, 0.2131698459998006, 0.2184453999998368, 0.21613486599926546, 0.21991718500066781, 0.20523282399881282, 0.21033845000056317, 0.20702777999940736], [0.21176138400005584, 0.21473641000011412, 0.2132631570002559, 0.21835279500010074, 0.2161309799994342, 0.2199190280007315, 0.20558182499917166, 0.21120865200100525, 0.20637444000021787, 0.218865716999062], [0.2148757619997923, 0.21310973500112596, 0.21861980799985758, 0.2159601740004291, 0.21991890399840486, 0.20546832400032145, 0.21043277100034175, 0.2071421590007958, 0.21884274199874199], [0.21541430599972955, 0.216381790000014, 0.21620968699971854, 0.21987036899918166, 0.20619947600062005], [0.21516045500175096], [], [0.22043247900001006, 0.2050366790008411, 0.21064046900028188, 0.20714837899868144, 0.21876435900048818], [0.21984098000029917, 0.20568978099981905, 0.21120185700056027, 0.20638315099859028, 0.21886727300079656, 0.20522059699942474, 0.21835139600079856, 0.2093953989988222, 0.22321079700122937, 0.21685283700026048, 0.21583015599935607], [0.20659240399982082, 0.21070191000035265, 0.20620713500102283, 0.2193019859987544, 0.20590338200054248], [0.21051213800092228, 0.2062777119990642, 0.2192106500006048, 0.20631649300048593, 0.21745328699944366, 0.20965518099910696, 0.22255786200003058, 0.2174443069998233, 0.21545910400163848, 0.21385920200009423, 0.21375739299946872], [0.21108423300029244, 0.20634450900070078, 0.21889951999946788, 0.20566574499935086, 0.21798978300103045, 0.2092971160000161, 0.22330136399978073, 0.21676166499855754, 0.21628770400093345, 0.213424245999704, 0.21338309299972025], [0.21095660100036184, 0.2063206729999365, 0.21889546099919244, 0.20586585000091873, 0.21781120499872486, 0.2092969240002276, 0.22330366800088086, 0.21675922099893796], [], [0.2071011690004525, 0.2188718549987243, 0.20517549400028656, 0.21835032499984663, 0.2093991809997533, 0.22321580100106075, 0.21684916699996393, 0.2158334220002871, 0.21447573600016767, 0.2133012839985895], [0.20709509900007106, 0.21918519599967112, 0.2053669369997806, 0.2183550190002279, 0.20939341000121203, 0.22323789799884253, 0.21682488700025715, 0.2158540840009664, 0.21368283799893106, 0.21344704700095463, 0.2103062009991845], [0.20707298900015303, 0.2190175919986359, 0.20538898599988897, 0.2183532290000585, 0.20939628300038748, 0.22322217600049044, 0.2168396319993917, 0.21584068599986495, 0.2138956529997813], [0.21877370000038354, 0.20535846600068908, 0.21835212400037562, 0.2093985799983784, 0.22321779300000344, 0.21684553000159212, 0.21583481899870094, 0.21407128000100784, 0.21349553099935292, 0.21042052099983266, 0.23004919300001347, 0.18564359599986346, 0.2167027590003272, 0.22972673600088456, 0.20916777699858358, 0.20727467500000785, 0.20616409100148303, 0.21474377599952277, 0.2329703100003826, 0.25282857499951206, 0.2640821839995624, 0.21136812999975518, 0.20731619599973783, 0.20770915300090564, 0.2259754000006069, 0.21845964999920398, 0.21186581000074511, 0.20969567399879452, 0.2227553419998003, 0.2086926219999441, 0.20787464400018507, 0.221381917999679, 0.20565607600110525, 0.20800514399888925, 0.21928248000040185, 0.21249876799993217, 0.22115590900102688, 0.21351409499948204, 0.22805530400000862, 0.2377730669995799, 0.25472339400039345, 0.22307126600026095, 0.22066913600065163, 0.21567989799950738, 0.22322404899932735, 0.2449635400007537, 0.25360026999987895, 0.21824066099907213, 0.20848481299981358, 0.20482623099997, 0.20691037800133927, 0.2204344849997142, 0.2042925709993142, 0.20756902399989485, 0.22247013800006243, 0.2236444770005619, 0.20441977900009078, 0.22130403899973317], [0.20628659199974209, 0.2178144079989579, 0.20929562600031204, 0.22330454900111363, 0.21675869899991085, 0.21628553200025635, 0.21342932900006417, 0.2134896879997541, 0.21042297900021367, 0.2300463289993786, 0.18626244599909114, 0.2164952370003448, 0.22960222300025634, 0.21033236400035094, 0.20596939099959855, 0.2068920279998565, 0.21419712900024024, 0.2329790999992838, 0.2530434990003414, 0.26377855999999156, 0.21172357000068587], [0.2182177810009307, 0.2093571850000444, 0.22320802799913508, 0.2168555379994359, 0.21621141900141083], [0.2179920080016018, 0.20929920799972024, 0.22329483300018182, 0.21676906399989093, 0.2162556469993433], [0.21759309199842392, 0.2099397260008118, 0.2226001390008605, 0.21696315799999866, 0.21593438899981265, 0.21389149700007692, 0.21376068300014595, 0.20984022299853677, 0.2304914659998758, 0.1856787400010944, 0.21651468699928955, 0.22958785199989507, 0.2104036159998941, 0.20588178199977847], [0.21776468999996723], [0.2226103549983236, 0.21674163300122018, 0.21615051600019797, 0.2134529279992421, 0.2134960260009393, 0.21039261799887754, 0.23004686400054197, 0.18626736799888022, 0.21650465500169958, 0.22959390799951507, 0.21033415499914554], [0.21748259099877032, 0.2159447320009349, 0.2138265039993712, 0.21314659299969207, 0.21044419700047, 0.23048519099938858, 0.18575647800025763, 0.21651088600083312, 0.22958886499873188, 0.21039834000112023, 0.20588855300047726, 0.20688496199909423], [], [], [], [0.21585823299938056, 0.21297828700153332, 0.2134636060000048, 0.2103982629996608, 0.2302890060000209, 0.18652462099998957, 0.21651909299907857, 0.2296722419996513, 0.21031837900045502, 0.20598834700103907, 0.20686286999989534, 0.21419778400013456, 0.23327911399974255, 0.252650910999364, 0.2637755619998643, 0.2124878449994867, 0.20715124400157947, 0.20724381099898892, 0.22603738399993745, 0.2180643740011874, 0.21225957899878267, 0.20971105700118642, 0.22164565599996422, 0.20988841899998079, 0.207753220000086, 0.22093133599992143, 0.20581539299928409, 0.20887318399945798, 0.21836696900027164, 0.21246142200106988, 0.22109290699881967, 0.21453284100061865, 0.2273483650005801, 0.23759625899947423, 0.2550608569999895, 0.2225062599991361], [], [0.21418273399831378, 0.21029947100032587, 0.23033884600044985, 0.1862439769993216, 0.21636204100104806, 0.2296279459988, 0.21031461200072954, 0.20667982700069842, 0.20624152699929255, 0.21415698599957977, 0.23324537100052112, 0.2527245439996477, 0.26403439400019124], [], [], [], [], [], [0.23097289399993315, 0.18572259299980942, 0.21670246400026372, 0.22985315400001127, 0.2090706870003487, 0.20725225000023784, 0.20646127999862074, 0.21446966900111875, 0.2330731169986393, 0.2527041740013374, 0.2640775509989908, 0.2113753949997772, 0.20758397500139836, 0.2076453270001366, 0.22626777699952072], [0.2300292649997573, 0.18651871099973505, 0.2163990709996142, 0.22963068900025974, 0.21031520600081421, 0.2066658039984759, 0.20626220700069098, 0.21415099300065776, 0.23324153199973807, 0.2527192309989914, 0.2636779260010371], [], [0.1855569679992186, 0.21651967900106683, 0.2298454709998623, 0.20969962299932376, 0.20660069299992756, 0.20653082500029996, 0.21442682599990803, 0.2330709729994851, 0.25269346900131495, 0.26407773199935036, 0.21162851000008231], [0.18610750500010909, 0.21636046999992686, 0.2296301599999424, 0.21031435799886822, 0.20667547400080366, 0.20625027399910323, 0.21415284800059453, 0.23324438000054215, 0.25272286600011284, 0.2637303859992244, 0.21244335799929104], [0.21642516700012493, 0.22980475300028047, 0.21032268399903842, 0.2059798080008477, 0.20655848699971102, 0.2144169229995896, 0.2330647319995478, 0.25269363100051123], [0.21661916399898473, 0.22983329700036847, 0.20906327800003055, 0.20738226499997836, 0.2061670340008277, 0.21474578699962876, 0.23297059399919817, 0.2528253950004, 0.2640849880008318, 0.21136583299994527, 0.207208460999027], [], [], [], [0.21633710500100278, 0.22976166799890052, 0.21032836199992744, 0.20597354500023357, 0.2068410940009926, 0.21422148300007393, 0.23299194799983525, 0.253021890999662, 0.26373062300081074], [], [], [0.2164475859990489, 0.22963278200040804, 0.2103151520004758, 0.2065819109993754], [0.21648071199888363, 0.22964895500081184, 0.21031294599924877, 0.2060567139997147], [0.21116866099873732, 0.20646060000035504, 0.2062326600007509, 0.21416081699862843, 0.2332469190005213, 0.2527256949997536, 0.26410966900039057, 0.21207250000043132, 0.20709507100036717, 0.20726860799913993, 0.22599848800018663], [0.20909322799889196, 0.20725497800049197, 0.20616392200099654, 0.21474145499996666, 0.23297128099875408, 0.2528311580008449, 0.2640792829988641, 0.21137197600000945, 0.2075840640009119, 0.20764006200079166, 0.22619849999864527], [], [], [], [], [0.20617101199968602, 0.21475134700085619, 0.23297144599928288, 0.25281690400152, 0.26409248799973284, 0.21136089599895058, 0.2072091050013114, 0.2078354239984037, 0.2259774540016224, 0.2184703429993533, 0.211745818000054, 0.2090561209988664], [], [], [], [0.20615450299919758, 0.21415193699976953, 0.23324812000100792, 0.25272585799939407, 0.2641167879992281, 0.2120631180005148, 0.20709215900023992, 0.20643994199963345, 0.2259778820007341], [], [], [0.20688052599871298, 0.21419748900007107, 0.23324155599948426, 0.2526408950016048], [0.20592672699967807, 0.21502958100063552, 0.2330186830004095, 0.2526639649986464, 0.26402466600120533, 0.2114931569994951, 0.20712938100041356, 0.20792184899983113, 0.2259332710000308, 0.21847878399967158, 0.21049118399969302, 0.2102900080008112, 0.22343066699977499, 0.20873407299950486, 0.20796899500055588, 0.22146817199973157, 0.20564097200076503, 0.20786186599980283, 0.21943122199991194, 0.2125018659990019, 0.2210532469998725], [0.21421616000043286, 0.2329924999994546, 0.2527854180007125, 0.2639676429989777, 0.2117964730005042, 0.207365068999934, 0.2077049680010532, 0.22611963399867818, 0.2180931340008101, 0.21188329299911857], [0.21477172699997027, 0.2329779760002566, 0.25266383399866754, 0.26424256900099863, 0.21127299799991306, 0.20729238499916391, 0.20783708000089973, 0.22597610599950713, 0.21848609500011662, 0.21173311399979866, 0.20894726400001673], [0.21419417799916118, 0.2329787140006374, 0.2530357859996002, 0.2637821210009861, 0.21172302400009357, 0.2073536839998269, 0.20770892600012303, 0.2261209019998205, 0.21808851300011156, 0.21225411799969152, 0.20926589900045656], [0.21471423500042874, 0.23296606199983216], [], [], [], [], [0.21441458799927204, 0.2330649089999497, 0.2526937340007862, 0.26407660899894836, 0.21173490900036995], [0.21442194100018241, 0.23306876000060583, 0.2526961539988406, 0.2640778879995196, 0.21137647300020035, 0.2078003799997532, 0.20771581000008155, 0.22611800200138532, 0.21809457699964696, 0.2118786850005563, 0.20943755799999053], [0.21418423099930806, 0.23324334300014016, 0.25264685200090753, 0.2637735989992507, 0.21248524799921142, 0.20714947400119854, 0.20724804800011043, 0.22603920599976846, 0.21805731499989633, 0.21226129299975582, 0.20971557399934682, 0.22164157500083093, 0.20988864699938858, 0.20775712700014992, 0.22092884599987883, 0.2058234830001311, 0.20886651200089545, 0.2183696020001662, 0.21246091200009687], [], [0.21419031500045094, 0.23327152899946668, 0.25266216099953454, 0.26377630900060467, 0.2117788590003329, 0.20766189499954635, 0.20742625300044892, 0.22603585099932388, 0.21807659800106194, 0.21225748599863437, 0.20929710700147552], [], [], [], [0.20715485899927444, 0.20724021900059597, 0.22603635899940855, 0.21807067000008828, 0.21225831599986122, 0.20932606399946962, 0.221988635001253, 0.20992869200017594, 0.20774804699976812, 0.22093590599979507, 0.2055686820003757, 0.20908685099857394, 0.21826598100051342], [0.20752125500075636, 0.22631066299982194, 0.21805752900036168, 0.2118772079993505, 0.20969332099957683, 0.22278415400069207, 0.20866169500004617, 0.2080940349987941, 0.22119527500035474, 0.20564546000059636, 0.20808630799911043], [0.20722998600103892, 0.2260312869984773, 0.21805268500065722, 0.21226003599986143, 0.2097181709996221, 0.22191128800113802, 0.2096762379987922, 0.20777517600072315, 0.22123689299951366, 0.20582803199977207, 0.20874489600100787, 0.21825493199867196, 0.21258980400125438, 0.22101083699999435, 0.21439431100043294, 0.22733561199856922, 0.2376189719998365, 0.25517627600129345, 0.22253811199880147], [], [], [0.2074779779995879, 0.22604103900084738, 0.21796345300026587, 0.21225987300022098, 0.20971854899835307, 0.22194877100082522, 0.20964065000043774, 0.20778048499960278, 0.22123498799919616, 0.20582860500144307], [0.20742217600127333, 0.22603754199917603, 0.21808202099964547, 0.21225666900136275, 0.20929496999997355, 0.2224232349999511, 0.20953408899913484, 0.20750093599963293, 0.22111635399960505, 0.20561636600177735, 0.20861978999892017, 0.2186333139998169, 0.21267057200020645, 0.22096319299998868, 0.21408822200100985, 0.2278764369984856, 0.2376049430004059, 0.2547227830000338, 0.22281656099949032, 0.22077040800104442, 0.21559769799932837, 0.22351584900025045, 0.24459739700068894, 0.2537642169991159, 0.21812234100070782, 0.2089120250002452, 0.20530157899884216, 0.20647286200073722, 0.2199053999993339], [0.22611704600058147, 0.2181062869985908, 0.21186493700042774, 0.20944654999948398, 0.2225804160007101, 0.2091508409994276, 0.2078128020002623, 0.2212291380001261, 0.205629066000256, 0.20855816299990693], [0.21292369500042696, 0.20927124399895547, 0.22218839600100182, 0.20962943999984418, 0.20766302199990605, 0.22111618499911856, 0.2056171620006353, 0.20862014100021042, 0.21863222799947835, 0.212664501999825, 0.2209787360006885, 0.2135512259992538, 0.2283212120000826, 0.23748463099946093], [0.21184824299962202, 0.20946073400045861, 0.2224009389992716, 0.20924793500125816], [], [], [], [], [], [0.2117146849996061, 0.20895834500151977, 0.2234284869991825, 0.20882060499934596, 0.20795283600091352, 0.221391044999109, 0.2056533210015914, 0.20800005899945972, 0.21929050300059316, 0.2124946669991914, 0.22115077499984181, 0.21314014400013548, 0.2283418620008888, 0.23787076399821672, 0.2547209540007316, 0.22307815199928882, 0.22056687800068175, 0.21545612999943842, 0.2229722470001434, 0.24538270100129012, 0.2537422389996209, 0.2182414870003413, 0.20782963999954518, 0.20504864900067332, 0.2072251689987752, 0.22048774500035506, 0.2042713190003269], [], [], [], [], [], [0.2090397709998797, 0.22334102199965855, 0.20868396699916048, 0.20795909800108348, 0.22138640099910845, 0.2056544560000475, 0.20800414100085618, 0.21928550799930235, 0.21249571199950879, 0.22115449700140744, 0.21338431099866284], [0.22277140799997142, 0.20861565000086557], [], [0.22248178200061375, 0.20902436299911642, 0.20781328600060078, 0.22122837599999912, 0.20563157600008708, 0.20861421700101346, 0.2186382029995002, 0.2125129050000396, 0.2211102339988429, 0.213546764000057, 0.22804081899994344], [], [], [], [], [], [], [], [], [], [0.2099478319996706, 0.2075000849999924, 0.2211166470005992, 0.2056166549991758, 0.20861974400031613, 0.2186327950003033, 0.2126692940000794, 0.22096957199937606, 0.2135576359996776, 0.2283182699993631, 0.23759971100116672], [0.20914675499989244, 0.20781273899956432, 0.2211885060005443, 0.20564609999928507, 0.20848219999970752], [], [0.20776829500027816, 0.22112138999909803, 0.20590484899912553, 0.20869943400066404, 0.21826708700064046, 0.21255972099970677], [], [], [], [0.20757534999938798, 0.22117244900073274, 0.20563379899977008, 0.20861839499957568, 0.21863306299928809, 0.212515496999913, 0.22110312699987844, 0.21355284700075572, 0.22832172800008266, 0.23748555299971486, 0.2548509389998799, 0.22292272599952412, 0.22141594900131167], [], [], [], [], [0.220940236999013, 0.20556744799978333, 0.208617463000337, 0.2186338040010014, 0.21267424500001653, 0.2209563229989726, 0.21454643400102213, 0.22744768699885753, 0.23760352300087106, 0.2547224779991666, 0.22281128200120293], [0.22131409699977667, 0.20564532000025793, 0.20800588199927006, 0.21927973900164943, 0.21249944800001686, 0.22115248699992662, 0.21352544099863735, 0.228050654000981, 0.23777507599879755, 0.25472590300159936], [], [0.2211184250008955, 0.20561945299959916, 0.208619450999322, 0.21863130200108571, 0.2125184239994269, 0.22109631199964497, 0.21355936800136988, 0.22832492499946966, 0.2374823230002221, 0.2548513429992454, 0.2229212029997143, 0.22128749000148673], [], [], [0.20563055999991775, 0.20855234100054076, 0.21871969199855812, 0.21250845100075821, 0.22112030199969013, 0.21353922500020417, 0.22804464500040922, 0.23778148800010968, 0.2548501869987376, 0.22292349500094133, 0.22045315200011828, 0.21545573900039017, 0.22285533099966415, 0.2454834780000965, 0.25374569599989627, 0.2182382039991353, 0.2078344380006456, 0.20562511199932487, 0.2069098000010854], [], [], [], [], [], [], [], [0.20582821400057583, 0.20867263999934949, 0.21829301300022053, 0.21260059799897135, 0.22103007599980629, 0.21439443200142705, 0.2273338729992247, 0.23760987400055456, 0.25517128399951616, 0.22255485599998792, 0.2202030360003846, 0.2156858899998042, 0.2232257359992218, 0.24495945899980143, 0.2536024200016982, 0.2182407999989664, 0.20847910900010902, 0.20602193100057775, 0.20667586399940774, 0.21946784899955674, 0.2050816789997043, 0.20849947800161317, 0.22136306099855574, 0.2234541160014487, 0.2048832599994057, 0.22127623800042784, 0.21325131099911232, 0.20789379100096994, 0.22522963699884713, 0.1983544909999182, 0.2095617310005764, 0.2269655670006614, 0.22951701399870217, 0.20677719500054081, 0.21289802899991628, 0.21553970599961758, 0.21222195399968768, 0.2136470740006189, 0.2082318810007564, 0.20773835999898438, 0.20828311500008567, 0.2123866750007437, 0.20802824099882855, 0.20643650400052138, 0.21196131400029117, 0.22902768399944762, 0.2081580270005361, 0.21273145899976953, 0.40743996300079743, 0.038922154999454506, 0.22737936500016076, 0.21840638699904957, 0.21276868700078921, 0.20543619000090985, 0.20788077099859947, 0.2067214859998785, 0.206582814000285, 0.20718522400056827, 0.22456269299982523, 0.20689725800002634, 0.2179006330006814, 0.2131791849988076, 0.206574621000982, 0.2094977819997439, 0.20822185199904197, 0.2088227240001288, 0.209239764000813, 0.22784960299941304, 0.2162054630007333, 0.2219451740002114, 0.24478020799870137, 0.21158960100001423, 0.20972189900021476, 0.21072869099953095, 0.20602242200038745, 0.20747374200072954, 0.22017743200012774, 0.2274525069988158, 0.21428157600166742, 0.22358009899835452], [0.2090086230000452, 0.21836105900001712, 0.2124659379987861, 0.22109826000087196, 0.21453280499918037, 0.22734775800017815, 0.2375931770002353, 0.2550569520008139, 0.2225131010000041, 0.22020793899901037, 0.215361426000527], [0.20870649900098215, 0.2182674550003867, 0.21255684199968528, 0.22111876199960534, 0.21439473499958694, 0.22733246200004942, 0.23760756100091385, 0.2551643349997903, 0.22256471599939687, 0.22023560900015582], [0.2182673919996887, 0.21259360600015498, 0.2211003829997935, 0.21453415200085146, 0.2273493229986343, 0.23758795499998087, 0.2550515060011094, 0.22252437899987854, 0.22137690899944573, 0.21492035600022064, 0.22353472800023155, 0.24459885699980077, 0.25376415599930624, 0.218741635000697, 0.2083633620004548, 0.2053091769994353, 0.20639738499994564, 0.21992737900109205, 0.20493914899998344, 0.20831790999909572, 0.2214809500001138, 0.22351121400060947, 0.20483054399846878, 0.2213244360009412, 0.21326545900046767, 0.20787865799866267, 0.22524353000153496, 0.19826513999942108, 0.20961307499965187, 0.22697439700095856, 0.22946530199988047, 0.20620197700009157, 0.21296608800003014, 0.21603412900003605, 0.21221218899881933, 0.2135738670003775, 0.20824765600082173, 0.20777419999831181, 0.20835638600146922, 0.21188580599846318, 0.20812661800118804, 0.2065945289996307, 0.21210699999937788, 0.22911034900062077, 0.2080131849997997, 0.21283894699990924, 0.4073017949995119, 0.03893310300009034, 0.22754808900026546, 0.2171032340011152, 0.2137951669992617, 0.20516255400070804, 0.2083326229985687, 0.20666599000105634, 0.20549253500030318, 0.20819041499999003, 0.22393594499953906, 0.2073623630003567, 0.21827035099886416, 0.21320897300029173, 0.20615444000031857, 0.2092372709994379, 0.20873759300047823, 0.2088065860007191, 0.20934865699928196, 0.22776781399988977, 0.21494508300020243, 0.22298401499938336, 0.2451349120001396, 0.21159811700090358, 0.20956736799962528, 0.20996229199954541, 0.20670712600076513, 0.20774129500023264, 0.2200185949986917, 0.22761418600020988, 0.21419690500079014, 0.2236965499996586, 0.20886205200076802, 0.2074279199987359, 0.20549322800070513, 0.21233821399982844, 0.20747925599971495, 0.20934305700029654, 0.20920666699930734, 0.20900929300114512], [0.21830938199855154, 0.2125518650009326, 0.22096138400047494, 0.2145477439989918, 0.22733388599954196, 0.23760158100049011, 0.255085484999654, 0.22251560400036396, 0.22026269900015905, 0.21545855099975597], [0.21825457200066012, 0.212587383999562, 0.22101931699944544, 0.21439440900030604, 0.22733396200055722, 0.23761480999928608, 0.2551738890015258, 0.22254603299916198, 0.22037446899958013, 0.2155423679996602], [0.21923251899897878, 0.21248953199938114, 0.22114644900102576, 0.21353316299973812, 0.22804705499947886, 0.2377788169997075, 0.2548433810006827, 0.22292820400070923, 0.22082112899988715, 0.21554782999919553, 0.22322866099966632], [0.22215932899962354, 0.21439548600028502, 0.22733139299998584, 0.23760443399987707, 0.25508919800086005], [0.22099295299994992, 0.21354491500096628, 0.22832400100014638, 0.23748169999998936, 0.2548521680000704], [], [], [0.22096073600005184, 0.21438935500009393, 0.2273348149992671, 0.23844940300114104, 0.2543528209989745, 0.22256679100064503, 0.2199976659994718, 0.21545742499984044, 0.22297888100001728], [], [], [], [], [], [], [], [], [0.22788596700047492, 0.23759572400012985, 0.25470957300058217, 0.22283519099983096, 0.22049192099984793, 0.2155285549997643, 0.22298940099972242, 0.24525769899992156], [], [], [], [], [0.2273511919993325, 0.2375833109999803, 0.2550413139997545, 0.22253835600167804, 0.22137057699910656, 0.21492793499965046, 0.22352893000061158, 0.24459767199914495, 0.2537632220009982, 0.21869755899933807, 0.20841633100098989, 0.2053035059998365, 0.20639897199907864, 0.2199318310013041, 0.2049397749997297, 0.20830095800010895, 0.2214896339992265, 0.22352108499944734, 0.20459599800051365, 0.2215506100001221, 0.2132728529995802, 0.2078725539995503, 0.2252486500001396, 0.19825002100151323, 0.2096197349983413, 0.22697743800017633, 0.22947113700138289, 0.20619122199968842, 0.21297015900017868, 0.21604089299944462, 0.21220326500042574, 0.2135750300003565, 0.20825401899855933, 0.2077670520011452, 0.2083631699988473, 0.211883032001424, 0.20812669299994013, 0.20658858899878396, 0.21209148900015862, 0.22899066700119874, 0.20813305099909485, 0.2127929359994596], [0.22745353500067722, 0.237598177000109, 0.2547242010004993, 0.22281229500003974, 0.2214271889988595, 0.21493831400039198, 0.22352348800086475, 0.2445964449998428, 0.2537631679988408, 0.21811942100066517, 0.2089070689999062, 0.20530803300061962, 0.20647096099855844, 0.21994090000043798, 0.20487900999978592, 0.2074769880000531, 0.22227163500065217, 0.22361778800041066, 0.20457309300036286, 0.22125058099845774, 0.21358598400001938, 0.20778020000034303, 0.22534956900017278, 0.19804791299975477, 0.20973485499962408, 0.2270594350011379, 0.22948469699986163, 0.2058330380004918, 0.21331528399969102, 0.2160512419995939, 0.21218487199985248, 0.2135566849992756, 0.20827923900105816, 0.20768205800050055, 0.20845793699845672, 0.21187779000138107, 0.2081260029990517, 0.2065031390011427, 0.21218887999930303, 0.22899891499946534, 0.20812643700082845, 0.2127920949988038, 0.4073494180011039, 0.03888737299894274, 0.22763100000156555, 0.21710270299990952, 0.2137912319994939, 0.20516727599897422, 0.2079636180005764, 0.20702919500035932, 0.20549835500059999, 0.2081917989999056, 0.22391989700008708, 0.2073733959987294, 0.21827387499979523, 0.2132092490010109, 0.20598948000042583], [], [], [0.2201926479992835, 0.215497093000522, 0.22339618099977088, 0.24496831000033126, 0.2535999890005769, 0.2182408199987549, 0.20849181700032204, 0.20604208300028404, 0.20667560899892123, 0.2194030210011988], [0.2245397429996956, 0.24460255600024539, 0.2537649890000466, 0.21812488000068697, 0.20844822599974577, 0.20479743199939549, 0.206911425000726, 0.22044226700018044, 0.20428735699897516, 0.20758085300076345, 0.22246757200082357, 0.22362126799998805, 0.2044424830000935, 0.2214033649997873, 0.21340641299866547, 0.20704914999987523, 0.22636420000162616, 0.19732478999867453, 0.21012191200134112, 0.22726742399936484, 0.22926032500072324, 0.20566708999831462, 0.21367745400129934, 0.2160837609990267, 0.21082334800121316], [0.2235381589998724, 0.24459481200028677, 0.253763851000258, 0.21874419999949168, 0.2083526559999882, 0.20537511000111408, 0.20667234599932272], [], [], [0.21812826299901644, 0.20844987500095158, 0.20554790899950603, 0.20639267499973357, 0.22033906700016814, 0.20437435100029688, 0.20761673499873723, 0.2224463830007153, 0.22361703800015675, 0.20440033699924243], [], [0.20839871700081858], [], [], [], [], [], [0.20598540699938894, 0.2064017659995443, 0.21993751100126246, 0.20494015799886256, 0.2074504900010652, 0.2223298019998765, 0.22353241599921603, 0.20458807500108378, 0.22151956199923006, 0.21330163899983745, 0.2077997129999858], [0.2050499380002293, 0.20707821199903265], [0.2064506060014537, 0.206389445998866, 0.21967775800112577, 0.2051825460002874, 0.2083284399996046, 0.2214765319986327, 0.2235034840014123, 0.20483149000028789, 0.22133069399933447, 0.213258023999515, 0.20788630100105365, 0.22523684799853072, 0.1983450450006785, 0.20956567299981543, 0.2269641250004497, 0.22945417399932921, 0.2068133510001644, 0.21248431300045922, 0.21591816900036065, 0.21223354199901223, 0.21355184700041718, 0.20837000800020178, 0.207728658000633, 0.20829360899915628, 0.21189668099941628, 0.2084409390008659, 0.20628748399940378, 0.2120916269996087, 0.22910097100066196, 0.20802276500035077, 0.2128297939998447, 0.40731971400055045], [0.2064758280012029, 0.2199020339994604, 0.204937186999814, 0.20747676700011652, 0.22227258900056768, 0.22362516099929053, 0.20456414799991762, 0.22124898200127063, 0.21359537099851877, 0.20771576300103334], [], [0.20639634400140494, 0.2201993519993266, 0.20437888000014937, 0.2077545119991555, 0.2224455539999326, 0.2236245809999673, 0.20439432800048962, 0.22136074999980337, 0.2135036929994385, 0.207631911000135, 0.2257065240009979, 0.19729112300046836, 0.21011897300013516, 0.2274137009990227, 0.22944896199987852, 0.20546611000099801, 0.2135508179999306, 0.21611460799977067, 0.2118465829989873, 0.21377881100124796, 0.2081690979994164, 0.20774418899964076, 0.2073886649995984, 0.2129663800005801, 0.20821268899999268, 0.20596460699925956, 0.21213704900037555, 0.22978904100091313, 0.20794614799888222, 0.21250367300126527, 0.40740459699918574, 0.03908308700010821], [0.2065179380006157, 0.22018331099934585, 0.2044286890013609, 0.2077517479992821, 0.22244509300071513, 0.22352498100008233, 0.20445152599859284, 0.22138791100042, 0.21345445699989796], [0.22013371699904383, 0.2044198849998793, 0.2077170370012027, 0.22232760400038387, 0.22364282599846774, 0.20442591500068374, 0.22124682600042433, 0.21358064899868623, 0.20760188000167545, 0.22566179699970235, 0.19746581599974888], [], [0.20810552800139703, 0.22132497699931264, 0.2234478680002212, 0.20488730299985036, 0.22127948299930722], [], [], [], [], [], [], [0.20753300300020783, 0.22228600299968093, 0.22363764799956698, 0.20443385700127692, 0.22124377000000095], [], [0.20747941699846706, 0.22227404400109663, 0.22363156900064496, 0.20444099699852814, 0.22131711400106724, 0.21363557699987723, 0.20762538700000732, 0.22552942599941161, 0.1980378460011707, 0.20964390599874605], [], [0.20744516200102225, 0.222324614000172, 0.2235448239989637, 0.20458155400046962, 0.22124810199966305, 0.2135796870006743, 0.207791566999731, 0.22533869600010803, 0.1980554799993115, 0.20973853100076667], [0.2075677730008465, 0.22243667899965658, 0.2236098610010231], [0.2213607060002687, 0.22346252600073058, 0.20483201299975917], [], [], [0.22244437300105346, 0.22349298299923248, 0.20445450599981996, 0.22140721100004157, 0.21339145000092685, 0.2070558399991569, 0.22635492900008103, 0.19733439199990244, 0.21011898100005055, 0.22740727699965646, 0.22911508600009256, 0.20567262199983816, 0.21368195099967124, 0.21607261000099243, 0.21093195399953402, 0.21458747100041364, 0.20829208699979063, 0.20732610099912563, 0.20756053700097254, 0.21269761300027312, 0.2081892019996303, 0.20627739500014286, 0.21170721599992248, 0.23038954599905992, 0.20797380300064106, 0.21241525299956265, 0.40728808600033517], [], [], [0.22233166600017285, 0.22364739799922972, 0.20441701200070383, 0.22125127899926156, 0.2135857949997444, 0.20759591600108251, 0.22566791999997804, 0.1974592529986694, 0.21013786100047582, 0.22725296300086484, 0.22950742799912405, 0.2057277250005427], [0.2052560270003596, 0.22129884899914032, 0.2132836609998776, 0.20786199900067004, 0.2252588339997601, 0.19806306099962967, 0.20979775300111214, 0.2269793919986114, 0.2294773459998396, 0.2061749320000672, 0.2129799490012374, 0.2160464349999529, 0.21219396599917673, 0.21355576400128484, 0.20826972099894192, 0.20768936199965538], [], [], [0.20438848599951598, 0.2213627830005862, 0.2135076159993332, 0.2073121680004988, 0.2259588779998012, 0.1973538420006662, 0.21012095399964892, 0.22741297699940333, 0.22945129899926542, 0.20546204400125134, 0.21355071200014208, 0.21605356199870585], [0.2044430320001993, 0.221393777999765, 0.21338346199991065, 0.20706120300019393, 0.22634774099969945, 0.19734185299967066, 0.21012021900060063, 0.2274096439996356, 0.22910586800026067, 0.20568020100108697], [], [], [], [], [], [], [0.22131038199950126, 0.21312373299952014, 0.2079004179995536, 0.22522300200034806, 0.1983625070006383, 0.2095608790004917, 0.22696468199865194, 0.22951339300016116, 0.2067767080006888, 0.21291577100055292, 0.21552348299883306], [0.22125021000101697, 0.21360397999887937, 0.20762948600167874], [], [], [0.20758696400116605, 0.22567760399942927, 0.19729592200019397, 0.2101158449986542, 0.22741586100164568, 0.22944514699884166], [0.20703865799987398, 0.22638019999976677, 0.19725215499965998, 0.20976751099988178, 0.22758538000016415, 0.22934548299963353, 0.20544809000057285], [0.20736036900052568, 0.22598505099995236, 0.19734786700064433, 0.2101212099987606, 0.22741101500105287, 0.2294558470002812, 0.20545809999930498, 0.21355191799921158, 0.21605860400086385, 0.21191792399986298, 0.2137817830007407, 0.20817483899918443, 0.20773732700035907, 0.20738590899964038, 0.21295739199922536, 0.2077470300009736, 0.20620784600032493, 0.2121723899999779, 0.2299734609987354, 0.20792722100122774, 0.21249989599891705, 0.40739460599979793, 0.03909666300023673, 0.22754384700056107, 0.21737803500036534, 0.21234281699980784, 0.2065397269998357, 0.20758989000023575, 0.206605915000182, 0.2062397689987847, 0.20837881700026628, 0.22336983400055033, 0.20753359400077898, 0.21859204799875442, 0.21327806600129406, 0.2057539999987057, 0.20908934500039322, 0.2085336220006866, 0.20873636599935708, 0.20960135600034846, 0.22823962999973446, 0.21498921000056725, 0.22303037299934658, 0.24521396400086815, 0.21146999199845595, 0.20918672800144122, 0.21032050699977844, 0.20650393799951416, 0.2078391590002866, 0.22016967499985185, 0.22753559900047549, 0.21353251499931503, 0.22389245399972424, 0.20831204000023718, 0.208101139000064, 0.20536689999971713, 0.212165183000252, 0.20736138699976436, 0.20921365700087335, 0.20894711700020707, 0.20969806299945049, 0.24022591299944906, 0.22809419800069008, 0.20368036800027767, 0.2185273919985775, 0.20537331400009862, 0.2211439849997987, 0.22587902400118764, 0.20787454399942362, 0.21231303599961393, 0.21813603500049794], [0.2265562240008876, 0.1972872219994315, 0.2097729930010246, 0.2275054129986529, 0.22944541700053378, 0.20542334099991422, 0.21368481300123676], [0.22553995700036467, 0.19783620000089286, 0.20979544699912367, 0.22719699899971602, 0.22949664600128017, 0.20581745699928433, 0.21331708800062188, 0.21606002299995453, 0.21206721599992306, 0.2136756729996705, 0.20829132399921946, 0.20767653700022493, 0.2083768840002449, 0.21192533599969465, 0.20814542900006927, 0.20648525199976575, 0.21213598900067154], [], [0.1977274490000127, 0.20997550299944123, 0.22741765300088446, 0.22951106799882837, 0.20572174500011897, 0.2134147460001259, 0.21597090199975355, 0.2118321329999162, 0.21377512500112061, 0.20815130899973155, 0.20776024800034065], [0.20965109500139079, 0.22717199599901505, 0.2294906990009622, 0.20582600699890463, 0.21331488299983903, 0.21605627400094818, 0.2120722420004313], [], [], [], [], [], [0.21012311900085479, 0.22727179899993644, 0.22926822699992044, 0.2056575120004709, 0.21361224300017057], [], [], [], [], [0.20957081000051403, 0.2269655899999634, 0.22945900699960475, 0.20621109300009266], [0.2097982729992509, 0.22720233800100686, 0.22950205400047707, 0.2058065869987331, 0.21332324600007269, 0.2160631340011605, 0.21206052799971076, 0.21351793899884797, 0.20845543799987354, 0.20767183499992825, 0.20832636500017543], [0.22727988000042387, 0.2292810359995201, 0.2055640480011789, 0.21365788099865313, 0.21618288500030758, 0.21053693400062912, 0.21414266899955692, 0.2087680160002492, 0.2074877689992718, 0.2074934669999493, 0.21280836300138617, 0.20821483100007754], [], [], [0.20630788100061181, 0.21324623299915402, 0.21611135300008755, 0.2118508790008491, 0.2137761979993229, 0.20816279999962717, 0.20774998100023367, 0.2080085239995242, 0.21235177100061264, 0.20820735699999204, 0.2059668319998309], [0.206776009999885, 0.21247519600001397, 0.21596726400093758, 0.21221600799981388, 0.21364239799913776, 0.20824271099991165, 0.2077331470009085, 0.20828879600048822, 0.2119010439982958, 0.20844122400012566, 0.20628746100010176, 0.2120917370011739, 0.22909629499918083, 0.20814034100112622, 0.21274668999831192, 0.4074148760009848, 0.0389230269993277, 0.227389794001283, 0.21717447999981232, 0.21396856299907085, 0.2049374260004697, 0.20832963099928747], [0.2054543719987123, 0.21355596900139062, 0.216064741000082, 0.21190757399926952, 0.21378638699934527, 0.2081808720013214, 0.20773108699904697, 0.20733187800033193], [], [], [], [], [0.21249129399984668, 0.2159235900016938, 0.2122274239991384, 0.21355328299978282, 0.20837394699992728, 0.20772445100010373, 0.2082984230000875, 0.21189350799977547, 0.20812585900057456, 0.20660114000020258, 0.2120924909995665, 0.2291041469998163, 0.20801873900018109, 0.21283274000052188, 0.4073137029990903, 0.03898885899980087, 0.2274683180003194, 0.2171039610002481, 0.2137975909990928, 0.20515982400138455, 0.20833597899945744, 0.20666602500023146, 0.20618560799994157, 0.20763893500043196, 0.2246314189997065, 0.20652215299924137, 0.21827027600011206, 0.21320708399980504, 0.20652801400137832], [], [], [0.21361607699873275, 0.21617776499988395, 0.21070063300066977, 0.21398998800032132, 0.2087518899988936, 0.20748968000043533, 0.20749444400098582, 0.21280681799908052, 0.2083170860005339, 0.20626856699891505, 0.2114837510016514, 0.22986994499842694], [0.21260447900021973, 0.2159515069997724, 0.21221957800116797, 0.21351835899986327, 0.20826012900033675, 0.20775832099934632, 0.20837125899925013, 0.21188062600049307, 0.2081254999993689, 0.20650764500169316], [0.2159772539998812, 0.2118263090014807, 0.21377645199936524, 0.2081557410001551, 0.20775524099917675, 0.2080237070003932, 0.2123400609998498, 0.20820473300045705, 0.20604534499943838, 0.21257094500106177, 0.22925127700000303, 0.2079519029994117, 0.2125052589999541, 0.4074073680003494, 0.039170691999970586, 0.22744050800065452, 0.217372950999561, 0.21289075999993656, 0.20599630799915758, 0.2076475339999888, 0.20652780599994003], [], [], [0.21276590900015435, 0.21352116100024432, 0.2084593239997048, 0.20753005199912877, 0.2084379820007598, 0.2120031270005711, 0.20814667199920223, 0.2059652890002326, 0.21257016500021564, 0.22919730299872754, 0.20810248100133322, 0.21240391399987857, 0.4073935300002631, 0.03923641700021108, 0.22734866499922646, 0.21737329099960334, 0.21371635899959074, 0.20525904500027536, 0.20762170099987998, 0.2068347360000189, 0.20601294400148618, 0.20820186199853197, 0.2233719169998949], [], [0.21180203199946845, 0.21372962500026915, 0.20847297399996023, 0.20752026700029091, 0.2079311340003187, 0.2123339350000606], [], [0.21221148799850198, 0.2135377120011981], [0.21381685900087177, 0.20819852499880653, 0.20771412599970063, 0.20727024100051494, 0.21256760399955965, 0.20818711100037035, 0.2062776759994449, 0.21171409900125582, 0.23037807000036992, 0.20798230199943646, 0.2124164569995628], [], [], [], [], [], [], [0.2136894930008566, 0.20846381499904965, 0.20752542199988966, 0.2079305760016723, 0.21240482999928645, 0.20823707199997443, 0.2059650489991327, 0.21256309599993983, 0.22921659700114105, 0.20796381299987843, 0.2125080549994891, 0.40741238900045573, 0.03917276299944206, 0.22743231900130922, 0.21737398899858817, 0.21298832899992703, 0.2058799740007089, 0.20764505400074995], [0.2137951669992617, 0.20818688600047608, 0.2077240830003575, 0.20727045400053612], [0.2139242600005673, 0.2087350960009644, 0.20749266399980115, 0.20749230799992802, 0.21280429999933403, 0.20832132599934994, 0.2062744129998464, 0.2114962280011241, 0.23060770600022806, 0.20795735299907392, 0.2124186720011494, 0.4072821659992769, 0.03935017600088031, 0.22742123199896014, 0.21751978599968425, 0.21224560300106532, 0.20665687899963814, 0.2071318620000966, 0.2069016229997942, 0.20625667400054226, 0.20811859099922003, 0.2236117810007272, 0.20754792299885594], [], [], [], [], [], [], [], [0.20812737100095546, 0.20733560000007856], [], [], [0.20787201699931757, 0.20739522300027602, 0.21298017000117397], [0.20769850099895848, 0.20717013900139136], [0.2073173049993784, 0.20756124500076112, 0.2126968209995539, 0.20819628900062526, 0.20627548400079831, 0.21169788299994252, 0.23040436299925204, 0.20796626199989987, 0.21241419900070468, 0.4072858539984736, 0.03934676900098566, 0.22742717099936272], [0.2077519639988168, 0.20833203000074718, 0.2118878709989076, 0.20812673900036316, 0.20659728300051938, 0.21207103000051575, 0.22898405699925206, 0.2081391240008088, 0.21283971599950746, 0.40729506199932075, 0.03887742500046443], [0.2077194760004204, 0.20830570199905196, 0.21188976300072682, 0.20812675900015165, 0.20660030399994866, 0.21208966499943926, 0.22910860100091668, 0.2080146899988904, 0.21283681900058582, 0.40730812500078173, 0.03893523599981563], [0.20794283300165262, 0.21229568699891388, 0.20802097799969488], [], [], [], [], [], [], [], [], [], [0.20833402900098008, 0.21199111900023127, 0.2081454399994982, 0.20596593200025382, 0.2125733909997507], [0.21187520800049242, 0.20812789000046905, 0.2064965179997671, 0.21218909100025485, 0.22900943300010113, 0.20811682400017162, 0.21240185399983602, 0.4073905419991206, 0.03923744399980933, 0.22763448899968353, 0.21710267900016333, 0.21372139200138918], [0.21199784799864574, 0.20814973600136, 0.2059657289992174, 0.21256749799977115, 0.22920559799968032, 0.20796902700021747, 0.21250795200103312, 0.4074153040000965, 0.03917066099893418], [0.2126437770002667], [0.20853383900066547, 0.20630089800033602], [0.20804201499959163, 0.20623171899933368, 0.21209370699943975, 0.2290898510000261, 0.2081471210003656, 0.21274108400029945, 0.40742480300104944, 0.03892404499856639, 0.2273836679996748, 0.21718058700025722, 0.21395760900122696], [0.20596384899909026, 0.21202449100019294], [0.2062119120000716, 0.21169817699956184, 0.2303703500001575, 0.20798738799931016, 0.2124911909995717, 0.40732394699989527, 0.03919425900130591, 0.227536340998995, 0.2173828080012754, 0.21224413399977493], [0.20595775699985097, 0.21211673700054234, 0.22996325799977058, 0.2079330470005516, 0.21250245599912887, 0.407398577001004, 0.03909053699862852, 0.22754698100106907, 0.21737611400021706, 0.21234999199987215, 0.20653545300046972, 0.20758077899881755, 0.20661263399961172, 0.20623680900098407, 0.20838251399982255, 0.22336943099981, 0.20753220799997507, 0.21859058100017137, 0.21328358500068134, 0.2057504809999955, 0.20909020399994915, 0.20853887100020074, 0.20872667099865794, 0.20960213500075042, 0.22824032400058059, 0.2149884229984309, 0.22302702300112287, 0.2452129760004027, 0.21147812299932411, 0.20918095900015032, 0.21032483799899637, 0.2065148070014402, 0.20782957899973553, 0.2201684550000209, 0.2275331319997349, 0.21354165199954878, 0.22388563099957537, 0.20831367000027967, 0.20809643600114214, 0.20537071799844853, 0.21216886600086582, 0.2073572150002292, 0.2092191739993723, 0.20894435800073552, 0.20969725400027528, 0.24023714099894278, 0.22808438799984287, 0.2036780100006581, 0.2185243330004596, 0.20537563699872408, 0.221145717001491, 0.22587051399932534, 0.20788151799933985, 0.2123109000003751], [0.20596375400054967, 0.21255800299877592, 0.22923041500143881, 0.20795748899945465, 0.21250743599921407, 0.4074087030003284, 0.0391743399995903, 0.2274349400013307, 0.21737350299918035, 0.2129037270005938], [], [], [0.21186873999977252, 0.22899404100098764, 0.20816267599911953, 0.21272720799970557, 0.4074482899995928, 0.03892009000082908, 0.22737829300058365, 0.21840314399923955, 0.21276691700040828, 0.20555603699904168, 0.2077875340000901, 0.20685756200145988, 0.20644584199908422, 0.2073019170002226, 0.22449258899905544, 0.20684851100122614, 0.2179134839989274, 0.2133772860015597, 0.20640252999874065, 0.20951066199995694, 0.20821439100109274, 0.2091709609994723, 0.20907106099912198, 0.2276989300007699, 0.2161610679995647, 0.2220623630000773, 0.24464354399970034, 0.2116113440006302, 0.20990896399962367, 0.2107792220012925, 0.20585953299996618, 0.20751960099914868, 0.22018544700040366], [0.2119632960002491, 0.22903491999932157, 0.20815331700032402, 0.21273544999894511, 0.40743226500126184, 0.0389237969993701, 0.2273808949994418, 0.21840898400114384, 0.21276879600009124, 0.20531813999878068], [], [], [], [], [], [0.21205093899880012, 0.22993119500097237, 0.20793971000057354, 0.2125032009989809, 0.40740193400051794, 0.0390863550001086, 0.22754776100009622, 0.21737492799911706, 0.21235178200004157, 0.20653380099975038, 0.20757589300046675], [0.22998934899987944, 0.20792150500165008, 0.21249729899864178, 0.40732674700120697], [], [0.21243495700036874, 0.407269052000629, 0.03936471300039557, 0.22741243400014355, 0.21752836199993908, 0.21224795499983884, 0.2066609969988349, 0.20713460899969505, 0.2069054440016771, 0.20625864299836394, 0.2080540450006083], [], [], [], [0.21275647299989942, 0.4074045939996722, 0.03887184999985038], [], [0.2254318699997384, 0.2171080379994237, 0.2137186620002467, 0.20525701000042318, 0.20761836800011224, 0.20683946999997715, 0.20601600000009057, 0.2081953920005617, 0.22343948399975488, 0.20744421199924545, 0.2185863859995152, 0.21328874400023778, 0.20600305600055435, 0.20938103499975114, 0.20821348000026774, 0.20918386400080635], [0.21271246199830784, 0.2049351680016116, 0.20833350399880146, 0.20666955200067605, 0.20619052999973064, 0.20763652099958563, 0.22462487700067868, 0.20652571299979172, 0.21826793500076747, 0.21320648799883202, 0.20657198499975493, 0.20891176800068934, 0.20873706100064737, 0.2087705609992554, 0.20930051200048183, 0.22779535799963924, 0.2163262449994363, 0.22182820400121273], [0.20526414999949338, 0.20759244600048987], [0.20678983499965398, 0.20715360100075486, 0.2069099879990972, 0.20626161099971796, 0.20805116399969847, 0.22369818100014527, 0.20734926400109543, 0.21891040699847508, 0.21295081100106472, 0.2058639229999244, 0.20899473099962051, 0.20871410700056003, 0.20887351599958492, 0.20960476000072958, 0.2282382299999881, 0.2149164579986973, 0.22284877300080552, 0.24522950500067964, 0.21106904599946574, 0.20966070599934028, 0.2103649119999318, 0.2060760370004573], [], [0.20802774599906115, 0.20661231700069038, 0.20665084999927785, 0.20721106800010602, 0.22456632499961415, 0.206535489000089, 0.21825813800023752, 0.2131939949995285, 0.2065700060011295, 0.2089977910000016], [], [], [], [], [], [0.20779835299981642, 0.20533404399975552, 0.20796228400104155, 0.20718390399997588, 0.22455822799929592, 0.20689735999985714, 0.21790409999994154, 0.21339105300103256, 0.2064005559986981, 0.20949325000037788, 0.20819382700028655], [0.20653361299991957, 0.20628565100014384, 0.2080470860000787, 0.22359292900000582], [0.20701194100001885, 0.20551295599943842, 0.2081926070004556, 0.22344687799886742, 0.20743821900032344, 0.21858406700084743, 0.213290738998694, 0.20600001999991946, 0.2093879450003442, 0.20821037399946363, 0.20926951200090116], [0.2075259619996359], [0.20675488499909989, 0.20637852199979534, 0.20752800500122248, 0.2242489079999359, 0.20733716299946536, 0.21891031499944802, 0.21284968500003743, 0.20582022600137861, 0.20895451599972148, 0.20886247499947785, 0.20871861799969338, 0.20975698700021894, 0.22808149400043476, 0.2149791270003334, 0.22295276099976036, 0.2451400919999287, 0.2111647580004501, 0.20954882799924235, 0.21031756000047608, 0.20584708499882254, 0.20815695200144546, 0.22048807099963597, 0.22766657099964505, 0.21316542100066727, 0.22374666899850126, 0.20844769600080326], [0.20626990900018427, 0.2080499379990215, 0.22370188400054758, 0.20734719800020684, 0.21891032900020946, 0.2129558859996905, 0.20586409799943794, 0.20899672400082636, 0.208712851999735, 0.20887301999937335, 0.20960830300100497, 0.22823675899962836, 0.2149171689998184, 0.2228531809996639, 0.24523154199960118, 0.2110597000009875, 0.20955481300006795, 0.210307744999227, 0.2059560079997027, 0.20804516099997272, 0.2205630040007236, 0.22757329100022616, 0.21329427999990003, 0.22364482900047733], [0.20664956699874892, 0.20721500100080448, 0.2245689270002913, 0.2065330819987139, 0.21825728099975095, 0.21320219500012172, 0.20656845000121393, 0.20898936099911225, 0.20874010700026702, 0.20874346399978094, 0.20926133099965227], [0.20590871700005664], [0.20658325200020045, 0.20718886199938424, 0.22456428199984657, 0.20689367700106231, 0.21790224600044894, 0.21318603799954872, 0.2065727520002838, 0.20947186800003692, 0.20824800499940466, 0.2087488029992528], [0.20624377800049842, 0.20836995299941918, 0.2233722860000853, 0.20754026000031445, 0.21859342999960063, 0.21317900299982284], [], [0.20606440999836195, 0.20837288700022327, 0.2233695129998523, 0.2075307570012228, 0.21858810899902892, 0.21328728300068178, 0.20597004199953517], [], [], [0.207568829999218], [0.20805101099904277, 0.22359422800036555, 0.20766215399999055, 0.21859924999989744, 0.21317683400047827, 0.2058687139997346, 0.20908595099899685, 0.20843125200008217], [0.20723306800027785, 0.22457194999878993, 0.20653006600150547, 0.2182591999990109, 0.2132041240001854, 0.20657048300017777, 0.20898173100067652, 0.20874859799914702, 0.20873815100094362, 0.20926726299876464, 0.2279194880011346, 0.2162126619987248, 0.2218936040007975], [], [0.224498293000579, 0.2068536850001692, 0.21790790900013235, 0.21338435299912817, 0.20640145800098253, 0.20950322699900426, 0.20822151500033215, 0.20917021199966257, 0.20897063800111937, 0.22779544699915277, 0.2161663229999249, 0.22205786800077476, 0.24464737599919317, 0.21160566599974118, 0.20971580800141965, 0.21092093100014608, 0.2058952709994628, 0.20751824599938118, 0.2201768280010583, 0.22732895299850497, 0.2142809840006521, 0.22364082599960966], [], [], [], [], [], [], [0.205812332998903, 0.21873827800118306, 0.21294767099971068, 0.20586286399884557, 0.20899532900148188, 0.2087137869984872, 0.20887400500032527, 0.2096021480010677, 0.22823875599897292, 0.21491696300108742, 0.2228444619995571, 0.245227094999791], [0.21827516899975308, 0.21321395199993276, 0.20599467800093407, 0.20939489299962588, 0.20820925800035184, 0.20933079200040083, 0.20936660499864956, 0.22775756400005776, 0.21488305700040655, 0.22300088600059098], [], [], [], [0.20716925499982608, 0.20925154799988377, 0.2087409479991038, 0.2088025220000418, 0.2093562900008692, 0.22776180499931797, 0.2148843590002798], [0.2057538740009477, 0.2090637750006863, 0.2087383559992304, 0.20871444399926986, 0.20976101900123467, 0.2280834559987852, 0.2149696619999304], [0.20640162900053838, 0.20948174499972083, 0.20820615100092255, 0.20912106200012204, 0.2090413459991396, 0.22779809500025294, 0.2161793220002437, 0.22200134199920285], [0.20586588400146866, 0.209082032999504, 0.2084403039989411, 0.20886394400076824, 0.20960085700062336, 0.22824103199855017, 0.21498659200005932, 0.2228575640001509, 0.24537847500141652, 0.2108112429996254, 0.2096593850001227], [0.20899865000137652, 0.20871821399850887, 0.2088647199998377, 0.20961285100020177, 0.22823463600070681, 0.21491879200038966, 0.22285988200019347, 0.24509100899922487, 0.2111901839998609, 0.20956067599945527, 0.21030348200110893, 0.20595940800012613, 0.20804315399982443, 0.22055811700010963, 0.22758198799965612, 0.21328390800044872, 0.22364812799969513, 0.20854528500058223, 0.2076008419990103, 0.20613574700109893, 0.2121648689990252, 0.20748040199941897, 0.20862531200145895], [0.20919142799903057, 0.208669383000597, 0.20881064499917557, 0.20934238600057142, 0.22777481800039823, 0.21546192899950256, 0.22246504800023104, 0.2451340600000549, 0.2116075659996568, 0.20967585400103417, 0.21036464799908572, 0.20629222400020808, 0.207640167000136, 0.22016410899959737, 0.22746799900050974, 0.21419366500049364, 0.2236990129986225, 0.2088664950006205, 0.20742749199962418, 0.20549421400028223, 0.212336487000357], [0.20893908200014266, 0.20848255300006713, 0.20872288400096295], [], [], [0.20918991899998218, 0.20865606500046852, 0.20881510199978948, 0.209335428000486, 0.2277813340006105, 0.21547534899946186, 0.2224474350005039, 0.2451342329986801, 0.21161638400008087, 0.20966947000124492, 0.21038042699910875, 0.2062856020002073, 0.20763384999918344, 0.22017165900069813, 0.2274606249993667, 0.21418882600119105], [], [0.20809923200067715, 0.2092570290005824, 0.20959469099943817, 0.22774742500041611, 0.2148827450000681, 0.22301264499947138, 0.2452116050008044, 0.21149155599960068, 0.20956584899977315, 0.21000486299999466, 0.20643704699978116, 0.20791579999968235, 0.22010706800028856, 0.22753289700085588, 0.21353586299846938, 0.2240203580004163, 0.20852156299952185, 0.20775954100099625, 0.20566814199992223, 0.21194935700077622], [0.20866733900038525, 0.20886633900045126, 0.20960044099956576, 0.2282410739990155, 0.21491693800089706], [], [0.20875951800007897, 0.20873335800024506, 0.20927397500054212, 0.22790915400037193, 0.21621932499874674, 0.22189105300094525, 0.24484611799925915, 0.21158454100077506, 0.20965918999900168], [0.20876419999876816, 0.20930971300003876, 0.22778775400001905, 0.21548247099963191, 0.22266938400025538, 0.24489957700097875, 0.21162329700018745, 0.20966498099915043, 0.21038864600086526, 0.2062829309998051], [], [], [], [0.20918084800177894, 0.20956032299909566, 0.22775238699978217, 0.2148838249995606, 0.22300537100090878, 0.24521265200019116, 0.21149724099996092, 0.20956855899930815, 0.21000806800111604, 0.20643503999963286, 0.20791092299987213, 0.22010796500035212, 0.22753617699891038, 0.21353533000001335, 0.2240129199999501, 0.20885854399966775, 0.2075243760009471, 0.20579558099962014, 0.21193317500001285, 0.20717438599967863, 0.20920662600110518, 0.20931876699978602, 0.20959242199933215, 0.24004044700086524, 0.22796716899938474, 0.20391667399962898, 0.21879468299994187, 0.205114334999962, 0.22110932699979458, 0.22560406100092223, 0.20871240999986185, 0.21203262400013045, 0.2176413239994872], [], [], [], [], [], [], [], [], [], [0.20873625999956857, 0.2092813630006276, 0.22782024799926148, 0.2163057880006818, 0.2218847000003734, 0.24481921400001738], [], [], [0.20901273999879777, 0.2277999270008877, 0.21620002800045768, 0.22195111499968334, 0.24477392599874293, 0.2115951940013474, 0.20972203199926298, 0.21073191200048313, 0.2060198199997103, 0.20747202299935452], [], [], [], [], [], [0.20897378799963917, 0.2277887769996596, 0.21617290700123704, 0.22205154199946264, 0.2446523979997437, 0.21160046600016358, 0.20972003399947425, 0.21092070800114016, 0.2058914419994835, 0.20751671899961366, 0.22007955700064485], [0.22774795400073344, 0.21488343099917984, 0.2230190730006143, 0.2452119780009525, 0.2114841989987326, 0.2095474939997075, 0.20995906300049683], [], [], [], [], [0.2277929040010349, 0.21618745699925057, 0.22195427699989523], [0.22141446599925985, 0.2452188280003611, 0.21086087999901793, 0.2097027670006355, 0.21027601800051343], [], [], [], [], [0.2092012369994336, 0.21031258099901606, 0.20601632800025982, 0.2079556650005543, 0.22045930000058434, 0.2276062759992783, 0.2131797120000556, 0.22425689000010607, 0.20831321100013156, 0.20810432299913373, 0.2053656400003092, 0.2120520309999847], [0.20970812100131297, 0.2102755289997731, 0.20614582300004258, 0.20787331499923312, 0.2204997610006103, 0.22763114100052917, 0.21317602699855343, 0.22373410600084753, 0.2084052480004175, 0.20792894499936665], [], [0.21078353300072195, 0.20585581499835826, 0.2075182610005868, 0.220182315000784, 0.22732196699871565, 0.21427871700143442, 0.22367881699938152, 0.20874792799986608, 0.20751223499974003, 0.20547383899975102, 0.21291351400032], [0.20990066900048987, 0.20667054200021084], [], [], [], [0.20996113900037017, 0.2067086349998135, 0.2076749000007112, 0.22005916499983869, 0.22762407200025336, 0.21420738199958578, 0.2233419229996798, 0.2087954950002313, 0.20749642299961124, 0.20580189700012852, 0.21233573000063188, 0.20736730200042075], [], [], [0.2060268699988228, 0.20747884299998987, 0.2201756070007832, 0.22745686400048726, 0.21424503599882883], [0.20608712300054322, 0.2078541850005422], [], [0.20588737199977913, 0.20751234899944393, 0.22008249200007413, 0.2274484380013746, 0.21428210199883324, 0.22363797500111104, 0.20879629399860278, 0.2074287040013587, 0.20551001300009375, 0.2129354329990747, 0.20722084500084748, 0.2093690969995805, 0.20928479299982428, 0.20871717100089882, 0.23975412299841992, 0.2294337280000036, 0.20261417900110246, 0.21875006200025382, 0.20559840299938514, 0.220810734999759, 0.2253874550006003, 0.2087532249988726, 0.2128124860009848, 0.2178333259998908, 0.23079108399906545, 0.20751076400119928], [0.2078643929999089, 0.22050903199851746, 0.22756802000003518, 0.2133000110006833, 0.22376371000063955, 0.2084069559987256, 0.2076129220004077, 0.20613489000061236, 0.2121631680001883, 0.20748325499880593, 0.20873445400138735, 0.20934120399942913, 0.20978031499907956, 0.23970862200076226, 0.2286443760003749, 0.20265695699890784, 0.21947716500108072, 0.20543984899995849, 0.22090547600055288, 0.2260466779989656, 0.20721968699945137, 0.21283518000018375, 0.21812634300113132, 0.232364723999126, 0.20751948699944478, 0.21696855700065498, 0.219025144000625, 0.20812022499922023], [], [], [], [0.20767743999931554, 0.22006219099966984, 0.22753549300068698], [0.22017800100002205, 0.2275381670006027, 0.21342919299968344], [], [], [], [], [], [0.22001854800146248, 0.22761693199936417, 0.214200931999585, 0.22368905000075756, 0.20886165000047185, 0.20742428099947574, 0.20549143199968967, 0.21234153099976538, 0.20747967600073025, 0.2093437659987103, 0.20917915600148262], [0.22046126599889249, 0.22761171800084412, 0.21317748999899777, 0.22373488999983238, 0.20840397700158064, 0.20844129799843358, 0.20542225100143696, 0.2120547649992659, 0.2074892729997373, 0.20914332699976512, 0.20903157199973066, 0.209697814001629, 0.23983956199845125, 0.22850362800090807, 0.20344251099959365, 0.21874376100095105, 0.20537315499859687, 0.22113600200100336, 0.22590401399975235, 0.20774648400038132], [0.22010861600028875, 0.2275195009988238, 0.21354913399954967, 0.22402648200113617, 0.20850575899930845, 0.20777256400106126, 0.20566374999907566, 0.21195067699954961, 0.20735740000054648, 0.20918458300002385, 0.2089255230002891, 0.2097020210003393, 0.24024548699890147], [], [], [], [], [], [], [], [], [], [0.21504764599922055, 0.22334700400097063, 0.20878868399995554, 0.20749924599840597, 0.20579857800112222, 0.21193586699882871, 0.20758721200036234, 0.20965475800039712, 0.20916113299972494, 0.20910200500111387, 0.23990814399985538, 0.22791802099891356, 0.20389681100095913, 0.2188978899994254, 0.20513954600028228, 0.22105622699928063, 0.22554793000017526, 0.20872757300094236, 0.21205432599890628, 0.21783500400124467, 0.23169366699949023, 0.20750933599993004, 0.2169751940000424, 0.21901007300039055, 0.209207724999942, 0.22058916300011333, 0.24017345299944282, 0.2232828559990594, 0.22284355900046648, 0.2243838490012422, 0.1993276679986593, 0.21470025700000406, 0.2128642099996796, 0.2229359070006467, 0.21751833100097429, 0.20713019199865812, 0.21017141900119896, 0.22051007200025197, 0.20458456199958164, 0.20980858099937905, 0.21325319500101614, 0.2063209599982656, 0.22219296700131963, 0.20654209799977252, 0.21085757599939825], [0.21317346999967413, 0.22373681099998066, 0.20840494700132695, 0.20761613199829299, 0.2061370440005703, 0.2121611220009072, 0.20748457799891185, 0.20873985400066886], [0.2236198480004532, 0.20878192399868567, 0.20748835300037172, 0.20579170299970428, 0.21187659600036568], [0.20831763400019554, 0.2081096450001496, 0.20536398100011866, 0.2120530049996887, 0.20748907199958921, 0.20914528400135168], [0.20871710400024313, 0.20748332500079414, 0.20550151499992353, 0.21295051599918224, 0.20722496500093257, 0.20934703499915486, 0.20923475400013558, 0.20873589300026651, 0.23975160400004825, 0.2294139819987322, 0.20266514500144694, 0.21869324799990864, 0.20584299700021802, 0.22067582899944682, 0.225576822000221, 0.2085023599993292, 0.21275007400072354, 0.21784511399891926, 0.23098929800107726, 0.20843600399894058, 0.21605799500139256, 0.21892502199989394, 0.20971514599841612, 0.22036035600103787, 0.23989186600010726, 0.22323709699958272, 0.22281262400065316, 0.224738138000248, 0.19991804899837007, 0.2140624090006895, 0.21286103000056755, 0.2230943300000945, 0.21746001199971943, 0.20779946199945698, 0.2099667969996517, 0.21980957000050694], [], [], [], [0.20822799999950803, 0.20804911599952902, 0.20537365400014096, 0.21216877100050624, 0.207426917999328, 0.20918346500002372, 0.20892760700007784, 0.20970114000010653, 0.2402430349993665, 0.22807673900024383, 0.20393538800090028, 0.2182622079999419, 0.20551019899903622], [0.2071963849994063, 0.20571944500079553, 0.21234123000067484, 0.20747776899952441, 0.20934581399887975, 0.20914961300150026], [0.2075192970005446, 0.20578758400006336, 0.2118784929989488, 0.20724736299962387, 0.20920845700129576, 0.20889909099969373, 0.20970012500038138, 0.24032689500018023, 0.2279727079985605, 0.2039312400011113, 0.21828327299954253], [0.20821206499931577, 0.20536304900087998, 0.2120545529996889, 0.2074894769993989, 0.20914336600071692, 0.20903378399998473, 0.20969793199947162, 0.23983938899982604], [], [0.20547250999879907, 0.21291128000120807, 0.20721158400010609, 0.20937460699860821, 0.2092819640001835, 0.2087216960007936, 0.23975246000009065, 0.229429203998734, 0.20261041600133467], [], [], [], [], [], [], [], [], [0.20542521199968178, 0.21205768099935085, 0.20748628500041377, 0.20914168400122435, 0.20903038299911714, 0.2097009099998104, 0.23983848600073543, 0.22850426500008325, 0.20294163699873025], [0.21187970900064101, 0.20724789499945473, 0.2092097550012113, 0.20889900399924954, 0.20970036800099479, 0.24032245499984128, 0.22797815999911109, 0.2039357960002235, 0.21826160800083017, 0.2056208069989225, 0.22105189000103564, 0.22570230099881883, 0.20869255199977488, 0.21160378100103117, 0.218090074000429, 0.2321688889987854, 0.20791353300046467, 0.21667336499922385, 0.21896118500080775, 0.20865728500029945, 0.22122705800029507, 0.24006595199898584, 0.2232495469997957, 0.2228059460012446, 0.22457888399912918, 0.19989002399961464, 0.2141673220012308, 0.21279424099884636, 0.22307292799996503, 0.2175985670000955], [], [0.21195739500035415, 0.2086715280001954, 0.2093799840004067, 0.2092784729993582, 0.20872566500111134, 0.23975312099901203, 0.22942392299955827, 0.2026657710011932, 0.21868635499959055, 0.2058500519997324, 0.22060816799967142], [0.20699506599885353, 0.20948000300086278, 0.20939481899949897, 0.2087053310006013, 0.2397607330003666, 0.22801741100010986, 0.20404592199884064, 0.2187414700001682, 0.2056054540007608, 0.22078806100034853, 0.22533916299835255], [0.20936628799972823, 0.20929210700160183, 0.2087108729992906, 0.23975646600047185, 0.22943677699913678, 0.20261944199955906, 0.21874525300154346, 0.2056029179984762, 0.22080065200134413, 0.22536263700021664], [0.20957528600047226], [0.20918552200055274, 0.20893239399993035, 0.20969897899885837, 0.24024142000052962, 0.22807914199984225, 0.20367611500114435, 0.21852366399980383, 0.2055045679990144, 0.2211778860000777, 0.22571480100123154, 0.20796483699996315], [], [], [0.20934744799887994, 0.20923352500176406, 0.2087301399988064, 0.23975335599971004, 0.22941850900133431, 0.20266690899916284, 0.2186892749996332, 0.20584632999998576, 0.22067477000018698, 0.22557570100070734, 0.20844369000042207], [0.20939755200015497, 0.2087011399999028, 0.2397682819992042, 0.22801325500040548, 0.20405694200053404, 0.2187368390004849, 0.20560890900014783, 0.2205246449993865, 0.2255294619990309], [], [], [], [0.20869062000019767, 0.20959066099931078, 0.2400346480008011, 0.22796492199995555, 0.20390980899901479, 0.2183681050009909, 0.20550973699937458, 0.2211082699996041, 0.22561378799946397, 0.20870490000015707, 0.2115981679999095], [0.20902853699953994, 0.2097084460001497, 0.23983455000052345, 0.22850992799976666, 0.20284444900062226], [0.20941127799960668, 0.2402263910007605, 0.22797048599932168, 0.20392317900041235, 0.21825333100059652, 0.2056276160001289, 0.22104904200023157], [], [], [], [], [0.23991426400061755, 0.22792122600003495, 0.2039038029997755, 0.21880008900006942, 0.20510468799875525, 0.2211097890012752, 0.2255960740003502, 0.20871870099836087, 0.2120409210001526, 0.21771719800017308], [0.2019301889995404, 0.21853113299948745, 0.20537309800056391, 0.22114301600049657, 0.2258877719996235, 0.2078621109994856, 0.2123199729994667, 0.2180688230000669], [0.21873087299900362, 0.20506258900059038, 0.22105669799930183, 0.2255406660005974, 0.2087331999991875, 0.2120536880011059, 0.217840866998813, 0.2316919950008014, 0.20750945700092416, 0.21697404499900586, 0.21900936100064428, 0.20921348499905434, 0.22058280300007027], [], [0.21874629400008416, 0.20537383499868156, 0.2209066180002992, 0.22614546600016183, 0.2077375690005283, 0.21244955399924947, 0.21806692199970712, 0.2324014799996803, 0.20793423200120742], [0.20689214800040645, 0.22052661399902718, 0.22553491000144277, 0.20873660599863797, 0.21205428200119059, 0.21784484399904613, 0.23169206500097062, 0.2075094009996974, 0.21697289499934413, 0.21900856499996735, 0.20921732500028156, 0.22069273099987186, 0.24004747199978738, 0.22328089100119541], [0.20513955900059955, 0.22105460300008417, 0.22555892399941513, 0.20872347800104762, 0.21205307499985793, 0.21782820399857883, 0.23169457200128818, 0.2075105829990207, 0.21697484200012696, 0.219012310000835, 0.20920139500049117, 0.22059755999907793, 0.2401653039996745, 0.22308812099981878, 0.22304012600034184, 0.22439573600058793, 0.19931483499931346, 0.21470423600112554, 0.21286367099855852, 0.22293397100111179, 0.21751861099983216, 0.20712835799895402, 0.21017228300115676, 0.22051937600008387, 0.20457669099960185, 0.20970892699915566], [0.22077668300153164, 0.2256566969990672, 0.20845178499985195, 0.21281682700100646, 0.21784107199891878, 0.2308082800009288, 0.2075923939992208, 0.21690595200016105, 0.21903181100060465, 0.20934392199887952, 0.22049428100035584, 0.2401070060004713, 0.22326671199880366, 0.22273779700117302, 0.2246545719990536, 0.19912504100102524, 0.214646446000188, 0.21301255300022603, 0.22289876099966932, 0.2177160779992846, 0.20743879600013315, 0.20980635900014022, 0.22027977399920928, 0.20495288300116954, 0.21007707199896686, 0.21329557600074622, 0.20603770600064308, 0.22201506499914103, 0.20690409000053478, 0.2112124479990598, 0.20553094200113264, 0.2062184989990783, 0.22248900399972626, 0.24134663699987868, 0.2488109269997949, 0.21023445900027582, 0.20863019300122687, 0.21164669799873082, 0.2185603819998505, 0.20766126200032886, 0.21437821700055792, 0.20467447500050184, 0.22581818799881148], [], [], [0.22106106000137515, 0.22557746799975575, 0.20872504500039213, 0.21204401699833397, 0.21777728900087823], [0.22109802500017395, 0.22585344000071927, 0.20788905399967916], [], [], [], [0.22107810099987546], [], [], [], [], [], [0.2092823339989991, 0.21220819700101856, 0.21762841599957028, 0.23173025300093286], [0.20772627100086538, 0.21233695799855923, 0.21817760300109512, 0.2322963520000485, 0.2075113249993592, 0.2169728219996614, 0.21908189700116054, 0.2082960269999603, 0.2215439809988311, 0.24004374499963888, 0.22332123600062914], [0.21237998099968536, 0.21805305599991698], [0.21161580800071533, 0.21808525799860945, 0.2320963660004054, 0.207511513001009, 0.21697214399864606, 0.21908665000046312, 0.20863448199997947], [0.21782184499897994, 0.23063694600023155, 0.20701137099968037, 0.2173542440013989, 0.21805799499998102, 0.2106601059986133, 0.2202067550006177, 0.24006181199911225, 0.22323431200129562, 0.22294636100014031, 0.22448985399933008, 0.19926767899960396, 0.21471823300089454, 0.2128679329998704, 0.22292693199960922, 0.21751926800061483, 0.20702444599919545, 0.21030475800034765, 0.22054220700010774, 0.20455784200021299, 0.210496305999186, 0.21250757800044084, 0.20677188800073054, 0.22211388999858173, 0.20668620100150292, 0.2107254729999113, 0.2056687599997531, 0.2066016930002661, 0.2225859579993994, 0.2413516359993082, 0.2488380100003269, 0.21025407600063772, 0.2084868429992639, 0.2117715460008185, 0.2185106380002253, 0.20773545599877252, 0.2143848590003472, 0.20463468700108933, 0.22578898499887146, 0.2047247980008251, 0.2137844729986682, 0.23187789900111966, 0.2526810219987965, 0.27364040900101827, 0.25700697600041167, 0.22093414299888536, 0.20991806100028043, 0.20825644900105544, 0.21368303399867727, 0.20991705100095714, 0.20773128499968152, 0.22353914999985136, 0.2456323810001777, 0.21888513799967768, 0.22695389399996202, 0.2087750410009903, 0.21928901899991615, 0.20944753599906107, 0.2177667180003482, 0.20749494899973797, 0.20857627999976103, 0.22356919599951652, 0.2035201490016334, 0.23754139599986956, 0.21480453299955116, 0.21063423899977352, 0.23183704999973997, 0.22895618199981982, 0.22138733900101215, 0.20715771299910557, 0.21287073399980727, 0.21246348400018178, 0.21436926600108563, 0.2082527869988553, 0.20553913700132398, 0.20908371899895428], [], [], [], [], [], [], [0.2176269029987452, 0.2316963860012038, 0.20759602100042684, 0.21690421699895523, 0.21903043900056218, 0.2090839339998638, 0.22075206000045, 0.24011195399907592, 0.22325938399990264, 0.2227937629995722, 0.22459529300067516, 0.19912994300102582, 0.21464808499877108, 0.21301916599986725, 0.22289874000125565, 0.21771137199903023, 0.20743761099947733, 0.20980759900157864, 0.22027208399958909, 0.20516421499996795, 0.20920343099896854, 0.2139646730011009, 0.2056354010001087, 0.22218203999909747, 0.20653524299996207, 0.2109154629997647, 0.20568196299973351, 0.20659792000151356, 0.22230529399894294, 0.24102737000066554, 0.24948976499945275, 0.20991744400089374, 0.20846070799962035, 0.2121434999990015, 0.21812325800055987, 0.20783045400094124, 0.21462203899864107, 0.20389395500023966, 0.22652107900103147], [0.20506369500071742, 0.21717724799964344, 0.2190298770001391, 0.20883002399932593, 0.22099629100011953, 0.24004954200063366], [], [], [], [0.21605925900075817, 0.21892547099923831, 0.20866400100021565, 0.221405952999703, 0.23989800500021374, 0.22324059799939278, 0.2228149390011822, 0.22473533299853443, 0.1999207810004009, 0.21405679800045618, 0.21286094400056754, 0.2230891219987825, 0.2174691090003762, 0.20779473900074663, 0.20996089300024323, 0.21981744099866773, 0.20557847500094795, 0.20812533800017263, 0.2145696579991636, 0.2053430970008776, 0.2221929369989084, 0.20653917200070282, 0.21086030100013886, 0.2051013159998547, 0.2070792390004499, 0.2224723389990686, 0.24102907899941783, 0.2493250010011252, 0.21006634900004428, 0.20800671899996814, 0.2119972010004858, 0.2186910619984701, 0.20763314300165803, 0.21461944499969832, 0.20410112399986247, 0.22642180699949677, 0.20478833800007124, 0.2135591869991913, 0.23225367200029723, 0.2526090400006069, 0.2737363889991684, 0.2568592730003729, 0.22093613099968934, 0.20912899100039795, 0.2089839310010575, 0.21282006499859563, 0.20999393800047983, 0.20840573900022719, 0.22363697199944, 0.24571685299997625, 0.2190445220003312, 0.22673191700050666], [0.21667481099939323, 0.2189651650005544, 0.20825182199951087, 0.22152796699992905, 0.24004186999991362], [], [], [], [0.20957823299977463, 0.22081197399893426, 0.23990722200142045, 0.22324501299954136, 0.22280826099995465, 0.2245742049999535, 0.2000502350001625, 0.21407193899904087, 0.2128553960010322, 0.22295328799918934], [], [], [0.21970574000079068, 0.24006835999898612, 0.2232071470007213], [0.22135732600145275, 0.2400660089988378, 0.22325424399969052, 0.22280089800005953, 0.22458582400031446, 0.19940371700067772, 0.21439725299933343, 0.21302484900115815, 0.2228955020000285, 0.21771110800000315], [], [], [], [], [0.22076362199914001, 0.2400536610002746, 0.2232286100006604, 0.22301774799962004, 0.22441829099989263, 0.19929291200060106, 0.21471734999977343, 0.21285270699991088, 0.22294178400079545, 0.21750998399875243, 0.20703479500116373], [], [], [], [], [], [], [0.1999729830004071, 0.21440235000045504, 0.21302293999906396, 0.22289692600134003, 0.21771083599924168, 0.2074378630004503, 0.2098050360000343, 0.22026950100007525, 0.2051766820004559, 0.2098423429997638], [], [], [], [0.19992491499942844, 0.21404966699992656, 0.21286006800073665, 0.22302687999945192], [0.19912366700009443, 0.2146487280006113, 0.21286511399921437, 0.22293675699984306], [0.2141049900001235, 0.21294189400032337, 0.2228948190004303, 0.21778051699948264, 0.20734959800029173, 0.20980497599884984, 0.22026462000030733, 0.20518622800045705, 0.20925549899948237, 0.2138807210012601, 0.2056328949984163, 0.22218382700157235, 0.2065358699983335, 0.2109149020016048, 0.20568442900002992, 0.20659717999842542, 0.2224730730013107, 0.2408590009999898], [0.21407103899946378, 0.21275705799962452], [0.21405312400020193], [], [], [], [], [], [], [0.22346868499880657, 0.21767265900052735, 0.20778762100053427, 0.2098615869999776], [0.20847527399928367], [], [], [0.20744113299952005, 0.20980227600011858, 0.2202907070004585, 0.20494782900095743, 0.20942665499933355, 0.21394479899936414, 0.20565889899989998, 0.22218020299987984, 0.20653550200040627, 0.21091635999982827, 0.20567602300070575, 0.20659940899895446, 0.22231104999991658, 0.2410279920004541, 0.24948560200027714, 0.20992239199949836, 0.20844967300035933, 0.21214903100008087, 0.2181314379995456, 0.20783206300075108, 0.2144812059996184, 0.2040277510004671, 0.22652839600050356, 0.20467922999887378], [0.20973337500072375, 0.22043153400045412, 0.20471057099894097, 0.20926631600013934, 0.21365893900110677, 0.2059997439992003], [], [], [], [], [], [0.2093664740004897, 0.2202413009999873], [0.2099535429988464, 0.2204615160007961, 0.20459162000042852], [0.21993956100050127, 0.20557912199910788, 0.20873854999990726, 0.21384219200081134], [0.22043464200032759, 0.204534001999491, 0.20914566900137288, 0.214031088999036, 0.2059016100010922, 0.22260567599914793, 0.2059079099999508, 0.21112743900084752], [], [0.20585491800011368, 0.20896062900101242], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [0.20455143700019107, 0.21015502299997024, 0.2128519830002915, 0.20658492799884698, 0.22225242199965578, 0.20647386200107576, 0.21091078400058905, 0.20568614699914178, 0.20659464500022295, 0.2224850160000642, 0.2409621499991772], [0.21010218799892755, 0.2126137250015745, 0.20662608000020555, 0.22211472199887794, 0.20669800600080634, 0.21137194599941722, 0.20543730999997933], [0.2088743179992889, 0.2138281490006193, 0.20563035499981197, 0.2221869789991615, 0.20653524000044854, 0.21091351399991254, 0.20568527100112988, 0.20659708699895418, 0.222480500000529, 0.24096008199921926, 0.24936474400055886, 0.2099085070003639, 0.20847075799974846, 0.21214231200065115, 0.2181159009996918, 0.207828303999122, 0.2146282030007569, 0.20466764800039527, 0.22582851500010293, 0.20467547699990973, 0.21379801399962162, 0.23192305199881957, 0.2526780240004882, 0.27364200100055314, 0.25685796799916716, 0.22107464100008656, 0.20985062600084348, 0.20825902499927906, 0.21300120600062655, 0.2103187140000955, 0.20808126599877141, 0.223407039000449], [0.2081101830008265, 0.2144738819988561, 0.20518972600075358, 0.2224601990001247, 0.20589573199868028, 0.21130694600105926, 0.20487447400046221, 0.2071412400000554, 0.22269600199979322, 0.24107737799931783, 0.24862790900078835, 0.21058010799970361, 0.2082334480001009, 0.2113306899991585, 0.21921871899940015], [0.21370420400126022, 0.20558427299874893, 0.22211755400167021, 0.20650554199892213, 0.2108758249996754, 0.20569464000072912, 0.20660303399927216, 0.22258141200109094, 0.24090816500029177, 0.2492703949992574, 0.20989082400046755], [0.2137005999993562, 0.20577879200027382, 0.22259069200117665, 0.20592318599847204, 0.2112293040008808, 0.20496848299990233, 0.20714319500075362, 0.2226928569998563, 0.24108248599986837, 0.24835752800026967, 0.21032204799848842, 0.208526222000728, 0.21136061799916206], [0.20558732800054713, 0.22220030000062252, 0.2061937559992657, 0.2110501090010075, 0.2048666949995095, 0.2072609229999216, 0.22260809999897901, 0.24105761000100756, 0.24923668799965526, 0.21010031100013293], [0.22212534899881575, 0.20650209599989466, 0.21087416200134612, 0.20567718499842158, 0.20660713400138775, 0.22247272099957627, 0.24103203800041229, 0.249270214999342, 0.209896280999601, 0.2085012799998367, 0.21214221700029157, 0.21850470100071107, 0.20745790399996622, 0.21466367500033812, 0.20458264199987752], [0.22246390300097119, 0.20589810499950545, 0.21130448899930343, 0.20487514100022963, 0.20714157899965358, 0.2226948480001738, 0.24107933800041792, 0.2484549649998371], [0.22218151100059913, 0.20653713699903165, 0.21091300700027205, 0.20566595700074686, 0.20647899199866515, 0.22244649000094796, 0.24102925899933325, 0.24941943300109415], [0.22255442200003017, 0.20591915600016364, 0.21123581299980287], [], [], [], [], [0.22248286699868913, 0.20590382299997145, 0.2113008449996414, 0.20487632100048359, 0.20714177100126108, 0.2226949659998354, 0.24108002299908549, 0.24845408300097915, 0.21074183099881338, 0.2082475360002718, 0.2112595569997211], [], [], [], [], [], [0.20630985000025248, 0.21110972099995706, 0.20487278799919295, 0.20713921700007631, 0.22269722600140085, 0.24107631799961382, 0.24921529200037185, 0.20999675499842851, 0.20822980900084076, 0.21133593900049163, 0.21925750700029312, 0.20734055199864088, 0.21458555699973658, 0.20413647400164336, 0.22678744999939227, 0.20412985800066963, 0.21412435499951243, 0.2322505359989009, 0.2525966850007535, 0.27386028399996576, 0.2568581970008381, 0.22093565299837792, 0.2090082650011027, 0.20863793999888003, 0.2132061940010317, 0.21006696299991745, 0.20818354499897396, 0.2238396990014735, 0.2457357690000208, 0.21903899399876536], [0.2107362890001241, 0.20565128900125274, 0.20660558399868023, 0.22247155800141627], [0.21098714399886376], [0.2108747919992311, 0.20567824099998688, 0.20659403200079396, 0.22248676100025477, 0.2410275169986562, 0.2492763090012886, 0.2099007229990093, 0.20847771800072223, 0.21214198099914938, 0.2185024970003724, 0.2074454350004089], [], [], [], [], [], [], [0.211289314998794, 0.20552450400100497, 0.2062259289996291, 0.22249073599959956, 0.24134050300017407, 0.24881641899992246, 0.21024289699926157, 0.20862773100088816, 0.21165013000063482, 0.2184955329994409], [0.2110562130001199, 0.20486767900001723, 0.20713784100007615, 0.22269709600004717, 0.24107699500018498, 0.24922870299997157, 0.20998454700020375], [], [], [], [], [], [], [], [0.21122074500090093, 0.20552410999880522, 0.20622143100081303, 0.2224897560008685, 0.2413431729983131, 0.2488137900018046, 0.21023892299854197, 0.20862905600006343, 0.21164829800000007, 0.21855505900020944, 0.2076662090003083, 0.21437723700000788, 0.20463777099939762], [], [], [], [0.21085772199876374, 0.2050998590002564, 0.2070862720011064, 0.22247164699911082, 0.24103106999973534, 0.249243240999931], [0.20551428699945973, 0.20620333200167806, 0.2224897689993668, 0.24134732899983646, 0.24880943300013314, 0.2102301550003176, 0.20863010399989435], [0.20543765799993707, 0.20634240899926226, 0.22249046400065708, 0.24133757399977185, 0.2488200780007901, 0.2102468159991986, 0.2084797660008917, 0.21176459999878716, 0.21851296100066975, 0.20773929099959787, 0.2143799300010869, 0.2046356669998204, 0.2257881659988925, 0.2047227210005076, 0.2137921230005304, 0.2318743590003578, 0.2526815329983947, 0.2736412910016952, 0.25757800999963365, 0.22036355099953653, 0.2099209570005769, 0.20825547399908828, 0.2136835900000733, 0.20990987699951802, 0.2078692860013689, 0.22345510800005286, 0.24560783000015363, 0.21886222799912503, 0.22738724900045781, 0.20836085900009493, 0.21928689199921791, 0.2094473260003724, 0.2177706849997776, 0.20749386200077424, 0.20858720099931816, 0.2235592609995365, 0.20360324900138949, 0.2374419649986521], [], [], [0.20714479900016158, 0.22269211000093492, 0.24108668999906513, 0.24836148400027014, 0.21031837699956668, 0.20852667600047425, 0.21135890299956372, 0.219374334999884, 0.20731397300005483, 0.2146399150005891, 0.204200733000107, 0.2261741099991923], [], [], [], [], [], [], [], [], [], [0.2071486430013465, 0.22258595499988587, 0.2410584339995694, 0.24923979400045937, 0.21015897100005532, 0.20801439699971525, 0.21199330399940663, 0.21870106800088251, 0.20762575200024003, 0.2146170419982809, 0.20403793800142012], [0.20634846899883996, 0.2225423240015516, 0.24088759199912602, 0.24926857900027244, 0.2102527179995377, 0.20809653700052877, 0.2121420349994878, 0.21850578500016127, 0.20741514499968616, 0.21463177800069388], [0.20699967099972127, 0.22244853600022907, 0.24102946800121572, 0.24933193499964545, 0.21006098599900724, 0.20800548600163893], [0.22247354499995708, 0.24103427400041255, 0.24924185399868293, 0.2101630910001404, 0.20800886300094135, 0.21199586500006262, 0.21869488799893588, 0.20763028400142503, 0.21461806600018463, 0.20409596899844473, 0.22639724600048794], [0.22261286899993138, 0.2410580489995482, 0.24923359899912612, 0.21009418700123206, 0.2080999999998312, 0.21199088399953325, 0.21870648000003712, 0.20762164699954155, 0.2143973519996507, 0.20412404200033052], [], [0.2224936530001287, 0.24133130300106131, 0.24882694099869695, 0.2102510170007008, 0.20809889100019063, 0.21213656600048125, 0.21850768199874437, 0.20745611900019867, 0.21466514700114203, 0.20463055099935445, 0.22575965800024278], [], [], [], [], [], [], [0.21026577900011034, 0.20851572799983842], [0.2105863489996409, 0.20823555999959353, 0.21132481600034225, 0.2191470420002588], [], [], [0.2100072130015178, 0.20806669699959457, 0.21242307399916172, 0.2181727110000793, 0.2077510520011856], [0.20825043900003948, 0.21125825400122267, 0.21922033999908308, 0.20751224600098794, 0.21458586100015964, 0.2041373920001206, 0.22626058799869497, 0.20462949200009461, 0.21412541900099313, 0.23214375099996687], [], [], [], [0.21215853600006085, 0.21814385099969513, 0.207779581000068, 0.21448975400016934, 0.2040514849995816, 0.22653614400041988, 0.20467295500020555, 0.2135563869996986, 0.23226250900006562, 0.25260732999959146], [0.21165496700086806, 0.21849300199937716, 0.20773853500031692, 0.2143771730006847, 0.20463741099956678, 0.22584722700048587, 0.2049285509983747, 0.2135587550001219, 0.23184537300039665, 0.25268352199964283, 0.27363984099974914, 0.25759082400145417, 0.22035244399921794, 0.21003627100071753, 0.20817311700011487, 0.2139801309986069, 0.20963134200064815, 0.20846679699934612, 0.22282235700004094, 0.24560784100140154, 0.2188479919987003, 0.22749841699987883, 0.20830476700029976, 0.21936778199960827, 0.21039619900147954, 0.2169008879991452, 0.20737309200012533, 0.2085408010007086, 0.22356432999913523, 0.20360434500071278, 0.23750329799986503, 0.21476584799893317, 0.21066452100058086, 0.2321020170002157, 0.2288138660005643, 0.22149327999977686, 0.2068697989998327, 0.21288119000018924, 0.21238346599966462, 0.21436089999951946, 0.20825356200111855, 0.20554403999994975, 0.20911265999893658, 0.20637708100002783, 0.20652943800087087], [], [0.21155635799914307, 0.21866478300034942, 0.20757917799892311, 0.2144474810011161, 0.20467062900024757, 0.22578766500009806, 0.20496729599835817, 0.21352325600128097, 0.231825659999231, 0.2526800150008057, 0.2736880899992684, 0.25755626300087897, 0.22033612799896218, 0.21074605000103475, 0.20744758099863247, 0.21402405800108681, 0.2096053879995452, 0.20853678999992553, 0.2227159730009589, 0.24561109599926567, 0.21916386399971088, 0.2271726380004111, 0.20831531600015296, 0.21935520999977598, 0.2104642230005993, 0.21683036099966557, 0.20737585700044292, 0.20852875699893048, 0.2235652889994526, 0.20360555700062832], [0.21871796999948856, 0.20725310299894772, 0.2145865340007731, 0.20413628200003586, 0.22670608299995365], [], [], [], [], [], [], [], [], [], [], [], [0.2077334960013104, 0.21449410899913346, 0.2042007720010588, 0.22625042599975131], [0.2075838479995582, 0.2144384330003959, 0.2046800570005871, 0.22578863599846954, 0.2049660180000501, 0.2135195040009421, 0.23182401200028835, 0.25268189199960034, 0.2736852979996911, 0.25755737100007536, 0.22033817900046415, 0.21073511599934136, 0.20745714599979692, 0.21402626100098132, 0.209608412000307, 0.20852734899926872, 0.22272128000076918, 0.24561072500000591, 0.21883385899855057, 0.22750453499975265, 0.20831275900127366, 0.21936007799922663, 0.21040092099974572], [0.20778144300129497, 0.21448369300014747, 0.20405310199930682, 0.22640986300029908, 0.20479915699979756, 0.21355772300012177, 0.2322600000006787, 0.2526078979990416, 0.27373108599931584, 0.25685803400119767, 0.22094019999894954, 0.20991452700036461, 0.20834738300072786, 0.21299620799982222, 0.2103285560006043, 0.20807596499980718, 0.22340754499964532, 0.24570497000058822, 0.2189853169984417, 0.22693059900120716, 0.2082133240000985, 0.21965464999993856, 0.20964092400026857, 0.21766480699989188, 0.20758656499856443, 0.20840031199986697, 0.22374384900103905, 0.2032122740001796, 0.23716710100052296, 0.21528416199907952, 0.21082209800079, 0.23172186800002237, 0.2293695119988115, 0.22148210700106574, 0.20678080200013937, 0.21278495599835878, 0.21241468400148733, 0.2131645249992289, 0.20915356399927987, 0.20569351500125777, 0.20910078899942164, 0.20629972300048394, 0.20674409499952162], [0.21431811900038156, 0.2040615229998366, 0.22676525700080674, 0.20409217499945953, 0.21412618400063366, 0.2322467729991331, 0.25259523800013994, 0.27385796300040965, 0.2568618419991253, 0.22093792000123358, 0.2090056689994526, 0.20863546799955657, 0.2132105569999112, 0.20995890999984113], [0.2144748989994696, 0.20402906100025575, 0.2265331269991293, 0.20467553100024816, 0.21355665900046006, 0.23226477400021395, 0.25267332600014925, 0.2736470259987982, 0.25685713900020346, 0.2210690270003397, 0.20978763600032835], [0.21456648800085532, 0.20405565299915907, 0.22641615099928458, 0.20479275300021982, 0.21355820600001607, 0.2322561750006571, 0.252611784999317, 0.27373204700052156, 0.2568574289998651, 0.2209391920005146, 0.2093965179992665, 0.20875719700052286, 0.2127939879992482, 0.20999261799988744, 0.20841600300082064, 0.2236282760004542, 0.24571846599974378, 0.21902850100013893, 0.22688148300039757, 0.2082202089986822, 0.21951705900028173, 0.20980405999944196, 0.21767050300150004, 0.20696459699865954, 0.2089848380001058, 0.2231622460003564, 0.20363176700084296, 0.237347279999085, 0.21482830999957514, 0.21128635800050688, 0.23172713399981149, 0.22991117099991243, 0.22112948799986043, 0.20632864700019127, 0.21286401500037755, 0.21257086799960234, 0.21317091099990648, 0.20918622099998174, 0.2055284779999056, 0.2081463860013173], [0.20467961199938145, 0.22578808800062689, 0.20496740999988106, 0.21351679300096293, 0.23182224799893447, 0.25268153800061555, 0.2736826950003888, 0.25755966599899693, 0.2203395280012046, 0.21063577399945643], [0.20400951599913242], [0.20403533300122945, 0.22648416699848894, 0.2044718870001816, 0.213865039000666, 0.2321973229991272, 0.2525955070013879, 0.2738604129990563, 0.2568572710006265, 0.22093749600026058, 0.20901059499919938], [0.2041440410012001, 0.22626862799916125, 0.2046043259997532, 0.21412486900044314, 0.23214309700051672, 0.25272129400036647, 0.2738572589987598, 0.25687202800145315, 0.2209459829991829, 0.2089918210003816, 0.20863228099915432, 0.2132275470012246, 0.2099582359987835, 0.20830992700030038, 0.22383014899969567, 0.24573136500112014, 0.21880186699854676, 0.22700827400149137, 0.20828233300017018, 0.2190256239991868, 0.21020902700001898, 0.2168876760006242, 0.20734229299887375, 0.20891449400005513, 0.2234875860012835, 0.20382709699879342, 0.2375090210007329, 0.21397171399985382, 0.21191297000041232, 0.2319811409997783, 0.22946913699888682, 0.2214806830015732, 0.20615221199841471, 0.21296071600045252, 0.2127373040002567, 0.21317048799937766, 0.20831919400006882, 0.20581707600103982, 0.2080128629986575, 0.20769952299997385, 0.20660121100081597, 0.20507274299961864, 0.21471935500085237, 0.2334630549994472, 0.23028980500021135], [0.22631800699855376, 0.20467432500117866, 0.21346716600055515], [], [0.2257654660006665, 0.20501519099889265, 0.2135130560000107, 0.23182278700005554, 0.2526796109996212, 0.27364142000078573, 0.25760063199959404, 0.22034119499949156, 0.21004014600111987, 0.20816911200017785, 0.2139732819996425], [0.20564215699960187, 0.213565882999319, 0.23224717900120595, 0.25250947199856455], [], [], [], [], [], [], [], [], [], [0.21386676499969326, 0.2321988309995504, 0.25259737899978063, 0.27385988800051564, 0.25685687599980156, 0.22093763900011254, 0.20900810499915679, 0.2086403209996206, 0.2132037310002488, 0.2100714540010813, 0.2083294570002181, 0.22373258100014937, 0.24571691699929943, 0.21905044199957047, 0.2267226540006959, 0.20837289100018097, 0.2195033890002378, 0.2097504689991183, 0.21675040899935993, 0.2077374079999572, 0.20919382100146322, 0.2230910819998826, 0.20372992099873954, 0.23734190200048033, 0.2148259160003363, 0.21128934499938623, 0.2317287080004462, 0.22951861399997142, 0.22149302400066517, 0.20618090300013137, 0.21288653599913232, 0.21272492599928228, 0.21317043800081592, 0.20919255800072278, 0.20501026599959005, 0.20818847400005325, 0.20755584799917415, 0.2068763700008276, 0.20498539099935442, 0.21461346300020523, 0.2334979570005089, 0.230238707999888, 0.22703110799920978, 0.23460831699958362, 0.2226328860015201], [0.21395073799976672, 0.23221581800135027, 0.252597151998998, 0.2738598460000503, 0.25685741500092263, 0.22093538799890666, 0.20900832100051048, 0.2086401319993456, 0.2132036530001642, 0.21007249100148329, 0.20832687199981592, 0.22373684699959995, 0.24571679099972243, 0.2190563549993385, 0.22671332500067365, 0.2083725800002867, 0.21934408800007077], [0.21379332400101703, 0.23190166099993803, 0.2526790179999807, 0.2736406989988609, 0.25685849000001326, 0.22107946899996023, 0.20985145099984948], [0.21351194700037013, 0.23182204499971704, 0.25268092899932526, 0.2736406910007645, 0.2575967209995724, 0.2203464559988788, 0.2100379060011619, 0.20817093000005116, 0.21397744299974875, 0.20967797099910968, 0.2084624730014184], [0.21377912699972512, 0.23188048699921637, 0.2526809500013769, 0.27363985299962224, 0.25685809700007667, 0.22108284699970682, 0.20991198800038546, 0.20825905699894065, 0.21368460600024264, 0.20992280800055596, 0.20772757200029446, 0.2235369099998934, 0.24555805699856137, 0.21896957500030112, 0.22694659599983424, 0.20877119000033417, 0.21928878200014879, 0.2094500790008169, 0.21776221799882478, 0.2074981210007536, 0.20839012999931583, 0.22375391800051148, 0.20352794999962498, 0.2375330760005454, 0.21481465499891783, 0.21062889700078813, 0.2318354189992533, 0.22894664800151077, 0.22138165799879062, 0.20717345500088413, 0.212872095999046, 0.2124592960008158, 0.21436860599897045, 0.20826138900156366, 0.20553371099958895, 0.20902543199918], [0.21379041399995913, 0.2321781499995268], [], [], [], [], [], [0.20949727699917275], [0.2086134460005269, 0.21279711299939663, 0.209993028000099, 0.20841343900065112, 0.22363062600015837, 0.2457174949995533, 0.21903620100056287, 0.22686731700014207, 0.20822614099961356, 0.21951312000055623, 0.20974235899848281], [0.2085531529992295, 0.21276729100100056, 0.20999147200018342, 0.20841730999927677, 0.2236268779997772, 0.24572147700018832, 0.219019064999884, 0.22689304500090657, 0.20821694799997204, 0.21952034499918227], [0.20817742899998848, 0.21398136499919929, 0.2095899569994799, 0.20838002399977995, 0.22295003600083874, 0.2456079759995191, 0.21885457700045663, 0.22739753699897847, 0.20836103500005265, 0.2192855100001907], [0.20835045399871888, 0.21271904400055064, 0.20999080299952766, 0.20841946500149788, 0.22362423199956538, 0.2457227539998712, 0.21901226199952362, 0.22690219300056924, 0.2082166389991471, 0.21958839400031138], [0.21282805199916766, 0.20999573100016278, 0.20833183200011263], [0.2099287569999433, 0.2077283719991101, 0.22352807500101335, 0.24556755699995847, 0.21897693099890603, 0.22693814900048892, 0.20821282399992924, 0.21965797600023507], [0.2099617660005606, 0.2082105040008173], [], [], [], [], [], [0.20807368300120288, 0.22340912299841875, 0.24570333000156097, 0.21899587999905634, 0.22692119699968316, 0.20821382000031008, 0.21965232000002288, 0.2096426309999515, 0.21766441299951111, 0.20757280300131242, 0.20841527099946688, 0.22372926800017012, 0.20322847399984312, 0.23716476600020542, 0.2148278869990463, 0.21128044900069654, 0.23172207400057232, 0.22920685499957472, 0.22138948400061054, 0.20687804899898765, 0.21290091999981087, 0.2124358069995651, 0.21316671000022325, 0.2091676300005929, 0.20554900900060602, 0.20922055699884368, 0.20632515500074078, 0.20672952200038708, 0.2062993869985803, 0.21320774600098957, 0.23358001099950343, 0.23015212300015264, 0.2269451209995168, 0.23441133900087152, 0.2203097620003973, 0.228285118999338, 0.24903041799916537, 0.2719465610007319, 0.24749952599995595, 0.20869675900030416, 0.22354334400006337, 0.221925175999786, 0.20818755000072997, 0.22698059399954218, 0.21524949299964646, 0.2053332590003265, 0.2134051390003151, 0.2195046769993496], [0.2083773710000969], [0.2084556120007619, 0.22280081800090556, 0.2456092369993712, 0.21884116399996856, 0.22750110900051368, 0.20830926599956, 0.21936375199948088, 0.21039987199947063, 0.2169013190014084, 0.20737570299934305, 0.20853345400064427, 0.22356524399947375, 0.20360479100054363, 0.2375018969996745, 0.21476463100043475, 0.21067269400009536, 0.23210508400006802, 0.22882395699889457, 0.22149229100068624, 0.20685925599900656, 0.21288252500016824, 0.21237809200101765, 0.2146338589991501, 0.20797465900068346, 0.2055502629991679, 0.2091088690012839, 0.20638157699977455, 0.20658335000007355, 0.20626725500005705, 0.21362683299958007, 0.23362574899874744, 0.2305382680006005, 0.2261077050006861], [0.22345732699977816, 0.24560835800002678, 0.21887153900024714, 0.2269606419995398, 0.20877827900039847, 0.21928759499860462, 0.2094471700002032, 0.2177692229997774, 0.20749362700007623, 0.20858941300139122, 0.22355644599883817, 0.20351688800110423], [], [0.2235246489999554, 0.24570329999914975, 0.21900424100022065, 0.22691241500069737, 0.20821494099982374, 0.21964690999993763, 0.20964437300062855, 0.21766692999881343, 0.20696688700081722, 0.2089804120005283, 0.22316986999976507, 0.20361977799984743, 0.23735326200039708, 0.21482909999940603, 0.2112834319996182, 0.23172628300017095, 0.22903292999944824], [0.22373740500006534, 0.2457197340008861, 0.2190631220000796, 0.2267055819993402, 0.20828030899974692, 0.21902268400117464, 0.21020510999915132], [], [], [0.20829124600095383, 0.21904764499959128, 0.210208626000167, 0.2168859710000106, 0.2073494579999533, 0.2089195699991251, 0.22348494099969685, 0.20383248100006313, 0.23750453899992863, 0.2139699430008477, 0.21191135399931227, 0.2319814150014281, 0.2294711179984006, 0.22147900800155185, 0.20614791399930255, 0.21296254600019893, 0.212735901999622, 0.21317170499969507, 0.2083190339999419, 0.20581761200082838, 0.20776617000046826, 0.20793925299949478, 0.20659252400037076, 0.20508283500021207, 0.21472320599968953, 0.23346544199921482, 0.2302929289999156, 0.22719268900073075, 0.23457520400006615, 0.22030701800031238, 0.228266228999928, 0.24902863999886904, 0.271951718001219], [], [], [], [], [], [], [], [], [], [0.20830263999960152, 0.21937251500094135, 0.20934975399904943, 0.21776055800000904, 0.20749458099999174, 0.20857812200119952, 0.2235656619996007, 0.20360265800081834, 0.23750673699942126, 0.2147072379993915, 0.21064538700011326], [0.21929066099983174, 0.20945910699992965, 0.2176629210007377, 0.20759283200095524, 0.20839417799834337, 0.2237503040014417, 0.2035340679994988, 0.2375242519992753, 0.21461372500016296, 0.21082281500093814, 0.23171965099936642], [], [0.21897659199930786, 0.2103023400013626, 0.21675297299952945, 0.2077326959988568, 0.2091972310008714, 0.2229613010003959], [], [], [], [], [], [0.2102150270002312, 0.21673627600102918, 0.2073252459995274, 0.20905630800007202, 0.2235245930005476, 0.2038414719991124, 0.23749313400003302, 0.21384245499939425], [], [], [0.20934731800116424, 0.2177627900000516, 0.20749344899923017, 0.20858348200090404, 0.22356448499886028, 0.20360130799963372, 0.23750706000100763, 0.21471150099932856, 0.21063753599992197, 0.23184043100081908, 0.22903059400050552], [0.21690591399965342, 0.20733365600062825, 0.20857348800018372, 0.22356714099987585, 0.2036035119999724, 0.23750547300005564, 0.21470463699915854], [], [], [], [], [], [0.20697544699942227, 0.20898669300004258, 0.22309434300041175], [], [], [], [0.20879350100040028], [0.2089255940009025, 0.22348357800001395, 0.20383880199915438, 0.23749991000113369, 0.21395920000031765, 0.21190386099988245, 0.23198190800030716, 0.22940937399835093, 0.2214961140016385], [0.2090617989997554, 0.22353999499864585, 0.20373106400074903, 0.2374775789994601], [0.20855069999925036, 0.22356409200074268, 0.20360351499948592, 0.23750503399969602, 0.21476489000087895, 0.21065779499986093, 0.23209175800002413, 0.22880992999853333, 0.22148048100098094, 0.20684441099911055, 0.21287039600065327], [], [], [], [], [], [], [], [0.20891212600145082, 0.22315133799929754, 0.20380646400008118, 0.23716510700069193, 0.21482882499913103, 0.21128180800042173, 0.23172384499957843, 0.2292034740003146, 0.22138910799912992, 0.20680481900126324, 0.21285085799900116], [0.22297110299950873, 0.20369034900068073, 0.23751455599995097, 0.21397152499957883, 0.21191511200049717], [0.20419725600004313, 0.23733771800107206, 0.21397136300038255], [0.23751092500060622, 0.2146323239994672, 0.2108200710008532, 0.23172094599976845, 0.22938963500018872, 0.2214919349989941, 0.20675158700032625, 0.2127855479993741, 0.212417352000557, 0.21316141900024377, 0.20914775599885616, 0.20570747700003267, 0.20909812200079614, 0.20628883099925588, 0.20681450400115864, 0.20631455200054916, 0.2135722849998274, 0.233737601998655, 0.22953406700071355, 0.22694443599903025, 0.2344729060005193, 0.2203034590002062, 0.22841986999992514, 0.24888216100043792, 0.2720243309995567, 0.2475120210001478, 0.20858498900088307, 0.22355974299898662, 0.22192362399982812, 0.20837253900026553], [0.2159689359996264, 0.21062908800013247, 0.23182848600117723, 0.22967174099903787, 0.22113392600113002, 0.20670164199873398, 0.212870995999765, 0.21236817099998007, 0.21445166500052437, 0.2082717009998305, 0.20534443799988367, 0.2090693000009196], [0.21129683300023316, 0.23173821800082806, 0.22930746599922713, 0.2213882560008642], [], [0.20564992099934898, 0.2131913480006915, 0.2119053789992904, 0.21463544799917145, 0.20796669199989992, 0.20555596300073375, 0.20910461300081806, 0.2066835549994721, 0.20673732300019765, 0.2058116499993048, 0.21363086400015163, 0.23362627599999541, 0.23054178299935302, 0.22616515600020648, 0.2341812900012883, 0.22271020100015448, 0.22641266199934762, 0.24858610699993733, 0.2718933020005352, 0.24751592999928107, 0.20931162600027164, 0.2230920910005807, 0.22165432399924612, 0.2088262239994947, 0.2265383350004413, 0.21514058200045838, 0.20566325999971014, 0.21310329399966577, 0.21978845500052557, 0.20728853400032676, 0.20917799199924048], [0.21296912000070733, 0.21273194500099635, 0.21317617499880726, 0.2083176390005974, 0.2058174970006803, 0.20776318899879698, 0.20783764400039217], [0.21278536499994516, 0.2124163270000281, 0.2131651409999904, 0.2091603450007824, 0.20555639600024733, 0.2092266199997539, 0.20631089199923736, 0.2067384399997536, 0.20630890400025237, 0.2136453809998784, 0.23313368799972523, 0.23014933000013116, 0.22694547600076476, 0.2344557269989309, 0.22030615400035458, 0.22826940500090132, 0.2490270509988477, 0.27202015700095217, 0.2474137770004745, 0.20870193599876075, 0.22355436399993778, 0.22193864200016833, 0.2083581429997139, 0.22682154900030582, 0.21534086300016497, 0.20524201999978686, 0.2134357610011648, 0.21947409699896525, 0.20674675600093906, 0.20896543500020925], [0.21284959700096806, 0.21256207499936863, 0.2131686320008157, 0.2091813059996639, 0.2055344820000755, 0.20856334599920956, 0.20699595299993234, 0.2067117140013579, 0.20516594000037003, 0.21428708199891844, 0.23350462300004438], [0.21289344300021185, 0.212445134000518, 0.2131676980006887, 0.2091748179991555, 0.205541744000584, 0.20920806499998434, 0.20634480599983362, 0.2067221029992652, 0.20540633800010255, 0.21410263500001747, 0.23352598200108332], [], [], [0.2127529669996875], [0.21318908700050088, 0.21256406099928427, 0.214062469000055, 0.20786377100012032, 0.20556535099967732, 0.20909492200007662], [], [], [], [0.21288881599866727, 0.21272501200110128, 0.21317174399882788, 0.20915428300031635, 0.20502312899952813, 0.20819433700125956, 0.2075586970004224, 0.20657915499941737, 0.20519810599944321, 0.2145664969993959, 0.23346469100033573], [0.21237098399979004, 0.2131447739993746, 0.20914158200139354, 0.20571719500003383, 0.20909849499912525, 0.2062787009999738, 0.20682373700037715, 0.2063182300007611, 0.21357163799984846, 0.2337457590001577, 0.2295219099996757, 0.22694330599915702, 0.23447199300062493, 0.22048121099942364, 0.22825034500056063, 0.24887469699933717, 0.2720235460001277, 0.24751766000008502, 0.2085822589997406, 0.22356249800031947, 0.22191390599982697, 0.20848353899964422, 0.22669099900122092], [], [], [], [0.214076529000522, 0.20786724699974002, 0.205559951999021, 0.2090998010007752, 0.20668704399940907, 0.20674840299943753, 0.20579769300093176, 0.21363587599989842, 0.23362679199999548, 0.2305433620003896, 0.22617040899967833], [], [], [], [], [], [], [], [0.20500676600022416, 0.20818621900070866, 0.20755734900012612, 0.20657922899954428, 0.20519928300018364, 0.21456479299922648], [], [0.20569800199882593, 0.20809318700048607, 0.20763417800117168, 0.206590267998763, 0.20518774500123982, 0.2145778779995453, 0.2334637659987493, 0.23043259700170893, 0.22703376099889283, 0.23469482700056687, 0.2227062379988638], [], [], [0.20569706900096207, 0.20908592399973713, 0.2062694249998458, 0.20682930099974328, 0.2062015240007895], [0.20534606799992616, 0.20906995100085624, 0.20626131700009864, 0.20683496200035734, 0.20630780999999843, 0.21357191300012346], [0.2090243359998567, 0.20611746400027187, 0.20683880599972326, 0.2063152970004012, 0.2136536679990968, 0.23364389000016672, 0.23001562200079206, 0.22644574399964768], [0.20793119999871124, 0.207608936001634, 0.20676418699986243, 0.20496759399975417, 0.21461227500003588, 0.23350305199892318, 0.2302992750010162, 0.22695020399987698, 0.23460432699903322, 0.22271218300011242, 0.22640850199968554, 0.24858096900061355, 0.2718994719998591, 0.24751610200110008, 0.20930942599989066, 0.22308699099994556, 0.22166733399899385, 0.20881746400118573, 0.22654002099989157, 0.21514687600028992, 0.2048260499996104, 0.21393461399929947, 0.21925327200005995, 0.2066918769996846, 0.20906175500022073, 0.21995438700105296, 0.21722267099903547, 0.23044383399974322, 0.255895545000385, 0.2775248029993236, 0.2978662540008372, 0.22688845499942545, 0.2078810840012011, 0.21427408299859962, 0.20331629700012854, 0.20873738000045705, 0.2075581629997032, 0.21603347400014172, 0.23518868000064685, 0.21043307000036293, 0.21505161699860764, 0.21499800700075866, 0.21694519700031378, 0.21408338499895763, 0.22781615200074157, 0.20631712599970342, 0.22442530000080296, 0.2103264079996734, 0.21719437100000505, 0.21714360499936447, 0.23460194200015394], [0.2081512170007045, 0.20742910400076653, 0.20660394599872234], [0.20737627899870859], [], [], [0.20756524699936563, 0.20657919800032687, 0.20519401499950618, 0.21457170200119435, 0.2334621119989606, 0.2304388590000599, 0.22703163500045775, 0.23468789199978346, 0.2227408729995659, 0.22638727500088862, 0.24858781100010674, 0.27188959199884266, 0.2475157090011635, 0.2093157049985166, 0.22309210800085566, 0.22164023799996357, 0.20883896700070181, 0.22653477099993324, 0.2153116619992943, 0.20458790299926477, 0.2140250760003255, 0.21917418700104463, 0.20602823099943635, 0.20963071000005584, 0.22010742100064817, 0.21724234300017997, 0.23043902299832553, 0.2558958550016541], [], [], [], [], [], [], [], [], [], [], [0.20764022200091858, 0.20659438899929228, 0.20507037500101433], [], [], [], [], [], [], [0.20676758400077233, 0.2049671330005367, 0.2146136840001418, 0.2335011269988172, 0.23023538699999335], [], [], [], [0.20686110600036045, 0.2063444029990933, 0.21362069800125028, 0.23362652499963588, 0.23053001199878054, 0.2261130740007502, 0.2342321380001522, 0.2226358200005052, 0.2260990180002409, 0.24887252899861778], [], [], [0.20559733399932156, 0.21358910400158493, 0.23362717399868416, 0.2305436960014049, 0.22622725999826798, 0.2339328050002223, 0.2203100260012434, 0.22898160299882875, 0.24858666900036042, 0.27189159599947743, 0.2475147660006769, 0.2093142829999124, 0.22309261200098263, 0.22164715599865303, 0.2088328370009549, 0.22653629900014494, 0.2152991769999062, 0.20550617499975488, 0.21311890300057712, 0.21976834499946563, 0.2073048309994192, 0.20924763000039093, 0.21862518600028125, 0.217236246999164, 0.23043970599974273, 0.25589521000074456, 0.27752216800035967, 0.2978410050000093, 0.22689372099921457, 0.20789248000073712, 0.2142605619992537, 0.20436330899974564, 0.20775750699976925, 0.2090158050013997, 0.21462226699986786], [0.20629780300077982, 0.2136428049998358, 0.23364124999898195, 0.2300249600011739, 0.22654969399991387], [0.20498636400043324, 0.214610871998957, 0.23344187499969848], [], [], [0.21413401700010581, 0.2335213179994753, 0.23022617399874434, 0.22694569600025716, 0.23435336900001857, 0.2203254369997012, 0.2282730270017055, 0.24903389899918693, 0.27184134900016943, 0.24763734299995122, 0.20859094499974162], [], [], [], [], [], [0.21361434700156678, 0.23362766599893803, 0.23052015000030224, 0.22611747200062382, 0.23420700399947236, 0.22030519399959303, 0.2282708510010707], [0.21472884099966905, 0.23346995199972298, 0.23030055900017032, 0.22718376699958753, 0.23454529600167007, 0.22031240499927662, 0.22828201099946455, 0.24903360400094243, 0.27184152500012715], [], [], [], [], [], [], [], [0.22652017100153898, 0.24843167899962282, 0.2720218989998102, 0.24741222900047433], [], [0.22310830999958853, 0.22182862699992256, 0.20849442500002624, 0.22679074299958302, 0.21521009400021285, 0.20524712500082387, 0.21343602999877476, 0.21946834400114312, 0.2067519079992053, 0.20907158500085643, 0.2196082699992985, 0.21730860000025132, 0.23046648200033815, 0.2559000460005336, 0.27739070399911725, 0.2979818420008087, 0.22614631099895632, 0.20819291599946155, 0.21463699900050415], [], [], [], [0.22298024999872723], [0.2097914789992501, 0.2262813430006645, 0.21530731299935724, 0.20547796200116863, 0.2131392719984433, 0.21974912400037283, 0.20731629600049928], [], [], [], [], [0.20820149700011825, 0.22696734000055585, 0.21535519999997632, 0.20546635199934826, 0.21316553699944052, 0.21956026000043494, 0.20699370700094732, 0.20923600499918393, 0.21881359799954225, 0.21761328600041452, 0.23035976000028313, 0.2560381490002328, 0.2773879369997303, 0.29798344600021665, 0.22614188399893465, 0.20816641800047364, 0.21442651500001375, 0.20467584499965596, 0.20703816100103722, 0.20935577700038266, 0.21471763499903318, 0.23342331400090188, 0.21203101299943228, 0.21521426899926155], [], [], [0.226544269000442, 0.21515682700010075, 0.20408759499878215], [0.20438152699898637, 0.21458348100168223, 0.2193624159990577, 0.2059941629995592, 0.20962833700104966, 0.21961347999967984, 0.21761631300068984, 0.2303604529988661], [], [], [], [], [], [], [0.20525075999830733, 0.21337780600151746, 0.21953649099850736, 0.20674225500079046, 0.20896574300059, 0.2192954699985421], [0.20459181099977286, 0.2140283909993741, 0.219193990000349, 0.20601641400025983, 0.20962998799950583, 0.22010036800020316, 0.21722616000079142, 0.23044159699929878, 0.2558961550003005, 0.27738125500036404], [], [], [0.21329891999994288, 0.2195944489994872, 0.20677841100041405, 0.20967624399963825, 0.21874310800012609, 0.21723104800003057, 0.23044009300065227, 0.255896409998968, 0.2775174540001899, 0.2978280850002193, 0.22682536200045433], [0.21333796299950336, 0.21939979099988705, 0.20675703400047496, 0.2090758319991437, 0.2196168829996168, 0.21731222400012484, 0.23046962000080384, 0.25589579500046966, 0.2773936519988638, 0.2979817830000684, 0.2262102370004868], [0.21321455799989053, 0.21947188999911305, 0.20700447499984875, 0.20923213300011412, 0.21918236800047453, 0.21730997799932084, 0.23046847800105752, 0.2558969609999622, 0.27739083800042863, 0.2979827459985245, 0.22614690600130416], [], [], [], [0.21338112499870476, 0.21953923100045358, 0.20678912500079605, 0.20896742999866547, 0.21929125300084706, 0.21768007299942838, 0.23036252400015655, 0.25603494700044394, 0.27740375400026096, 0.29798443199979374, 0.22605118899991794], [0.2140828749998036, 0.2190324999992299, 0.20670744400013064], [0.21366522000062105, 0.21940376000020478, 0.20677555299880623, 0.20897470100135251, 0.2193178919987986, 0.21768696199978876, 0.23036114100068517, 0.25603570900057093, 0.2780758219996642, 0.29747677799969097, 0.22686394700031087, 0.20788975600044068, 0.21425562999866088], [], [], [], [0.20930756800044037, 0.21931823399972927, 0.21742085199912253, 0.23056198800077254, 0.25603294800021104, 0.27740055799949914, 0.2978838069993799, 0.22615937900081917, 0.20758485899932566, 0.21451998300108244], [], [], [0.20924124099838082, 0.21871694000037678, 0.21745000699957018, 0.23055738000039128, 0.2560356869998941, 0.27740215999983775, 0.2979790930003219, 0.22605782500068017, 0.2075899979990936, 0.21462146700105222, 0.20519212299950595, 0.20694105700022192, 0.20945810100056406, 0.21458203099973616, 0.23338861400043243], [], [0.2091257209995092], [], [], [], [], [], [], [], [], [], [], [0.21951082099985797, 0.21719856900017476, 0.2304376259999117, 0.2560063970013289, 0.27781643100024667, 0.29747042499911913, 0.22686255500047992, 0.2078884559996368, 0.21428067600027134, 0.20405181599926436], [0.21770892800122965, 0.23036887799935357, 0.2560353129993018, 0.27740307500062045, 0.2979823830009991, 0.22605299399947398, 0.20887528300045233, 0.21426661999976204, 0.2040864930004318, 0.2079738289994566, 0.20855693299927225, 0.21503232600116462, 0.23518523199891206, 0.21043930599989835, 0.2150532249997923, 0.21499762799976452, 0.21694564700010233, 0.21408185300060723], [], [], [0.21758521099945938, 0.23046280600101454, 0.25590552299945557, 0.27738939200025925, 0.29798314799882064, 0.22614545000033104, 0.2081663099997968, 0.21442980100073328, 0.20343475399931776, 0.20827180800006317, 0.20768393999969703], [], [], [], [], [0.20799135499873955, 0.2143545480012108, 0.2033328409997921, 0.20852207299867587, 0.20762033500068355], [], [], [], [], [], [0.20789375500135066, 0.2143357160002779, 0.20439119999900868, 0.20762261799973203, 0.20915269299985084, 0.2144566630013287, 0.2338172219988337, 0.21179647999997542, 0.21505383800104028, 0.21500152599946887, 0.2167741869998281], [0.21440816700123833, 0.20433739699910802], [0.21418414500112704], [0.2142845109992777, 0.2039245989999472, 0.20809158000156458, 0.20860131699919293, 0.21500520200061146, 0.23519689699969604, 0.2104228529988177, 0.21505054000044765, 0.21499999600018782, 0.21687619700060168], [], [], [], [0.20450287099993147, 0.20756122700004198, 0.20844066900099278], [0.20392931700007466, 0.20755837300021085, 0.2084360150001885, 0.21561975499935215, 0.2334253120006906], [], [0.2085795250004594, 0.2075096789994859, 0.216041702999064, 0.2351803360015765, 0.21044475700000476, 0.21505634499953885, 0.21499576600035653, 0.21694709099938336, 0.21419348900053592, 0.2279140649989131, 0.20610642199972062, 0.22492462400077784, 0.20982315800029028, 0.21720190399901185, 0.21738899200136075, 0.23448706699855393, 0.21710512800018478, 0.21327797699996154, 0.22668975700071314], [0.20796222799981479], [0.20885450900095748, 0.20710553800017806, 0.21648836900021706, 0.23519263399975898, 0.2104272819997277, 0.21505138099928445, 0.21499857399976463, 0.21693917000084184, 0.21408958000029088, 0.22782299699974828, 0.20630923899989284, 0.22442670900090889, 0.21032539999941946, 0.21718946900000446, 0.21715318099995784, 0.23459497799922246, 0.2172401700008777, 0.2132750410000881, 0.22669238900016353, 0.23474322999936703, 0.20698498999990989, 0.20650353400014865, 0.20493043299939018, 0.2103086050010461, 0.23065522799879545, 0.23454181400120433, 0.25462441600029706, 0.22181807800006936, 0.20617225199930544, 0.2292848649994994, 0.21343030500065652, 0.21089329999995243, 0.20605243099998916, 0.205863851999311, 0.21250590199997532], [0.20889597200039134], [0.2076758819985116, 0.20836417200007418, 0.21564538900020125, 0.23556773600103043, 0.2104521589990327, 0.21505521000108274, 0.2149957120000181, 0.21694737899997563, 0.2142012079984852, 0.22790202000032878, 0.20611106400065182], [0.2075740219988802, 0.20844757200029562, 0.21558832499977143, 0.2334836459995131, 0.21188614500169933, 0.2152036079987738, 0.21512087600058294, 0.2169465749993833, 0.2140853100008826, 0.22787545299979683, 0.20567540599950007, 0.22490730100071232, 0.2104323530002148, 0.2170479099986551, 0.21718116300144175, 0.23493088299983356, 0.21723873399969307, 0.21304202399915084, 0.22663974600072834, 0.23493638899890357, 0.20636457200089353, 0.20648661199993512, 0.20553268900039257, 0.20939736400032416, 0.23130334399866115, 0.23490525800116302, 0.2546264369993878, 0.22127673999966646, 0.20641779000106908, 0.22937204200025008, 0.21322771899940562, 0.20994495900049515, 0.20763831099975505, 0.20614560799913306, 0.2129419200009579, 0.20642505599971628, 0.21975367999948503, 0.2234591239994188, 0.21900800399998843, 0.2211520520013437, 0.20928229600031045, 0.21043302699945343, 0.21643274999951245, 0.21119155599990336, 0.21860367699991912, 0.20846119000088947, 0.2193967879993579, 0.21748018499965838, 0.20569272300053854, 0.2132325429993216, 0.2255602450004517, 0.19743830500010517, 0.2121218520005641, 0.227240467998854, 0.21897185499983607, 0.2227515670001594, 0.21259185600138153, 0.2178266539995093, 0.22782942000048934, 0.21520712599885883, 0.21369958200011752, 0.22041404000083276, 0.21280897699944035], [0.20894597600090492, 0.21467314199981047, 0.2334937859995989, 0.21194940299938025, 0.2153236989997822, 0.2148964360003447, 0.2169111729999713, 0.214095905999784, 0.2279043170001387, 0.20603170899994439, 0.22461909800040303], [], [], [0.2149637820002681, 0.23338003599928925, 0.21194580200062774, 0.21533054400060792, 0.21488919900002657, 0.21691174399893498, 0.21429083700058982, 0.22771160599950235, 0.2060496960002638, 0.2247499950008205, 0.21035272399967653, 0.21706290299880493, 0.21707712600073137], [], [], [], [], [], [0.21598974699918472, 0.233369080000557, 0.21222800800023833, 0.21506923099877895, 0.21499731299991254, 0.21678148499995586, 0.21428995200039935, 0.227826496000489, 0.20593618599923502], [0.21594338800059631, 0.23342443900037324, 0.2120260519986914, 0.21508009700119146, 0.21512232799977937, 0.21693391400003748, 0.21409474499887438, 0.22785047500110522, 0.20570220199988398, 0.22489797699927294], [], [], [], [], [], [], [], [], [], [], [0.210364621001645, 0.2150745229992026, 0.21488867699918046], [], [], [], [], [0.21497542200086173], [], [], [], [], [0.21406635599851143, 0.2171822210002574, 0.2138217240008089, 0.2277730829991924, 0.20610562700130686, 0.22442329499972402, 0.2103269889994408, 0.21719873800066125, 0.21738884299884376, 0.23448060200098553, 0.2171120240000164, 0.21327815699987696, 0.2266896370001632, 0.23473181599911186, 0.20698835400071403], [], [0.21468290200027695, 0.21688955100034946, 0.21420503099943744, 0.22789426500094123, 0.2061874649989477, 0.22484830700159364, 0.2098119129987026, 0.2172031390000484], [0.21503456399841525, 0.2169139970010292, 0.21409635700001672, 0.2278372170003422, 0.20594137999978557], [], [], [], [0.2146277520005242, 0.22772539899960975, 0.2060412080008973, 0.22468119000041042], [0.21382309199907468, 0.22783938999964448, 0.2061968270008947, 0.22590169999966747, 0.20908054400024412, 0.21710636500029068, 0.2171739079985855, 0.23447702200064668, 0.21714815400082443, 0.21323204699911003, 0.22682341700055986], [0.20664212200063048, 0.2244830550007464, 0.21034623400009878, 0.21706687199912267, 0.21713988299961784, 0.2347277570006554, 0.21724353100034932, 0.21327063100034138, 0.22669019599925377, 0.23475631399924168, 0.20653875100106234, 0.20635848699930648, 0.2054209380003158, 0.2093893700002809, 0.23150604399961594, 0.23467197399986617, 0.2546247400005086, 0.22135684699969715, 0.20660715099984373, 0.22929280900098092, 0.21304739599872846, 0.21128339800088725, 0.20636224199915887, 0.20605468900066626, 0.21293949199935014, 0.2066216670009453, 0.21957914999984496, 0.2251036359994032, 0.21734505700078444], [], [0.20601683300083096, 0.2246240209988173, 0.21031218400094076, 0.2172411559986358, 0.2170944410008815, 0.2348109199992905, 0.21724137100136431, 0.21326661499915645, 0.22641099000065878, 0.23493381799926283], [0.2244297720008035, 0.2103285949997371, 0.21706908899977861], [0.20861386499927903, 0.21706689600068785, 0.2170860360001825, 0.23481107799852907, 0.21724346300106845, 0.21326915299869142, 0.22641024800032028, 0.235015469001155, 0.20641916599925025], [], [], [0.21773300000131712, 0.23459160099992005, 0.21724164099941845, 0.213273544999538, 0.22669146200132673, 0.2347494209989236, 0.20683292700050515, 0.20631036200029484, 0.20527142399987497, 0.20945047799978056, 0.2313619189990277, 0.23467639400041662, 0.2546262100004242, 0.22180925700013177, 0.20618328099953942, 0.22928097400108527, 0.21342185499997868, 0.2109110649998911, 0.2061570669993671, 0.20584867199977452, 0.21316288799971517, 0.20646923900130787, 0.21962658199845464], [0.21710892000010062, 0.23471392799910973, 0.2168964219999907, 0.21323399100037932, 0.22689672300111852, 0.23447881099855294, 0.20751615700100956, 0.20664022699929774, 0.20505160100037756, 0.21016772300026787, 0.2304293229990435], [], [0.21718552300080773, 0.23447076599950378, 0.2170515580000938, 0.21327543599909404, 0.2266914000010729, 0.23473701699913363, 0.20698782799991022, 0.20651209599964204, 0.20492286300031992, 0.21031294200111006, 0.2306480309998733], [], [], [], [], [], [0.21710261500084016, 0.21300492999944254, 0.22681598599956487, 0.2349550070011901, 0.20636565699896892, 0.20648509100101364, 0.20552760899954592, 0.209193578999475, 0.23150753899972187, 0.23489494500063302, 0.25462804199923994, 0.22127962200102047, 0.20641593300024397, 0.22920766999959596, 0.21340554999915184, 0.2099303190007049, 0.2076470390002214, 0.20584993599914014, 0.21316183599992655, 0.20646991200010234, 0.21962572600023123, 0.22360180900068372, 0.21899549599947932, 0.22087264900073933, 0.2095703599989065, 0.2101684830013255], [0.2168868239987205, 0.2132319890006329, 0.2268173709999246, 0.23458113900051103, 0.20702106399949116, 0.2066743100003805, 0.20471816799908993, 0.2107414490001247, 0.2302662900001451, 0.23448336299952643, 0.2546237830010796, 0.22190728199893783, 0.20617295100055344, 0.22962295199977234], [], [0.22732453000025998, 0.23477350999928603, 0.2065321000009135, 0.20636104199911642, 0.20542454099995666, 0.20938608600044972, 0.2315112060005049, 0.23466753599859658, 0.2546255890010798, 0.22135837099995115, 0.2066057419997378, 0.2292912150005577, 0.2130508819991519, 0.2112789069997234, 0.20702967600118427, 0.20602455100015504, 0.21261884900013683, 0.20647903799908818, 0.21993344700058515, 0.22469865799939726, 0.21745716499935952, 0.22118392000083986, 0.20974860299975262, 0.21021313100027328, 0.21637604599891347, 0.21095309100019222, 0.21842971300065983, 0.20892906100016262, 0.21917004600072687, 0.2174892559996806, 0.2062635259990202, 0.2126159440012998, 0.2253848009986541], [], [], [0.20636543199907464, 0.20648557700042147, 0.2054214569998294], [], [], [0.20628459799991106], [0.20638396200047282, 0.20549743400079024, 0.20940542999960599, 0.23143820699988282], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [0.20627620800041768, 0.2053061599999637, 0.20933145399976638], [0.2065914739996515], [], [0.20665337399987038, 0.20471162300054857], [0.20542921900050715, 0.20938383000066096, 0.23151376399982837, 0.23466361999999208, 0.2546276550001494, 0.22136044400031096, 0.20660620299895527, 0.22918344900062948], [], [], [], [0.20465014200090081, 0.20933153899932222, 0.2315016230004403, 0.23467416899984528, 0.25462468799923954, 0.22135737400094513, 0.20660632499857456, 0.22929417800150986, 0.2130459799991513, 0.21128627700090874, 0.20598423599949456], [], [], [0.21016671899997164, 0.23042273499959265, 0.23414135399980296, 0.25462057900040236, 0.22191129000020737, 0.2061699329988187, 0.22972286799995345, 0.2129997700012609, 0.21105847699982405, 0.20601086100032262], [0.21040201600044384, 0.23016180400009034, 0.23448243599887064, 0.254622376000043, 0.2219106680004188, 0.2061709690005955, 0.22971360799965623, 0.21301248700001452, 0.21105122599874448, 0.20578813400061335, 0.2058554280010867, 0.213152997999714, 0.20647303899932012, 0.21962717099995643, 0.22360498799935158, 0.2189263670006767, 0.22095521799928974, 0.20956926200051385, 0.21017016699988744, 0.21738990599988028, 0.21099704500011285, 0.21853090600052383, 0.20877622899934067, 0.2191232620007213, 0.2175681610005995, 0.20514592499966966, 0.21323549699991418, 0.22537643899886461, 0.1972588309999992, 0.2122377450014028, 0.22786908699890773, 0.21888739300084126, 0.22294090700052038, 0.2120671789998596, 0.21762024499912513], [], [0.23067194599934737, 0.23453714700008277, 0.2546270410002762, 0.221815004999371, 0.2061749240001518, 0.2292835999996896, 0.2134271800005081, 0.21090338500107464, 0.20699087599859922, 0.20619894599985855, 0.21241155000097933], [], [], [], [], [], [], [], [0.20661128299980192, 0.22918392900101026, 0.21317937099956907, 0.2099537270005385, 0.20835156300017843, 0.2058463710000069, 0.2127458859995386, 0.20650550900063536, 0.2199110989986366, 0.22472090600058436, 0.21740016900002956], [], [], [0.2060425750005379, 0.2292803059990547, 0.2134083550008654, 0.21092406199932157, 0.2061380969989841, 0.20585241000117094, 0.21315932799916482, 0.2064709109999967, 0.21962497200001962, 0.22360378400117042, 0.21893119899868907], [0.22919396700126526, 0.21318487899952743, 0.20995202399899426, 0.20710828099981882, 0.20614818600006402, 0.21244028200089815, 0.20712721400013834, 0.2197381519999908, 0.2236181629996281, 0.2183114880008361, 0.22147932699954254, 0.20941770799981896, 0.2098353679994034], [0.2292290140012483, 0.21341549799944914, 0.21088739299921144, 0.2069890660004603, 0.20620091899945692, 0.2129600059997756], [], [], [0.21079033600108232, 0.2073202459996537, 0.20614508499966178, 0.21294015500097885, 0.20642799899906095], [], [], [], [0.21080901499954052, 0.20626615600122022, 0.2060533369985933, 0.2129384480012959, 0.2066264429995499, 0.219577059000585, 0.2251063969997631, 0.21739942400017753, 0.2210756019994733, 0.20928855700003623, 0.210701464999147, 0.2166419910008699, 0.21107312099957198, 0.21853559500050324, 0.2087191119990166, 0.21917625700007193, 0.21749532200010435, 0.20570229300028586, 0.2129467230006412, 0.2254785789991729, 0.19757484500041755, 0.21228908199918806, 0.22719017700001132, 0.2188891270016029, 0.22294007199889165, 0.2124382220008556, 0.21790037699975073, 0.2282482999999047, 0.21495317200060526, 0.2133512559994415, 0.2204068470000493, 0.2142555070004164, 0.2124730659998022, 0.21882145800009312, 0.21162545299921476, 0.20868529200015473, 0.20800167999914265], [], [0.20639218900032574, 0.20605731800060312, 0.21294016199863108, 0.20654534500135924, 0.21962261199951172, 0.22358264099966618, 0.2188830710001639, 0.22115159399982076, 0.20928281399937987, 0.21043398800065916], [0.2059928079997917, 0.21240510899951914], [], [0.20604493600149, 0.21241963600004965, 0.2071273099991231, 0.2197381089990813, 0.22360850500081142, 0.21832028499920852, 0.2214681430014025, 0.20943183099916496, 0.21030169100049534, 0.2172741060003318], [], [], [], [], [], [0.21263629700115416, 0.20648302799963858, 0.2199252800000977, 0.22470798199901765, 0.21745186100088176, 0.22118616399893654, 0.20974880700123322, 0.21021434199974465, 0.21611191500051063], [], [], [], [], [], [], [], [], [], [], [], [0.2126224599996931, 0.20647993400052655, 0.2199294980000559, 0.22470348400020157, 0.21745572500003618, 0.22118395299912663, 0.2097480299999006, 0.21021514600033697, 0.21635022699956608, 0.21085714900073071], [], [0.21298634799859428, 0.2064327530006267, 0.21974521099946287, 0.223467089001133, 0.21900198199909937, 0.22115205000045535, 0.2092863199995918, 0.21043069400002423, 0.21712727500016626, 0.2111313589994097, 0.21841049900103826, 0.20875812099984614, 0.21918693599945982, 0.21748060900063138, 0.20518165199973737, 0.213233673999639, 0.2255668270008755, 0.19743169199864496, 0.21212231800018344, 0.22760770600143587, 0.21888951799883216, 0.22293867400003364, 0.21212004900007742, 0.2178230839999742, 0.22863444699942193, 0.21496541100168542, 0.2134809619983571, 0.2202623350003705, 0.21440938300111156, 0.21238602699850162, 0.2187790040006803, 0.21173463800005266, 0.2094669599991903, 0.20757486300135497, 0.22293792100026621, 0.2278513799992652, 0.2111019389994908, 0.2112867819996609, 0.37233779200141726, 0.08751614799984964, 0.2651819879993127, 0.28787102600108483, 0.2585776749983779, 0.2194131730011577, 0.23717371199927584, 0.22767348700108414, 0.22318018499936443, 0.24153750900040905, 0.26699723699857714, 0.2852777700009028, 0.22842725699956645, 0.2091329869999754, 0.23220529700120096, 0.22319240299839294, 0.23695297200174537, 0.2535074869992968, 0.20879265400071745, 0.22243984699889552, 0.24469465599941032], [], [], [], [], [], [], [], [0.21294493999994302, 0.20642540599874337, 0.21975102900069032, 0.22346148900032858, 0.21900584700051695, 0.22115301099984208, 0.20928188099969702, 0.2104327689994534, 0.21712460200069472, 0.2111247929988167, 0.21841100200072106], [], [], [], [], [], [0.2065074870006356, 0.2195232349986327, 0.22510744800092652, 0.21740219700041052, 0.22125064399915573, 0.20974994599964703, 0.21021626699985063, 0.21598143600022013, 0.2111820339996484, 0.21858900600091147, 0.20847126800072147, 0.21939567899971735, 0.21747645499999635, 0.20634863099985523, 0.212748924999687, 0.2254478079994442, 0.19786608100002923, 0.21211300700088032, 0.22671953300050518, 0.218971865999265, 0.2227463090002857, 0.21295137999914004, 0.21794785699967179, 0.2273475160000089, 0.2152088740003819, 0.2136823800010461, 0.22032240799853753], [0.20647984299830568, 0.21963002200027404, 0.22360596600083227, 0.21881209099956322], [0.21935582800142583, 0.2246373539983324, 0.21745670800009975, 0.2211830860014743, 0.21013532599863538, 0.20982833100060816, 0.21637577500041516, 0.2109555499991984, 0.2184227859997918, 0.20893323700147448, 0.21917493699947954, 0.21748017099889694, 0.20626228700166394, 0.21262094599842385, 0.2254391400001623, 0.1977978980012267, 0.21211185899846896, 0.22692145500150218, 0.21889927099982742, 0.2229491069992946, 0.21261318600045342, 0.2179565989990806], [], [0.2195819250009663, 0.2235749429983116, 0.21887730800153804, 0.22114961599982053, 0.20928626400018402, 0.21069965499918908, 0.21659734500099148, 0.21095094499833067, 0.218439603000661, 0.20892288700088102, 0.21905997899921203], [], [], [], [], [], [], [0.21699977000025683, 0.22110624600099982, 0.2095676459994138, 0.210169579999274, 0.21730652200130862, 0.21107273999950849, 0.2185371129999112, 0.20871748699937598, 0.21917663300155255, 0.2175006419984129, 0.20511493500089273], [], [], [], [], [], [], [], [0.20937919700008933, 0.21029017900036706], [0.21013304900043295, 0.20979974799956835, 0.21650366200083226, 0.21113678599976993, 0.2184122569997271, 0.20878192800046236, 0.2191928399988683, 0.21746901900041848, 0.2061553029998322, 0.21260662900021998], [0.21022240899947064, 0.21650481200049398], [], [0.2171136930010107, 0.21109553299902473, 0.21857217700016918, 0.20848436699998274, 0.2193908110002667, 0.21765449099984835, 0.20522603599965805, 0.21336604300086037, 0.22515440799907083, 0.19747914800063882, 0.21213849999912782], [], [], [], [], [], [], [], [], [], [0.21659134200126573, 0.21114806399964436, 0.21857970299970475, 0.20847869600038393, 0.2193918480006687, 0.21747694299847353, 0.2056141419998312, 0.21323529800065444, 0.22537743500106444, 0.19725928499974543, 0.2122465539996483], [], [], [], [0.21649945399985882, 0.21094240300044476, 0.2185637839993433, 0.20849076800004696, 0.21939116599969566, 0.21764715199969942, 0.20583825500034436, 0.21294999199926679, 0.22548487600033695, 0.1974564250012918], [0.21911990099943068, 0.20881744799953594, 0.2191770440003893, 0.21747232400048233], [], [], [], [], [], [], [0.21842993199970806, 0.20876176199999463, 0.219121129000996], [], [], [], [], [0.2184665760014468], [0.2084481039983075, 0.21940418000122008, 0.21741067099901557, 0.20643937100066978, 0.2127598869992653, 0.22545984700082045, 0.19786344900057884, 0.21211555199988652, 0.22657120899930305], [], [], [], [], [], [], [0.21906248300001607, 0.2175661660003243], [], [], [], [], [], [0.20674453700121376, 0.21276420799949847, 0.22546578199944634, 0.19770818500001042, 0.2122333589995833, 0.22713952800040715, 0.21888892999959353, 0.22293933000037214, 0.21241456899952027, 0.2179103580001538, 0.22825725300026534, 0.21495984400098678, 0.2134767869993084, 0.22026743099922896, 0.2142473849999078, 0.2124835640006495, 0.2188231510008336, 0.21174080699893238, 0.2094389410012809, 0.20759590599845978, 0.22294057300132408, 0.22786344999985886, 0.21110342599968135, 0.21127402799902484, 0.3723278659999778, 0.08752608900067571, 0.2651738509994175, 0.2878809860012552, 0.25857725799869513, 0.21941359900120005, 0.23710138099886535, 0.227761449999889, 0.22317979200124682, 0.24153777500032447, 0.2669937479986402, 0.2852798570002051, 0.2284313430009206, 0.20912916399902315, 0.23217232000024524], [0.20565926199924434, 0.21292880900000455, 0.22547247400143533, 0.19758557000022847, 0.21228764599982242], [], [], [], [], [0.20552272100030677, 0.21319642799971916, 0.2255539289999433, 0.19744488700052898, 0.21212235199891438], [0.20637891500155092, 0.21275141399928543, 0.22545235799952934, 0.19786555800055794, 0.21211353199942096, 0.22670007499982603, 0.2189736450000055, 0.22273099400081264, 0.21294182100064063], [], [], [0.212611035000009, 0.22539174700068543, 0.19786651199865446, 0.21211275499990734, 0.22674940300021262], [], [], [], [], [], [], [], [], [], [], [], [], [0.21295438299966918, 0.2254925640008878, 0.19745065799907024, 0.21218887100076245, 0.22724240699972142, 0.21888882799976273, 0.22275519700087898, 0.2125873649983987, 0.21782952300054603, 0.2278314169998339, 0.21520588100065652], [0.21259866900072666, 0.2254217019999487, 0.19779481499972462, 0.21211140800005523, 0.22697264099952008, 0.21888828100054525, 0.22294263000003411, 0.21258066199879977, 0.21801703100027225, 0.22752891500022088], [], [0.1974238469992997, 0.21212314500007778, 0.22755411300022388, 0.21888823700101057, 0.22294070399948396, 0.21217566199993598, 0.2178170240003965, 0.22820100799981446, 0.21534388799955195, 0.21335054799965292, 0.22040897900114942, 0.21425972799988813, 0.21246701999916695, 0.21882038900002954, 0.2116257380002935, 0.20868469199922401, 0.20799658699979773, 0.22332254100001592, 0.22783359300046868, 0.21121762500115437, 0.21103056399988418, 0.37236318299983395, 0.08761592699920584, 0.26519274600104836, 0.2880073429987533, 0.25857226600055583, 0.2194182589992124, 0.2369837420010299, 0.22789203399952385, 0.22318076000010478, 0.24153745500007062, 0.26698631599902, 0.2852871620016231, 0.22843611399912334, 0.2091245709998475, 0.232175172001007, 0.2231725319998077], [0.21224183699996502, 0.2271218140012934, 0.2188877139997203, 0.22294103099920903, 0.2124338079993322, 0.2179055070009781, 0.22824909200062393, 0.21495277099893428, 0.21335263500077417], [0.2120878490004543, 0.22756290399956924, 0.21889895499953127, 0.22294970700022532, 0.21221105599943257, 0.21773736700015434, 0.22820108999985678, 0.2154297739998583, 0.21334688100068888, 0.220413646000452, 0.21419453599992266], [], [], [], [], [], [], [], [0.21211783299986564, 0.22701064600005338, 0.2188891549994878, 0.2229435610006476, 0.21251114699953177, 0.21791561700047168], [0.22708213099940622, 0.21890102900033526, 0.22295107100035239, 0.21253389000048628, 0.21770377599932544, 0.2279055340004561, 0.21543536799981666, 0.21334768499946222, 0.2204130680001981, 0.21419870600038848, 0.21247882600073353], [0.22752604999914183, 0.2188917510011379, 0.22294608499942115, 0.2122003650001716, 0.21774777800055745], [], [], [0.22309504700024263, 0.2123806749987125, 0.21783267600039835, 0.22783186299966474, 0.21556200900158728, 0.21335033199829923, 0.22041383900068467, 0.21420118500100216, 0.2124695200000133, 0.21889924799870641, 0.21162328600075853, 0.2081885079987842, 0.20827874099995825, 0.22353592300169112, 0.2277646980001009, 0.21098179599903233, 0.21117552400028217, 0.37243449299967324, 0.08766638400084048, 0.26519433700013906, 0.2880041619991971, 0.25847920200067165, 0.2195314029995643, 0.2369845749999513, 0.22781669899995904, 0.22326404200066463, 0.24153135999949882, 0.26687201499953517, 0.2854180569993332, 0.22845233299995016, 0.20892015600111336, 0.23220095800024865, 0.22328180799922848, 0.2369668470000761], [], [], [], [0.22295298599965463, 0.21268360300018685, 0.21802748700065422, 0.2280273849992227, 0.21495544800018251, 0.21346737100066093, 0.22027569099918765, 0.21425148799971794, 0.21247742299965466, 0.21882318999996642, 0.21162742900014564], [0.21885333499994886, 0.2277604680002696, 0.21542741899975226, 0.2133486239999911, 0.2204109319991403, 0.21426254800098832, 0.2124580199997581, 0.2188231910004106, 0.21162416100014525, 0.20818736999899556, 0.20827864500097348, 0.22353759500037995, 0.22775288199954957, 0.2110287369996513, 0.21116008500030148, 0.3724322439993557, 0.08766052499959187, 0.26519395300056203, 0.2880064430009952, 0.2584802679994027, 0.21952712100028293, 0.23698411399891484, 0.22788421400036896, 0.22318343200095114, 0.2415360309987591, 0.26687346499966225, 0.28541801600113104, 0.22844208399874333, 0.2091171750016656, 0.23204040999917197, 0.22327647299971431, 0.23705763399993884, 0.25349890399957076, 0.20867198000087228], [], [], [], [0.21769836299972667, 0.22779590099889901], [0.21565041600115364, 0.21335958399868105, 0.22041718600121385, 0.2129243219987984, 0.21337277900056506], [0.21444122399952903, 0.2199349290003738, 0.21440537399939785], [], [], [], [], [], [], [], [], [0.21273372399991786, 0.2124607850000757, 0.21890000900020823, 0.2116224229994259, 0.20818736100045498, 0.20828380199964158, 0.22353559099974518, 0.2277761620007368, 0.21097064799869258, 0.21117959399998654, 0.3724328410007729, 0.08766998200007947, 0.265193121998891, 0.2879996890005714, 0.2583520080006565, 0.21962164099932124, 0.23700226999972074, 0.2277107280006021], [0.21252266999908898], [], [0.21238167299998167, 0.21878176999962307, 0.21173798900053953, 0.20945554900026764, 0.20758255299915618, 0.22293822500068927, 0.22785851799926604, 0.2111023590005061, 0.21128023900018889, 0.3723347619998094, 0.08751902500080178, 0.26517978199990466, 0.28787286700026016, 0.2585783309987164, 0.21941310900001554, 0.23710714700064273], [0.21211887800018303, 0.20931329199993343, 0.20756999500008533, 0.22293796700068924, 0.22784464199867216, 0.2111015509999561, 0.21129279600063455, 0.3727740869999252, 0.08707935200072825, 0.2651832769988687, 0.28787014999943494, 0.2585767960008525, 0.21941371399952914, 0.23717962699993222, 0.22766847800085088], [0.2080378959999507, 0.2084467399999994, 0.2235313569999562, 0.22779585900025268, 0.21096624700112443, 0.21118087499962712, 0.3724345800001174, 0.08767134499976237, 0.2651941280000756, 0.28789600299933227], [0.20788850200005982], [], [0.22294781199889258, 0.22784683000099903, 0.21113034399968456, 0.21126258799995412, 0.37219718899905274], [0.21141102500041598, 0.21100401500007138, 0.3724366549995466, 0.08765764400050102, 0.2651935739995679, 0.2880069610000646, 0.2584814700003335], [], [], [], [0.21113370499915618], [], [], [], [], [], [], [], [0.21116650600015419, 0.21102620300007402, 0.3723641910000879, 0.08761289799986116, 0.26519157599977916, 0.2880083800009743, 0.25857545500002743, 0.2194152310003119, 0.23698600199895736], [0.21113254800002323, 0.21102626100037014, 0.37236531900089176, 0.0876109799992264], [0.21125978400050371, 0.3725509759988199, 0.08768011400024989, 0.2651917710009002, 0.2878974579998612, 0.25848481799948786, 0.21961446400018758, 0.2370066229996155, 0.2277174240007298, 0.22327543199935462], [0.21115829500013206, 0.3724305050000112, 0.08766279299925372, 0.2651941750009428, 0.2880053039989434, 0.2584805580008833, 0.21952882199911983, 0.2369848930011358, 0.22781718999976874], [], [], [], [], [0.3723649829989881, 0.08762095300153305, 0.26519284099958895, 0.28800690099888016, 0.2585647940013587, 0.21942621699963638, 0.23698355299893592, 0.2278899350003485, 0.22318202200040105, 0.24153590199966857, 0.2668737250005506], [0.3722518350004975, 0.08767438599898014, 0.2650682240000606], [], [0.21953415400093945, 0.23698740100007853, 0.22781369499898574, 0.22325626200108672, 0.2415194449986302, 0.2668706510012271, 0.2854177339995658, 0.2284748980000586, 0.20891516799929377, 0.23221086200101126, 0.22315366600014386], [], [], [0.20923508399937418, 0.2320814340000652, 0.22328281299996888, 0.23699384800056578, 0.25374108600044565, 0.20824793799874897, 0.22288178500093636, 0.24476958100058255, 0.23989053799959947, 0.2106569480001781, 0.21914591699896846], [], [], [], [], [], [], [0.23205271000006178, 0.22326969700043264, 0.2370571600004041, 0.253495209999528, 0.20867324299979373, 0.2225819600007526, 0.24469641899850103, 0.24053651699978218, 0.21105039000030956, 0.21834388200113608], [], [0.2232607170008123, 0.23704141499911202, 0.2535035609998886, 0.2087872909996804, 0.22244519300147658, 0.24469380999835266, 0.24054725400128518, 0.21104032099901815, 0.21841355800097517, 0.2121178779998445, 0.2060883289996127], [], [], [0.2225877059991035, 0.24469747799957986, 0.24017217900109245, 0.21122658999956911, 0.21845963799933088, 0.21226519700030622, 0.20598497799983306, 0.2146792319999804, 0.20619040699966718, 0.2070645500007231], [], [], [], [], [], [], [], [], [], [0.2227603689989337, 0.24474572100007208, 0.24002458700124407, 0.2113315739989048, 0.21848495499943965, 0.21228812300068967, 0.20598667000012938, 0.21467738700084738, 0.2061918079998577, 0.20706580600017332, 0.22114398799931223, 0.2085887390003336, 0.22371122899858165, 0.20913789400037786, 0.21648163300051237, 0.2116902760008088, 0.2064925750000839, 0.21003985999959696, 0.22229111199885665, 0.20638896300079068, 0.22332952699980524, 0.22533031400053005, 0.20698501199876773, 0.21509814900127822, 0.23173669099924155, 0.20948201200008043, 0.20676108000043314, 0.22049153999978444, 0.21198137200008205, 0.21050827100043534, 0.20334835999892675, 0.20955504199991992, 0.2072694890011917, 0.20650030099932337, 0.21480173599957197, 0.21799356900010025, 0.2093228329995327, 0.21421542500138457, 0.2104851129988674, 0.21968386499975168, 0.20547233300021617, 0.22514585300086765, 0.2216571409990138], [], [], [], [], [], [], [], [0.21133377000114706, 0.21847716299998865, 0.21226986699912231, 0.20599226900048961, 0.21463473199946748, 0.20623545899979945, 0.20706869800051209, 0.22114458699979878, 0.2085873289997835, 0.2236899639992771], [0.2112283890000981, 0.21846192900011374, 0.21224241299933055, 0.20598774000063713, 0.2146305919995939, 0.2062388930007728, 0.20706649999920046, 0.2211442870011524, 0.2085883419986203, 0.22371537199978775, 0.20901675800087105], [0.21834644299997308, 0.2122111450007651, 0.2059846939991985], [], [], [], [0.20603808300074888, 0.21445571799995378, 0.20682035900063056, 0.20693899799880455], [0.214654874000189, 0.20622419800019998, 0.20706838600017363, 0.22115388000020175, 0.20857790499940165, 0.2236467030015774], [0.2143341680002777, 0.20678910999959044, 0.20701120600097056, 0.22084029399957217, 0.20834280499911983, 0.22392308300004515, 0.2089443080003548, 0.21656919099950755, 0.21242620700104453, 0.20629931099938403], [0.20751906000077724, 0.20668087999911222, 0.22090705600021465, 0.2084104390014545, 0.22392422099983378, 0.20880487899921718, 0.21674874299969815, 0.21249432700096804, 0.20623766999960935, 0.20923653099998774, 0.22264713500044309, 0.2068170820002706, 0.22275709499990626, 0.22558959199886885, 0.20733808499971929, 0.21440474200062454, 0.23170743099944957, 0.20987951300048735, 0.20709637999971164, 0.21974825500001316, 0.21218324300025415, 0.21131818399953772, 0.20338422399981937, 0.2099115390010411, 0.20644476499910525, 0.2063572839997505, 0.21445251300065138, 0.2184754999998404, 0.20911196300039592, 0.21397002400044585, 0.21100094400026137, 0.21911655099938798, 0.20560510199902637, 0.22496083100122632, 0.2216199399990728, 0.21825965000061842, 0.22915866999937862, 0.208757828000671, 0.20623504799914372, 0.2054862820004928, 0.20928912199997285], [0.2066579530001036], [0.20730331699996896, 0.2211139569990337, 0.20834416800062172, 0.22383796999929473, 0.2090261070006818, 0.21652582400020037, 0.21246518599946285, 0.20594290199915122, 0.20975409600032435, 0.22254340200015577], [0.20683871599976555, 0.22101923899936082, 0.2083461639995221, 0.2239299580014631, 0.2089359349993174, 0.21652594300030614, 0.21246642999903997, 0.20594650100065337, 0.20974851599930844, 0.22261109099963505, 0.2060795750003308, 0.22338994100027776], [0.22091074899981322, 0.2085623309994844, 0.22370683900044241, 0.209152522000295, 0.21647597499941185, 0.21169392299998435, 0.2064874810002948, 0.2100014799998462, 0.22229183899980853, 0.20628328199927637], [0.22093964200030314, 0.2083398249997117, 0.22392674300135695, 0.20893901599993114, 0.21656760800033226, 0.21242719299880264, 0.20594576800067443, 0.2097468949996255, 0.2226180560010107, 0.2060395509997761, 0.2233265679988108], [], [0.2083012589991995], [], [], [], [], [], [], [0.21663867899951583, 0.21167656400029955, 0.20581076300004497, 0.21051984999940032, 0.2223511989996041, 0.20632144100090954, 0.2233497669985809, 0.22544246899997233, 0.2069071920013812, 0.21521087099972647, 0.23161247200005164], [0.2129397129992867, 0.20623083899954509], [], [], [], [], [], [0.2124593789994833, 0.20626896599969768, 0.20924152500083437, 0.22264806099883572, 0.20680525400166516, 0.22276954199878674, 0.22542387700013933, 0.20695430600062537, 0.2148293249993003, 0.2317279580001923], [0.21166883899968525, 0.20647694100080116, 0.21001947399963683, 0.22229180999966047, 0.2063952700009395, 0.22332727699904353, 0.22532298899932357, 0.20699299800071458, 0.21509574800074915, 0.23173467899869138, 0.20977138899979764], [0.20583139900008973], [], [], [0.2102774409995618, 0.22227805699913006, 0.20633341500069946, 0.22335102000033658, 0.22540375199969276, 0.2070509690001927, 0.21510431699971377, 0.23173725999913586, 0.20930508000128611, 0.20661954000024707], [0.2104514319998998, 0.22232252300091204, 0.20633105999877444, 0.22335117100010393, 0.22541545600142854, 0.20693502399990393, 0.21520882099866867, 0.23173537900038355, 0.20928839800035348, 0.20649899899945012], [], [], [0.21002420599870675, 0.22221864099992672, 0.2063336999999592, 0.22335102200122492], [], [], [0.2094339889990806, 0.22264855000139505, 0.20644625999921118, 0.2231276300008176, 0.2254303899990191, 0.20694928800003254, 0.21483050899951195, 0.23172805000103835, 0.20990438099943276, 0.20664740199936205, 0.220246221000707, 0.21220299100059492, 0.21128973600025347, 0.2027785309983301], [], [0.20628508599838824, 0.2234490900009405, 0.225273071000629], [0.20603756099990278, 0.22343898200051626, 0.22553604200038535, 0.20667865199902735, 0.21507943899996462, 0.23173088100156747, 0.20990275299845962, 0.2065761100002419], [], [], [0.2231289649989776, 0.22542536400032986, 0.20667635800054995, 0.21508015399922442, 0.2317321950013138, 0.20989803500015114, 0.2065784469996288, 0.22035139099898515, 0.21210797800085857, 0.2109289660002105, 0.20273698799974227], [0.20748287599963078, 0.2148361309991742, 0.23172848200010776, 0.20990405400152667, 0.2066415909994248, 0.22023790499952156, 0.2120495369999844], [], [], [0.20667620600033842, 0.21508130300026096, 0.23173332999976992, 0.20989156200084835, 0.2065826769994601, 0.220339088999026, 0.21194267200007744], [], [0.20682393700008106, 0.21480583800075692, 0.23179535800045414, 0.2098848519999592, 0.20707787099854613, 0.21976711300158058, 0.2121934759998112, 0.21130656199966324, 0.20290029399984633, 0.21029781499964884, 0.20652766300008807], [], [], [0.21440617500047665, 0.2317109289997461, 0.20988151100027608, 0.20708843099964724, 0.2197550910004793, 0.21218830500038166, 0.21131248699930438, 0.20337350199952198, 0.20983088100001623], [0.20788296700084175, 0.2065106640002341, 0.22049662599965814, 0.2119763899991085, 0.21050403800109052, 0.20334775799892668, 0.2095554360003007, 0.20726878700043017, 0.2064994709999155, 0.21480417500060867, 0.21799283999826002], [], [0.20673486000123376, 0.21964035099881585, 0.21217852900008438, 0.21132221700099763], [0.2066130789989984, 0.22023725000144623, 0.21219872899928305, 0.21129968199966243, 0.20284555000034743], [], [], [], [], [], [], [0.22047937300158083, 0.21199954799885745, 0.2105168070011132, 0.20334876699962479, 0.20955584900002577, 0.20726978099992266, 0.2064998320001905, 0.21479962800003705, 0.21784903099978692, 0.20944779999990715, 0.21421764799924858, 0.2104817670006014, 0.21969235799952003, 0.20546216200091294, 0.22514000899900566, 0.22158523500002048, 0.21813751599984244, 0.2286837240008026, 0.2081893159993342, 0.20616160400095396, 0.20754350799870736, 0.20933061200048542, 0.22010049900018203, 0.2292587600004481, 0.24121957500028657, 0.20836205100022198, 0.21122752299925196, 0.21510650100026396, 0.20982664700022724, 0.2070064170002297, 0.20589600399944175, 0.20915507700010494, 0.23127073099931295, 0.21691624100094486, 0.21212118999937957, 0.2229412990000128, 0.2054970860008325], [], [0.220342733000507, 0.2119423870008177, 0.21049929399850953, 0.20334647700110509, 0.20966359399972134, 0.2072613979999005], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [0.22039149800002633, 0.21195354900009988, 0.21050118499988457, 0.20334739300051297, 0.20955649700044887], [0.2110486530000344, 0.20341168999948422, 0.2095574230006605, 0.207268299000134, 0.20649801099898468, 0.21480327900098928, 0.2178397789994051, 0.20945526600007724, 0.2142199289992277, 0.2103801930006739, 0.21943516999999702, 0.2058210550003423, 0.2251369829991745, 0.2197008620005363, 0.21997995899982925, 0.22872285099947476, 0.20802054200066777, 0.2063134310010355, 0.20656931399935274], [], [0.21052810299988778, 0.20335155000066152, 0.20955734599920106, 0.20726932700017642, 0.20649783000044408, 0.21479976899900066, 0.21784673700130952, 0.2094495969995478, 0.21421777399882558, 0.21038117700118164], [], [], [], [], [], [0.21085980299903895, 0.20274680300099135, 0.21028248599941435, 0.20675901499998872], [0.211272379001457, 0.20352375599941297, 0.2098932650005736, 0.2064363739991677, 0.20632717400076217, 0.21445434899942484, 0.21802968600059103, 0.2095533859992429, 0.2139800759996433, 0.21099920500091685, 0.21907933199872787], [0.2035966709991044, 0.2095710230005352, 0.20676301999992575, 0.20700292800029274, 0.21481917399978556, 0.21763137699963409, 0.20965811099995335, 0.21422655300011684, 0.21036471400111623, 0.21932407399981457], [], [0.2098621010009083, 0.2067510079996282, 0.20657852399926924, 0.21449980800025514, 0.21806743900015135, 0.20956879500045034, 0.2140624999992724, 0.2104466639993916, 0.21957843900054286, 0.2055354450003506, 0.22503772500022023, 0.22164131200042902, 0.21828553999876021, 0.22855269300089276, 0.20804152999880898, 0.20671966500049166, 0.20686256599947228, 0.20934538100118516, 0.220100538999759, 0.2292587560004904, 0.2414766009987943], [0.2066316150012426, 0.20676183300020057, 0.21451116499883938, 0.21806668400131457, 0.20921724799882213, 0.2142909789999976, 0.21055446399986977, 0.21950887300044997], [0.206210734000706, 0.20671864100040693, 0.21445490199948836, 0.2180272959994909, 0.20949337199999718], [], [], [], [], [], [], [0.20665458899929945, 0.21450305300095351, 0.218067436999263, 0.20921749300032388], [], [], [], [], [], [0.20653241500076547, 0.21435490799922263, 0.21848587299973588, 0.2091029230014101, 0.21396268799981044, 0.21100153499901353], [0.2145178840000881, 0.21806192499934696, 0.20922271300150896, 0.2144795409985818, 0.2109944590010855, 0.21908244699989154, 0.2055171119991428, 0.22503181499996572, 0.22162472600030014, 0.21829938900009438, 0.22910260999924503], [], [], [], [], [0.21445604799919238, 0.21796633200028737], [0.21453676700002688, 0.2179873859986401, 0.20957124500091595, 0.21405580999999074, 0.21045070699983626, 0.21957504899910418, 0.20553941200159898, 0.22503836499890895, 0.2216361330010841, 0.21829088699996646, 0.22855449399867211, 0.2084164950010745, 0.20643834799921024, 0.20619343500038667, 0.20890022799903818, 0.2207874490013637, 0.22917015500024718, 0.24198422999870672, 0.20835262900072848, 0.21205757999996422, 0.2146141630000784, 0.20946649899997283, 0.20574760899944522, 0.20487063200016564], [0.21811199500007206, 0.209327934000612, 0.21421609100070782, 0.21048387799964985, 0.21968899599960423, 0.2057669759997225, 0.22503263300131948, 0.22161896299985528], [], [0.21492798899998888, 0.21045432000028086, 0.2195508709992282], [0.214069883000775, 0.21044332500059681, 0.2195807899988722, 0.205531494000752, 0.22503781100022024, 0.221647471000324, 0.21827975199994398, 0.22855067399905238, 0.20804300400050124, 0.20671857299930707, 0.20700261700039846, 0.20935690199985402, 0.22001326999998128, 0.22925806599960197, 0.24130978900029731], [], [], [], [0.21420477900028345, 0.21048153400079173, 0.21967980599947623, 0.20547516899932816, 0.225148753999747, 0.2216926870005409, 0.2179874360008398, 0.2286797469987505], [], [], [], [], [], [], [], [], [0.21397475100093288], [], [], [0.2108309030008968, 0.21951631699994323, 0.20543041599921708, 0.2251423010002327, 0.22157387400147854], [], [], [], [], [], [], [], [], [], [0.20551245999922685, 0.22503289700034657, 0.2216307679991587, 0.21829507900110912, 0.2285549619991798, 0.20842432500103314, 0.20684072599942738, 0.20589895299963246, 0.20947156399961386, 0.22027349100062565, 0.22906327300006524], [], [0.22504037100043206, 0.2216565079997963, 0.2182751879990974, 0.22854482299953816, 0.2080454990009457, 0.20672082999954, 0.2062938760009274, 0.2088842149987613, 0.2207773330010241, 0.22917753999900015, 0.24180897699989146, 0.20836385599977802, 0.21212432500033174, 0.21436071900097886, 0.20966597899860062, 0.20591215700005705, 0.20485731300141197, 0.21151345699945523, 0.2310234929991566, 0.21725449000041408, 0.21188623000125517, 0.2233289439991495, 0.20402312199985317, 0.20647561700025108, 0.20505321599921444, 0.2322437880011421, 0.21138654700007464], [0.22496162799870945, 0.22162455700163264, 0.2182566309984395, 0.22915872200064769, 0.20875695399990946, 0.20614910000040254], [0.21846648499922594, 0.22854456999994, 0.20804980300090392, 0.20616266099932545, 0.20741690099930565, 0.20937280700127303, 0.2200990269993781, 0.22925158599900897, 0.24134885800049233, 0.2083637510004337, 0.21201016799932404, 0.2144951120008045, 0.2096584939990862, 0.20626954100043804, 0.2064408629994432, 0.20945402400138846, 0.23111669199897733, 0.21725962900018203, 0.21187683300013305, 0.22329856199939968, 0.20491064000088954, 0.20679395300066972, 0.2045039849999739, 0.23192973799996253], [], [], [], [0.21966416600116645, 0.22869053599970357, 0.20818019400030607, 0.20616757300012978, 0.2071098569995229, 0.20963697300066997, 0.2201542619986867, 0.22915864000060537, 0.2413830749992485, 0.20835562200045388, 0.2112267360007536, 0.2151086519988894, 0.2098221630003536, 0.2063608190001105, 0.20644526300020516, 0.20927651000056358, 0.23127144599857274, 0.2169201040014741, 0.21201321499938786], [], [0.20861267899999802], [], [], [0.20821377299944288, 0.20681422499910695, 0.20585510700038867, 0.20946892500069225, 0.22027655499914545, 0.229063879000023, 0.24193543600085832, 0.20835331799935375], [0.20568463200106635, 0.20619367099970987, 0.20889685899965116, 0.2207835460012575, 0.22917297699859773, 0.24198423900088528, 0.2081794820005598, 0.21213308400001551, 0.2146360229999118, 0.2093873279991385], [], [], [], [], [], [], [0.20623537199935527, 0.2093312409997452, 0.22010070100077428, 0.2292586379990098, 0.24159469500045816, 0.20846479700048803], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [0.20605330400030653, 0.20934730199951446, 0.2200997189993359, 0.22925715900055366, 0.24164162300075986, 0.20809495100002096, 0.21213144899957115, 0.2146369300007791, 0.20938612899954023, 0.2062468929998431, 0.20643740800005617], [0.207448070999817, 0.2092909740003961, 0.22003671099992061, 0.22921390800001973, 0.24204746699979296, 0.2089036119996308, 0.21106114000031084, 0.214709268999286, 0.2101830030005658, 0.2062394980002864, 0.2055074309992051, 0.2095022190005693, 0.23101862499970593, 0.21748033599942573, 0.21203934100049082, 0.2228107060000184, 0.205102474999876, 0.2070653040009347, 0.20446609899954638, 0.23195232000034594, 0.2121199470002466, 0.2496349469984125, 0.20540432699999656, 0.21822198500012746], [], [0.2070270669992169, 0.20928409599946463], [], [0.20929625800090434, 0.22003334500004712, 0.22921946499991463, 0.2420148129986046, 0.20882804100074281, 0.21116775900009088, 0.21465757700025279], [], [], [], [], [0.2088535419989057, 0.2207797949995438, 0.22916798000005656, 0.2416594750011427, 0.20836400400003185, 0.21122856500005582, 0.21509576099924743], [], [], [0.2093747010003426, 0.22010054599923023, 0.2291580220007745], [0.22015632100010407, 0.2291542679995473, 0.24229265800022404, 0.20882819300095434], [0.22044924600049853, 0.22908576800000446, 0.24165986699881614, 0.2083658830015338, 0.2112298419997387, 0.21515547299895843, 0.20977619200129993, 0.20622226799969212, 0.2054402220001066, 0.21037007399900176], [0.22028226499969605, 0.22906722700099635, 0.24168076000023575, 0.208363322999503, 0.21201238299909164], [], [], [], [], [], [], [], [], [], [], [], [], [], [0.2116337730003579, 0.2145636419991206, 0.20947317399986787, 0.20598470799995994, 0.20638572800089605, 0.20972437700038427, 0.23102071699941007, 0.2172469800007093, 0.2122690739997779, 0.2229869469992991, 0.20449471900064964, 0.20689110099920072, 0.20457279900074354, 0.2319465010004933, 0.21237236199885956, 0.25021473100059666, 0.2060118629997305], [0.2120010029993864], [0.21450839800127142, 0.20963222099999257, 0.20567338799992285], [0.21112292500038166], [0.20942817799914337, 0.2059145349994651, 0.2058606000009604, 0.21028029499939294, 0.2310214299996005, 0.2172434020012588, 0.2122736219989747, 0.22293978900052025, 0.2045040160010103, 0.20689300699996238, 0.20446875899870065], [], [], [0.20945769200079667, 0.20575132799967832, 0.20486793000054604, 0.21148843799892347, 0.23102291200120817, 0.2172526670001389, 0.21188858399909805], [0.20490329899985227, 0.2051048390003416], [0.20559339400097087, 0.20639211299931048], [], [], [0.2055209680002008, 0.20945147299971723, 0.2310223770000448, 0.21724938300030772, 0.2122628019988042, 0.22295900500103016, 0.20500994400026684, 0.2070574459994532, 0.20446593199994822, 0.2319120739994105], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [0.2059122219998244, 0.2095526470002369, 0.23101977599981183, 0.2174783699992986, 0.21204016199953912, 0.22294009500001266, 0.2048672330001864, 0.2071211950005818, 0.20418857599906914, 0.23198752900134423, 0.21231484099916997], [0.2054438499999378, 0.2103313879997586, 0.23127472000123817, 0.21692435899967677, 0.21200003900048614, 0.22305354600030114, 0.20498426399899472, 0.20624403300098493, 0.20501429099931556, 0.23222984299900418, 0.21206572700066317, 0.2502708840002015, 0.2052160189996357, 0.2164305099995545, 0.20669389700015017, 0.2296619870012364], [], [], [], [], [0.21029255299981742, 0.23129483199954848, 0.2169469279997429, 0.21175835500071116, 0.2232241410001734], [], [], [], [], [], [], [0.20923949600000924, 0.23127810300138663, 0.2169310150002275, 0.2117747699994652, 0.22327044600024237, 0.2052021519994014, 0.2068909989993699, 0.20457710200025758, 0.23194149099981587, 0.21237513000050967, 0.24978899100096896, 0.20520093899904168, 0.21643273799963936, 0.206692773001123, 0.22966598099992552, 0.21385342299981858, 0.20748490799996944], [], [], [], [0.21038808599951153, 0.23107089500081202, 0.2172584639993147, 0.2118796899994777, 0.22332714900039718, 0.20444688300085545, 0.20672324799852504, 0.20453491400076018, 0.23222845700001926, 0.21228038200024457, 0.25012629800039576], [], [], [], [0.21022141199864564, 0.2310266620006587, 0.2172566810004355, 0.2118833780004934, 0.2233278559997416, 0.20444646800024202], [], [], [], [0.21302402899891604, 0.2229693600002065, 0.20501384000090184, 0.20704874100010784, 0.20417708399872936, 0.23214738700153248, 0.21221234899894625, 0.24988233499971102, 0.20585967100123526, 0.21703767299914034, 0.20608827700016263, 0.2292222510004649, 0.21400188199913828, 0.20801171099992644, 0.21003279100114014, 0.21306786300010572, 0.22474372599936032, 0.22685331300090184, 0.21208695699897362, 0.20698246500069217, 0.20753017799870577, 0.20971458300118684, 0.22523456799899577, 0.21739715400144632, 0.20733048599868198, 0.20892235199971765, 0.20895469100105402, 0.20785307900041516, 0.21143548699910752, 0.20700318600029277, 0.22569379400010803, 0.22245195799951034, 0.2078146879994165, 0.22108356000171625, 0.20916074499837123], [], [], [], [], [], [], [], [], [], [0.21206446299947856, 0.222920021000391, 0.20534927699918626, 0.20673323700066248, 0.204540796999936, 0.2319401980003022, 0.2123782949984161, 0.2498484540010395, 0.20522196399906534, 0.2164299710002524, 0.2066926740008057, 0.2298088169991388, 0.213676117000432, 0.20841917500001728, 0.2101620739995269, 0.21296899400113034, 0.224497232999056, 0.22700205900036963, 0.212051115999202, 0.20648077100122464, 0.20737304799877165, 0.21052482400045847, 0.22525953900003515, 0.21706946800077276, 0.20703055599915388, 0.20893584100122098, 0.20886591499947826, 0.2084578590001911, 0.21089960399876873, 0.20726846300021862, 0.225607502999992, 0.22295167599986598, 0.20772427700103435, 0.22075658699941414], [0.2118757389998791, 0.2228257989991107, 0.20494291800059727, 0.20624781599872222, 0.2050132640015363, 0.23222973699921567, 0.21206250800059934, 0.25026795099984156, 0.20521159599957173, 0.2164325829999143, 0.20669351200012898, 0.22966473199994653, 0.21384131199920375, 0.2076019300002372, 0.21054266600003757, 0.21342129500044393, 0.22412267599975166], [], [], [0.20663053800126363, 0.20459789499909675], [0.20637365199945634, 0.20503185400048096, 0.2322311699990678, 0.21204201300133718, 0.25066768399847206, 0.2060088310008723, 0.21734535199902894, 0.20560633100103587, 0.22923056999934488, 0.21399960500093584], [0.2062567709999712, 0.20501237999997102, 0.23223062400029448, 0.21205730700057757, 0.25064771699908306, 0.206010507999963, 0.21734085699972638, 0.20560233899959712, 0.2292382740015455], [0.2067360879991611, 0.2045410049995553, 0.2319409709998581, 0.21237673600080598, 0.24984858899915707, 0.20522015900132828, 0.2164310320004006, 0.2066914139995788, 0.229801919998863, 0.21368058000007295, 0.20813011800055392], [0.20674257500104432, 0.20449224000003596, 0.23204593599984946, 0.21224716799952148], [], [0.20450627700120094, 0.23193135099973006, 0.21237785799894482, 0.24985070700131473, 0.20522244499989029, 0.21643102499911038], [0.2043205769987253, 0.23217518599994946, 0.21228161200087925], [0.23207354999976815, 0.2123685629994725, 0.2501503019993834, 0.2052659480013972, 0.2174449319991254], [0.23192157700032112, 0.21217402599904744, 0.24987968000095861, 0.20600209799886215, 0.21734999399996013, 0.20564716199987743, 0.2292997220010875, 0.2140675619993999, 0.20814807399983692, 0.21034632800001418], [0.23199429600026633, 0.21230508999906306, 0.2499408029998449, 0.20526884799983236, 0.21743835600136663, 0.20627886799957196, 0.22912594499939587, 0.21393008300037764, 0.20811838100053137, 0.2100940130003437, 0.21306192099837062, 0.2247497590014973, 0.22685191799973836, 0.2120612019989494, 0.20661865300098725, 0.20784314299999096, 0.20967688699965947, 0.2253557730000466, 0.21740605400009372, 0.20694310999897425, 0.20860606900168932, 0.2092719140000554, 0.20813409599941224, 0.2109033630003978, 0.20722175999981118, 0.2260093999993842, 0.22251644099924306, 0.20774748300027568, 0.22078520200011553, 0.2088131140008045, 0.20721214299919666, 0.21348840800055768, 0.20352558000013232, 0.215201581000656, 0.2209615899992059, 0.2170580300007714, 0.22919620199900237, 0.2131742920009856, 0.2355656089985132, 0.25137006000113615, 0.2739842379996844, 0.22207336700012092, 0.2159856039997976], [0.2124165509994782, 0.2502777209992928, 0.2052745060009329, 0.2164092069997423], [0.20406779599943548, 0.21720778600138146, 0.2061739429991576, 0.2291319680007291], [0.21642816300118284, 0.20652036699902965], [0.21704280599988124, 0.20609721600158082, 0.22921105199930025, 0.21400474599977315, 0.20801718099937716, 0.21002931200018793, 0.21306488899972464, 0.22474644900103158, 0.22685271499904047, 0.21205357200051367], [0.20630293500107655, 0.22912133799945877, 0.21381969699905312], [0.2293282470000122, 0.21357384099974297, 0.20841263799957233, 0.21017555899925355, 0.2129673660001572, 0.22449465400131885, 0.22700410399920656], [], [0.22927808700114838, 0.21405244499874243, 0.20814702899951953, 0.21039714200014714, 0.21279414200034807, 0.22493802499957383, 0.22635077199993248, 0.2120495490016765, 0.20689463300004718, 0.2075334209985158, 0.21014333099992655], [0.2093121420002717, 0.21036799600005907, 0.21273350299998128, 0.22498791399993934, 0.22640464399955817, 0.21206903799975407, 0.20766700900094293, 0.2070107689996803, 0.20949172499967972, 0.2253274570011854, 0.21767904199987242, 0.20703926299938757, 0.20815787600076874, 0.2092786260000139, 0.20819154399941908, 0.21083041400015645, 0.20762117599952035, 0.2257032210000034, 0.2224528749993624, 0.20772636699985014, 0.22109980300047027, 0.20877518800079997, 0.2070168209993426, 0.21401600200078974, 0.20308033899891598, 0.2150982599996496, 0.22142624800108024, 0.21666754099896934, 0.2290908880004281, 0.21317542500037234, 0.23557699699995283, 0.2518549790001998, 0.2735365009993984, 0.22199853700112726, 0.2161015089986904, 0.20765625600142812, 0.2216748809987621, 0.2155531910011632, 0.23360682699967583, 0.2099198969990539, 0.21194424200075446, 0.21477261899963196, 0.2266186260003451, 0.21620368299954862, 0.2051313960000698, 0.20870293200096057, 0.21072610699957295, 0.2196793709990743, 0.21244331500020053, 0.21855933600090793, 0.20854022200001054, 0.20961324499876355, 0.22553941700061841, 0.20676427299986244, 0.22447182799987786, 0.21078206099991803, 0.20807392099959543, 0.20850173800135963, 0.21005415599938715, 0.21021635500073899, 0.2126249339999049, 0.23757842499981052, 0.20448660399961227, 0.21320470799946634, 0.2327516330005892, 0.20970171400040272, 0.22782226699928287, 0.20807832299942675, 0.21037498400073673, 0.21310036599970772, 0.20844680800109927, 0.21028623999882257, 0.21225392500127782, 0.2122333939987584, 0.21940479300064908, 0.2113424879989907, 0.22006781900017813], [0.2082183949987666], [0.20815150299858942, 0.2103456670010928, 0.21285124799942423, 0.22493567600031383, 0.22635660999912943, 0.21205524200013315, 0.2075036470014311], [], [], [], [], [], [], [0.20799183800045284], [0.21004153399917413], [0.21272837899959995, 0.22456122200128448, 0.22683771799893293, 0.21207356300146785, 0.2073939709989645], [0.21302507700056594, 0.22472984900014126, 0.226851154000542, 0.21208351399945968, 0.2069878639995295, 0.20752804900075716, 0.20924078899952292], [0.22463303899894527, 0.22700060200077132, 0.2120749909990991, 0.20635240199953842, 0.2074758410017239, 0.21013777299958747, 0.22564640599921404, 0.21709480800018355, 0.20700528000088525, 0.20853799599899503, 0.20851017600034538, 0.20856471700062684, 0.21052407899878745, 0.20782873300049687, 0.22549989800063486, 0.22321564300000318, 0.20708658599869523, 0.221453277999899, 0.2084237530016253, 0.2072323279990087, 0.2134616309995181, 0.20277806900048745, 0.21622069899967755, 0.22068125999976473, 0.2167132380000112, 0.22934610000083921, 0.21326540799964278, 0.23535628200079373, 0.2522268550001172, 0.2737941300001694, 0.2218639449984039, 0.21519346000059159, 0.20859701500012306, 0.22203377299956628, 0.2151365010013251, 0.2340239989989641, 0.20890768999925058, 0.21285594900109572, 0.2133612269990408, 0.22818728900165297, 0.2157055899988336, 0.20448981000117783, 0.20959121699888783, 0.21095607499955804, 0.21941261299980397, 0.21217452300152218, 0.21878145600021526, 0.20771661099934136, 0.2093955919990549, 0.22622093300014967, 0.20701048800037825, 0.2247133210003085, 0.21072398499927658, 0.20749893100037298, 0.2087244920003286, 0.2100912869991589, 0.20975182600159314, 0.21290362399849982, 0.2375776710014179, 0.20507360999908997, 0.21312044600017543, 0.23140874300042924, 0.21061080199979187, 0.226567518999218, 0.209070322000116, 0.21016457900077512, 0.2132199709994893, 0.20781995200013625, 0.21151930499945593, 0.2109702110010403, 0.21338876799927675, 0.21968179699979373, 0.20986030899985053, 0.22072501700131397, 0.2100941029984824, 0.20982224900035362, 0.22150146500098344, 0.22328496699992684, 0.2073869369996828, 0.20805540999936056, 0.22159870200084697, 0.23182202099997085, 0.21916474399949948, 0.21422480399996857, 0.21703766000064206, 0.2053276749993529, 0.21728842899938172, 0.20336609200057865, 0.21301343999948585, 0.23386581400154682, 0.21229910999863932, 0.21781743800056574, 0.21658895399923495, 0.2293395770011557, 0.21603126199988765], [0.22471465400121815, 0.22684152399961022, 0.21207852000043204, 0.20738238400008413, 0.20725257999947644, 0.20935673199892335, 0.22547821800071688, 0.21769497000059346, 0.20703021400004218, 0.2080109779999475, 0.20848683799886203, 0.20881891300086863, 0.21030031500049517, 0.2078443159989547, 0.22557264399983978, 0.22312868399967556, 0.2076981900008832, 0.22078059500017844, 0.20884296399890445, 0.2069803980011784, 0.21369088099891087, 0.20282004600085202], [0.22493184100130748, 0.2263649999986228, 0.21206192300087423, 0.2074913500000548, 0.20713603900003363, 0.20935231700059376, 0.22547776799910935, 0.21769042599953536, 0.20703312200021173, 0.20809469199957675, 0.2084219270000176, 0.20881611700133362, 0.21030104999954347, 0.20784507499956817, 0.22559730600005423], [0.22685258700039412, 0.21207630800017796, 0.2066108359995269, 0.2077170840002509, 0.2094805019987689, 0.22566506000111985, 0.21740490899901488, 0.20670111500112398, 0.2084780419991148, 0.20850849199996446, 0.2089218000000983, 0.2103234500009421, 0.20773341299900494, 0.2254971630009095, 0.2231481540002278, 0.20726059899971006, 0.22137321199988946, 0.20835662799981947, 0.2072325560002355], [0.20721996799875342, 0.2077250330003153, 0.2094779010003549, 0.2256694499992591, 0.21704081400093855], [0.20632668799953535, 0.20732392399986566, 0.21033055299994885, 0.2254538950001006, 0.21705669400034822, 0.2070435149998957, 0.20874687200011977, 0.20837912999922992, 0.20889668299969344, 0.21031830300125876, 0.20783660099914414, 0.2255038710009103], [], [], [], [], [], [], [0.20720395399985136, 0.20960786400064535, 0.22528659899944614, 0.21769677700103784, 0.20703000299909036, 0.20819672400102718, 0.2092761200001405, 0.20818836899888993, 0.21084050700119406, 0.20753747699927771], [0.20701645000008284, 0.2093450739994296, 0.2254768350012455, 0.21768507799970394, 0.2070363359998737, 0.2080970900005923, 0.20886368899846275, 0.20846033999987412, 0.2107799720015464], [0.20754407999993418, 0.209273194999696, 0.22569427500093298, 0.21740243299973372, 0.20694883999931335, 0.20820805699986522, 0.20850638699994306, 0.20892158700007712, 0.21032100500087836, 0.20773259299858182, 0.22550051800135407], [0.20978565999939747, 0.22537149300114834, 0.21704914899964933, 0.20705314000042563, 0.2087437169993791, 0.20837786499942013, 0.20889695400001074, 0.21031661599954532, 0.2078417900011118, 0.2255642660002195, 0.22291764799956582, 0.20753554700058885, 0.2211606450000545, 0.20874811700014106, 0.20705960799932654, 0.21360237299995788, 0.2026396509991173, 0.21609004200035997, 0.22094165199996496, 0.21676827900046192, 0.22894511599952239, 0.21359936900080356, 0.23521800999878906, 0.2520191470011923, 0.27390491199912503, 0.22174069799984863, 0.21560319300078845, 0.20824776500012376, 0.2220269350000308, 0.21518359099900408, 0.23387884500152722, 0.21003702899906784, 0.21180795500004024, 0.21353303499927279, 0.22795656900052563, 0.21617325700026413, 0.20461609000085446, 0.20896914199875027, 0.21095424499981164, 0.2195806090003316], [0.20930928100096935, 0.2257276139989699, 0.2174081200009823, 0.20666264299870818, 0.20847050300108094, 0.20851029499863216, 0.20892308900147327, 0.21032709799874283, 0.20773260700116225, 0.22549535999860382, 0.22315233000153967, 0.20725941699856776, 0.2213802090009267, 0.20834975899924757, 0.20723294500021439, 0.21346475800055487, 0.20277996599907055, 0.2162412180005049, 0.22075430900076753, 0.21682050699928368, 0.22911896400000842, 0.21347323000009055, 0.23516904999996768, 0.2522290819997579, 0.273795606000931, 0.22186216999944008, 0.21535941599904618, 0.20843287800016697, 0.22199399600140168], [], [], [], [], [], [], [], [], [], [], [0.20752183200056606, 0.20861444099864457, 0.2092697309999494, 0.20813580700087186, 0.21090962999915064, 0.20721619899995858, 0.22600640000018757, 0.22252575600032287, 0.20774103199983074, 0.2207905169998412, 0.20880801400016935, 0.2072175730008894, 0.213483808998717, 0.20352172100137977, 0.21520286499981012, 0.22095719400022062, 0.2170618749987625, 0.22919427499982703, 0.21317855200140912, 0.23555713599853334, 0.25137806500060833, 0.2739829389993247, 0.2220730690005439, 0.21598337100112985, 0.20778955799869436, 0.2216916270008369, 0.21509086599871807, 0.23388374900059716, 0.21009409699945536, 0.21175104000030842, 0.2149576240008173, 0.22661300399886386, 0.21622087700052361, 0.20495128100083093, 0.20877637499870616, 0.21079938100047002, 0.21967997799947625, 0.21232771800168848, 0.2187036569994234, 0.20766182700026548, 0.20930917099940416, 0.22657487700053025, 0.20687463899957947, 0.22444894299951557, 0.2106342240003869, 0.20823125999959302, 0.20838980000007723, 0.20970505500008585, 0.21035705900067114, 0.21230647799893632, 0.2376133440011472, 0.20493035199979204, 0.21329261900064012, 0.23129520299880824, 0.2106456290002825, 0.2283047839991923, 0.20764450100068643, 0.2104126140002336, 0.21344355200017162, 0.2078411740003503, 0.21089283999936015, 0.2112363029991684, 0.21306523400016886, 0.2197096310010238, 0.21018211299997347, 0.22093592300007003, 0.21052079499895626, 0.20975638300114952, 0.2207101240001066, 0.22314728499986813, 0.20782681799937563, 0.20762775000002875, 0.22151852100068936, 0.23177324700009194, 0.22015762099908898], [], [], [], [], [], [], [0.2081387950001954, 0.20842357799847377, 0.2088167580004665, 0.21030065400009335, 0.2078441699995892, 0.22557625599984021, 0.22312821200102917, 0.20771728999898187, 0.22076176700102224, 0.20885463500053447, 0.20717707599942514, 0.2135369030002039, 0.20291985099902377, 0.21580089700000826, 0.22089890600000217, 0.2171326460011187, 0.22859413799960748, 0.21373297100035415, 0.23497357099950023, 0.2520121649995417, 0.2739783039996837, 0.22165453400157276, 0.21622257499984698], [0.2088767919995007, 0.20810950900158787, 0.2108225609990768], [0.20838283599914575, 0.20889945199996873, 0.21032046700020146, 0.20773234000080265], [0.2088482519993704], [0.20814444299867318, 0.21084077399973467, 0.20726318600100058, 0.22560553800030902, 0.22294698800033075, 0.20772984699942754, 0.22079658700022264, 0.20880261300044367, 0.20717897199938307], [0.2088237889984157, 0.21030276200144726, 0.20784362399899692, 0.2255700860005163, 0.22290397899996606, 0.2075429759988765, 0.22115219600163982, 0.2087566149984923], [0.20846850800080574, 0.2102325510004448, 0.20784552699842607, 0.22565978500097117], [0.21024079400012852, 0.20779124599903298, 0.22550683700137597, 0.2231806609997875, 0.20723265299966442, 0.22131887700015795, 0.20843671100010397, 0.20723289899979136, 0.21346581800025888, 0.20277847400029714, 0.2162194909997197, 0.2206658819995937], [0.20740810300048906, 0.2254595150006935, 0.22310002499943948, 0.20770834500035562, 0.22077041099873895, 0.20884912500150676, 0.20717418999993242, 0.2135409949987661, 0.20291520600039803, 0.21579928800019843, 0.22083421800016367], [], [0.207214368001587, 0.22559423099846754, 0.2229432900003303, 0.20773569300035888, 0.22079453799960902, 0.2088047529996402, 0.20721943200078385, 0.21348150899939355, 0.20351331399979244, 0.21520861300086835, 0.22090371000012965], [0.2077346749993012, 0.22549410600004194, 0.2231653400012874, 0.2072481909999624, 0.22131139500015706], [0.22580324999944423, 0.22242738800014195, 0.20775288900040323, 0.22078117999990354, 0.20881684300002235, 0.20720759100004216, 0.213492449000114, 0.2035288959996251, 0.21520070400038094, 0.22139174499898218, 0.2166302090008685], [0.20792587799951434, 0.2208948080005939, 0.20883481599958031, 0.20698195899967686, 0.21359978500004217, 0.2026400120012113, 0.2160854579997249, 0.22094274499977473, 0.2167788679998921, 0.22902997500023048, 0.21371820899912564, 0.23499264500060235, 0.25201495100009197, 0.27391142700071214, 0.22173482299876923, 0.21560621600110608, 0.20824537299995427, 0.22202142300011474, 0.21519112500027404, 0.23387741199985612, 0.21003061000010348, 0.21181292399887752, 0.21353683500092302, 0.2279537699996581, 0.21616882499984058, 0.20462510700053826, 0.20896786999946926, 0.21095184799924027, 0.21968717700110574, 0.21233281399872794, 0.21839972700036014, 0.20780029100023967], [], [], [], [], [0.20737089999965974, 0.22110088500085112, 0.20882620200063684, 0.20698313799948664, 0.2136007150002115, 0.20263876199896913, 0.21608850200027518, 0.22094183000081102, 0.216775996999786, 0.2289365100004943], [0.22116756300056295, 0.20874041900060547, 0.20695741300005466, 0.21351044899893168, 0.20274192000033509, 0.21615763699992385, 0.22094048899998597, 0.21665998900061822, 0.22907215699888184, 0.21359778800069762, 0.2351491299996269], [0.22132781100117427, 0.20851876199958497, 0.2072048440004437, 0.21333277600024303, 0.2027831969990075, 0.21624941200025205, 0.2209533269997337, 0.2166624210003647, 0.22907685300015146, 0.21348629199928837], [0.20871364400045422, 0.20720193300076062, 0.21333980499912286, 0.20278110900108004, 0.2162478509999346, 0.22075256599964632, 0.21681736699974863, 0.22911296200072684, 0.21347904799949902, 0.23516640500020003], [0.221047634999195], [], [], [0.20698885300043912, 0.2139983070010203, 0.20311185799982923, 0.21509038399926794, 0.22143418199993903, 0.2166533800009347, 0.2290987389988004, 0.21317348100092204, 0.2355697130005865, 0.25136790399847087], [0.20617521299936925, 0.21406062500136613, 0.20301192999977502, 0.21507913099958387, 0.2214155239998945, 0.21667720299956272, 0.22908585000004678, 0.21338844100137067, 0.23538429600012023, 0.25187677499889105, 0.2735244329996931, 0.22241134100113413, 0.2163627619993349, 0.20714449799925205, 0.22177971300152421, 0.21518165999987104, 0.23361079200003587, 0.2105411249995086, 0.21128322799995658, 0.21492017799937457, 0.22664183400047477, 0.2161694530004752, 0.20565053899917984, 0.20974580100119056, 0.20927728199967532, 0.2196408950003388, 0.2131104439995397, 0.2178493970004638, 0.2085311359987827, 0.20964036800069152, 0.22559958300007565, 0.20667491799940763, 0.22465103000104136, 0.21087730799990823, 0.2080915989990899, 0.20829513100034092, 0.21057088499946985, 0.20990048800013028, 0.21233498199944734, 0.2375789480011008, 0.20480017400041106, 0.21360544500021206, 0.23048612599995977], [], [0.2135489559987036, 0.2029090330015606, 0.21569803899910767, 0.22094185000059952, 0.21720540999922378, 0.22860700000092038, 0.21372887199868273, 0.23497734900047362, 0.252013433000684, 0.27391613500003587], [0.21343899400017108, 0.20272958499845117, 0.21615561300131958, 0.22094065399869578, 0.2166586150015064, 0.2290718909989664, 0.21359918500093045, 0.23521223999887297, 0.2520238050001353, 0.2737982849994296], [0.21401607999905536, 0.2030817989998468, 0.21509311800036812, 0.22143047099962132, 0.2166642000011052, 0.22909138799877837, 0.21317436400022416, 0.23557582300054491, 0.251474237000366, 0.2738566850002826], [0.20311925200076075, 0.2150865919993521, 0.22139429399976507], [0.2026388100002805, 0.21609417400031816, 0.22094231200026115, 0.21665814299922204], [0.2027457289987069, 0.21616019000066444, 0.2209412610009167, 0.21666170899879944, 0.22907300500082783, 0.2135946239995974, 0.23514974300087488, 0.2521041219988547, 0.27379662600105803, 0.22186370700001135, 0.21536361199832754, 0.20843114500166848, 0.2220397609999054], [0.20309224700031336, 0.21508972499941592, 0.22143363000031968, 0.21665919199949712, 0.22909381300087261, 0.21317402599925117, 0.2355743749994872, 0.2514689300005557, 0.27386257400030445, 0.2220736740000575, 0.2160490429996571], [0.20301237999956356, 0.21507516000019677, 0.22142163600074127, 0.21667158099990047, 0.22908814199945482, 0.21317828400060534, 0.23557750799955102, 0.25186754499918607, 0.2735297039998841, 0.22211385000082373], [0.20258275300147943, 0.21606660899851704, 0.22094349300095928, 0.21677975499915192, 0.2290324170007807, 0.21372415699988778, 0.2349839439993957, 0.2520136110015301, 0.273914015999253, 0.22173241599921312, 0.21561040500091622], [], [], [], [], [], [], [0.21619103499870107, 0.22094493199983845, 0.21666118600114714, 0.22907436800051073, 0.21358786999917356, 0.23515427200072736, 0.25210593399970094, 0.2737963599993236, 0.22186280400092073, 0.2153632399986236, 0.20843136599978607, 0.22204614000111178, 0.21567724699889368, 0.23360981900077604, 0.20985060299972247, 0.21197140500044043, 0.21326593599951593, 0.22801826400063874, 0.21569579199967848], [], [], [], [], [], [], [0.2170013499999186, 0.22913348099973518, 0.21346351800093544, 0.235175525998784, 0.2522273850008787, 0.27379434700014826, 0.22186276199863642, 0.21535593699991296, 0.20843576600054803, 0.22200705900104367, 0.2152119809998112], [], [], [0.216669171999456, 0.22908054199979233, 0.21348313400085317, 0.23526508699978876, 0.2521107749998919, 0.2737978610002756, 0.22186078599952452, 0.2153625179998926, 0.20843214799970156, 0.22205099800157768, 0.21533539299889526], [], [], [], [], [0.21447489700040023, 0.23538548000033188, 0.2518751629995677, 0.2735258659995452, 0.22241214099994977, 0.21576492600070196, 0.20762669000032474, 0.22160522299964214, 0.21513015600066865, 0.23388974199951917, 0.21059014399907028, 0.21123847700073384, 0.2149739430005866, 0.22663334699973348, 0.21618111499992665, 0.20556912099891633, 0.20978372300123738, 0.20920361800017417, 0.21967771100025857, 0.2131424719991628, 0.21785080399968137, 0.20854821499960963, 0.2096252800001821, 0.22553444799996214, 0.20676014899981965, 0.2244718810015911, 0.21106726600010006, 0.2080846599983488, 0.2082202760011569, 0.21055607899870665, 0.20968914500008395, 0.2126541530014947, 0.23757969199868967, 0.20479983699988225, 0.21358638499987137, 0.23047930400025507, 0.210920478000844, 0.22844798599908245, 0.20779283299998497, 0.21039856400057033, 0.2131012820009346, 0.20843248899836908, 0.21030103000157396, 0.21223246599947743, 0.2126643840001634, 0.21899015999952098, 0.21134841499952017, 0.22026174500024354, 0.21024536900040403, 0.21016069399956905, 0.22064336900075432, 0.22282149700004084, 0.20760043900008895, 0.20799314299983962, 0.2216212009989249, 0.23275369700058945, 0.2194336899992777, 0.21264572600011888, 0.21720207300131733, 0.20629603499946825, 0.2166311790006148, 0.20336410599884402, 0.21242033400085347, 0.2335906669995893, 0.21257363999939116, 0.21825983000053384, 0.2159243330006575, 0.2294698249988869, 0.2161556360006216, 0.2116000450005231, 0.21036549999917042, 0.21201303800080495], [], [], [], [], [], [], [], [], [], [0.2131870009998238, 0.2354739789989253], [], [], [], [], [], [0.21586246299921186, 0.2075760830011859, 0.2216681209993112, 0.21512195499963127, 0.23388755499945546, 0.2103204140003072, 0.2115121300012106, 0.21497796399853542, 0.22663065100095992, 0.21618626300005417, 0.20552010999927006], [0.21598007200009306, 0.20779754199975287, 0.2217005220009014, 0.21492711499922734, 0.23401571099930152, 0.21012468000117224, 0.21164461199987272, 0.2150559660003637, 0.22661506899930828, 0.2162281159999111, 0.2048181089994614], [0.21631588600030227, 0.20712737599933462, 0.22177648400065664, 0.21520297300048696, 0.23360742399927403, 0.21052269299980253, 0.21133892999932868, 0.21486310500040418, 0.2266460000009829, 0.2161638050001784], [0.21602424699995026, 0.2075993300004484, 0.2216832499998418, 0.21525645399924542, 0.2338033779997204, 0.210019349000504, 0.2118096100002731, 0.21490520400038804, 0.22661540899935062, 0.21621035899988783, 0.20512963399960427, 0.2086968120001984, 0.21072815799925593, 0.2196782560004067, 0.21243645600043237, 0.21857194699987303, 0.20847692400093365], [0.20825036600035673, 0.22203373000047577, 0.21502664899890078, 0.23401280400139512, 0.21005968499957817, 0.21170973100015544, 0.21362361299907207, 0.22795928900086437, 0.2157844829998794, 0.20463847599967266], [], [0.20714832699923136, 0.22178404499936732, 0.21496261100037373, 0.2337982290009677, 0.2105752539991954, 0.2112515759999951, 0.21495428300113417, 0.22663780099901487, 0.2161753239997779, 0.20557318800092617], [0.2217127959993377, 0.21552344800147694, 0.23361080799986667, 0.20993409499897098, 0.21189245599998685, 0.214420386000711, 0.22699719599950186, 0.2162331939998694, 0.20481011199990462, 0.20881187400118506], [0.2157746960001532, 0.23361967799974082, 0.20997777699994913, 0.2118475290008064, 0.21486483899934683, 0.22661317799975222, 0.21621588400012115, 0.20495630799996434, 0.2087835210004414, 0.21079268100038462, 0.21968017399922246, 0.21232732600037707, 0.21870009399935952, 0.20766775099946244, 0.20942553100030636, 0.22649122500115482], [0.20868480399985856, 0.21148027600065689, 0.21505576799972914, 0.22662251899964758, 0.2161973290003516, 0.20550827700026275, 0.2088306299992837], [], [], [], [], [], [], [], [], [], [], [], [], [0.21145850900029473, 0.21503484200002276, 0.2266250949996902, 0.21619228800045676, 0.20551550200070778, 0.20888962499884656, 0.2101523150013236, 0.2196786569984397, 0.21304777600016678], [], [], [0.22796526899946912, 0.21578363300068304, 0.20438221899894415, 0.20958620500096004, 0.2109571170003619, 0.21939657099937904, 0.21219114899940905, 0.2187649280003825, 0.20787267000014253, 0.2092979839999316, 0.2264706109999679], [0.20555596799931664, 0.20898141199904785, 0.21095626000169432, 0.2193927469998016, 0.21219604599900777, 0.21876096199957829, 0.20787251700130582, 0.2092976189996989, 0.22677736100013135, 0.20664581199889653, 0.22456077500100946, 0.2106729400002223, 0.20751515699885204, 0.20903285900021729, 0.20984151100128656, 0.21016551699904085], [0.20464381800047704, 0.2089226369989774, 0.21094269300010637, 0.21969655099928787, 0.21232735500052513, 0.2185316850009258, 0.20778131800034316, 0.20935394399930374, 0.2265823769994313, 0.2067405529996904, 0.22443755499989493], [], [0.20869139400019776, 0.2107322709998698, 0.21967902100004721, 0.2123285340003349], [0.20972632099983457, 0.2090047069996217, 0.21989496700007294, 0.21311096899989934, 0.21784347699940554, 0.20852934000140522, 0.20964511599959224, 0.22560350599997037, 0.20667223099917464, 0.22465587300030165, 0.21086678699975892, 0.208244724000906, 0.20897725000031642, 0.20982660799927544, 0.209839342000123, 0.21239181800046936], [], [0.2089482709998265, 0.21094507800080464, 0.2196942559985473, 0.2123273090001021, 0.218397360000381, 0.2079121530005068, 0.20927586200014048, 0.22666332600056194, 0.20663660099853587], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [0.20973739999863028, 0.20927704600035213, 0.2196464240005298, 0.21311073300057615, 0.21782214599988947, 0.2085503639991657, 0.20963599199967575, 0.22559101300066686, 0.2066857110003184, 0.22447267200004717, 0.21106271399912657, 0.20808786300040083, 0.20822130399938032, 0.2105622979997861, 0.20967715800179576, 0.2126812209990021, 0.23758024299968383], [0.20881289900171396, 0.21091154999885475, 0.2196968520001974, 0.21232759099984833, 0.21853605300020718, 0.20777883799928532, 0.20925707800051896], [], [], [], [], [], [], [], [], [0.20990030400025717], [0.21359317200040095, 0.21798264400058542, 0.20854568200047652, 0.20961935899867967, 0.22553524900104094, 0.20676278700011608, 0.22447154899964517, 0.21078153800044674, 0.20807007899929886, 0.208505870999943, 0.21005701800095267], [0.21311165199949755, 0.21783326900003885, 0.2085488329994405, 0.20963095600018278, 0.22553312899981393], [], [], [], [], [0.21841406299972732, 0.20780022899998585, 0.2092972059999738], [], [], [], [0.20841242400092597, 0.20928515599916864, 0.22655212700010452, 0.20678396800030896, 0.22447193700099888, 0.21078161199875467, 0.2080836340010137, 0.20849237199945492, 0.20957415299926652, 0.21064267300062056, 0.2121095990005415, 0.23761188400021638, 0.20503245299914852, 0.21319243899961293, 0.23138661700068042, 0.21105479200014088, 0.22782767900025647, 0.20809459799966135, 0.21034615799908352, 0.2129850030014495, 0.20784531099889136, 0.21088797400079784, 0.21236978599881695, 0.2121877420013334, 0.21947993299909285, 0.21108687200103304, 0.2200748509985715, 0.21042656999998144, 0.20978142700005264, 0.2212526590010384, 0.22262940099972184, 0.20783873700020195, 0.20780200700028217, 0.22136484399925394, 0.23176830699958373, 0.2202162909998151, 0.21328397700017376, 0.21719174700047006], [], [], [0.20853423699918494, 0.20963619699978153, 0.2255962070012174, 0.2066784069993446, 0.22464205300093454, 0.21089019199825998, 0.20808991500052798, 0.20822425500045938], [], [], [], [], [0.2076565000006667, 0.209308768999108, 0.22657792599966342, 0.2067459139998391, 0.22453506400051992, 0.21065699000064342, 0.2074452159995417, 0.20901572000002488, 0.20983888699993258, 0.21028207600102178], [0.20998453900028835, 0.22553636100019503, 0.20677821400022367, 0.2244724279989896, 0.21078182500059484, 0.20807854300073814, 0.20849659599844017, 0.21005231300114247, 0.210223471000063, 0.21206670599895006], [], [0.20930346899876895, 0.22646832999998878, 0.2069834180001635, 0.22456012300062866, 0.21067551799933426, 0.20751268099957088, 0.20903217800150742, 0.20984335399953125, 0.2101663359990198, 0.21254563500042423, 0.2376077160006389, 0.20489270399957604], [], [], [], [0.22649511700001312, 0.20686084699991625, 0.22446874500019476, 0.2107852320004895, 0.20808835299976636, 0.2084846199995809, 0.20957868799996504, 0.2106476790013403, 0.21210212199912348, 0.2375448940001661], [], [], [], [], [0.22455873999933829, 0.21067969300020195, 0.20751163200111478, 0.2087189509984455, 0.2100909180007875, 0.21021550899968133, 0.21254801500072062, 0.2374933390001388], [0.22463711500131467, 0.21069853199878708, 0.2075110420009878, 0.20872016799876292, 0.210091511000428, 0.21021772800122562, 0.2125486689983518, 0.23749353700077336, 0.2050391220000165, 0.2131567640008143], [], [0.22445103300015035, 0.2106355390005774, 0.20823705600014364, 0.20838598999944224, 0.20970560500063584, 0.21035483599916915, 0.21230794100119965, 0.2376122609985032, 0.2049370960012311, 0.2132205999987491], [], [], [0.20940853699903528, 0.20855484999992768, 0.21024611299981188, 0.20984480700099084, 0.2123860239989881, 0.23777887300093425, 0.2045383690001472, 0.21388705699973798, 0.23073060100068687, 0.21062611599882075, 0.2284072689999448, 0.20787393499995233, 0.2101130959999864, 0.21311472300112655, 0.20841610800016497, 0.2103722789997846, 0.2121587349993206, 0.21266663400092511, 0.21912835799957975, 0.2112159509997582, 0.2203225070006738, 0.2101569770002243, 0.21018801299942425, 0.22062572499999078, 0.2224718519992166, 0.20777730400004657, 0.2078302709996933, 0.2213826280003559, 0.23178035599994473, 0.22022394800114853, 0.21326323599896568, 0.21714140699987183, 0.205661042000429, 0.2172406730005605, 0.2033434329987358, 0.21267704700039758, 0.23381311699995422, 0.21248313400064944, 0.2180981889996474, 0.21606998499919428, 0.2293417690016213, 0.21615267299966945, 0.21158952999940084, 0.2106324050000694, 0.21235989699925995, 0.21679909900012717, 0.2057392710012209, 0.20687577100034105, 0.22571167199930642, 0.21183851800014963, 0.2325755849997222, 0.2542478499999561, 0.2759311509998952, 0.2609949840007175, 0.21904894999897806, 0.21237757400012924, 0.2269202090010367, 0.21338862999982666, 0.20553383399965242, 0.20593424599974242, 0.20849112500036426, 0.22267006999936712, 0.21434318300089217, 0.21929004399862606, 0.21269581600063248, 0.20846486399932473, 0.21861247300148534, 0.21230667999952857], [0.20808270999987144, 0.20822370700079773, 0.2105417419988953, 0.2097081400006573, 0.21264365299975907, 0.237579270000424, 0.2048112709999259, 0.2135710549991927, 0.23047350800152344, 0.21064626999941538, 0.22867276800025138, 0.207851828999992, 0.21038378499906685, 0.21310041500146326, 0.20844307399966056, 0.2102919249991828, 0.2122438210008113, 0.21265692099950684, 0.21898720399985905, 0.2113457790001121, 0.2201907439994102, 0.21033657000043604, 0.2096014960006869, 0.22120071799872676, 0.22282945400002063, 0.20760162600163312, 0.20799052499933168, 0.2216144699996221, 0.23276093000094988, 0.21942870699967898, 0.21264518299904012, 0.2172095599999011, 0.20628867400046147, 0.21663138000076287, 0.2033721230000083, 0.21241310499863175, 0.2335582030009391, 0.21257756699924357, 0.2182883440000296, 0.2159089610013325, 0.22940018599911127], [], [], [], [0.20744800499960547, 0.20901654700173822, 0.20984191399838892, 0.2102734939999209, 0.21241921900036687, 0.23760887200114666, 0.20495114599907538, 0.2132066419999319, 0.23139517399977194, 0.2106378130010853, 0.22742588499932026], [0.20809440699849802, 0.20837120000032883], [], [0.20866222299991932, 0.20976670799973363, 0.21034605100066983, 0.21233186800054682, 0.23760887299977185, 0.20494614499875752, 0.2132128780012863, 0.23120731499875546], [], [], [], [], [], [], [0.20838245599952643, 0.20970763399964198, 0.21035300299990922, 0.21317562200056273, 0.23766143799912243], [0.21016980999957013, 0.20990256999903067, 0.21238465900023584, 0.23765611199996783, 0.20468052999967767, 0.2135961359999783, 0.23048982200089085, 0.2111242779992608, 0.22843400400051905, 0.2076253720006207, 0.21037182100008067, 0.2131073339987779, 0.20842423500107543, 0.21031143799882557, 0.21222018000116805, 0.21266710799864086, 0.2189980570001353], [], [], [], [], [], [], [], [0.20984894499997608, 0.21016853000037372, 0.21254687799955718, 0.23760145800042665, 0.20490445900031773, 0.21327175599981274, 0.23152943999957643, 0.211154095000893, 0.22611011200024222, 0.20871190999969258], [0.2098529190006957, 0.212382391000574, 0.23772007699881215], [], [], [0.21023566300027596, 0.21206129500023962, 0.23761521300002642, 0.2050239000000147, 0.21319861899974057, 0.23180264300026465, 0.21063788299943553, 0.22783367199917848, 0.20808471700001974, 0.2103622370013909, 0.2130991769990942, 0.20772141899942653], [0.2120955150003283, 0.2375481809995108, 0.205543079000563, 0.2126843320002081, 0.23130620299889415, 0.21064747200034617, 0.22829920000003767, 0.20776277200093318, 0.21033340800022415, 0.21340920199872926, 0.20784309299961023, 0.21089044000109425, 0.21124239299933834, 0.21305904899963934, 0.2197107510000933, 0.21109015900037775, 0.2200958730009006, 0.2104386409992003, 0.20977031999973406, 0.22070816300038132, 0.22313389100054337, 0.2078270829988469, 0.2076364710010239, 0.22152534399901924, 0.23176748400146607, 0.22026265999920724, 0.21324982800069847, 0.21716395699877467, 0.2053988110001228], [0.2125492370014399, 0.23749810799927218, 0.2050508140000602, 0.21314540700041107, 0.2315252970001893, 0.2105205619991466, 0.22675389899995935], [], [], [], [0.21492112200030533, 0.23010123600033694, 0.2106470390008326, 0.22902244299984886, 0.20787279199976183, 0.21011838000049465, 0.21311188299841888, 0.2084206510007789, 0.2103168400008144, 0.21221351499843877, 0.21266647300035402, 0.21911829300006502, 0.21122043400100665, 0.2203190549989813, 0.21016558799965424, 0.21017815500090364, 0.22063040300054126, 0.22281569899860187, 0.2076411990001361, 0.20796370200150704, 0.2216309249997721, 0.23274297599891725, 0.21943459999965853, 0.21265285500157916, 0.21718911700008903, 0.2065518669987796], [], [], [], [0.21347470199907548], [], [], [], [], [], [0.21318463100033114, 0.23126214100011566, 0.21064488499905565, 0.22829099699993094], [], [], [0.2130794490003609, 0.2310501869997097, 0.2104701770003885, 0.2287150299998757], [], [], [], [0.20963546900020447, 0.22617095799978415], [0.22845203899851185, 0.2078025080008956, 0.2103917000004003, 0.2130993729988404, 0.20843925600092916, 0.21029628399992362, 0.21223760599968955, 0.2126624009997613, 0.218986522000705, 0.2113474559992028, 0.2201975059997494], [0.2082889889989019, 0.21008691300085047, 0.21388849499999196, 0.20721276099902752, 0.2113579730012134, 0.21096162299909338, 0.21338195899988932, 0.2196656329997495, 0.21020978100023058, 0.22107015999972646, 0.2095433790000243], [], [], [], [], [], [], [], [], [], [0.20827179200023238, 0.21007177499996033, 0.21368839499882597, 0.20764602700000978, 0.21108068899957289, 0.2108435650006868, 0.21340022799995495], [], [], [0.20763511899895093, 0.21037171900024987, 0.21310258000085014, 0.20842840099976456, 0.21030617099859228, 0.21222614900034387, 0.21266585800003668, 0.2189940509997541, 0.2113494000004721, 0.2202657840007305], [], [0.2082530819989188, 0.20996763500079396], [0.21005507100016985, 0.2132724959992629, 0.20784458200068912, 0.2108890199997404, 0.2123660170000221, 0.21211661900088075], [0.2100708569996641, 0.2136979179995251, 0.20760089400027937, 0.21109576699927857, 0.2108535799998208, 0.21337541000139026, 0.21966359399993962, 0.21040066599925922, 0.22093916300036653, 0.20995085100003053, 0.20958645099926798, 0.22135933299978205], [0.20999102200039488, 0.2138479469995218, 0.20760073699966597, 0.21109646799959592, 0.21085347299958812, 0.2133772110009886, 0.2196645179992629, 0.2102131379997445, 0.221066651000001, 0.20964977700168674], [0.21033219099990674, 0.21341305399982957, 0.20784207900032925, 0.21089241099980427, 0.21124018599948613, 0.21306153800105676, 0.21971045499958564, 0.21048590800091915], [], [], [], [0.21344811000017216, 0.2075677020002331, 0.21108119999917108, 0.21084252299988293, 0.21352023700092104, 0.21970457799943688, 0.21019528199940396, 0.22093843299990112, 0.21052209400113497, 0.20969622099983098], [0.2138957240003947, 0.2072159620001912, 0.21135495799899218, 0.21096327800114523, 0.21338392699908582, 0.2196666700001515, 0.21020888000020932, 0.22107247600069968, 0.20954364099998202, 0.20992875199954142], [0.20724096699996153, 0.21135864600000787, 0.21096508399932645, 0.2133870260004187, 0.21966663599960157, 0.21014339700013807, 0.2204869500001223, 0.2100854629989044, 0.20989800200004538], [0.20835736800108862, 0.21036565999929735, 0.2121479140005249, 0.21266643599847157, 0.21913650700116705, 0.21121390699954645, 0.2203229589995317, 0.21015019700098492, 0.21019750999948883, 0.2206219300005614], [0.21089496000058716, 0.21123105699916778, 0.2130696390013327, 0.21970753299865464, 0.21018619000096805, 0.22093627699905483, 0.21052338000117743, 0.20974948999901244, 0.22068769300130953, 0.22318145299868775, 0.20782601500104647, 0.2076243550000072, 0.22150990099908086, 0.2317809930009389, 0.22006571499878191], [], [], [0.21109901599993464, 0.21085814599973673, 0.21337892699921213, 0.2196638460009126, 0.21021105399995577, 0.22106894199896487, 0.20964477300003637, 0.2098723750004865, 0.22142121400065662, 0.2233014670000557, 0.20774999499917612], [0.21108307299982698, 0.21084535100089852, 0.2133957489986642, 0.21964076299991575, 0.21040168500076106, 0.2209382099990762, 0.2105210870013252, 0.2096927450002113, 0.22076060399922426, 0.2231886419995135, 0.2078254130010464, 0.2076214169992454, 0.22138199500113842], [], [0.21226668700001028, 0.2121719459992164], [0.21248845199988864, 0.2195526899995457, 0.21110423000027367, 0.2200807139997778, 0.21043133400053193, 0.20977687400045397, 0.22070621899911202, 0.2231290319996333], [], [], [0.21896610600015265, 0.21111820500118483, 0.22032274099910865, 0.21014339300018037, 0.21020458500061068, 0.2206933260004007, 0.22271403899867437], [0.21019505399999616, 0.22049073400012276, 0.21009135900021647, 0.20989797499896667, 0.2215628600006312], [0.2207210609994945, 0.21044547999917995, 0.20976315700136183, 0.2207091929994931, 0.2231398479998461, 0.20782752800005255, 0.20763142699979653, 0.22152304200062645, 0.23176929299916083, 0.22021608500108414], [0.22094238399949973, 0.20994960200005153, 0.20958867999979702, 0.22135996299948602, 0.22328974500123877, 0.20782464600051753, 0.20761878099983733, 0.22138063899910776, 0.23192004700104007, 0.21995763299855753], [0.22107306299949414, 0.20954908400017302, 0.20992544100045052, 0.22150179599884723, 0.22330867700111412, 0.20753623800010246, 0.20785893899846997, 0.22140835900063394, 0.2319120779993682, 0.21904920800079708, 0.21422449099918595], [0.2198823260005156, 0.2103748289991927, 0.20978640999965137, 0.221265628000765, 0.2227891919992544, 0.2076620730003924, 0.2078065660007269, 0.22136310399946524, 0.2317684139998164, 0.22042078699996637], [0.20956853100142325, 0.20992321399899083, 0.22150137199969322, 0.22331654600020556, 0.20752872400043998, 0.20785457199963275, 0.2214086980002321, 0.23181632700107002], [0.2091328650003561, 0.2213220440007717, 0.22364256199944066, 0.20764154000062263, 0.2079614809990744, 0.22163952800110565, 0.23273678999976255, 0.21943501100031426, 0.21265692099950684, 0.21718346200032101, 0.2066184389987029, 0.21665724200101977, 0.20307336000041687], [0.2095934169992688, 0.2213643110007979, 0.22329542799889168, 0.20782095800132083, 0.20761707199926605, 0.2213815680006519, 0.23191860699989775, 0.21995263099961448, 0.2136182819995156, 0.21717330100000254, 0.2051987619997817], [], [0.22146252800121147], [0.22119731599923398, 0.2228402870005084, 0.20760406800036435, 0.20780104999903415, 0.22173361599925556, 0.23160809300134133, 0.22024275999865495, 0.21303396900111693, 0.21722007999960624, 0.2062697550009034, 0.21657127299840795], [], [0.20760824199896888, 0.20779724800013355, 0.2213624690011784, 0.23196793399984017, 0.22025563699935446, 0.2130313079996995, 0.21722218600007182, 0.206260282000585, 0.2165759050003544, 0.20346896699993522, 0.2123978299987357, 0.23350298200057296, 0.21258764400045038, 0.21833574099946418, 0.2158063620008761, 0.2293301519985107, 0.21636430000035034, 0.21148479499970563, 0.20984341100120218, 0.2125226339994697, 0.21653608300039195], [], [0.20779675299854716, 0.2213676220017078, 0.23172392199921887, 0.22025475699956587, 0.21325792800053023, 0.21714908300054958, 0.20565312699909555, 0.2172414970009413, 0.20334084999922197, 0.21239649100061797], [0.20775116799995885], [0.20796637600142276, 0.22162391299934825, 0.23274743799993303, 0.2194353949998913, 0.21264809499916737, 0.2171962850006821, 0.20653733399922203, 0.21639785600018513, 0.20335591600087355, 0.21242659500057925, 0.23360790500009898], [0.20770222099963576, 0.2213812619993405, 0.23191723600029945, 0.21905022300052224, 0.21432984999955806, 0.2169642009994277, 0.20549577100064198, 0.21732427200004167, 0.20315935799953877, 0.21300356900064799, 0.23416922999967937, 0.21237686799941002], [0.2213857859987911, 0.23174113100139948, 0.2202595039998414, 0.213252477999049, 0.2171567759996833, 0.20564383900091343, 0.2172420829992916, 0.2033382210011041, 0.21239953300027992, 0.23387823599841795, 0.21257316100127355, 0.21794560499984073, 0.21623880699917208], [0.2216096270003618, 0.23277163300008397, 0.2190316559990606, 0.21303876700039837, 0.21721532400079013, 0.20627955199961434, 0.21662930999991659, 0.20338279600036913, 0.2124052210001537, 0.23355735399854893, 0.21258094800032268, 0.21828698399986024, 0.2159095780007192, 0.2293991829992592, 0.21624204300132988, 0.21160922799936088, 0.21031886099990516, 0.21203233000051114, 0.2165208749993326, 0.20661978499992983, 0.20693016000041098, 0.22571444300047006, 0.2118280569993658, 0.23230001000047196], [0.21896769999875687, 0.2130627149999782, 0.21713537899995572], [0.21362625599977036, 0.21679876899906958, 0.20549381999990146, 0.21732888699989417, 0.2031551620002574, 0.21300198300014017, 0.2341730930002086, 0.21248080800069147, 0.21749138599989237, 0.21667505799996434, 0.22934815799999342, 0.216152910999881, 0.21159448999969754, 0.21062388999962423, 0.2123614890006138, 0.21680093100076192, 0.2044827659992734, 0.2073602429991297, 0.22500570500051253, 0.21214354100084165, 0.2337474559990369, 0.2542417069998919, 0.27593890500065754, 0.2604157349996967, 0.2195670279998012], [0.207510366999486], [0.20530276399949798, 0.2172809910007345, 0.20336879900060012, 0.21301274799952807, 0.2338671979996434, 0.2125867089998792, 0.21754175100068096, 0.21660084900031507, 0.22932854999999108, 0.21636455999941973, 0.21148654299940972], [0.20519213800071157, 0.2175068079995981, 0.20296562200019252, 0.21295961900068505, 0.23369724999975006, 0.21229337200020382, 0.21816853299969807, 0.21623455000008107, 0.22934896699916862, 0.2160230360004789, 0.21047314799943706, 0.21108564600035606, 0.21247117200073262, 0.21666872599962517, 0.2057231220005633, 0.20735774300010235, 0.22518474099888408, 0.2120511980010633, 0.23320929599867668, 0.25432545600051526, 0.27606522899986885, 0.2598459750006441, 0.2199828239990893, 0.21256582500063814, 0.22687828599919158, 0.21304382200105465, 0.205682321000495], [0.21724434200041287, 0.203278348000822], [0.21659173700027168, 0.2033192010003404, 0.2125484089992824, 0.2339410790009424, 0.21248339299927466, 0.21800083900052414, 0.2161678890006442, 0.22933949799880793, 0.21615145900068455, 0.21158414799901948, 0.21064032899994345, 0.21235885200076154, 0.2168006179999793, 0.20562394599983236, 0.20676642199941853, 0.22578147600142984, 0.21192633099963132, 0.23303438800030563, 0.25361830799920426, 0.2760649120009475, 0.25982954499886546, 0.22009477900064667, 0.2125235490002524, 0.2268171750001784, 0.21322879299987108, 0.2058723549998831, 0.2061486149996199, 0.20833139400019718, 0.222629166999468, 0.21433316200091213, 0.21912842199890292, 0.21274629300023662, 0.2079893730006006, 0.21854515300037747, 0.2113642879994586, 0.2088981180004339, 0.21214116599912813, 0.21234965400071815, 0.21668220100036706, 0.22210388899839018, 0.24599856500026362, 0.3559146260013222, 0.09668044799946074, 0.21435920300064026, 0.23440078499879746, 0.20367374000124983, 0.21157923199825746, 0.2303139250016102, 0.2163556929990591, 0.23020429300049727, 0.22090006699909281, 0.20600120200106176, 0.2064981949988578, 0.21751023000069836, 0.20617787199989834, 0.2097908350006037], [0.2172240559993952], [], [], [], [0.21740738699918438], [0.20296810600120807, 0.21296271399842226, 0.23387652300152695, 0.21257586399951833, 0.21770212099909259, 0.21649651000006997, 0.2294655639998382, 0.21615993800151045, 0.2116046319988527, 0.21032510199984245, 0.21203068500108202, 0.2165226809993328, 0.205426978000105, 0.2073579690004408, 0.22500647000015306, 0.21214345599946682], [0.20339992899971548, 0.21248825399925408, 0.23379513600048085, 0.21258216599926527, 0.21795090900013747], [0.20307750299980398, 0.2123758039997483, 0.23371172100087279], [], [], [], [0.20331779799926153, 0.21300590800092323, 0.23394462099895463, 0.21257514900025853, 0.21753450899996096], [], [], [], [], [], [], [], [], [], [], [], [], [], [0.21236556499934522, 0.2335836570000538, 0.2125846230010211, 0.21826180599964573, 0.21594792699943355, 0.2293981820002955, 0.21624446700116096, 0.21161235499857867, 0.2103121239997563, 0.21203504200093448, 0.21651969300000928, 0.20659589800015965, 0.20677067900032853, 0.22579015799965418, 0.21191475100022217, 0.23232339499918453, 0.25458740000067337, 0.2759294179995777, 0.26100629100074, 0.21904083899971738, 0.21237364700027683, 0.22709297399887873, 0.21321923100003914, 0.20554626800003462, 0.20615157700012787, 0.20833039100034512, 0.2226903470000252, 0.21426447600060783, 0.2191956359984033, 0.21267986300154007], [], [0.21066270300070755, 0.21756510099839943, 0.21658426900103223, 0.22933293700043578, 0.21613902799981588, 0.21139695399870106, 0.21007545300017227, 0.21245248300147068, 0.21666770599949814, 0.20537798899931659, 0.20748809200085816, 0.2250168520004081, 0.21202223199907166], [], [], [0.21622434100027021, 0.2293038459993113], [], [], [], [], [], [], [], [0.2166072340005485, 0.2293958879999991, 0.21624851299930015, 0.21155608499975642], [0.21450547899985395, 0.21120752599927073, 0.2100716149998334, 0.21244977400056086], [], [0.20993089900002815, 0.21245513100075186, 0.21666794999873673, 0.2058039710009325], [0.20984348399906594, 0.21251894899978652, 0.2165412579997792, 0.20565315900057612, 0.20735755500027153, 0.22617703399919264, 0.21106880099978298, 0.23322366700085695, 0.25432713400005014, 0.2760677160003979, 0.2598355249992892, 0.21998886700021103], [0.21203555499960203, 0.21652408199952333, 0.20526112799961993, 0.20748884400018142, 0.22500890500123205, 0.21211975799997163, 0.2335220360000676, 0.25433095499829506, 0.2760669980016246, 0.2598303649992886, 0.22009514399906038, 0.21252395200099272, 0.22681608499988215, 0.21307820699985314, 0.20464993799942022, 0.20654215900140116, 0.2088491119993705, 0.22283602300012717, 0.21404355300001043, 0.21940577699933783, 0.21214480900016497, 0.2078750350010523, 0.21915009499934968, 0.21109641099974397], [], [], [], [0.21198417599953245, 0.21717964000163192, 0.20504816999891773, 0.20717595700079983, 0.22603838000031828, 0.21138794399848848, 0.2330870900004811, 0.2542149410001002, 0.276062221999382, 0.25994477899985213, 0.22002921300008893, 0.21244354300142732, 0.22681714099962846, 0.213520568999229, 0.20553573700090055, 0.205808098999114, 0.20861447800052701, 0.22267353700044623, 0.21434969999972964, 0.21912710399919888, 0.21275114200034295, 0.20747283799937577, 0.21902145000058226, 0.21138333300041268, 0.20848706499964464, 0.21245601000009628, 0.21244823999950313, 0.21656973600147467, 0.2218097429995396, 0.24641933599923505, 0.3558731129996886], [0.2123660769993876, 0.21680336600002192, 0.20463643800030695, 0.20730948799973703, 0.2261980430012045, 0.21132350100015174], [0.21201626199945167, 0.21729229499942448, 0.20460622999962652, 0.2073608470000181, 0.2250057260007452, 0.2121432839994668, 0.23362290200020652, 0.25419972599956964, 0.2760635850008839, 0.2598304620005365, 0.22009346499908133], [0.2168130750014825, 0.20448070899874438, 0.20736274299997604, 0.22500593600125285, 0.2121356999996351, 0.23367595600029745, 0.25421409999944444, 0.2760627330007992, 0.26040039399958914, 0.21957852999912575, 0.21243999600119423, 0.22681560199998785, 0.21351502099969366, 0.204623145998994, 0.20638481199966918, 0.20866433400078677, 0.22282576699944912, 0.21418236600038654, 0.21931309899991902, 0.2120838430000731, 0.20799557700047444, 0.21902688699992723, 0.2115232249998371, 0.20844481899985112, 0.2121133180007746, 0.2127327439993678, 0.21669821300019976, 0.22190411100018537, 0.24641690499993274, 0.3559127600001375, 0.09602520299995376, 0.21497796199946606, 0.23438460100078373], [], [], [], [], [], [0.20458779399996274, 0.2073688830005267, 0.2250074309995398, 0.21212419600124122, 0.2336604059983074, 0.2542301730009058, 0.2760638250001648, 0.2598312829995848], [], [], [], [], [], [0.2070775890006189], [], [], [], [], [], [], [], [], [0.2073111030003929, 0.2262054660004651, 0.21106093199887255], [], [], [], [], [], [], [], [0.2065709300004528, 0.22597551100079727, 0.21139749599933566, 0.23317393800061836, 0.25413826600015454], [0.2068859649989463, 0.22571172500101966, 0.21183253299932403, 0.2324792740000703], [0.22580250800092472, 0.21190000000024156, 0.2322965409985045, 0.2543309730008332, 0.27606465499957267, 0.259833592999712, 0.22008836700115353, 0.21264280699870142, 0.22681429100157402], [0.22564798799976415], [0.21138568300011684, 0.23313540699928126, 0.25420106100136763, 0.2760666089998267, 0.2598285259991826, 0.2200953000010486, 0.2125243229984335, 0.22681753000142635, 0.2130702869999368, 0.20591016999969725, 0.20586989000003086, 0.20849800999894796, 0.2228047090011387, 0.21436003300004813, 0.21911630199974752, 0.21208301600017876, 0.2080585740004608, 0.2190586139986408, 0.21140063300117617, 0.20844592499997816, 0.21246235800026625, 0.21247264499834273, 0.21657717200105253, 0.2216858379997575, 0.24654455100062478, 0.3558440589986276, 0.09581901999990805, 0.21516093400168756, 0.23442636399886396], [0.21105590200022561, 0.23323838399846863, 0.25433125700146775, 0.2760651959997631, 0.2598309799996059, 0.22009527099908155, 0.21252101300160575, 0.22681554999871878, 0.21308828499968513, 0.2057062540006882], [], [0.22752797800058033, 0.21323098900029436, 0.20549266200032434, 0.20581015800053137, 0.20860740299940517, 0.2226803369994741, 0.2143552699999418, 0.21912212200004433, 0.2122023709998757, 0.2079828969999653, 0.21903957600079593, 0.2113904879988695, 0.20844630700048583, 0.21245655399980024], [0.22681597000155307, 0.213010025998301, 0.20578895100152295, 0.20601811499909672, 0.20854361599958793, 0.2228122060005262, 0.21433723100017232], [0.20659275899924978, 0.20594435800012434, 0.20880871300141735, 0.22232335299850092, 0.21415424299993902], [0.20612057399921468, 0.2061449779994291, 0.20832798700030253, 0.22269546200004697, 0.214253316000395, 0.21920544900058303, 0.21271186000012676, 0.20845877200008545, 0.2185991379992629, 0.2108209670004726, 0.20949681299862277, 0.21207851000144728, 0.21181960200010508, 0.2166803969994362, 0.22124934800012852, 0.2465090780005994, 0.3554800570000225, 0.09617426799923123, 0.21523725299994112, 0.23449936699944374, 0.20305455700145103, 0.21169741899939254, 0.2308719699994981, 0.21597574900079053, 0.230242415000248, 0.22093697999844153, 0.20658447000096203, 0.20646231200043985, 0.21762244799901964, 0.20640344000094046, 0.20995975099867792], [0.20455401899926073, 0.20650856400061457, 0.20884680099879915, 0.22283927000171388, 0.21422479399916483, 0.21929173299940885, 0.2120869730006234, 0.2078877959993406, 0.21914923199983605, 0.21145174200137262], [0.20551210099984019, 0.20581396900161053, 0.2084979100000055], [], [0.20606099600081507, 0.2085977369988541, 0.22282722900126828, 0.21417349399962404, 0.2193189280005754, 0.21208247899994603, 0.20799916599935386, 0.21902578200024436], [0.2063959690003685, 0.20866825000121025, 0.22281142799874942, 0.21420233500066388, 0.21930762999909348, 0.2120846320012788, 0.2079908739997336, 0.21903011699942, 0.2115178530002595, 0.20844681299968215, 0.21201083100095275], [], [], [0.20587222299946006, 0.20879179800067504, 0.2223218889994314, 0.21418236600038654, 0.2191997000008996, 0.21268897699883382, 0.20846748300027684, 0.21861601499949757], [], [], [0.2058321859985881, 0.20852295200165827, 0.22281252599896106, 0.21436653599994315, 0.21910700000080396, 0.21208356900024228, 0.20799931099827518, 0.21913296600178, 0.21140211799865938, 0.20844525100073952, 0.21243332199992437], [], [], [], [], [], [], [], [], [0.20833632399990165, 0.22263191499951063, 0.21433786499983398, 0.21912340600101743, 0.21274997900036396, 0.20798251899941533, 0.21854793400052586, 0.21136488799857034, 0.20866106799985573, 0.2123337460016046], [0.20868828300081077, 0.22281328799908806, 0.21421169600034773, 0.21930061500097509, 0.21208478699918487, 0.2078886839990446], [0.20849769199958246, 0.2228065859999333, 0.2143635770007677, 0.21911059699959878, 0.21208280000064406, 0.20799774399893067], [0.2085453570016398, 0.22281312799896114, 0.21416754100027902, 0.21932298799947603, 0.21208241299973452, 0.20800066900119418, 0.21912694899947383, 0.21140667799954826, 0.20844523300002038, 0.21211773800132505, 0.2127276189985423], [0.22232764300133567, 0.21416159299951687, 0.21921844099961163, 0.21270280300086597, 0.20846229599919752, 0.2186090230006812, 0.2110860609991505, 0.20938804900106334, 0.21191547199850902, 0.21225991000028444, 0.2167031680000946], [], [0.22264240100048482, 0.21423269899969455, 0.21921195600043575, 0.21270863300014753, 0.20845933800046623, 0.2186049149986502, 0.2108170350002183, 0.2094978519999131, 0.21207959900129936, 0.21223400799863157, 0.216265288001523, 0.22125296499871183, 0.24650819500129728, 0.35576993899849185, 0.09588726900074107, 0.21523479700044845, 0.2344919299994217, 0.20319273899986, 0.21161257099993236], [], [0.2192795919982018, 0.21209177400123735, 0.20788617200014414, 0.2191495360002591, 0.21119026799897256, 0.2087118029994599, 0.21190473600108817, 0.2129642119998607, 0.21671708199937711, 0.22164921200055687, 0.24650944200038793], [0.20942118300081347, 0.2188199979991623, 0.21093790200029616, 0.20890692799912358, 0.21213054200052284, 0.2123519140004646, 0.21668395699998655, 0.22121903299921541, 0.24650537600064126, 0.3554755320001277, 0.09617812900069111, 0.2152325099996233, 0.23453613499987114, 0.20270577699920977, 0.21199069900103495, 0.23029419100021187], [0.20788098800039734, 0.2190214099991863, 0.2113848289991438, 0.20844606600076077, 0.2124852609995287, 0.21244301800106768, 0.21657239900014247, 0.2215321989988297, 0.24661112600006163, 0.35565227500046603, 0.09588543199970445, 0.21523426000021573, 0.23448693899990758, 0.20319938200009346, 0.21172278999983973, 0.2307165799993527, 0.2161465200006205, 0.23007585699997435, 0.22091971100053343, 0.2061849700003222, 0.20626792799885152, 0.21747967600094853, 0.20662608099883073], [], [], [], [], [0.2079835490003461, 0.21903525999914564, 0.21140105400081666, 0.20844509800008382, 0.21246028799941996, 0.2124797150008817, 0.2165737089999311, 0.22171379199971852], [0.2185914359997696, 0.21082975700119277, 0.20891203099927225, 0.212120968999443, 0.21235707300002105, 0.21668396099994425, 0.22124273299959896, 0.2465066590011702, 0.3554769469992607, 0.09617734899984498, 0.21523650100061786, 0.23450956300075632, 0.2027312369991705, 0.21198969299985038, 0.23085710399936943, 0.2158673500016448, 0.23030662699966342, 0.221010983999804, 0.2066029540001182, 0.20645740399959323, 0.21751272700021218, 0.20616815799985488, 0.20985699899938481, 0.21121465299984266, 0.20816897400072776, 0.20780893499977537, 0.23147782500018366, 0.21307259000059275, 0.2053081590001966, 0.21864452699992398, 0.20731360199897608, 0.2090601460004109, 0.21047166899916192], [0.2185554029983905, 0.21136641900011455, 0.20848614100032137, 0.21245074800026487], [0.2087505930012412, 0.2117749939989153, 0.21305168100116134], [0.20928622499923222], [], [], [0.2085306139997556, 0.2118684349989053, 0.21296214500034694, 0.21671802200035017, 0.22164161000000604, 0.2466164960005699, 0.3556461810003384, 0.09588568999970448], [0.21233794900035718, 0.21239160699951753, 0.21657054100069217], [], [], [0.2121558159997221, 0.21234742999877199, 0.21667662500112783, 0.22170726699914667], [], [], [], [0.2116341269993427], [], [0.21246386300117592, 0.2124445069985086, 0.21656993600117858, 0.22167133299990383, 0.24654435699994792, 0.3558439919997909, 0.09582039399901987, 0.21515843800079892, 0.2345069750008406, 0.2034781739985192], [], [], [0.21286170999883325, 0.21669860600013635, 0.2217397920012445, 0.24654421599916532, 0.3558448280000448, 0.09581839800011949, 0.21515994099900126, 0.2345071520012425, 0.20347527699959755, 0.21143031300016446], [], [], [], [], [], [0.21614991899878078, 0.2208782430006977, 0.24642405700069503, 0.35584214699883887, 0.09582240300005651, 0.2151596840012644], [], [], [], [], [0.22093699499964714, 0.2465479470010905, 0.3556429339987517, 0.09598964500037255, 0.2151163850012381, 0.23448203099906095, 0.2032053580005595], [], [], [], [], [], [0.09572684100021434, 0.21510519399998884, 0.23447823999958928, 0.20332933999998204, 0.21158970200121985, 0.23071305799930997, 0.2161402290003025, 0.2300822760007577, 0.22091332099989813, 0.206559053998717, 0.20646792300067318, 0.21762268699967535, 0.20639947900053812, 0.21000753400039684, 0.21072892799929832, 0.2081630810007482, 0.20780892299990228, 0.23147263600003498, 0.21343546999924, 0.2049367119998351, 0.21865252899988263, 0.2073011940010474, 0.20907391499895311, 0.21058105700103624, 0.22097823500007507, 0.21122590899904026, 0.21033765699939977], [], [0.21481655199931993, 0.2344308040010219, 0.20333988099991984, 0.2115867230004369, 0.23071102799985965, 0.21613366400015366, 0.2300880809998489, 0.22090742000000319, 0.20655946700026107, 0.20647395999912987, 0.21762107200083847, 0.20639582900003006, 0.21001104999959352, 0.2107316389992775, 0.20816257400110771, 0.20780818899947917, 0.23246999199909624, 0.212685592001435, 0.2046830939998472, 0.2186559869987832], [0.2149223489996075, 0.2344055590001517, 0.2034938359993248, 0.2114091189996543], [], [], [], [], [], [], [], [], [], [], [0.20309764900048322, 0.21170227599941427, 0.23087034600030165, 0.21586479999859876], [], [], [], [], [], [0.21134698900095827, 0.230461445000401, 0.21619109199855302], [0.21161421000033442, 0.23084868200021447, 0.215980867998951, 0.23023871400073403, 0.2209281129998999, 0.2059353419990657, 0.20639023300100234, 0.21747640399917145, 0.20643207899956906, 0.2099420540016581, 0.2096503529992333], [], [], [], [0.21143156599828217, 0.2306608300004882, 0.21612679800091428, 0.23009459499917284, 0.22100800900079776, 0.20557000000007974, 0.2064775329999975, 0.2173929099990346, 0.20619390600040788, 0.21007414999985485], [], [], [0.2303166389992839, 0.21615985499920498, 0.23033455200129538, 0.22067743899970083, 0.20555824499933806, 0.2064765119994263, 0.21739077100028226], [0.23121326799991948, 0.2206855060012458, 0.2059040409985755, 0.20630498500031536, 0.21744652300003509, 0.20658524000100442, 0.20985564999864437, 0.20980565900026704, 0.209427517000222, 0.20780842600106553, 0.23165189599967562, 0.2128369579986611], [0.23019973000009486, 0.2206610900011583, 0.2058515600001556, 0.20631086899993534, 0.2174453449988505, 0.2065871659997356], [0.2300575539993588, 0.22099322400026722, 0.20643755399942165, 0.20648015400001896], [0.23001952999948116, 0.22095243200055847, 0.20594323799923586, 0.20639180100079102, 0.2174757819993829, 0.2064335150007537, 0.20994167499884497, 0.20964730000014242, 0.20964858600018488, 0.20699278699976276, 0.2322885640005552], [0.2070120530006534, 0.20638601199971163], [], [0.20555225699899893, 0.20646641700113832, 0.2174976609985606, 0.20630478000020958, 0.20996154400017986, 0.20976061100009247, 0.20902560200011067, 0.20746503900045354, 0.23242564999964088, 0.2130679460005922, 0.20556757600024866], [], [], [], [], [], [], [], [0.20648847600023146, 0.21750559199972486, 0.20619520000036573, 0.2097867539996514, 0.21128108799894108, 0.20805424700120057, 0.20772643899908871, 0.2315603370007011], [], [], [0.2063009339999553, 0.21744716000102926, 0.2065853709991643, 0.20985683300023084, 0.20980126799986465, 0.20943051199901674, 0.20730617500157678, 0.23214838700005203, 0.21284247399853484, 0.20565583700044954, 0.21860467199985578, 0.20733436000045913, 0.20841406900035508, 0.2106713529992703, 0.22103910999976506, 0.2115075399997295, 0.21023962200160895, 0.20940687999973306, 0.2111993620001158, 0.21644173899949237, 0.2114168719999725, 0.21561286299947824, 0.2075701490011852, 0.21740723499897285, 0.20777117900070152, 0.21831036799994763, 0.22995891499886056, 0.209257697000794, 0.21136358600051608, 0.2042133079994528, 0.22183837800002948, 0.21787833099915588, 0.2137541650008643, 0.2163685350005835, 0.22836015499888163, 0.20395705400005681, 0.22174923800048418, 0.22500544600006833, 0.20282862900057808, 0.20745914899998752, 0.20542999699864595, 0.21235488000093028, 0.21650034099911863, 0.20715920499969798, 0.2111710180015507, 0.2067722479987424, 0.204105957000138, 0.2176988840001286], [0.2062627759987663, 0.21741822800140653], [0.20639451099850703, 0.21747723299995414, 0.2064343750007538, 0.20993791699947906, 0.20965028700084076, 0.20964793399980408, 0.2069939239991072, 0.23229016100049193, 0.2130506730009074, 0.20565080599953944, 0.21855375599989202], [0.20648154800073826, 0.21741099300015776, 0.20620048999990104, 0.2100753499998973, 0.20988997699896572, 0.20902938600011112, 0.20745160300066345, 0.23243368399926112, 0.2129328880000685, 0.20553263900001184, 0.21861901600095734], [0.21731012700001884, 0.20636463999835541, 0.21041231200069888, 0.21088816100018448, 0.20773711999936495, 0.20771491900086403, 0.23278323200065643, 0.21236486799898557, 0.20521271100005833, 0.21885807699982252, 0.2065468159999], [0.21714021899970248, 0.20666110300044238, 0.2097850930003915, 0.21073549099855882, 0.20859859400115965, 0.2077252019989828, 0.231563413000913, 0.21319588999904227, 0.20531179400131805, 0.21862446099839872, 0.20723580900084926, 0.20843904899993504, 0.2109360310005286, 0.22081961999901978, 0.21165693799957808, 0.21041383400006453, 0.20914696700128843, 0.21098336599970935, 0.21644443399964075, 0.21149281500038342, 0.21565245800047705, 0.20753193800010195, 0.21741173699956562, 0.20779604199924506, 0.21843178200106195, 0.22993220799980918, 0.20942133999960788, 0.21150370800023666, 0.2042480620002607, 0.22159138699862524, 0.2175041020000208], [0.20676687900049728, 0.20996155899956648, 0.2097639280000294, 0.2090283620000264, 0.20746040100129903, 0.23242829899936623, 0.21293157400032214], [0.20640776899927005, 0.20953196400114393, 0.21121535699967353, 0.20816694899986032, 0.20780777700019826, 0.23147558200071217, 0.21306794900010573, 0.2053075269996043, 0.2186489169998822, 0.20730738299971563, 0.20906776099946, 0.21054307499980496, 0.22062818900121783, 0.2115929989995493, 0.21034411499931593, 0.20955124200008868, 0.21019477200024994, 0.21660800599966024, 0.211691698001232, 0.21567010499893513, 0.207583376999537, 0.2173663210014638, 0.2080951850002748, 0.2182194229990273, 0.2298383899997134, 0.20995444700020016, 0.21114234299966483, 0.20412653000130376, 0.22151530500013905, 0.2172396209989529, 0.21356799299974227, 0.21653222799977812, 0.2285738880000281, 0.20462841800144815, 0.22142854999947303, 0.22539259599943762, 0.2027699490008672, 0.20779543800017564, 0.20506943699911062, 0.21178301100007957, 0.2167813460000616, 0.20745499999975436, 0.2114301389992761, 0.20636535700032255, 0.20436845400035963, 0.21746033999988867, 0.23414185299952806, 0.22225619800155982, 0.20748393499889062, 0.2088127130009525, 0.22332064399961382, 0.20462713699998858, 0.2294714590007061, 0.2260771309993288, 0.20661033199939993, 0.21491373000026215], [], [0.2098869029996422, 0.2097403329989902], [0.21008052400065935, 0.20988758400017105, 0.20902909100004763, 0.2072552009994979, 0.23260887099968386, 0.21295631900102308, 0.20474841199938965, 0.21940441200058558, 0.20716377999997349, 0.20864542100025574], [0.2098599330001889, 0.20979556599922944, 0.20943633100068837, 0.20699086400054512, 0.23239843000010296], [], [], [], [0.20987606999915442], [], [], [], [], [], [0.210886365000988, 0.20773834499959776, 0.20771585799957393, 0.23246563100110507, 0.21268674399834708, 0.20510554400061665, 0.2189581630009343, 0.20655765299852646, 0.20909184100128186, 0.21058670200000051, 0.2218373799987603, 0.2113210590014205, 0.2098951259995374, 0.20914482899934228, 0.21095897200029867, 0.21626765600012732, 0.21138642199912283, 0.21555167400038044, 0.20816148999983852, 0.2170223140001326, 0.2083493610007281, 0.21818434200031334, 0.22934833299950697, 0.20987442600016948, 0.21162385599927802, 0.20428850099960982, 0.2210221060013282, 0.21744142599891347, 0.21401296300064132, 0.21616308500051673, 0.22831646299891872, 0.20469070800027112, 0.22128968400102167, 0.22533750399998098, 0.20348911600012798, 0.20765312399998948], [], [], [], [], [], [], [0.21058208099930198, 0.20870088199990278, 0.20766477300094266, 0.23163312099859468, 0.2129030830001284, 0.2055660149999312, 0.2186139599998569, 0.20731421600066824, 0.20842790300048364, 0.21092212899930018, 0.22083488399948692, 0.21163891200012586, 0.21007489300063753], [0.20874806299980264, 0.20766007999918656, 0.23163994200149318, 0.21289715499915474, 0.2055756650006515, 0.21860968900000444, 0.20732263199897716, 0.20842155300124432, 0.2106707519997144, 0.2210381109998707, 0.2115140309997514, 0.21023461799995857, 0.2094078129994159, 0.2115897160001623, 0.21613527199951932, 0.2113365020013589, 0.21562305799852766, 0.2075603500015859, 0.21740700800000923, 0.20778273999894736, 0.21831146400108992, 0.22995643799913523, 0.20925817399984226, 0.21136497699990286, 0.2042744690006657, 0.22178383199934615, 0.2178551030010567, 0.21376630699887755, 0.21636879700054124, 0.2283510479992401, 0.20397090799997386, 0.2217480830004206, 0.22500437400049123, 0.2028280390004511, 0.20745740399979695, 0.20543035300033807, 0.2123552009998093, 0.2164875229991594, 0.2071710569998686, 0.2111762810000073, 0.20677014700049767, 0.20410312099920702, 0.21782261100088363, 0.23458896599913714, 0.22236454999983835, 0.20781334300045273, 0.2086793319995195, 0.2234611000003497, 0.20429873000102816, 0.22925660599867115, 0.2264705680008774, 0.20634713300023577, 0.21595963799882156, 0.2172697200003313, 0.2073559809996368, 0.2091482680007175, 0.20967607599959592, 0.2134997180000937, 0.22796589100107667, 0.24950988499949744, 0.22986993999984406, 0.21034304299973883, 0.21319550900079776, 0.21887558500020532, 0.23031120799896598, 0.2240494249999756, 0.22300408500086633, 0.21615861799909908, 0.21262429800117388, 0.2106730460000108, 0.23173128999951587, 0.25415946999964945, 0.23801518800064514, 0.2083863099996961, 0.21328951800023788, 0.2193230949997087, 0.21645623499898647, 0.22968150599990622, 0.20707051800127374, 0.22817412899894407, 0.2485391050013277, 0.22270610999839846, 0.20903317700140178, 0.22951522299990756, 0.20964275900041685, 0.2025668099995528, 0.22108761399977084], [0.20860154699948907, 0.2077225869998074, 0.23156697200101917, 0.21319916299944452, 0.20531305400072597, 0.21856875099911122], [0.20785301999967487, 0.20772137899984955, 0.2324724909994984, 0.21268376800071565, 0.20467628400001558, 0.2187167939991923, 0.2072242409994942, 0.20908079000037105, 0.21058350000021164, 0.2218370570008119, 0.21036399100012204, 0.210806215998673, 0.20917864500006544, 0.21037649900063116, 0.21644635099983134, 0.211719417000495, 0.21555715999966196, 0.20823156100050255, 0.21697315699930186, 0.20780246499998611, 0.21867519300030835, 0.22943377800038434, 0.20990114799860748, 0.2111482710006385, 0.20465861299999233, 0.22107211200091115, 0.21734368099896528, 0.21383124699968903, 0.21629705099985586], [], [0.2070003379994887, 0.23229527800140204, 0.21302746599940292, 0.20556982199923368, 0.2186502170006861, 0.2072760900009598, 0.20849635599915928, 0.2107098960004805, 0.2210359269993205, 0.21121891499933554, 0.21042243700139807], [0.2076567009989958, 0.2315804260015284, 0.21311881899964646, 0.20531056099935086, 0.21863375800057838, 0.2073278810003103, 0.2090474569995422, 0.21036051900046004], [0.2315730549998989, 0.21289173500008474, 0.20555864699963422, 0.21861713399994187, 0.2073075179996522, 0.20843464999961725, 0.21092391000092903, 0.22083290599948668, 0.21164216400029545, 0.21013578900056018], [0.23147920700102986, 0.21308068599864782, 0.20530982600030256, 0.21863937899979646, 0.20732019299975946, 0.20905426300123509, 0.21046568699966883, 0.220613831999799], [], [], [], [], [], [], [], [], [], [0.21263763400020252], [0.20531818400013435, 0.21856711899999937, 0.20730784999977914, 0.2084338149998075, 0.21093489800114185, 0.22082190199944307, 0.21165458500036038, 0.2101784869992116, 0.2093281500001467, 0.21067630799916515, 0.21660284900099214, 0.21169425200059777, 0.2156398379993334, 0.20754383399980725, 0.21741209799984063, 0.20778406499994162, 0.21832026000083715, 0.23005909099993005, 0.2091920349994325], [], [], [], [], [], [0.2189442440012499, 0.20657823599867697, 0.20908615799999097, 0.21058579400050803, 0.22183744399990246, 0.2108283150009811, 0.21033491999878606, 0.20918352700027754, 0.21039264099999855, 0.21644398600074055, 0.2117006560001755, 0.21556131499892217, 0.20823068800018518, 0.21697630599919648, 0.20779525200123317, 0.21869289799906255, 0.22942147300091165, 0.2098948869988817, 0.21114937600032135, 0.2046684130000358, 0.22106836800048768, 0.21739350999996532], [], [0.2185931919993891], [0.21003723700050614, 0.21038338299877068, 0.22073329600061697, 0.2116571130009106, 0.21041772799981118, 0.2091980289987987, 0.21140934800132527, 0.21607875099834928, 0.21135772400157293, 0.21565805199861643, 0.2075260440014972, 0.21741199999996752, 0.2078009259985265, 0.21843902399996296], [0.2090417029994569, 0.21036218399967765, 0.22073334500055353, 0.21165700299934542], [0.208405864001179, 0.21067467899956682, 0.2210376980001456, 0.21140048099914566], [0.20847966099972837, 0.21071487900007924, 0.22103970300122455, 0.21121580399994855, 0.21042314799888118, 0.20944412400058354], [0.21053700299853517, 0.22073614100008854, 0.21165706900137593, 0.21041655799854198, 0.20914504100073827], [0.22084467700005916, 0.21148207700025523, 0.21023288200012757, 0.2094092269999237], [0.22097524200034968, 0.2112313859997812, 0.21033916300075362, 0.20955501499884122, 0.21019997400071588, 0.21661053499883565, 0.2116750889999821], [], [], [], [], [], [0.22104535400103487, 0.21121087099891156, 0.2104242900004465, 0.2094548040004156, 0.2112969379995775, 0.21644817199921818, 0.21140065800136654, 0.21544050099873857, 0.2070556190010393, 0.2179541280002013, 0.20779634999962582], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [0.20980289799990715, 0.21036609600014344, 0.2094032499990135, 0.21089663800012204, 0.2166123980005068, 0.21156092199998966, 0.21560721599962562, 0.20722589600154606, 0.21760181299941905, 0.20791903700046532, 0.21830781300013768, 0.22996320499987633, 0.2092563659989537, 0.21136434000072768, 0.204207573999156, 0.22183927900005074, 0.21756996700059972], [0.20990934899964486, 0.20913891800046258, 0.210957530000087, 0.21613905300000624], [], [0.20917318600004364, 0.21036211399950844, 0.21645083899966266, 0.21173847899990506, 0.2155517659994075, 0.20767545700073242], [], [], [], [], [], [], [], [0.20915256000080262, 0.210717833999297, 0.2166143220001686, 0.21159653199902095, 0.21564611500070896, 0.2075374849991931, 0.21741287000077136, 0.20779003200004809, 0.2183221590003086], [], [], [0.2161352330003865, 0.21134303599865234, 0.2156176990010863, 0.2075651619998098, 0.21740803899956518, 0.20777679300044838, 0.21831111699975736, 0.22995770899979107, 0.20925748400077282, 0.2113640759998816, 0.20421577799970692], [0.21645283999896492, 0.21166396900116524, 0.21559920799882093, 0.20757845000116504], [0.21613654300017515, 0.2112442790003115, 0.2156640339999285, 0.20752007299961406, 0.2174123460008559, 0.20780671799911943, 0.21850337500109163, 0.22984684299990477, 0.20942580999872007, 0.21149962800154753, 0.2042473229994357], [0.21586997499980498, 0.20717031999993196, 0.21768843999961973, 0.2079069100000197, 0.21829793300094025, 0.22998335199918074, 0.20925362700108963, 0.21136646099876089, 0.20410460800121655], [], [], [], [], [], [], [], [], [], [0.21560268900066148, 0.20716550199904304], [0.21554843000012625, 0.20768070400117722, 0.2172533899993141, 0.20808607199978724, 0.21822934500050906, 0.22983831199962879, 0.2099434140000085, 0.21114632900025754, 0.20462971099914284, 0.221020386001328], [], [], [], [], [], [0.20887180799945781, 0.21669983500032686, 0.20808611800021026, 0.21823570499873313, 0.2298644319998857, 0.2099109930004488, 0.21114699999998265, 0.20464763900054095, 0.2210737200002768, 0.21734655799991742, 0.21382813299896952, 0.21618931000011798], [], [], [], [], [0.208172648000982, 0.2169736539999576], [], [], [], [], [0.2173397570004454], [], [0.21725883599901863, 0.2080853500010562, 0.21822462899945094, 0.22983868200026336, 0.20994800199878227, 0.211145478000617, 0.2041337509999721, 0.2215108609998424, 0.21739954199983913, 0.21342583899968304, 0.21653967300153454, 0.22854636999909417, 0.20463164600005257, 0.22149081099996693, 0.2253260119996412, 0.20277495099981024, 0.20780061799996474, 0.2050638769997022, 0.21178544700160273, 0.21677276799891843], [], [0.21736740499909502, 0.20809352400101488, 0.21821555599854037, 0.22984037900096155, 0.20995907399992575, 0.21110586099894135], [], [], [0.20884302800004662, 0.21845797099922493, 0.22935209900060727, 0.2098794519988587, 0.21122924400151533, 0.20464282099965203, 0.2210414450000826, 0.21741822799958754, 0.21375953099959588, 0.21636989900071057, 0.22835563799890224, 0.2044962480013055, 0.22149635699861392, 0.2253103530001681, 0.20307098900048004, 0.2075024919995485, 0.20506184199985, 0.21185038200019335, 0.21686453000074835], [0.2185540239988768, 0.22935594500086154, 0.2098872289989231, 0.2112279060002038, 0.2046369740000955, 0.22104237399980775, 0.21741422200102534, 0.2137479129996791, 0.21636806599963165, 0.22833245500078192], [], [], [], [], [0.20924144700074976, 0.2111237439985416], [], [], [], [], [], [], [0.20918184900074266, 0.211347864000345, 0.2042778899995028, 0.22178060800069943], [], [], [], [0.21151008900051238, 0.20425014499960525, 0.2215902450006979, 0.21747236599912867, 0.21342371300124796, 0.2165404839997791, 0.22853271799976937], [0.21106253000107245], [], [0.2046300509991852, 0.22104680899974483, 0.21741586800089863, 0.21374481599923456, 0.21636089400089986, 0.22834481499921822, 0.2045472930003598, 0.22149372400053835, 0.2253166919999785, 0.2030096919988864], [0.2042905559992505, 0.2210231120006938, 0.21744764699906227, 0.21378958500099543, 0.21636586000022362, 0.22832916199877218, 0.20469267100088473, 0.2212880490005773, 0.2253404959992622, 0.20302989700030594, 0.20749816299939994], [0.2039789610007574, 0.22167226800047501, 0.2178818489992409, 0.21377325799949176, 0.2163675459996739, 0.22834502200021234, 0.20394605500041507, 0.22174862800056871, 0.22500489599951834, 0.20282781400055683, 0.2074584309993952, 0.20543096300025354, 0.21238335599991842, 0.21646491600040463, 0.20716504099982558, 0.21117384299941477, 0.20677135799996904, 0.20410386500043387, 0.21776455600047484], [0.20410699899912288, 0.22196617100053118, 0.21797636699920986, 0.21377819200097292, 0.21636710900020262, 0.2283393759989849, 0.2037258340005792, 0.22185805799927039, 0.22502714000074775, 0.20252029800030869, 0.20752032199925452], [0.22158729099828633, 0.2176985820005939, 0.21378396399995836, 0.21636602000035055, 0.22833414299930155, 0.20395925200136844, 0.2217495439999766, 0.22500560499975109], [0.21446490900052595, 0.21616769200045383, 0.22832260900031542, 0.2037233329992887, 0.22185870800058183, 0.22503003099882335, 0.20283014600136084, 0.2073266009992949, 0.20553344099971582, 0.2126956350002729, 0.21613604100093653], [], [0.2161970460001612, 0.228558692999286, 0.20378792900010012, 0.22185772900047596, 0.22480561200063676, 0.2027406629986217, 0.207418261001294, 0.20572647199878702, 0.2124662830010493, 0.21641992699915136, 0.2069096110008104], [0.20504068700029165, 0.22129056599987962, 0.22530317900054797], [0.2046277059998829, 0.22143159699953685, 0.2253959390000091, 0.2025488929994026, 0.20790124999984982, 0.20517947400003322, 0.21171127300112857, 0.21683392100021592, 0.2074592399985704, 0.21086935899984383, 0.206940708001639, 0.20437532999858377, 0.21745103600005677, 0.23407840500112798, 0.222261595999953, 0.2073712119999982, 0.20884186900002533], [0.22151545300039288, 0.22542053799952555, 0.20253399000102945, 0.20727483199880226], [0.22145559799901093, 0.22540135199960787, 0.20254363100139017, 0.2073377389988309, 0.20570413000132248, 0.21190621299865597, 0.21659078300035617, 0.20752529200035497, 0.21087767599965446, 0.2068269629999122, 0.20446122700013802], [0.22175161999984994, 0.22500870899966685, 0.20283007100078976, 0.20732359700014058, 0.20553185300013865, 0.2122755500004132, 0.21660789999987173, 0.2071488049987238, 0.2111006040013308], [0.2217031540003518, 0.2254615570000169, 0.2024206520000007], [0.20321848000094178, 0.20733784599906357, 0.205538037000224, 0.21249634599917044, 0.21634242700019968, 0.20704701900103828, 0.21124295899971912, 0.20649034899906837, 0.20442112300042936, 0.21762927000054333, 0.23493429500013008, 0.22236279499884404, 0.20781596699998772, 0.20867961600015406, 0.22346002100130136, 0.20429822099868034, 0.22925612100152648, 0.2264699949992064, 0.20634730600067996, 0.21596520299863187, 0.2172652340013883, 0.2073584989993833, 0.2091454719993635, 0.20967864300109795, 0.21349658199869737, 0.2279667030015844, 0.24950884799909545, 0.22987536499931593, 0.21034028400026727, 0.21319372600009956, 0.2188749100005225, 0.2303087170002982, 0.22405355800037796], [0.20241725699997914, 0.20740270099850022, 0.20567740200021944], [], [], [], [0.20774554099989473], [], [], [], [], [], [], [0.20518412400087982, 0.2121611299990036, 0.21639102100016316, 0.20745335100036755, 0.21087269500094408, 0.20693499199842336, 0.20438420500067878, 0.21739465199971164], [0.2056617800008098, 0.21244805099922814, 0.21640460500020708, 0.20702746999995725, 0.21124231700014207, 0.20649722599955567, 0.20442150700000639, 0.21762921800109325, 0.2349071439984982, 0.22236965900083305, 0.2072787569995853], [0.2054307919988787, 0.21226800000113144, 0.21659489499870688, 0.20715375600047992, 0.21116456799973093, 0.20651225300025544, 0.2042994000003091, 0.21762897100052214, 0.2346278639997763, 0.22225640099895827, 0.2073761830015428], [0.2115238699989277, 0.2167950330003805, 0.20766701300090062, 0.21113957099987601, 0.20724939899992023, 0.2039120629997342, 0.21704677699926833, 0.23433109700090426, 0.22228422999978648, 0.20860589199946844, 0.2085800830009248, 0.22279077999883157, 0.2042919260002236, 0.2293675399996573, 0.22634439900139114, 0.20711928699893178, 0.21573765100038145, 0.2168579699991824, 0.20741299300061655, 0.21037218799938273, 0.2084670090007421, 0.2133166980001988, 0.2279664159996173, 0.24962782900001912, 0.22974573400097142, 0.21046910399854823, 0.2132220840012451, 0.21882856499905756, 0.23017550300028233], [0.21181630099999893, 0.21672001099977933, 0.20766468000147142, 0.21114188399951672, 0.20724850399892603, 0.20386108300044725], [], [0.2123294619996159, 0.21628033200067875, 0.20717702999900212, 0.2111759819999861, 0.20676989000094181, 0.2041039619998628, 0.21782778299893835, 0.23460057100055565, 0.2223615429993515, 0.20781821700074943, 0.20867855500000587], [0.20762012600062008, 0.21110799099915312, 0.2064900760015007], [0.20745261599950027, 0.2113455939997948], [], [0.20770079599969904, 0.2111428860007436, 0.206858084000487, 0.20388046899824985, 0.21741318900058104, 0.23427185400032613, 0.2223656200003461, 0.20734583900048165, 0.20870664999893052, 0.2233295679998264], [], [], [], [], [0.2074432990011701], [], [], [], [], [], [], [0.21116761599841993, 0.20627588600109448, 0.20442832899971108, 0.21743833999971685, 0.23414729199976136, 0.22234250800102018, 0.20738577999873087, 0.20881174900023325, 0.22332787600134907, 0.20463275199836062, 0.2294708620011079, 0.22607468599926506], [0.21097731400004704, 0.20671679000042786, 0.2041039819996513, 0.21783019000031345, 0.23459904599985748], [], [], [0.20385955100027786, 0.2170600290010043], [0.20446743100001186, 0.2174364680013241, 0.23425905899966892, 0.22225643199999467], [0.20442361999994318, 0.21763266100060719, 0.23478188299850444, 0.22233555300044827, 0.2073906440000428, 0.20881302099951426, 0.2233261080000375, 0.2046295470008772, 0.22947014499914076, 0.2260747979998996, 0.20661046700115548, 0.2150143910002953, 0.21748285600006056, 0.20797414600019692, 0.20925206699939736, 0.2091895300000033, 0.21359182900050655, 0.22849979300008272, 0.2495186050000484, 0.22969618999923114, 0.2099302410006203, 0.21351961699838284, 0.2190875420001248, 0.2303794610015757, 0.22384587399938027, 0.2231210440004361, 0.21469620899915753, 0.21373850900090474, 0.21073587499995483, 0.231828031999612, 0.2542428809992998, 0.23815619699962554, 0.20794295400082774, 0.21269121899968013, 0.21965820799960056, 0.21689357800096332, 0.22979784900053346, 0.20695689899912395, 0.22842270500041195, 0.2484847269988677], [0.20430258800115553, 0.21742609499960963, 0.2341473220003536], [0.20426285100074892, 0.2176247669995064, 0.23463272800108825, 0.22225509099916962, 0.2074780559996725, 0.20880942800067714, 0.22322247099873493], [], [], [0.20410819099924993, 0.21759334899979876], [0.21743153099851042, 0.23415129100067134, 0.22234008899977198, 0.20738717800122686, 0.20881140699930256, 0.22332737800024915, 0.20463201900020067, 0.2294709639991197, 0.22607373500068206, 0.20661050299895578], [], [], [0.21744688299986592, 0.23504277800020645, 0.22186691999922914, 0.20860343700041994, 0.2085889110003336, 0.22277855399988766, 0.2042997819989978], [], [], [], [], [], [], [0.20728244200108747, 0.20879174800029432, 0.22332690399889543, 0.2046330510002008, 0.22946949600009248, 0.22615339599906292, 0.20661587200083886, 0.2149217749993113, 0.2174831370011816, 0.20797875499920337, 0.2092486439996719], [], [], [], [], [], [0.20832769800108508, 0.22333388199876936, 0.20456239000122878, 0.22946744299952115, 0.22646242399969196, 0.20635216200025752, 0.21587212899976294, 0.2173711010000261, 0.2072648150005989, 0.20921190299850423, 0.20968570600052772, 0.2134981159997551, 0.22797097100010433, 0.24951055900055508, 0.22980613599975186, 0.21041973100000178, 0.21319633699931728, 0.21887546300058602, 0.23031659600019339, 0.2240441430003557, 0.22300334200008365, 0.21472178799922403, 0.21406323600058386, 0.21067357399988396, 0.2317253269993671, 0.2541623899996921, 0.23801575800098362, 0.20838262399956875, 0.213196049000544, 0.2193844560006255, 0.21646899899860728, 0.22968800800117606, 0.20708719299909717, 0.2281782669997483, 0.24852303900115658, 0.22270614299850422, 0.20896223500130873], [], [], [], [], [], [], [0.2085684579997178, 0.2228090450007585, 0.20428557499872113, 0.22936242900141224, 0.22635095799887495, 0.20654841100076737, 0.2158145390003483, 0.2173124529999768, 0.2072606599995197, 0.2104169529993669], [0.22306088500045007, 0.20446642500064627, 0.22946888499973284, 0.2263997569989442], [0.22324606300026062, 0.20428314799937652, 0.22925686800044787], [0.205135338999753, 0.22926042600010987, 0.22646897099912167, 0.20634761300061655, 0.21587664400067297], [0.22947419500087562, 0.22608519099958357, 0.20660368100107007, 0.2149155819988664, 0.21760686299967347, 0.20787000000018452], [], [0.20643092899990734, 0.2148497190009948, 0.21748239699991245, 0.20797928499996488, 0.20924757099965063, 0.20918936199996097, 0.21359208300054888, 0.22849841599963838, 0.24951801499992143, 0.2296950250001828, 0.2099336819992459, 0.21351576400047634, 0.21908952100056922, 0.23037357599969255, 0.22385281499919074, 0.2231243190017267, 0.21469444599824783, 0.21385223800098174, 0.21062293899922224, 0.2318260760002886, 0.25424226700124564, 0.2381552520000696, 0.20794131499860669, 0.21269048100111831, 0.21965719999934663, 0.21689109900034964, 0.22980292300053407], [0.21581920199969318, 0.21723163299975567], [0.21558489299968642, 0.21727034099967568], [], [], [0.21668186299939407, 0.207808526000008, 0.2093510779995995, 0.2090686840001581, 0.21393511300084356, 0.22815582299881498, 0.24951651300034428, 0.22969383700001345], [0.2072719509997114, 0.20921251099935034, 0.20906186500178592, 0.21394099699864455, 0.22815173600065464, 0.24951401999896916, 0.22979843300163338, 0.20981585099980293, 0.21351387399954547, 0.21908960700056923, 0.23037062299954414, 0.22385727599976235, 0.22312429699923086, 0.2146959239998978, 0.2141299020004226, 0.21067011400009505, 0.2315921850004088, 0.2541854270002659], [], [], [], [0.21036637500037614, 0.20847504999983357, 0.2133180460004951, 0.22796578099951148, 0.2496216320014355, 0.2297530679988995, 0.2104716459998599, 0.21321791800073697, 0.21871930999986944], [0.209154258000126, 0.20967494300020917, 0.21350166699994588, 0.22796648599978653, 0.2495107310005551, 0.22980678900057683], [0.20915609300027427, 0.21338695399936114, 0.22796538200054783, 0.24951088899979368, 0.2298772119993373, 0.21033879199967487, 0.2131941560000996], [0.20919170000161103, 0.21359733999997843, 0.22849775099894032, 0.24952003399994283, 0.22970342400003574, 0.20992100100011157, 0.2125411119995988, 0.21971449100055906, 0.2306483880001906, 0.22268574699955934], [0.20862130199930107, 0.2133260650007287, 0.22796575800020946, 0.2495117050002591], [0.21343847800017102], [], [], [0.21300868299840658, 0.21901216500009468, 0.23036721800053783, 0.22386149100020702, 0.22312360499927308, 0.2146963440009131, 0.21412992799923813, 0.21067157099969336, 0.2315903970011277, 0.2543035559992859, 0.23802250300104788, 0.20817524799895182, 0.21336216100098682, 0.21889519700016535, 0.21674677899864037, 0.22994446700067783, 0.20717475300079968, 0.22816318099830823, 0.24843510500068078, 0.22270534400013275, 0.20896371900016675, 0.2294801419993746, 0.20916326800033858, 0.20310802099993452, 0.22105952200035972, 0.22282994300076098, 0.20634264199907193, 0.2129461349995836, 0.20432256599997345, 0.20658345700030623], [0.21320880399980524, 0.2187248530008219, 0.23030436299995927, 0.22431686699928832, 0.2227895609994448, 0.21612605300106225, 0.21324119400014752, 0.2102945599999657, 0.23149905699938245, 0.2542784510005731, 0.2378639069993369], [0.21909073300048476, 0.23030780099907133], [0.21888149599908502, 0.23032178200082853, 0.2238655919991288, 0.22312282100028824, 0.21469740700013062, 0.2141291120005917, 0.2106714559995453, 0.23159119699994335, 0.2543089789996884, 0.23801733000073, 0.20899384899894358, 0.21298376199956692, 0.21910325099997863, 0.21685469700059912, 0.22928329900059907, 0.20755330199972377, 0.22776886400060903], [0.22369653999885486], [0.22300705700035905, 0.2146594819987513, 0.21412619600050675, 0.21067301200127986, 0.23159076899901265], [0.22311066499969456, 0.21470559999943362, 0.21372971200071333, 0.21073686399904545, 0.23181885200028773, 0.254253791001247, 0.23817050899924652, 0.20794533499974932, 0.2126922219995322, 0.21958368500054348, 0.216940672000419, 0.22804729800009227, 0.20848949599894695, 0.22862970900132495, 0.2485129729993787, 0.2224770829998306], [0.2227961980006512, 0.21612207899852365, 0.21261629600121523, 0.210671820999778, 0.23173374500038335, 0.2541597749986977], [0.21256057799837436, 0.21037286200044036, 0.23182364999956917, 0.25424208000004, 0.238156680999964, 0.2079390990002139, 0.2126890800009278, 0.2196783500003221, 0.21686769099869707, 0.22993002200018964, 0.20714391000001342, 0.22818402600023546, 0.24845337300030224, 0.2226942350007448, 0.20887080099964805], [0.21028509099960502, 0.2315107270005683, 0.25422353700014355], [0.23160085799827357, 0.2541882870009431, 0.2381572039994353, 0.208169577001172, 0.2124565599988273, 0.21968152200133773, 0.21686149299966928, 0.22993934899932356, 0.2067978890008817, 0.22841448899998795, 0.24856522199843312, 0.22269966400017438, 0.20896289400116075, 0.22948302999975567, 0.20917906199974823, 0.2030900150002708, 0.22105935499894258, 0.22283384799993655, 0.20528920100150572, 0.21364393299882067, 0.2043255330008833, 0.20592328599923349, 0.21339640900077939, 0.2299026609998691, 0.20564635700065992, 0.21031320099973527, 0.20815534199937247, 0.21071648900033324], [], [0.20794053700046788, 0.21269472699896141, 0.21958619900033227, 0.2169424040002923, 0.22805588399933185, 0.2089949319997686, 0.22828653200122062, 0.24821703799898387], [0.21298441599901707, 0.21921181900142983, 0.2164573449990712, 0.22968160700111184, 0.20756839199930255, 0.22776856599921302, 0.24844417500025884, 0.22270737100006954, 0.20903406599973096, 0.22948376800013648, 0.2096462999998039, 0.20256256500033487, 0.2210873210005957, 0.22427373599930434, 0.20522752400029276, 0.21269870499963872, 0.2052280999996583, 0.20596154000122624, 0.2122248599989689, 0.23171661000014865, 0.20460885300053633, 0.21067868299905967, 0.20813656300015282, 0.21096104900061619, 0.20859642300092673, 0.20707501599827083, 0.2089643690014782, 0.21062065299884125, 0.20785393600090174, 0.20606161099931342, 0.21318229300050007, 0.22050249299900315, 0.2141029120011808, 0.217100304998894, 0.22971168700132694, 0.2109941990001971, 0.20704248699985328, 0.20621850899988203, 0.207918845999302, 0.22076293200007058, 0.24052026999925147, 0.2199423370002478, 0.21725544299988542, 0.23291611000058765, 0.21067261899952427, 0.21180756500143616], [0.21292254199943272, 0.2190660050000588, 0.2168663390002621, 0.22927230200002668, 0.2066922309986694], [], [], [0.21297838899954513, 0.21910905200093111, 0.21645604799959983, 0.22968211300030816, 0.2067060119989037, 0.2284066789998178, 0.24866653000026417, 0.22270778300116945, 0.20903598699987924, 0.22952033399997163], [0.21320516000014322, 0.21885382199980086, 0.21674421100033214, 0.22994464700059325, 0.20717458099898067, 0.2281615440006135, 0.24843899000006786, 0.22270502900028077, 0.2089623070005473, 0.22947848799958592, 0.20915773100023216, 0.20311666300040088, 0.22105825599828677, 0.22295491300064896, 0.20621207099975436, 0.21295337599985942, 0.20432077400073467, 0.2066722050003591, 0.2125167109988979, 0.23171559000002162, 0.2041181559998222, 0.21090112999991106, 0.20832788000006985, 0.21047700400049507, 0.2089912680003181, 0.20645735300058732, 0.20921499399992172, 0.21073591399908764, 0.20781816199996683, 0.2063075639998715, 0.21252340899991395, 0.22131395900032658, 0.21401086200057762], [0.21890816499944776, 0.21674797699961346, 0.22994329600078345, 0.20711939499960863, 0.22818079199896601, 0.24847441200108733, 0.22270343600030174, 0.20896452399938426, 0.2294805080000515, 0.2091703679998318, 0.20310003499980667, 0.22105987500071933, 0.22282945400002063, 0.2058369890000904, 0.2132036799994239, 0.20439653100038413, 0.2060140899993712, 0.21323951900012617, 0.22995975199955865, 0.2058886419999908, 0.21058728500065627, 0.20823409500007983, 0.21067340899935516, 0.20875307900132611, 0.20690321499932907, 0.20875808200071333, 0.2105741739997029, 0.20793186999981117, 0.20630255300056888, 0.21302596199893742, 0.22134151799946267, 0.21369062099984149, 0.2167108450012165, 0.22908078000000387, 0.2119442009989143, 0.20693997099988337, 0.2062168650008971, 0.20813684300082969, 0.22098955399997067, 0.24072876499849372, 0.2200060190007207], [0.2193281460004073, 0.21645504499974777, 0.22968300200045633, 0.20673618699947838, 0.22840901900053723, 0.2486403410002822, 0.22270715099875815, 0.20902725900123187, 0.2294973719999689, 0.2096222759992088], [0.21634100899973419], [0.21689995599990652, 0.2282487049997144, 0.20829876300012984, 0.22862740599885, 0.24849110400100471, 0.22257059999901685, 0.20907325000007404, 0.2295996400007425, 0.20918778399936855, 0.20285715899990464, 0.221112962000916], [0.20788933999938308, 0.22777552899970033, 0.2483995969996613, 0.22270523699990008, 0.2089622010007588, 0.229477990000305], [0.20695607500056212, 0.22816500199951406, 0.2490329649990599], [], [0.22802823999882094, 0.2489418340010161, 0.22226776099887502, 0.2090340840004501, 0.229593816000488, 0.20952815700002247, 0.2025734819999343, 0.22114342599888914, 0.2242043750011362, 0.2047669629992015, 0.2129595229998813, 0.2043203100001847, 0.20667938100086758, 0.21250875199984876, 0.23171735299911234, 0.20411732899992785, 0.210906543999954, 0.20832426600100007, 0.21098273899951892, 0.20848230100091314, 0.20687715299936826], [0.22819062500093423, 0.24832321099893306, 0.22186348300056125, 0.20968116599942732, 0.22968118300013884, 0.20922478700049396, 0.2027131949998875, 0.22118750200024806, 0.22298303299976396, 0.20547943400015356], [], [0.20918766099930508, 0.22960167800010822, 0.20920001600097748, 0.20273974199881195, 0.221186247001242, 0.22297503600020718, 0.20511153999905218, 0.2131514070006233, 0.20491022399983194, 0.20558094099942537], [0.22951975099931587, 0.20949377000033564, 0.20251630900020245, 0.22108320000006643, 0.22287996399973053, 0.20512339100059762, 0.21363503700013098, 0.20445507699878362, 0.2058259610003006, 0.213381704999847, 0.2298955370006297, 0.20564836700032174, 0.21088314599910518, 0.20780675199966936, 0.21104833600111306, 0.20794551399922057, 0.20742312299989862], [], [0.20394607900016126, 0.2208057240004564, 0.22419231700041564, 0.20446139399973617, 0.2129759899999044, 0.20438100799947279, 0.2060326900009386, 0.21321985800022958, 0.23171049799930188, 0.20413772699976107, 0.2107833310001297, 0.2080516459991486, 0.21072312900105317], [], [0.20301721999931033, 0.22101955899961467], [0.20314797300125065, 0.22103647099902446, 0.22418075300083729, 0.2044733129987435, 0.21296503600024153, 0.20439370300118753, 0.2060203979999642, 0.21323290100008307, 0.2303933839993988, 0.2054546269991988, 0.21058946500124875, 0.20824451099906582, 0.21071212199967704, 0.208821247000742, 0.2067734180000116, 0.20875474700005725, 0.21057510200080287, 0.20846936299858498, 0.20603901200047403, 0.2128173599994625, 0.22128107200114755, 0.21405943799982197, 0.216352272000222, 0.2290796479992423, 0.21193267300077423, 0.20698590699976194, 0.20624220900026558, 0.20809645199915394, 0.2209706859994185, 0.24072547700052382, 0.22003386600044905, 0.21671244100070908, 0.23342333999971743, 0.21053106199906324, 0.21185723100097675], [], [0.2210651580007834, 0.22418036099952587, 0.20422621599936974, 0.21319967300041753, 0.20439591400099744, 0.20601633499973104, 0.21323743900029513, 0.22996618799879798, 0.2058819499998208, 0.21058832900052948, 0.20824039100079972, 0.2106679489988892, 0.20875484000134747, 0.20690178099903278, 0.20875600299950747, 0.2105731210012891, 0.2084575999997469, 0.20577918399976625, 0.21302478899997368, 0.2213392859994201, 0.21368844999960857, 0.2167161010002019, 0.2290798989997711, 0.21194241200100805, 0.2069433390006452], [0.221081473000595, 0.22284061400023347, 0.20683972599908884, 0.21261572700132092, 0.20507162600006268], [], [], [0.22076237100009166, 0.2241709110003285, 0.20509865099847957, 0.21261906400104635, 0.20506532899889862, 0.20598085800156696, 0.21245144099884783, 0.23171445700063487, 0.20436610399883648, 0.21086987200033036, 0.20813773299960303], [0.2211184019997745, 0.22296169599940185, 0.20513073300026008, 0.21315017300003092, 0.2049097979997896, 0.20567511500121327, 0.21349220199954289], [0.20453553299921623, 0.21297155700085568, 0.2043947499987553, 0.20601833000000624, 0.21323471200048516, 0.2303816210005607, 0.2054665189989464, 0.2105897220008046, 0.20824281699970015, 0.21071188299902133, 0.20871018700017885], [], [], [0.20620845399935206, 0.21297361600045406, 0.20437907799896493, 0.2066208980013471, 0.212659356999211, 0.2317099310002959, 0.20412422299887112, 0.21079941900097765, 0.20803784999952768, 0.2108147809994989], [0.2129356209989055, 0.20433077000052435, 0.20657884200045373, 0.21262560099967232, 0.2317145619999792, 0.2041193969998858, 0.21080236499983585], [0.21327844699953857, 0.2044148850000056, 0.20582576500055438, 0.21338141300111602, 0.22989372799929697, 0.20600106100027915, 0.21058699099921796, 0.20815955299985944, 0.21076209000057133, 0.20875248099946475, 0.20690074400044978, 0.20876352000050247, 0.21034365199921012, 0.20810430600067775, 0.20634533199881844, 0.2130280159999529, 0.22101540300172928, 0.2139879229998769], [], [], [], [], [0.21320848499999556, 0.2044004159997712, 0.20582493399888335, 0.21338051600105246, 0.2298953569988953, 0.20600051200017333, 0.21058787500078324, 0.20815957500053628], [], [], [0.21288706899940735, 0.2050596509998286, 0.2059270550016663, 0.21249162899948715, 0.231720146999578, 0.20436577200052852, 0.21072721000018646, 0.20825977499953297, 0.21101288899990323, 0.20844931600004202, 0.20695519000037166, 0.20909998699971766, 0.2103416739992099, 0.2078159240008972, 0.2064320339995902, 0.2125045989996579, 0.22118913099984638, 0.21405276200130174, 0.21708606499851157, 0.22829283500141173, 0.21204056199894694, 0.20693082400066487, 0.2062656660000357, 0.20800586199948157, 0.22097135799958778, 0.24072369400164462, 0.22003002899873536, 0.21671611000056146, 0.23342703399976017, 0.21052774000054342, 0.21192569699996966, 0.2255371239989472, 0.2249034530013887, 0.2066843839984358, 0.22393906400066044, 0.20356716900096217, 0.208183699998699, 0.21754766600133735, 0.21465716699822224, 0.21276090200080944, 0.20704359500086866, 0.22748045299886144, 0.21788805899996078, 0.21340950500052713, 0.2239179520001926, 0.22096628399958718, 0.21156984600020223, 0.21029266599907714, 0.21635990800132276, 0.2511455539988674, 0.21938827200028754, 0.22533459199985373, 0.20859143900088384, 0.21181428999989294, 0.20872833499925036, 0.21635766500003228, 0.1458967760008818, 0.00937930699910794, 0.0073507440010871505, 0.011096545998952934, 0.008325155000420636, 0.007410693999190698, 0.00886193200130947, 0.007971081999130547, 0.008220409999921685, 0.00832785700004024, 0.009126508000917966, 0.007508971999413916, 0.007816716999514028, 0.006670648999715922, 0.007241185001475969, 0.005392399998527253, 0.006481412001448916, 0.006190611999045359, 0.006697553999401862, 0.006260697000470827, 0.007388435000393656, 0.0056165250007325085, 0.006534797999847797, 0.007106494998879498, 0.005451007000374375, 0.005576531000770046, 0.00507292699876416, 0.005322492999766837, 0.005700309000530979, 0.004784026999914204, 0.00526599300064845, 0.005399100000431645, 0.005380587999752606, 0.005553506000069319, 0.005643946000418509], [0.20433764200060978, 0.20557149299929733, 0.2135913990005065, 0.23002857800020138, 0.2054551929995796, 0.21044439700017392, 0.20820335899952624, 0.2107219579993398, 0.2084270640007162, 0.20726008000019647, 0.20916349700019055, 0.2099258819998795, 0.2083278270001756, 0.20640747799916426, 0.21330252400002792, 0.2209739370009629, 0.2140853769997193, 0.21662118899985217, 0.22921519100054866, 0.21155439599897363, 0.2069779080011358, 0.2061833009993279, 0.20812584899977082, 0.22135885900024732, 0.24077179099913337, 0.2199576140010322, 0.21680063599887944, 0.2316971990003367, 0.21175394500096445], [0.20510590499907266, 0.20586660300068615], [0.2058318479994341, 0.21338350900077785, 0.22989826999946672, 0.2056464800007234, 0.2103138950005814, 0.20815499299897056], [], [], [], [0.2059607950013742, 0.21223384499899112, 0.23171522800112143, 0.20461251799861202, 0.21067378500083578, 0.20814210000025923, 0.21095636799873319, 0.20860062200154061, 0.20707652799865173, 0.20895930900042003, 0.21061690699934843, 0.2076107340017188, 0.2062548379999498, 0.2132089389997418, 0.2205242290001479, 0.2141034589985793, 0.2170145340005547, 0.22980376700070337, 0.21070732099906309, 0.20733084300081828, 0.2061043880003126, 0.20798323599956348, 0.22069895499953418, 0.240627356000914, 0.21995136699842988, 0.21724942500077304, 0.23291709499972058, 0.21061152199945354], [], [], [], [], [], [0.2059390419999545, 0.21249648999946658, 0.23171794900008535, 0.20436492599947087, 0.21072701400044025, 0.20826528699944902, 0.21100672500142537, 0.2084556989993871, 0.2069247830004315], [0.20657611199931125, 0.21263253600045573, 0.23171236100097303, 0.2041217099995265, 0.21080081000036444, 0.2080371499996545, 0.21087475499916764, 0.20900050199998077, 0.20645198000056553, 0.20868594199964718, 0.21057730100073968], [], [], [], [], [], [], [0.21324000299864565, 0.22986321300049894], [0.2133363789998839], [0.21315467100066599, 0.2317071309989842, 0.20412989199940057, 0.21079411200116738, 0.20804194300035306, 0.210808312998779, 0.20907982000062475, 0.20640217899926938], [], [], [], [], [], [0.21245429800001148, 0.2317156570006773, 0.20436485699974583, 0.21072667299995373, 0.20825571400018816, 0.21101797899973462, 0.2084450000002107, 0.2069554989993776, 0.20911427399914828, 0.21033252000052016], [0.21350691500083485, 0.23001346799901512, 0.20546443100101897, 0.2104443349999201, 0.20818749099998968, 0.2107203039995511, 0.2084300839997013, 0.20725595700059785, 0.20916673200008518, 0.2099220719992445, 0.2083306740005355], [0.20407148499907635, 0.2105930880006781, 0.20815880699956324, 0.21076274200095213, 0.20860152899876994, 0.2069481819999055, 0.20886898700155143, 0.21034292199874471, 0.20800957500068762, 0.20641199400051846, 0.2130427719985164, 0.22102403000099002, 0.21399756999926467, 0.21674416400128393, 0.2290841529993486, 0.21154101799947966], [], [], [], [0.21067869099897507, 0.20814666800106352, 0.2109521919992403, 0.2086071890007588, 0.20700548899912974, 0.2089888480004447, 0.2105825359994924, 0.20762306000142416, 0.2063012170001457, 0.21309282899892423], [0.21073143600006006, 0.2082726709995768, 0.21099698100078967, 0.20846619499934604, 0.20692134400087525, 0.20874389699929452, 0.21073577499919338, 0.20781705400077044, 0.20643475699944247, 0.2123960300014005], [0.2107838800002355, 0.20816049999848474, 0.2107634580006561, 0.20859956000094826, 0.20695003099899623, 0.2088702020009805, 0.2103441599992948, 0.20800570400024299, 0.20641408399933425, 0.21304270700056804, 0.22102695099965786, 0.21400093600095715, 0.21673340999950597, 0.2290897610000684, 0.2115409889993316, 0.20733753500098828, 0.2062224579985923, 0.20803013800104964, 0.22111040500021772, 0.24073076799868431, 0.22001437500148313, 0.216742668999359, 0.23168984899893985, 0.21225880100064387, 0.21137738499965053, 0.22600410000086413, 0.2246209799995995], [0.21031767199929163, 0.20815855100045155, 0.21071693200065056, 0.20843033799974364, 0.20725517599930754, 0.20916837000004307, 0.209919445000196], [0.20814725200034445, 0.2110034289999021, 0.20843934999902558, 0.20695631700073136, 0.20912460100043972, 0.21039847599968198, 0.20774435900057142, 0.20641984999929264, 0.21297112200045376, 0.2207250159990508], [], [0.20780779300002905, 0.2106058210010815, 0.20831103599994094, 0.2073188289996324, 0.2091328219994466], [0.21072471600018616, 0.20842563399855862, 0.20726317099979497, 0.20914156100116088, 0.20994703299948014, 0.20832767700085242, 0.20640751799874124, 0.2133039930013183, 0.22098503399865876, 0.21402563700030441], [0.21076605099915469, 0.20807432800029346, 0.20737659500082373, 0.2089584429995739, 0.21034355300071184, 0.20800065199910023, 0.20641730399984226, 0.21304393699938373, 0.22094800800005032, 0.21408967600109463, 0.21662316599940823, 0.22920690700084378, 0.2115401680002833, 0.2073331909996341, 0.20622487499895215, 0.20803292100026738, 0.2211103820009157, 0.24073055400003796, 0.22001844300029916, 0.21673860399823752, 0.2316902080001455, 0.2122585010001785, 0.2113762940007291, 0.22600237999904493, 0.22462321000057273, 0.20655880300000717, 0.22441321199949016, 0.2035050800004683, 0.2081676769994374, 0.21720864700000675, 0.2147699820015987, 0.21202986199932639, 0.20736759700048424, 0.22809201499876508, 0.21772785800021666, 0.21361069600061455, 0.22333074100060912, 0.22143199099991762, 0.21045479199892725, 0.21086446899971634, 0.21651101899988134, 0.2514537540009769, 0.21758574200066505, 0.22572525599935034, 0.20910215000003518, 0.21277886099960597, 0.20816489299977547, 0.21696444600092946, 0.14576975399904768], [0.20795330299915804, 0.20742417700057558, 0.20911022899963427, 0.21034732800035272, 0.20792892200006463, 0.20638265600064187, 0.2131318529991404, 0.22096289600085584, 0.21410084899980575, 0.216615979999915, 0.22920523599896114, 0.21154210200074886, 0.20697502300026827, 0.2062969010003144, 0.2082674079993012, 0.22114463000070828, 0.24073194499942474, 0.21993401600047946, 0.21682278699881863, 0.23169304700059, 0.21225313600007212, 0.2113054250003188], [], [0.20695639900077367, 0.20887343899994448, 0.2103441550007119, 0.208004541000264, 0.20641417599836132, 0.21304371100086428, 0.2209477020005579], [0.20700842900077987, 0.20898374900025374, 0.2105813849993865, 0.20762451399968995, 0.2063069039995753, 0.2130836050000653, 0.22067445399989083, 0.21398737200070173, 0.21711266199963575, 0.22973545000058948, 0.21079368499886186, 0.2071862120010337, 0.20618328700038546, 0.2080291419988498, 0.22070000700114178, 0.24058396399959747, 0.22000635899894405, 0.21723181000015757, 0.2329240880008001, 0.21052601200062782], [0.20737597900006222, 0.2089648990004207, 0.21034433900058502, 0.20792935799909174], [0.20683458500025154], [], [0.20895549499982735, 0.21055987599902437], [0.2091356929995527, 0.21049734500047634, 0.20793281999976898, 0.20627240000067104], [0.20900142199934635, 0.2103505330014741, 0.2077111779999541, 0.20642648299872235, 0.21251455300080124, 0.22117918299954908, 0.21405478000087896, 0.2171014399991691, 0.2284090360008122, 0.21208398700036923], [0.209107505999782, 0.21035254299931694, 0.20793096799934574, 0.20637548100057757, 0.21313898799962772, 0.22096105400123633, 0.21410614399974293, 0.21660891299870855, 0.22920624800099176, 0.21154322300026251, 0.2069760819995281, 0.20628795300035563, 0.20826639699953375, 0.22115232400028617, 0.24073264499929792, 0.21994085000005725, 0.21681682300004468, 0.2316935070011823, 0.21224915699895064, 0.2113057549995574, 0.226042303000213, 0.22466954000083206, 0.2064436319997185], [0.20895313800065196, 0.21061606699913682, 0.20784873100092227, 0.2061282350005058], [0.2107364339990454, 0.20781799100041098, 0.20600698800080863, 0.2128286119987024, 0.22127201500006777], [0.21108016799917095, 0.20789079899986973, 0.20602838000013435, 0.21282250799959002, 0.2212771350004914, 0.21406542499971692, 0.21635058399988338, 0.2290802010011248, 0.21192710399918724, 0.20698537499993108], [0.20793640700139804, 0.20621171499988122, 0.21330071599913936, 0.22097315000064555, 0.21408039400012058, 0.21664673799932643, 0.2292068669994478, 0.2115470610006014, 0.20697490999918955, 0.20618435899996257], [], [], [], [], [], [], [0.20763217200146755, 0.2063141809994704, 0.21307120900019072, 0.22068500699970173, 0.21398867899915786, 0.21710740800153872, 0.2297376649985381, 0.21079559800091374, 0.20718163600031403, 0.20580937699924107, 0.20839880499988794, 0.2207020330006344, 0.24058795199925953, 0.2200114030001714, 0.2172115630000917, 0.23293755700069596, 0.21052609599973948, 0.21193070200024522, 0.22552839199852315, 0.2249084720006067, 0.20668262700019113, 0.22392507800032035], [0.2079315629998746, 0.20630672100014635, 0.21302487600041786, 0.22133876499901817, 0.21369625300030748, 0.21670656000060262, 0.22908277599890425, 0.21194057100001373, 0.20694125200134295, 0.2062189659991418, 0.2080293069993786], [0.20606748800128116, 0.21317171000009694, 0.22051321099934285, 0.21410241699959442, 0.2170209710002382], [0.20634778600106074, 0.2130298819993186, 0.2210197820004396, 0.21396821499911312, 0.21662679000110074], [0.20636663000004773, 0.21298526099963055], [0.20625555399965378, 0.21314835200064408], [], [], [0.2132627009996213, 0.2209623440012365, 0.21407610999995086], [], [0.2130470089996379, 0.22094878700045228, 0.21409493799910706, 0.2166198480008461, 0.22920588699889777, 0.21154132400079106, 0.2069755789998453, 0.2065765770003054, 0.20803717600028904, 0.22111082799892756, 0.24073172799944587, 0.22002045900080702, 0.21673648300020432, 0.23169010699893988, 0.21225733800019952, 0.21137434000047506, 0.22596370199971716, 0.22466407499996421, 0.2065550000006624, 0.224423248999301, 0.203497252001398, 0.20816742399983923, 0.21720911299962609, 0.21477074500035087, 0.21202943400021468, 0.20736864799982868, 0.22809214500011876, 0.21773262699935003, 0.2136022739996406, 0.22333134200016502, 0.22143316899928323, 0.21045358700030192, 0.2108634449996316, 0.2165129100012564, 0.25145571699977154, 0.21758535799926904, 0.2256129779998446], [0.21315340699948138, 0.22047594400100934, 0.2141032349991292, 0.2171104019998893], [], [], [0.2128137780000543, 0.2212876089997735, 0.21368711099967186, 0.21672082800068893, 0.22907917799966526, 0.21193753300030949, 0.20698472699950798, 0.20623637700009567, 0.20809670200105757, 0.22097316599865735, 0.2407264360008412, 0.22003722899899003, 0.2167082490013854, 0.23341798699948413, 0.21053341399965575, 0.21185891899949638, 0.2256203260003531, 0.22469238499979838, 0.20689315399977204, 0.22394747500038648, 0.20346885999970254, 0.20816820100117184, 0.21732109499862418, 0.21464074600044114, 0.21259557400117046, 0.20739109299938718], [], [0.21501405600065482, 0.21701128199856612, 0.229732382000293], [0.2139904879986716, 0.21710244200039597, 0.22841285200047423, 0.21212444299999333, 0.20684778699978779, 0.20613813300042239, 0.20839649499976076, 0.22069981999993615, 0.24059574999955657, 0.22001751700008754, 0.2167260090009222], [0.21729734699874825], [0.21035052700062806, 0.20695050199901743, 0.20621963899975526, 0.20802887799982273, 0.22111058900009084, 0.24073003500052437, 0.22001059700050973, 0.21674714199980372, 0.2316903930004628, 0.21225854799922672, 0.21137824899960833, 0.22600367800077947, 0.22472181299963268, 0.206447656999444, 0.22440378600003896, 0.20351067900082853, 0.20816872300019895, 0.2172078989988222, 0.214771038001345, 0.21240048199979356, 0.20706936999886238, 0.22803381900121167, 0.21771849499964446, 0.21362209399921994, 0.22332922100031283, 0.2214331070008484, 0.21045407299970975, 0.21086633000049915, 0.21651013999871793, 0.2514548819999618, 0.21758383599990339, 0.22573478600133967, 0.20909380299963232, 0.21277840599941555, 0.20816533499964862, 0.21696393199999875, 0.14579681800023536, 0.008920469001168385], [0.20698469799935992, 0.20618530700085103, 0.2081252799998765, 0.22135787600018375, 0.2407718409995141, 0.21997670800010383, 0.216782838000654, 0.23170405899873003, 0.21174450000034994, 0.21171595400119259], [0.2068016789999092, 0.2062411869992502, 0.20838576300047862, 0.22058465699956287, 0.24072414800139086, 0.22002355299991905, 0.2167208880000544, 0.233429891999549, 0.21052688700001454, 0.2119299490004778, 0.22553123099896766, 0.22490650799954892, 0.20668278800076223, 0.2239317959993059, 0.20357433700155525, 0.20818382499965082, 0.2175498910000897, 0.21464879799896153, 0.21277006099990103, 0.2070422030010377, 0.2274493650002114, 0.2178902220002783, 0.21340481399965938, 0.2239164399998117, 0.22097609499905957, 0.211562362001132, 0.21029130299939425, 0.21636129999933473, 0.2511459030010883, 0.21938775299895497, 0.2253390540008695, 0.2085749649995705, 0.21181957199951285, 0.20815824400051497], [0.20693158199901518, 0.20618854200074566], [0.20610286999908567, 0.20798194400049397, 0.2206992089995765, 0.24058226300076058, 0.22000233799917623, 0.21724204900056066, 0.23291948500082071, 0.21060489599949506, 0.211836743999811, 0.22552776600059588, 0.22490777500024706, 0.20699681599944597, 0.22365308699954767, 0.20365810700059228, 0.20825818099910975, 0.21742541099956725, 0.21482030200058944, 0.2126758409995091, 0.2069125640009588, 0.22746023000036075, 0.2178789350000443, 0.21386300999984087, 0.2235538719996839, 0.2209436810007901, 0.21154372499950114, 0.21034615300050064, 0.21634034299859195, 0.2510692960004235, 0.21938925600079529, 0.2253264599985414, 0.20887703900007182, 0.21199699600038002, 0.20830733500042697, 0.21675092000077711, 0.14556717299819866], [], [], [0.20619151899882127, 0.20823797000048216, 0.22051961299985123, 0.24045065099926433, 0.22015314400050556, 0.21710913400056597, 0.2328554180003266, 0.21069426000030944, 0.21185723999951733, 0.2254200530005619, 0.2250433350000094, 0.206898441998419, 0.22386716900109604, 0.2037460089995875, 0.20792345799964096, 0.21758374000091862, 0.21469658199930564, 0.21260413200070616, 0.207249007999053, 0.22712342200065905], [0.20809728499989433, 0.22097767500054033, 0.24072749799961457, 0.22003872400091495, 0.21670595700015838, 0.2318012549985724, 0.21214799400149786, 0.21185886099920026, 0.22562257500067062, 0.2246417679998558], [0.2079154519997246, 0.22066787800031307], [0.2080479270007345, 0.22111354600019695, 0.24073297499853652, 0.21992503700130328, 0.21683062599913683, 0.23169098800099164, 0.21225602499907836, 0.21136882100108778, 0.22596600699944247, 0.2246667700001126, 0.2065465129999211, 0.22443705899968336, 0.20348939699943003, 0.20776339800067944, 0.21751948400014953, 0.21485068400033924, 0.21202997000000323, 0.20737126200037892, 0.22809095499906107, 0.21774203300083173, 0.21265277599923138], [], [], [], [0.2205315809987951, 0.24045505399953981, 0.21993547400052194, 0.21726165099971695, 0.2329150679997838, 0.21068159000060405, 0.2118561459992634, 0.22544016000028932, 0.2250431070006016, 0.20689934000074572, 0.2235978159988008, 0.204012132000571, 0.2079315859991766, 0.2175740520015097, 0.21470175799913704, 0.2126022379998176, 0.2072486779998144, 0.22712306700123008, 0.21787428799871122, 0.21387202000005345, 0.22355390200027614, 0.22093336500074656, 0.21168645299985656, 0.21026465899922187, 0.21630639100112603, 0.2511744369985536, 0.21926445999997668, 0.22532136800145963, 0.20888460700007272, 0.21200116899854038, 0.20857939300003636, 0.21648396199998388], [0.22117735099891433, 0.24073753000084253, 0.21994749099940236, 0.21681038200040348, 0.23169381899970176, 0.21223709200057783, 0.21130646299934597, 0.2260280900009093, 0.2246839210001781, 0.20643125700007658, 0.22458484399976442, 0.2031469969988393, 0.20800410700030625, 0.21757847600019886, 0.2148529360001703, 0.21202877600080683, 0.20737176699913107, 0.22809079900071083, 0.2177570639996702, 0.2126364529995044, 0.22401476300001377, 0.22160458600046695, 0.21040611500029627], [], [], [], [0.2171048049985984, 0.2328637880000315, 0.21068679300151416, 0.2118570959992212, 0.2254074499996932, 0.22504323400062276, 0.20689931999913824, 0.22360501200091676, 0.20377707300031034, 0.20816461899994465, 0.21751093499915441], [0.21178455100016436, 0.2115040320004482, 0.22489383199899748, 0.2250406760012993, 0.2068996990001324, 0.22386857399942528], [], [0.21171297900036734], [0.2256271940004808, 0.2246439089994965, 0.2064446799995494, 0.2243954189998476, 0.20351912300066033, 0.20816800899956434, 0.2172070150008949, 0.21477184699870122, 0.21259299800112785, 0.20689170900004683], [0.22550017799949273, 0.22490152600039437, 0.20699860700005956, 0.2236468219998642, 0.20366481500059308], [0.20789313800014497, 0.22367030100031116, 0.20353546799924516, 0.20831623600133753, 0.21746964099838806, 0.2146000130014727, 0.21289007599989418, 0.20692018999943684, 0.2274632999997266, 0.2178844760001084, 0.21341264100010449, 0.22392072799993912, 0.22103901300033613, 0.21153813300043112, 0.21034244399925228, 0.21628130899989628], [0.20690233200002695, 0.2236113140006637, 0.20377345599990804, 0.20813745299892616, 0.21743014200001198], [], [0.22395936499924574, 0.203463076000844, 0.20816771899990272, 0.21720724499937205], [], [0.20818766500087804, 0.21753931300008844, 0.21467089199904876, 0.2127506220003852, 0.20704895400012902, 0.22746697399998084, 0.21784766200107697, 0.21342199299942877, 0.22390916599943012, 0.2208324729999731, 0.21166863399957947, 0.210327947001133, 0.21635555200009549, 0.2511536999991222, 0.21937586100102635, 0.22536284199850343, 0.2080395380016853, 0.2122279619998153, 0.2082887969991134, 0.21694931099955284, 0.14591091700094694, 0.009129317999395425, 0.00729976699949475, 0.011126128001706093, 0.008276838998426683, 0.007583477001389838, 0.008839699999953154, 0.008009571000002325, 0.008226222998928279, 0.008342541999809328, 0.009104754000873072, 0.007540553000580985, 0.007804272998328088, 0.00668304400096531, 0.00716720600030385, 0.00550665199989453, 0.0064588739987812005, 0.006192163000378059, 0.006700043000819278, 0.006284809000135283, 0.007327216999328812, 0.005643669001074159, 0.006511326999316225, 0.007149016999392188, 0.005550197000047774, 0.005578309999691555, 0.00507301800098503, 0.0053233660000842065, 0.005702960999769857, 0.00479018499936501, 0.005274015000395593, 0.005381480999858468, 0.005381062999731512, 0.005568423001022893, 0.005692380998880253, 0.004870594000749406, 0.005232468000031076, 0.0038564149999729125, 0.0041961890001402935], [0.20800715400037006, 0.21758075300022028, 0.21486287199877552, 0.21201902800021344, 0.2073718989995541, 0.2280907100011973, 0.21777555699918594, 0.21261687799960782, 0.22401507700124057, 0.22161786899960134, 0.21018917100082035, 0.21096817599936912, 0.21657616300035443, 0.2516311460003635, 0.2175981939999474, 0.2256157349984278, 0.2089341830014746, 0.21306719799940765, 0.20778063000034308, 0.21725783799956844, 0.1458292059996893, 0.008892609999747947, 0.008017259000553167, 0.011005206000845646], [0.2077682230010396, 0.21752106699932483, 0.21485032700002193, 0.21202994899977057, 0.20737191000080202, 0.2280907929998648, 0.2177459809990978, 0.2126492879997386, 0.224121469000238, 0.22147708100055752, 0.21052418100043724, 0.21062713999890548, 0.21669918299994606, 0.2515120919997571, 0.2175852920008765, 0.22561562699956994, 0.20894464400043944, 0.21306380200076092, 0.20816198399916175, 0.21697312499964028, 0.1457255860004807, 0.009027485999467899, 0.008085433000815101, 0.011186501000338467, 0.00832062399967981, 0.007409591999021359, 0.008856156000547344, 0.007977756000400404, 0.00822000199877948, 0.008332925001013791, 0.009118984999076929, 0.0075151400014874525, 0.007814750999386888, 0.00667152099958912, 0.007240410999656888, 0.005359882001357619, 0.0065134739998029545, 0.006191349999426166, 0.006648697999480646, 0.0062802900010865415, 0.007332457998927566, 0.005699770999854081, 0.006531896000524284, 0.007108789000994875, 0.005427129999588942, 0.005564090999541804, 0.005086315999506041, 0.005319682000845205, 0.005590131999269943], [0.2082228210001631, 0.21746607499881065, 0.21459249700092187, 0.2129010799999378, 0.2069144769993727, 0.22746215500046674, 0.21788238900080614, 0.21384559699981764, 0.22349325199866144], [0.20798568899954262, 0.2175742679992254, 0.21485090100031812, 0.2120286129993474, 0.20737189300052705, 0.22809224800039374, 0.21775039299973287, 0.21264379500098585, 0.22401418699882925], [0.21746418299881043, 0.21460958600073354, 0.21277871500024048], [0.2172775670005649, 0.21462293100012175], [0.21750186799908988, 0.2147352990014042], [0.21721524600070552, 0.2147719069998857, 0.21203083000000333, 0.2073693389993423, 0.22809160299948417, 0.2177377690004505, 0.21276186000068265], [0.21301376299925323, 0.20689699499962444, 0.22803238500091538, 0.21771394499955932, 0.21362642900021456, 0.22333026900014374, 0.2214308210004674, 0.21071583299999475, 0.2106224069993914, 0.2165100900001562, 0.25145145999886154, 0.21758514100110915, 0.22573897799884435, 0.20920256300087203, 0.21265127399965422, 0.20816560899947945, 0.21696274500027357, 0.1460215839997545, 0.009066923999853316], [0.21274071500010905, 0.20705643999826862, 0.22747058000095421, 0.2178499620004004, 0.213417553999534, 0.22340976700070314, 0.22133401799874264, 0.21165391100112174, 0.2103397800001403, 0.21623225999974238], [0.20707519100142235, 0.22803513999861025, 0.21772304400110443, 0.21361745299873292, 0.22332854800151836, 0.2214330049991986, 0.21045377100017504, 0.21086638999986462, 0.21651046199986013, 0.2514550510004483, 0.2175828729996283, 0.22573385100076848, 0.20909605899942107, 0.21277755300070567, 0.20816622099846427, 0.21696367600088706, 0.1457995309992839, 0.008918842000639415, 0.008224474000599002, 0.011084129999289871, 0.0083261109994055, 0.007411185000819387, 0.00892880199899082, 0.007895090000602067, 0.008220404999519815, 0.008373219001441612, 0.009208692999891355], [0.20727028300098027, 0.22747713299941097, 0.21785387199997786, 0.21341336600016803, 0.22340502699989884, 0.22134005400039314, 0.21117617299933045, 0.21081330900051398, 0.2162308930001018, 0.25129337900034443, 0.21925174100033473], [], [], [], [], [], [0.22761734899904695, 0.2178565800004435, 0.21341413000118337, 0.22333030699883238], [], [], [0.21340389199940546, 0.2239133370003401, 0.22098802300024545, 0.2115530379996926, 0.21029198900032497, 0.21636289799971564, 0.2511464689996501, 0.2193849870000122, 0.22534496400112403, 0.2080484889993386, 0.21222601899899018], [], [], [0.22333780799999658, 0.22132194700134278, 0.21053223099988827, 0.21062281800004712, 0.21670374599852948, 0.2515103640016605, 0.21758293299899378, 0.22561728700020467, 0.20921262800038676, 0.21279361599954427, 0.20816248200026166, 0.2169709169993439, 0.14571724199959135, 0.009033491000081995, 0.00808302800032834, 0.01118542400035949, 0.00832380599968019, 0.007409862000713474, 0.008859633999236394, 0.007973976000357652, 0.008220076000725385, 0.0083287540001038, 0.009125070999289164, 0.007510616000217851, 0.007816437999281334, 0.0066712150000967085, 0.00724117100071453, 0.005393924999225419, 0.006478973000412225, 0.006191057000251021, 0.0066953330006072065, 0.006264988998736953, 0.007380781000392744, 0.005621517999315984, 0.006533208001201274, 0.007106937999196816, 0.005453043000670732, 0.005573804999585263, 0.005050079000284313, 0.0053212689999782015, 0.005645081999318791, 0.004866833000050974, 0.005260120000457391, 0.005398617999162525, 0.005381403001592844, 0.005553832999794395, 0.005589819998931489, 0.005006347000744427, 0.005172023000341142], [0.21122911400016164, 0.21063082900036534, 0.2165096499993524, 0.2514527769999404, 0.21758500699979777, 0.22573737799939408, 0.2090920720002032], [], [0.2104525120012113, 0.2106074429993896, 0.21670850199916458, 0.2515065550014697, 0.21758445699924778, 0.22561471299923141, 0.20922157500172034, 0.21278489799988165, 0.20816306300002907, 0.21696926499862457, 0.14571080800124037], [0.21166937599991797], [0.2115465349997976, 0.21029359200110775, 0.21636171999853104, 0.2511493670008349, 0.21938121799939836, 0.22535253100068076, 0.20804338900052244, 0.21222721099911723, 0.20828870900004404, 0.21694983300039894, 0.14590431400029047, 0.00913405800019973], [0.21153156200125522, 0.2103367089985113, 0.21628879300078552, 0.2511453179995442, 0.21938966299967433, 0.22533023600044544, 0.2086000140006945, 0.21181204799904663, 0.20873997499984398, 0.21634465900024225, 0.14588994000041566, 0.009379806000652025, 0.0073582869990787, 0.011090893000073265, 0.008325664999574656, 0.007411742000840604, 0.008863920998919639, 0.007969634001710801, 0.008219773999371682, 0.008369011000468163, 0.009085477999178693, 0.007570997000584612, 0.007753940999464248, 0.006669857999440865, 0.007522179999796208, 0.00510960900101054, 0.00648447200001101, 0.006189678000737331, 0.006698690998746315, 0.006257207000089693, 0.007396073000563774, 0.005624920999252936, 0.006524332000481081], [], [], [], [], [], [], [], [], [], [], [], [], [0.21026817799975106, 0.21630666999953974, 0.25106526000126905], [], [], [], [0.21081632299865305, 0.2162279980002495, 0.25129037000078824, 0.21759197099891026, 0.22717467400070745, 0.20803562099899864, 0.2122312530009367, 0.20828848000019207, 0.21694746399953146, 0.14591851899967878, 0.009124379999775556, 0.007689215000937111, 0.011086287999205524, 0.008325832000991795, 0.007411597998725483, 0.008869355000570067], [], [0.21632479300023988, 0.25114145199950144, 0.2175854340002843, 0.2257384610002191, 0.20938361499975144, 0.21246956499999214, 0.20828088099915476, 0.21683294600006775], [0.21652430200083472, 0.25145981700006814, 0.21758473999943817, 0.22561315299935814, 0.20922672400047304, 0.2127810820002196, 0.20816381700024067, 0.2169675160002953, 0.14577034399917466, 0.008963045000200509, 0.00808266999956686], [0.21627289900061442, 0.25138699499984796, 0.21758511100051692, 0.22573887999897124, 0.20920675300112634, 0.21264622599846916, 0.2081652450015099], [], [], [], [], [], [], [0.22471493200100667, 0.20882549099951575, 0.2122372150006413, 0.20828644999892276, 0.21694228100022883, 0.1459317219996592, 0.009117601000980358, 0.007692031000260613, 0.01108748399929027, 0.008326260000103503, 0.007411798000248382, 0.008868872000675765, 0.007966029999806779, 0.008220117999371723, 0.008372782000151346, 0.009203526000419515, 0.007443488999342662, 0.007769875001031323, 0.0066454649986553704, 0.007533512000009068, 0.005096423999930266, 0.006486985001174617, 0.006190363999849069, 0.006698273999063531, 0.006254416999581736, 0.007400076001431444, 0.005628226999760955, 0.006662480000159121, 0.006991668999035028], [0.2089569970012235, 0.21199241199974495, 0.20831588900000497, 0.21633909499905712, 0.14598918500087166, 0.009303087999796844, 0.007397790999675635, 0.011083036000854918, 0.008384769998883712, 0.007341235001149471, 0.009011718999317964, 0.007812366000507609, 0.008221015999879455, 0.008371497999178246, 0.00926793600046949, 0.007441853000273113, 0.007697471999563277, 0.00664223000057973, 0.007540837999840733, 0.005087375000584871, 0.0065086869999504415, 0.006187530998431612, 0.006681862001642003, 0.006252006000067922, 0.00740486899849202], [], [], [], [], [], [], [], [0.2125465199987957, 0.20814365800106316, 0.21642483899995568, 0.14547378099996422, 0.009254197999325697, 0.007367972999418271, 0.011083090999818523, 0.008326801000293926], [], [], [], [], [0.20815671600030328, 0.21642259500004002, 0.14548262499920384, 0.009257500001695007, 0.006959319998713909, 0.011072629000409506], [0.2079110929989838, 0.21630216599987762, 0.14546643600078824, 0.009253723999790964], [], [], [0.21697970000059286, 0.1457358520001435, 0.00901943700046104, 0.008071304999248241, 0.011193042999366298, 0.008082551999905263], [], [], [], [], [0.010216271000899724, 0.007064867999361013, 0.01132005100043898, 0.008087690999673214, 0.007582578000437934, 0.00883775100010098, 0.00801047999993898, 0.008224854998843512, 0.008394101001613308, 0.009059760999662103, 0.0075869020001846366, 0.007815382999979192, 0.0066208689986524405, 0.007238798001708346], [0.00930521400005091, 0.007343556000705576, 0.0110887669998192, 0.00832554799853824, 0.007411377000607899, 0.00886809199982963, 0.007967428000483778, 0.008219354000175372, 0.008371698999326327, 0.00919733999944583, 0.0074790329999814276], [0.009054352000021026, 0.007338680001339526, 0.010952456999802962, 0.008479938000164111, 0.007596710000143503, 0.008861545999025111, 0.008007073000044329, 0.008229425000536139, 0.008379003998925327, 0.008886481000445201], [], [0.009109198001169716, 0.007534133999797632, 0.011189110999112017, 0.008313255000757636, 0.007334042998991208, 0.008837049001158448, 0.008010411998839118, 0.008223855000323965, 0.008397826999498648, 0.00906053300059284], [], [], [], [], [], [], [], []], "generated_texts": ["<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_124215|>```\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please provide a clear and concise request", "<|vq_lbr_user|>\n\nIt", "<|vq_lbr_userWhat is the best way to get a 3D model of a house?\n\nThere are several ways to obtain a 3D model of a house", "<", "<|vq_lbr_124740|>", "<", "<|vq_lbr", "<|vq_lbr_image_12486|>", "", "<|vq_lbr_audio_124437", "<|vq_lbr_image_124", "<|vq_lbr_audio_124437|>", "\n\nIt looks like the text you provided", "\n\n```\n\nIt looks like the text you provided is", "<", "<|vq_lbr\n\nIt looks like the text you provided is a mix of multiple languages", "<|vq_lbr_image_12471|>", "<|vq_12471|>\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel", "ition<|vq_lbr_image_12486|>", "<|vq_lbr_image", "\n\nIt looks like your text is", "\n\nIt looks like your text is a mix of multiple languages and possibly some random characters", "\n\n```\n\nIt looks like the text you", "<|vq_lbr_image_1245|>", "\n\nThe text you provided appears to be a mix of random characters, symbols, and fragments of text in multiple languages. It doesn't form a coherent or meaningful sentence or paragraph. If you have a specific question or need assistance with a particular topic, please provide a clear and concise request", "<", "<|vq_lbr_audio_124437| \n```\n\nIt", "<|vq_lbr_image_12471|>", "<|vq", "ins<|vq_lbr_124740|>", "<|vq_12471|>\n\nIt looks like your message got garbled or mixed up with a lot", "<|vq_lbr", "<|vq_lbr_audio_124740|>", "<|", "<|vq_lbr_audio_124740|", "<|vq_lbr_image_1245|>\n\nIt looks like the text you provided", "<|vq_lbr_124740|", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_124740|", "od", "<|vq_lbr_audio", "<", "<|vq_lbr_userWhat is the best way to get a 2D array in Java?\n\n", "\n\nIt looks like your message got garbled or", "<|vq_lbr_audio_124", "<|vq_lbr_audio_124437|>\n\nIt looks like the text you provided is a", "\n\nIt looks like the text you provided is a mix of multiple languages and appears to", "ot<|vq_12471|", "nores", "<|vq_lbr_image_12486|", "<|vq", "<|vq_lbr_image_124", "<|vq_lbr_audio_124740|>", "<|vq_lbr", "%&'()*+,-./012345", "<", "ed<|vq_lbr\n\nIt looks like the text you provided is a mix of different languages and symbols, making it difficult to understand or translate. If you have a", "<", "<|vq_lbr_audio_124740|>", "<|vq_lbr_124740|>", "AMPLE<|vq_lbr_124740|>", "<", "<|vq_lbr", "<", "<|vq_lbr_audio_124", "<|vq_lbr_audio_124437", "<|", "<|vq_lbr_image_12486|>", "", "\n\n```\n\nIt looks like the text", "<|vq_124", "<|vq_lbr", "<|vq_lbr_image_124", "<|vq_lbr\n\nIt looks", "ige<|vq_lbr_audio_124437|", "", "<", "<", "<|", "<", "<|", "<", "<|vq_lbr_124740|>", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! If you have a specific", "<", "<|vq_lbr_", "<|vq_lbr_audio_124740|>", "<|", "<|vq", "<", ".com\n\n", "z<|vq_12471|>\n\nIt looks like your message got", "", "<|vq_l", "<|vq_l", "<|vq_12471|>", "<|vq_lbr\n\nIt looks like the", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form", "<|vq_lbr_audio_124740|>", "<|vq_lbr_user", "<|vq_lbr_image_1245|>", "<|vq_lbr_audio_124437", "<|vq_12471|>\n\nIt looks like your message", "<|vq_lbr_userWhat is the best way to get a good grade in", "\ufffd<|vq_lbr", "\n\nIt looks like the text you provided is a mix", "<", "\n\n[\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't", "<|vq_lbr_image_1245|>", "<|vq_lbr_audio_124740|\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand or provide a meaningful response", "<", "<|vq_lbr_124740|>", "<|vq_lbr_image_1240|>```\n\nIt looks like the text you posted is a garbled mix of multiple languages", "<|", "ated<|vq_12471|>\n\nIt looks like you've pasted a large amount of text", "<", "<|vq_12471|>\n\nIt looks like your message contains a mix of text in multiple languages and possibly some code", "<|vq_lbr_124740|>", "<|vq_lbr_userWhat is the best way to get a job?\n\nThe best way to get a job can vary depending on your industry, experience level, and personal circumstances, but here are some general steps that can help you increase your chances of finding a", "<|vq_lbr_124740|", "ized<|vq_lbr_audio_124437", "<|vq_lbr_audio_124740", "<|vq_lbr\n\nIt looks like your message", "<|vq_lbr\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand", "<|vq_lbr_audio_124437|>\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random", "S", "<|vq_lbr\n\nIt looks like your message got garbled and turned into", "\n\nIt looks like your message contains a mix of text in multiple languages and", "\n\nIt looks like your message got garbled and turned into a mix of", "<|vq_lbr_124740|>", "\n\nIt seems like the text you provided is a mix of different languages and characters, making it difficult to", "<", "<|vq_lbr\n\nIt looks like the text you provided is a mix of different languages", "<|vq_12471|>\n\nIt looks like the text you posted is a garbled mix of code, comments, and possibly", "<", "<|vq_lbr_", "<|vq", "\n\n", "\n\nIt looks like the text you provided is a mix of different languages and symbols, making it difficult to understand. If you have a specific question or need assistance", "<|vq_lbr_image_12486|>", "Data<|vq_lbr_audio_124740|>", "<|vq", "<|", "<|", "<|vq_lbr_audio_124740|>", "<|vq_l", "<|vq_lbr_audio_124877|><\n\nIt looks like", "<|vq_lbr_image_", "<|vq_lbr_audio_124740", "\ufffd<|vq_lbr_image_1245|>\n\nIt looks like the text you provided is a mix of different languages and characters,", "<|vq_lbr_image_12486|>\n\nIt looks like the text you provided is", "<|vq_lbr_audio", "<|vq_lbr_image_12457|>", "<|vq_lbr_audio", "an<|vq_lbr_image_12486|>", "<|vq_lbr_audio_124437|>", "\n\n```\n\nIt looks like the", "<|vq_lbr_audio_124877|>", "ed<|vq_lbr_124740", "<|vq_lbr_image_12486|>", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of", "\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124740|>", "<|vq_lbr_124740|><", "<|vq_lbr_image_12471|>", "<|vq_", "<|vq_lbr_124740|>", "<|vq_lbr_124740|>", "\ufffd<|vq_lbr_124740|>", "<", "<|vq", "<|vq_l", "<|vq_l", "\n\n```\n\nIt looks like the text you provided is a mix of random characters and words in multiple languages, and it doesn't form a coherent sentence or paragraph. If you have a specific question or need assistance with something,", "<|vq_lbr_audio_124437|>\n\nIt looks like the", "<|vq_l", "<|", "<", "<|vq_124", "<|vq_lbr_", "<|vq_lbr", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124215|>", "\n\n", "<|vq_lbr_audio_124215|>", "\n\nIt looks like the", "<|vq_lbr_image_12486|>", "<|vq_lbr\n\nIt looks like your", "<|", "StatusCode<", "<|vq_lbr_user\n\nIt looks like the text", "<|vq_lbr", "ed<|vq_lbr_", "\n\n```\n\nIt looks like the text you provided is a mix of random characters and symbols, and it doesn't form a", "<|vq_lbr_audio_124740|>", "<|vq_12471|>\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel", "<|vq_lbr\n\nIt looks like the text you provided is a mix of multiple", "<|", "<", "<|vq_lbr_image_12486|>\n\nIt looks like", "<|vq_lbr_audio_124740|>", "\n\n```\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a", "\n\nIt looks like the text you provided is a mix of", "<|vq_lbr_image_12486|>", "<|vq_lbr_124740|>", "<|vq_lbr", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! If you have a specific", "<|vq_12471|>\n\nIt looks like your message got a bit garbled! If you have", "<|vq_lbr_124740|>", "<|vq_lbr_image_124", "\u0c41<|vq_lbr_124740|><\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel", "<|vq_lbr_image_", "<|vq_lbr_audio_124740|>", "<|vq_lbr_124740|>", "<|vq_lbr_audio_", "<|vq_l", "\ufffd 0.0.0.0\n\nIt looks like the text you provided is a", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_124", "<", "<|vq_lbr", "<|vq_lbr_audio_124", "\n\nIt looks like your message contains a", "\n\n```\n\nIt looks like the text you provided is a mix of different languages", "\n\n", "<", "<|vq", "<|", "<|vq", "<", "<|vq_lbr", "<|vq_12471|>\n\nIt looks like the", "<|vq_lbr_image_12486|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please provide a clear and concise request, and I'll do my best to help you.\n\nIt seems like the text you provided is a mix", "<|vq_lbr_userWhat is", "\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel\n\nSure! If", "\n\n```\n\n", "<|vq_lbr_audio_124437|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance", "<", "<", "<|vq_lbr_image_", "Space<|vq_lbr_image_1245|>", "\n\nIt looks like the text you provided is a mix of different", "<", "able<|vq_lbr_image_12457|>", "<|", "<|vq_12471|", "<", "<|vq_lbr_124740|>", "<", "", "<|", "<|vq", "<|vq", "igration<", "<|", "<|vq_lbr_audio_124437|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult", "<|vq_lbr_124740", "<|vq_lbr_audio_", "<|vq_l", "<|vq_lbr_image_12457|>", "<|vq_lbr_image_12473|>", "<|vq_lbr_image", "<|vq", "<|vq_lbr_audio_124740|>", "<|vq", "<", "<|vq_lbr_audio_124740|>", "<|vq_lbr", "<|vq", "<|vq_lbr_image_1245|>", "<|vq_lbr\n\nIt looks like", "ysics\n\n", "<|vq_lbr_124740|>", "<|vq_lbr_image_1245|>", "\n\n```\n\nIt looks like the text you provided is a mix of different languages and characters", "<|vq_l", "<|vq_lbr_image_12486|>", "<|vq_lbr_image", "<|vq_lbr_124740|>", "```\n\nIt looks like the text you provided is", "<|vq_lbr_audio\n\nIt looks like your message got", "<|vq_lbr\n\nIt looks like your message got", "<|vq_lbr\n\nIt looks like you're trying to create a comprehensive and detailed description for a product or service, possibly related to a \"Mikrofon\" (microphone) and its usage in various contexts. However, the text appears to be a mix of multiple languages and unrelated content, making it difficult to understand the exact request.\n\nIf you could clarify the specific details or the main focus of the product or service you want to describe, I can help you create a clear and", "orerected<|vq_lbr_124819|>", "<|vq_lbr_image_12486|>", "<|vq_l", "\n\nIt looks like the text you provided is a", "<|vq_lbr_audio_124740", "<|vq_12471|>\n\nIt looks like the text you provided is a mix", "<|vq_lbr_124740|>", "<|vq_lbr_image_124", "<|vq_lbr_audio_124437| \n", "<|vq_lbr_image_1245|", "\n\n```\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't seem", "<|vq_lbr_audio_124740|", "<|vq_12471|>\n\nIt looks like the text you provided is a", "<|vq_lbr_audio_124215|>", "<|vq_lbr_audio_124215|>", "<|vq_lbr_image_", "<|vq_lbr_user\n\nIt looks like", "<|vq_lbr_audio_124437|", "<|vq_lbr_audio_124437|}\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please provide a", "<|vq_12471|>\n\n", "<|vq_lbr_audio_124437|}\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't form a coherent sentence or request. If", "<|vq_lbr_image_12486|>", "<|vq_lbr_image_12486|>", "<|vq", "<|vq_lbr\n\nIt looks", "<|vq_lbr_124740|>", "```\n\nIt looks", "<|", "<|vq_lbr_image_1245|", "<|vq_12471|>\n\nIt looks like your message", "<|vq_lbr_124740|>", "<|vq_lbr\n\nThe problem is to compute the sum of the", "<|vq_lbr", "<|vq_lbr_", "<|vq_lbr_124", "<|vq", "", "<|vq_lbr_124740|", "<|", "<", "<|vq_lbr_audio_124740|>", "<", "<|vq_12471|>", "<|vq_lbr_image_12486|>", "<|vq_lbr\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand or translate accurately. If you have a specific part of the text you'd like to translate or if you have a different text that needs translation, please provide that", "<|vq_lbr_audio_124740|>", "<|vq_l", "<|vq_lbr_124740|>", "<|", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent or", "<|vq_lbr\n\nIt looks like the text you provided is a mix of different languages and characters,", "<|", "<", "entication<|vq_12471|>\n\nIt looks like you're trying to create a complex and detailed prompt for a text-to-image AI model, specifically for generating an image of a \"beautiful woman with", "IONS<|vq_lbr\n\nIt looks like the text you provided is a mix of random characters and phrases that don't form a coherent or understandable message. If you have a specific question or need help with a particular topic, feel\n\nIt looks", "phere<|vq", "<|vq", "<|vq_lbr_124740|>", ">\n\nIt looks like your message contains a mix of different languages and possibly some garbled text. If you have a specific question or need assistance with something, could you please clarify or provide more details? I'm here to help!\n\n\n\nIt looks like your message might be empty. If you have a question or need assistance, feel\n\nIt looks like your message might be empty. If you have a", "<|vq_l", "<|vq_lbr_audio_", "<|vq_lbr\n\nIt", "<|vq_lbr_image_12473|", "<|vq_l", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124877|>", "<|vq_lbr_124740", "<|vq_lbr", "esised<|vq_lbr_124740|>", "<|vq_lbr_audio_124740|>", "<|vq_l", "<|vq_lbr_audio", "<|vq_lbr\n\nIt looks like the text", "<", "<", "<|vq_lbr\n\nIt looks like your message got garbled or mixed up with a", "<|vq_lbr_124044|>", "<|vq_lbr\n\nIt looks like your", "<|vq_l\n\nIt looks like the text you provided is a mix of random characters and fragments from different languages, making it difficult to understand or translate", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_124215|>", "<|vq_12471|>\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel", "<|vq_lbr_audio_124740|>", "<|vq_lbr", "<|", "\n\n", "", "<", "<|vq_lbr_image_12486|>", "<|vq_lbr_audio_124437", "ctor<|vq_lbr_124740|>", "\n\nIt looks like the text you provided is a mix", "<", "<|vq_lbr_124740|>", "<|vq_lbr\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand or translate accurately. If you have a specific part of the text", "<|vq_lbr_124740|>", "<|vq_lbr_124740|>", "<", "im<|vq_lbr_image_1243|>", "<", "<|vq_lbr_", "<|vq_124", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and symbols, making it difficult to", "<|vq_12471|>\n\n", "<", "<|vq_l", "<|vq_lbr_124740|", "<|vq_lbr_audio_124437|>", "ed<|vq", "\n\n```\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't form", "o<|", "ente<|vq_lbr\n\nIt looks like your message got a bit gar", "", "<|vq_lbr\n\nIt looks like the text you provided is a mix of random characters, symbols, and", "<|vq_12471|>\n\nIt looks like", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a", "<", "ical<|", "<|vq_lbr_audio_124215|>", "p>\n\nIt looks like", "er", " \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\n```\n\nIt looks like the text you provided is a mix of different languages and characters", "<|", "<|", "<|vq_lbr_image_12486|>", "<|vq_lbr_audio_124", "<|vq", "<|vq_lbr_image_12486|>", "<|vq_lbr_audio_124", "<|vq_lbr_image_1245|>\n\nIt looks like the text", "<|vq_12471|", "<|vq_12471|>\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text.", "", "<|vq_lbr_image_1245|>\n\nIt looks like the text you provided is a mix of different languages", "<|vq_12471|>\n\nIt looks like the text you", "<|vq_lbr_124", "\n\n```\n\nIt looks like the", "<|vq_lbr_image_12471|>", "<", "play<|", "<|vq_12471|>\n\nIt looks like your message got", "<|vq_lbr_audio_124877|><\n\nIt looks like the text you provided is a", "<|vq_lbr_image_12473|>", "<|vq_lbr_124740|>", "", "<|vq_lbr_124740|>", "<|vq_lbr_image_124", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and characters", "ansform<|vq", "<|vq_lbr_image_12486|>", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_124877|><\n\nIt looks like the text you provided is a", "\n\n```\n\nIt looks like", "<|vq_lbr_124740|><\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand or translate accurately. If you have a specific portion or a particular language you'd like to focus on,", "<", "<|vq_lbr_audio_124", "<|vq_lbr_image_12486|>", "<|vq_12471|>\n\nIt seems", "<|vq_l", "\n\nIt looks like the text you provided", "\n\nIt looks like the text you provided is a mix of code snippets, comments, and possibly", "\ufffd \t\ufffd \t\ufffd \t\ufffd \t\ufffd \t\ufffd \t\ufffd \t\ufffd \t", "<|vq_lbr_image_12486|>", "<", "<|vq_lbr_124740|>", "\n\nIt looks like", "\n\n```\n\nIt looks like the text you provided is a mix of different languages", "<|vq_lbr_audio_", "<|vq_lbr_124740|>", "<|vq_l", "ICALLINKS<|vq_lbr\n\nIt looks like the text you provided is", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you posted is a mix of multiple languages and possibly some corrupted or random data. It doesn't seem", "<|vq_lbr_", "<", "<|vq_lbr_audio\n\nIt looks like you're trying to create a new file in a directory using a command line interface. However, the command you provided seems to be a mix of different languages and characters, which", "<|vq_lbr_image_12486|>", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random", "\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent sentence or paragraph. If you have a specific question or need assistance", "<|vq_lbr_audio_124437| 1.0.0.0.0.0.0.0.0.0.0.", "<|vq_lbr_audio_124437|>", "<|vq_lbr_userWhat is the best way to get a 2D array in Java?\n\nIn Java, you can create a 2D array using the following syntax:\n\n```java\nint[][] array = new int[rows][columns];\n```\n\nHere, `rows` and", "```\n\nIt looks like the text you provided", "<|vq_l", "<|vq_lbr_image_12457|>", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel", "/", "<|vq_lbr_image_12473|>", "c<|vq_lbr", "<|vq_lbr_124740|>", "<|vq_l", "<|vq_lbr_audio_124740|>", "<|", "<|vq_lbr_audio_124877|>", "er<", "<|vq_12471|>\n\nIt looks like your message got gar", "<|vq_l", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages", "<|vq", "<|vq_lbr_image_1240|>", "<|vq_lbr_124740|><\n\n", "<|vq_lbr_image_12486|>", "\u0438\u0435<|vq_lbr_image_1245|", "<|vq_lbr_image_1245|>", "<|vq_lbr_image_12486|>```\n\n", "<|vq_l", "<|vq_lbr_124740|>", "<|vq_", "<|vq_lbr", "\ufffd\ufffd\ufffd\ufffd\ufffd\u0081\u0082\u0083\u0084\u0085", "<|vq_", "<|vq_lbr_image_12486|>", "<|vq_lbr", "<|vq", "icesshould\n\nIt looks like the text you provided is a mix of different languages and symbols, making it difficult to understand. If you have a specific question or need assistance", "<|vq_lbr_audio_124437", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124", "<", "<|vq", "<|vq_lbr_audio_124215|>", "<|vq_lbr_124", "", "<|vq_lbr_image_", "<|vq_lbr", "\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel", "<", "<|vq_lbr_image_1245|>", "", "<|vq_lbr_audio", "\n\nIt looks", "\n\nIt looks like the text you provided is a mix of different languages", "<|vq_lbr_audio_124740|>", "<|vq_lbr_user", "<|vq_l", "ated\n\n```\n\n", "<", "jects<|", "<|vq_lbr_124044|>", "<|vq_12471|>\n\nIt looks like your message contains a mix of text", "\u043b\u0435\u043d<|vq_lbr_audio_", "<|vq_lbr_audio_124877|>", "<|", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled!", "<|vq_lbr_image_124", "<|vq_l", "<|vq", "<|", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand or provide a meaningful response. If you have a specific question or need assistance with a particular topic, please provide a clear and concise query, and I'll", "oruesi\n\nIt looks like", "<|vq_lbr_image_12486|>", "<|vq_lbr_audio_124437", "```\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you", "<|vq_lbr_audio_124877|>", "\u09be", "<|vq_12471|>\n\nIt looks like the text you provided", "<|vq_lbr_user|>\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. Could you clarify what you need help with? If you have a specific question or need assistance with a particular topic, feel", "<|vq_lbr_image_12486|>", "<|vq_lbr", "<|vq_lbr_user\n\nThe text you provided appears to be a", "<|vq_12471|>\n\n", "al<|vq_lbr_image_12457|>```", "<|vq_lbr_audio_124437|>", "<|vq_lbr_image_1245|>", "<|vq_lbr\n\n", "<|vq_12471|>\n\n", "s<|vq_lbr_124740|>", "\n\n", "ProgressBar<|vq", "ine<|vq_lbr_124740|", "[\n\nIt", "<|vq_lbr_image_12486|>", "\n\n", "<|vq_lbr_image_12486|>", "<|vq_lbr_image_12457|>", "<|vq_lbr_124740|>", "<|vq_lbr_image_12486|>\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't form a coherent or understandable sentence.", "<|vq_lbr_124740|>", "ology<|", "<|vq_lbr_image_12486|>", "<|vq_l", "\ufffd<|vq_lbr_124740|>", "<|vq_lbr_audio_124437|>", "<|vq_lbr_124740|>", "<|vq_12473|>\n\nIt looks like your", "<|vq_lbr_userWhat is", "<|vq_lbr", "<|vq_lbr_image_12486", "\n\nIt", "", "<|vq_lbr_audio_124740|>", "<|vq_12471|>\n\nIt looks like the text you provided is", "<|vq_lbr_image_12486|>", "<|vq_lbr_audio_124215|>", "<|vq_lbr_audio_124437|>", "<", "<|vq_lbr_image_12457|>", "<|", "<|vq_lbr_audio_124215|>", "<|vq", "able<", "<|vq_lbr_image_12486|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic,", "<", "<", "an<|vq_lbr_124740", "\uc11c<|vq_lbr_image_12486|>", "<|vq", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you provided", "<|vq_lbr_audio_124437|>", "<|vq_lbr_image_12486|>", "<|", "<|vq_lbr_audio_124740|>", "", "<|vq_lbr_audio_124877|>", "<|vq_lbr_124740|>", "<|vq_lbr_124740|>", "\n\nIt looks like your text is", "<|vq_lbr_audio_124437|>", "<", "", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you provided is a mix of different languages and characters, and", "", "<|vq_lbr_image_12486|>", "<|vq_lbr_image_124", "<|vq_lbr_124740|>", "<|vq_lbr_image_12457|>```\n\nIt looks like the text you posted is a mix of different languages and possibly some code or data that got scrambled. If you have a specific question or need help", "<|vq_lbr_124740|>", "<", "\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand or translate. If you have a specific question or need assistance", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_124740|>", "<|vq_lbr_image_12471|", "<|vq_lbr", "<", "\n\nIt looks like you're trying to create a script that uses the `ffmpeg` command to extract a specific segment from a video file. However, the script you", "", "<|vq_lbr_audio_124740|>", "<|vq_lbr\n\nIt looks like the text you provided is a mix of different languages and characters, making", "<|vq_lbr_image_12486|>", "<", "<|vq_lbr_", "\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a garbled or corrupted output. It", "<|vq_lbr_user\n\nIt looks like your message got a bit garbled! If you have", "<|vq_lbr_audio_124740|>", "<|vq_lbr_124740|>", "<", "<|vq_lbr_audio_124437|>", "\n\n", "<|vq_lbr_audio_124740|>", "<|vq_lbr_", "<|vq", "<|vq", "\n\n", "<|vq_lbr_audio_124740|>", "<|vq_lbr_user\n\nIt looks like your message got a bit garbled! If you have a specific question", "<|vq_lbr_124740|>", "<|vq_lbr\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel free to ask!\n\nIt looks like your message got a bit garbled! If you have a\n\nIt looks like your message got a bit garbled! If you have a\n\nIt looks like your message got\n\nIt looks\n\n", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and", "<|vq_lbr_image_12471|>```\n\nIt looks like the text you", "<|vq_lbr_image_124", "<|", "<|vq_lbr_audio_", "<|vq_lbr_image_1245|>", "isse<|vq_lbr", "\n\n```", "<|vq_lbr_audio_124437| \n```", "<|vq_lbr_image_12486|>", "<|", "<|vq_lbr\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text", "<|vq_lbr_image_12486|>", "<|vq_lbr_124740|>", "<", "<|vq", "<|vq_lbr_image_12486", "<", " 1. 2. 3. 4. 5. 6. 7", "<|vq", "<|vq_lbr_124", "<", "\n\n```\n\nIt", "<|vq_lbr_image_12486|>", "Title<|vq_lbr_124740|>", "\t\t{\n\t\t\t\"role\": \"assistant\",\n\t\t\t\"content\": \"I am an\n\n", "<|vq", "", "<|vq_lbr_124740|>", "<|vq", "<|vq", "<", "<|vq_lbr_audio_124740|>", "<", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't form a coherent sentence or phrase.", "<|vq_lbr_image_1240|>", "", "<|vq_lbr_124740|>", "<|vq_lbr_audio", "<|vq_lbr_audio_124740|>", "<", "<|", "<|vq_lbr_image_1245", "ue", "<|vq_124", "ade<|vq_lbr_image_12486|>", "<|", "<|", "<|vq_lbr_audio_124", "<", "<|vq_lbr_audio_124740|>", "<|vq_12471|>\n\nIt looks like your message contains a mix of different languages and symbols, making it", "<|vq_12471|>\n\nIt", "<", "<|vq_12471|>\n\nIt looks like the text you", "ies<|vq", "\n\nIt looks like your text is", "<|vq", "\n\nIt looks like your message contains a mix of text in multiple languages and possibly", "<|vq_lbr_124740|>", "\n\nIt looks like your message contains a mix of text in multiple languages and possibly some code or data that got scrambled. If you have a specific question or", "<|vq_lbr\n\nIt looks like the text you provided is a mix of different languages and characters, making", "<|vq_lbr_audio_124740|>", "\n\n[\n\nIt looks like the text you provided is a", "ard<|", "<", "ENTIAL<|vq_12471|>\n\nIt looks like", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124", "<|vq_lbr_124740|><\n\nIt looks like you're trying", "<|vq_lbr_image", "<|vq_lbr_audio", "<|vq_lbr_124", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to", "<|vq", "<|vq_lbr_image_12486|>", "<|vq_", "<|vq_lbr_image_1240|", "<|vq_l", "<|vq_lbr_audio_124437|", "<|vq_lbr_userWhat is", "<|vq_lbr_audio_", "<|vq_lbr", "<", "<|vq_lbr_124740|>", "<|vq_12471|>\n\n", "<|vq_l", "arerect", "<|", "<|vq_lbr_image_12473|>", "<|vq_lbr_124740|>", "<|vq_l", "\n\n[\n\nIt", "", "<|vq_lbr_image_12486|>", "<|", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and appears to", "<|vq_lbr_audio_124437", "<|vq_lbr_124819|>", "<|vq_lbr\n\nIt looks like the text you provided is", "\n\nIt", "<|", "<|vq_lbr_image_12457|>", "<|vq_l", "<|vq_lbr_audio_124437|>", "<", "<|vq_lbr_audio_124437|>", "<|vq_lbr_user|>\n\nIt looks", "<|vq_12471|>", "<|vq_lbr_audio_124740|", "<|vq_lbr_audio\n\nIt", "<|vq_lbr\n\nIt looks like the text you provided is a mix of multiple", "<", "<|vq_lbr_image_12486|>", "<|vq_lbr_audio_124215|>", "<|vq_lbr_audio_124877|>", "or<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you posted is a mix of multiple languages and possibly some random characters or code snippets. It seems to be a garbled or corrupted", "ility<|vq_lbr_image_", "<", "<", "<|vq_lbr_audio_124740|", "<|vq_12471|>\n\nIt looks like the", "<|vq_lbr_", "<|vq_lbr_image_12486|", "\n\n```", "<|", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of random characters and words from various languages, making it difficult to understand or provide a meaningful", "<|vq", "<|vq_lbr_audio_124437|>", "<|vq_lbr_audio", "<|vq_lbr_image_1245|>", "se", "<|vq_l", "<|vq_lbr", "<|vq_lbr_audio_", "<", "\n\n[", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't", "<|vq_lbr_user|>\n\nIt", "<|", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel", "<|vq_lbr_124740|>", "<|vq_", "<|vq_lbr_audio_124215|>```\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't", "<|vq_lbr_124740|>", "ri<|vq_lbr_124740|>", "<", "<|vq_lbr_audio_124437|>", "z\n\nIt looks", "\ufffd ", "<|vq_lbr", "```\n\nIt looks like the text you provided is a mix of random characters and phrases in multiple languages", "<|vq_lbr_image_1240|>", "<|vq_lbr_audio", "<", "<|", "<|vq_lbr_image_1245|>```\n\nIt", "\n\nIt looks like the text you provided is a", "<|vq_12471|", "<", "<|vq_lbr_audio_124740|", "/\n\nIt looks", "as<|vq_lbr\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance", "afarian<|vq_lbr_image_12486|>", "", "", "<|vq_lbr_audio_124740|>", "ing", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and characters", "\n\n", "\n\n", "<|vq_lbr_124740|>", "<|vq_lbr\n\nIt looks like your message got a bit garbled! If you have", "<|vq_lbr_image_12486|>", "<|vq_lbr_audio_124215|>```\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't seem to form a coherent sentence", "<|vq_lbr_image_124", "<", "\u1014\u103a", "<|vq_lbr_124740|>", "<|vq_", "<|vq_lbr_user|>\n\nIt looks like your message", "<|vq_lbr_audio_124740", "<|vq_", "<|vq_lbr\n\nIt looks like the text you provided is a mix of different languages and characters", "<", "<|vq_lbr_audio_124740|>\n\nIt looks like the text", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages", "<", "or<|vq_l", "<|vq_lbr_image_12486|>", "<|vq_lbr_audio_124437", "\n\n```\n\nIt looks like the text you provided is a mix of", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you provided is a mix", "<|vq_lbr_audio_124437|>", "<", "<|vq_lbr_audio_124740|>", "\n\n```\n\n", "<|vq_12471|>\n\nIt looks like your message got garbled or", "\n\n[\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent or meaningful sentence or paragraph. If you have a specific", "<", "ychology<|vq_lbr_image_12486|>", "<|vq_lbr_user|>\n\nIt looks like your message got a", "aps\n\nIt seems like the text you", "<|vq_lbr_image_1245|>", "<|vq_lbr_audio_", "<|vq_lbr_image_12457|>", "<|vq_12471|>\n\nIt", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you provided is a mix of different languages and", "\ufffd<|vq_lbr_audio_124215|>", "\n\nIt looks like your message contains a mix of different languages and possibly some random text. If you have", "<|vq_12471|>\n\nIt looks like the text you provided is", "<|vq_lbr_image_12486|>", "<|", "<|vq_124", "<|vq_lbr_audio_124740", "<|vq_lbr_124740", "<|", "<|vq_12471", "\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random", "<", "ystem<|vq_lbr_audio_124877|>", "\n\n```\n\nIt looks like the", "<|vq_lbr_124740|>", "ra<|vq_l", "<|vq_lbr_audio_124740|>", "\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or", "<|vq", "<|vq_lbr\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand the context or the specific request. If you", "<|vq_lbr", "```\n\nIt looks like the text you provided", "\n\nIt looks like the text you provided is", "<|", "<|vq_lbr_image_12473|>", "\n\n", "<|vq_lbr_image_12486|>", "\u0430\u0442<|vq_lbr_audio_", "<|vq_lbr_image_12486|>", "", "<|vq_124", "<|vq_lbr_image_1245|>\n\nIt", "<|vq_lbr_image_12457|>", "<|vq_lbr_audio", "<|vq_lbr_image_12457|>", "<", "<", "<", "<|vq_lbr", "<|vq_lbr_124740|>", "<|vq_lbr", "<|vq_lbr", "\n\n```\n\nIt looks like the text you provided is", "<", "", "<|vq_12471|>\n\nIt looks like your", "<|", "<|vq_lbr_124740|>", "<|vq_lbr", "<|vq_l", "<|vq_lbr_image_1245|>", "elihood<|vq_lbr\n\nIt looks like your message got garbled or mixed up with a lot of", "<|vq_12471|>\n\nIt", "<|vq_lbr_image_12486|>", "<|vq_lbr_image_12473", "<", "<|vq_lbr\n\nIt looks like the text you provided is a mix of different languages and", "cover\n\nIt looks", "<|vq_lbr_image", "<|vq_lbr_124740|><\n\nIt looks like the text you provided is a mix of different languages and symbols, making it difficult to understand or translate accurately. If you have a specific part", "<|vq_lbr_image_12457|>", "<|vq_lbr_image_12486|>", "<|vq_12471|>\n\nIt looks like", "ir<|vq_lbr_audio_124437|>", "<|vq_lbr\n\nIt looks like the text you provided is a mix of different languages and symbols, making", "<|vq_lbr_audio_124437|>", "<|vq_lbr_audio_124215|>", "```", "<|vq_12471|", "<|vq_lbr\n\nIt looks like your message got a bit garbled! If you have a specific question", "<", "\u043d\u044b\u0439<|vq_lbr_user|>\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. Could you clarify what you", "<|vq_lbr_image_1245|>", "<|vq_l", "<|vq_lbr_image_12486", "<", "*", "<|vq_12471|>\n\nIt looks like", "binations\n\nIt looks", "<|vq", "<|vq_lbr_image_12486|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a", "```\n\nIt looks like the text you posted is a mix of random characters and", "\n\n", "<|vq_lbr", " \ufffd \ufffd\n\nIt looks", "<|vq_lbr_audio_124877|>", "ACH<|vq_l", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_124740|>", " 0.5\n\nIt looks like the text you posted is a garbled mix of code, comments, and possibly some corrupted data. It appears to be a mix of Java code and", "\n\n", "<|vq_lbr_audio", "<|vq", "<|vq_lbr_124740|>", "<|vq_lbr\n\nIt", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! If you have a specific question or need help", "r<|vq_lbr_124740|>", "<|vq_lbr_audio_124740|>", "<|vq_lbr_124740|", "<|vq_lbr_user", "<|vq_lbr_image_12486|>", "<|vq", "<|vq_lbr_image_1245|>", "<", "<|vq_lbr_image_12486|>```\n\nIt looks like the text you", "<|vq_lbr_image_1245|>\n\nIt looks like the text you provided is a mix", "<|", "<|vq_lbr_124740|>", "<", "\n\nIt looks like your message got garbled and turned into a massive block of text that doesn't make sense", "\n\nIt looks like the text you provided is a mix of different languages and symbols, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please provide", "<|vq_lbr_image_12486|>", "<|vq_lbr_124740|>", "<|vq_lbr_124819|>", "<|vq_l", "<|vq_lbr", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! If you have a specific question or need", "<", "<|vq_l\n\nIt looks like the text you provided is a", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! Could you clarify what you're looking for or ask your question again? I'm", "<", "\n\n```", "<", "<", "or<|vq_lbr_image_12457|>", "<|vq_lbr_image_12486|>\n\nIt looks", "ink<|vq", "<|vq_lbr\n\nIt looks like", "<|vq_lbr\n\nIt looks like your message got gar", "<|vq_lbr_image_1245|>", "<|vq_lbr_audio_", "<|vq_lbr_audio_", "", "Text<", "<", "<|vq_lbr_124740|><\n\nIt looks like the", "<|vq_lbr_124740|", "<|vq_lbr", "/\n\nIt looks like your message got gar", "", "<|vq_lbr_image_", "<|vq_lbr_124740|>", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a", "<|vq_12471|>\n\nIt looks", "<|vq_l", "<|vq_lbr_image_12471", "<|vq", "<|vq_lbr\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel", "<|vq_12471|>\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel", "\n\n", "<|vq_lbr_audio_124740|>", "<|vq_lbr_124740|", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124740|>", "<|vq_lbr", "\ufffd<", "<|vq_lbr_audio_124437|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to", "<|vq_lbr_audio_124740|>", "<|vq_lbr", "<", "<|vq_lbr_image_1240|>", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you", "<|vq_lbr_image_12486|>\n\nIt looks", "<", "<|vq_lbr\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel\n\nSure! Here\n\n", "", "<", "<|vq_lbr_audio_124740|>", "<|vq_lbr_124740|>", "List<|vq_12471", "<|vq_lbr_124740|>", "<|vq_12471", "\n\nIt looks like", "<|vq_lbr_audio_124740|>", "\n\nIt looks like your message contains a mix of text in multiple languages and possibly some code or data that might be corrupted or incorrectly", "\n\n```\n\nIt looks like", "<|vq_lbr", "<|vq_lbr_image_1243|>", "<|vq_lbr_audio_124215|>\n\nIt looks like the text you provided is a mix", "<", "<|vq_lbr_124740|>", "<|vq_lbr_image_1245", "<", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_124740|>", "<|", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and", "<|vq_l", "<|vq_lbr", "<|vq_lbr_audio_124740|>", "", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! Could", "<|vq_lbr_audio_124740|>", "<|vq", "<|vq_lbr_124740|>", "<", "\n\nIt looks like your message contains a mix of text in multiple languages and possibly some code or data", "<", "<|vq_lbr_image_1245|>", "<|vq_lbr_image_1245|>```\n\nIt", "", "<|vq_lbr_image_12471|>```\n\nIt looks", "<|vq_lbr_audio_124740|>", "<|vq_lbr_124740|>", "\n\n```\n\n", "<|vq_lbr", "<|vq_lbr_audio_124437|>", "<|vq_lbr_audio_124437|>", "<|vq_12471", "<|vq_12471|>\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel", "<|vq_lbr_audio_124437|}\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel", "<|vq_lbr_image_1245|>\n\nIt looks like the text you", "<|vq", "", "<|vq_lbr_124740|>", "<", "<|vq_lbr_124740|>", "<|vq_12471|>", "ic<|vq_lbr_", "\ufffd 0\ufffd 0\ufffd 0", "\n\n```\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't form a coherent sentence or paragraph. If you have a specific question or need assistance with a particular", "<|vq_lbr_124740|>", "<|vq_l", "<|vq_lbr_image_1245|>", "<|vq_lbr_124740|", "\n\n", "", "<|vq_lbr_124740|>", "<|vq_lbr_image_12486|>", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you posted is", "<|vq", "<", "<|", "<", "<|vq_lbr_audio_124437|>", "<|vq", "i<|vq_lbr_124740", "<", "<|vq_lbr\n\nIt looks like the text you", "<|vq_lbr_image_124", "ual<|vq_l", "<|vq_lbr_124740|>", "\ufffd<|vq_lbr", "<|vq_lbr_124819|>", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please provide a clear and concise request,", "<|vq_12471|>\n\nIt looks like your message contains a mix of text", "<|vq_lbr_audio_124215|>", "<|vq_lbr\n\nIt looks like your message got a bit garbled! If you have a specific question or", "<|vq_lbr_image_12471|>", "be\n\nIt looks like your message contains", "<|vq_l", "\u043d\u044b\u0439<|vq_lbr\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent sentence or paragraph. If you have a specific question or", "<|vq_12471|>\n\nIt looks like the text you provided", "quez", "\n\nIt looks like the text you", "\u043d\u043e", "<|vq_lbr_audio_124740|>", "<|vq", "<|vq_lbr_124740|>", "\n\n```\n\n", "<|vq_lbr_124740|><\n\nIt looks like the text", "<|vq_lbr_124740|>", "ion<|vq_lbr_124740|>", "\n\nIt looks like your message got a bit garbled", "<|vq_lbr_image_12473|>\n\nIt looks like the text you provided is a mix of different languages and characters", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_124740|>", "<|vq_lbr_image_1245|>```\n\nIt looks like the text you provided is a mix of different languages and symbols,", "<|", "<|", "<|vq_lbr_audio_124740|>", "\n\nIt", "<|vq_lbr_124740|>", "<|vq_12471|>\n\nIt looks like the text you provided", "", "<|vq_lbr_image_12457", "\n\n```\n\nIt looks like the text you provided is", "<|vq_lbr_userWhat is the best", "ations<|vq_lbr_audio_124215|>", "<", "\n\nIt looks like", "<|vq_lbr_image_12486|>", "<|vq_lbr_audio_124437| \n```\n\n", "\ufffd \ufffd\ufffd\ufffd\n\n", "<", "<|vq", "<|vq_lbr_image_12471|>", "<|vq_lbr_audio_", "<|vq_lbr", "<", "<", "<|vq_lbr_image_12486|>", "<|vq_lbr_audio_124437| \n```", "\u0442<|vq_lbr_audio_124740|>", "<|vq_l", "FileSync", "<", "```\n\nIt looks like the text you provided is a mix of multiple", "<|vq_lbr_124740|><\n\nIt looks like", "<|vq", "<|vq_lbr_audio_124", "<|", "<|", "<|vq_lbr_user|>\n\nIt looks like your message got", "<|vq_lbr_audio", "<|vq_lbr", "<|vq_lbr_audio_124740|>", "<|vq_l", "<", "\n\n```\n\nIt looks", "<|vq_lbr_audio_124215|>", "<|vq_lbr_audio_124215|><\n\n[assistant]\n\nIt looks like the text you provided is a mix of different languages and characters, and", "<|vq_lbr\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to be a coherent or meaningful", "<|vq", "<|vq_lbr_124740|>", "<|vq_lbr_124740|>", "\n\nIt looks like", "<|vq_lbr_124740|><\n\nIt looks like the text", "<|vq_lbr_image_12486|>", "<|", "<|vq_lbr_image_12457|>", "", "<|vq_lbr", "ats", "\n\n```\n\nIt looks like the", "<|vq_lbr_userWhat is the best way to get a 2D array in Java?\n\nIn Java, you can create a ", "<|vq_lbr_image_1245", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124740|>", "\n\nIt looks like your message contains a mix of different languages and possibly some random text. If you have a specific question or need assistance with something, please let me know, and I'll do my best to help!\n\nIt looks like your message contains a", "<|vq_lbr_image_12486|>", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_", "<|vq_lbr_124740|", "<|vq_lbr", "<|vq_l", "<|vq_lbr_audio_124215|>", "<|vq_12471|>\n\nIt looks like the text you provided is", "Message", "<", "<", "\n\nIt looks like the text you provided is a mix of", "<|vq_lbr_124740|>", "<|vq_lbr_image_12457|>", "<|vq_12471|>\n\nIt", "\n\n```\n\nIt looks like your message got a bit garbled", "<|vq_lbr", "<|vq_lbr\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent or", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of", ">\n\nIt looks like the text you provided is a", "<|vq_lbr_124740|>", "<|vq_lbr_124740|>", "<|vq_l", "<|", "\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent sentence or", "<|vq_lbr_124", "<|vq_lbr_image_12486|>", "<|vq_lbr|>\n\nIt looks like the text you provided is a mix", "<|vq_lbr_audio_124215|>", "<|vq", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124740|>", "\n\n", "\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel", "<|vq_lbr_audio_124437| \n```", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you posted is a mix of different languages and symbols", "<|vq_l", "<|vq_lbr\n\n", "<|vq_lbr_124740|>", "<|vq_lbr_audio_", "<|vq_lbr_124740|><\n\nIt looks like the text", "<|vq_lbr_audio_124215|>", "<|vq_lbr_audio_124740|>", "<|vq_lbr_image_1245|>", "", "<|vq_lbr", "<|vq_lbr\n\nIt looks", "<|vq_lbr_image_1245|>\n\nIt looks like the text you provided is a mix", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124477|>", "<|", "ctions<|vq_12471|>\n\nIt looks like", "<|vq_lbr_image_11504|>", "<|vq_l", "<", "ier", "<|vq_lbr_audio_124740|>", "\n\n", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124437|>", "<|vq_lbr_userWhat is the best way to get a job?\n\nThe best way to get a job can vary depending on your industry, experience level, and personal circumstances", "<|vq_12471|>\n\nIt looks like the text you provided", "<", "\n\nIt looks like your message contains a mix of text in multiple", "<", "iti", "<", "/\n\n", "", "<|vq_12471|>\n\nIt looks like the", "\n\n```\n\nIt looks like your message contains a mix of text in different languages and possibly some code or technical terms.", "<|vq_lbr_audio_124740|>", "<|vq_lbr", "\n\nIt looks like your message got garbled", "\n\nIt looks like the text you provided is a mix", "ies", "<|vq_lbr_audio_124215|>", "\n\n[\n\nIt looks like the text you provided is", "<|vq_lbr_audio_124740|>", "<|vq_l", "<|vq_lbr_124740|>", "<|vq_lbr\n\nIt", "\n\nIt looks like the text you provided is a mix of different languages and possibly some code", "<|vq_lbr_audio_124437|\n\n", "<|vq_lbr_image_12473|>", "<|vq_lbr\n\nIt looks like the text you", "<|vq_lbr_image_1245|>", "<|vq_lbr_user", "<|vq_lbr_audio", "<|vq_12471|>\n\nIt looks like your message got garbled or mixed", "<|vq_lbr_image_12457|>", "<", "<|vq_lbr", "<|", "<|vq_l", ")\n\nIt looks like the text", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent or meaningful sentence. If you have a specific question or need assistance with a particular topic, feel\n\nIt", "<|vq_lbr_audio_", "<|vq_lbr_124740|", "<", "<|vq_lbr_audio_", "<|vq_lbr", "\n\nIt looks like the text you", "<|", "<|vq_lbr_audio_124740|>", "\n\n", "<|vq_lbr_124740|>", "otes<|vq", "\n\n```\n\nIt looks like the text you provided is a mix of random characters and symbols,", "<|vq_lbr_124740|", "\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent sentence or paragraph. If you have a specific question or need assistance with a particular topic,", "<|vq_lbr_124", "selor<|vq_lbr_124740|>", "<|vq_lbr\n\nIt looks like the text you provided is a mix of random characters, symbols, and possibly some corrupted data. It doesn't form a coherent or understandable sentence or paragraph. If you have a specific", "<", "<|vq_lbr_audio_124740|>", "<|vq_l", "<|vq_l", "<|vq_12471|>\n\nIt looks", "<|vq_lbr_user=\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel free to let me know what you're looking for, and I'll do", "<", "iet<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you posted is a mix of different languages and symbols, possibly from a corrupted or incorrectly formatted document. If you have a specific question or need help with a particular", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters, making", "<|vq_12471|>\n\nIt seems like the text you provided is a mix of different languages and characters, making it difficult to understand or provide a meaningful response.", "<", "<|vq_lbr", "<|", "<|vq_12471|>", "<|vq", "<", "<|vq_lbr_124740|>", "```\n\nIt looks like the text you posted is a mix", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you posted is a mix of different languages and symbols, possibly from a corrupted or", "<|", "<|vq_lbr_audio", "<|vq_lbr_image_12486|>\n\n", "<", "<|vq_lbr_audio_124437|}\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If", "<|vq_12471|>\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel", "or<|vq_lbr_124740|>", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_124215|", "<", "<|vq_lbr\n\nIt looks", "<|vq_12471|>\n\nIt looks", "<|vq_lbr_image_1240|>", "<|", "<|vq_12471|>\n\n", "<|vq_lbr_audio_124877|>", "<|vq_lbr_124819|>", "\ufffd<", "ing<|vq_124", "<", "<|", "<|vq", "<|vq_lbr_124740", "<|vq_lbr_124740|>", "", "<|vq_lbr_image_1245|>", "<|vq_12471|>\n\nIt looks", "<|vq_lbr", "<|", "<|vq_lbr_audio_124437|>", "<|vq_lbr\n\nIt looks like", "<|vq_lbr_124740|>", "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!", "\n\nIt looks like the text you posted is a garbled mix of code, comments, and possibly some", "<|vq_lbr_image_1245|>", "<|vq_12471|>\n\nIt", "<|vq_lbr_audio_124740", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages", "\n\nIt looks like the text you", "\n\n", "<|vq_lbr_audio_124437|>\n\nIt looks like the text you provided is a mix of different languages and", "<|vq_lbr_audio_124740|>", "<|vq_lbr_124740|", "<|vq_lbr_image_1245|>", "<|vq_12471|>\n\nIt looks like the text you provided is a", "<|", "<|vq_12471", "<|vq_lbr_image_12486|>", "<|vq_lbr_user\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a", "\n\nIt looks like your message got garbled and contains a mix of unrelated text and code snippets. If you have a specific question or need help with", "<|vq_lbr_124740|><\n\nIt looks like", "<", "<|vq_lbr_audio_", "<|vq_lbr_user", "<|vq_lbr\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help", "\n\n```", "<|vq_l", "<", "<|vq_lbr_audio_124740|", "ARY<", "", "<|vq_lbr_audio_124877", "<|vq_lbr_audio_124437|>", "\n\n```\n\n", "<|vq_12471|>\n\nIt looks like the", "<|vq_lbr_user|>\n\nIt looks like your message got garbled or mixed up with", "<|vq_l\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. Could you", "<|vq_lbr_audio_124437|}\n\nIt looks like the text", "<|vq_lbr_124740|>", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124437|>\n\nIt looks", "<|vq_lbr\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel\n\nSure!", "<|vq_lbr_image_12486|>", "<|", "", "<|", "<|", "<|vq_lbr", "", "<|vq_lbr_audio_124740|>", "\n\nIt looks like your message", "<|vq_lbr_audio_124877|>", "\n\n", "<|vq_lbr", "", "<|vq_lbr_audio_", "\n\n```\n\nIt looks like", "<|vq_lbr\n\nIt looks like the text you", "<|vq_lbr_image_12471|>", "<|vq_lbr_image_12486|>\n\nIt looks like the text you provided is a mix of random characters and symbols that doesn't form a coherent or understandable message. If you have a specific question or need help with a particular topic, feel", "<", "VIDE\n\nIt looks like your message contains a mix of text in multiple languages and possibly some code or data that got scrambled. If you have a specific question or need help with a particular topic, feel", "<|vq_lbr_audio_124215|>", "<|vq_lbr_image", "<", "<|vq_lbr_image", "<|vq_lbr_124740|>", "<|", "<|vq_l", "<|", "<", "<|vq_lbr_image_12486|>", "<|vq_lbr_audio_124437|}\n\nIt looks", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and characters, making it difficult to understand or translate.", "<|", "ica<|vq_lbr_124740|>", "", "\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with", "iniaprevious<|vq_12471", "<|vq_lbr", "<|vq_12471|>\n\nIt looks", "<|vq_lbr\n\nIt looks like your", "/2/2/2/2/2/2/2/2/2", "<|vq_lbr_image_12457|>", "<|vq_lbr_audio_", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_", "\n\n```\n\nIt looks like the text you provided is a mix", "<|vq_lbr_audio_124437|>", "<|vq_lbr_audio", "\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please provide a clear and concise", "<|vq_lbr_user\n\n[User]\n\n\n\n[Assistant]\n\n\n\n[User]\n\n\n\n[Assistant]\n\n\n\n", "\n\n```\n\nIt looks like the text you provided is a mix of different languages and characters, and", "<|vq_lbr_image_12471|>", "/\n\nIt looks like your message got a bit garbled", "<|vq", "<|vq_lbr_audio_124740|>", "<|vq_lbr", "<|vq_lbr", "<|vq_12471|>\n\nIt looks", "<|vq_lbr_audio_124", "<", "<|vq_lbr_124819|", "<|vq_lbr_audio", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form", "<|vq_lbr_audio_124437|>", "<|vq_12471|>\n\nIt looks like your message", "<|vq_lbr_image_1240|>", "<|vq_12471|>\n\nIt looks like your message", "<|vq_l", "<|vq_lbr_124740|>", "\n\n[assistant]\n\n", "<|vq_lbr_audio_", "View<|vq_12471|>\n\nIt looks like your message contains a mix of text in multiple languages and possibly some code or data", "```\n\nIt looks like the text", "<", "<", "<|vq_lbr\n\nIt looks like your message got a bit garbled! If you have a", "", "<|vq_lbr_user\n\nThe user wants to know how many days\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser\n\nUser", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel", "<|vq_lbr_audio_124", "<|vq_l", "<|vq_lbr_image_124215|>", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_124437|>\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent", "<|vq", "<|vq_lbr_124740|><\n\nIt looks like the text you provided is a mix of random characters and phrases in multiple languages, which doesn't form a coherent or understandable request. If you have a specific question or need", "s<|vq_lbr_124740|>", "<|vq_12471|>\n\nIt looks like", "<|vq_lbr_124044|>", "\n\nIt looks like the", "Item<|vq_lbr_", "<|vq_lbr_audio_124437|}\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand.", "<|vq_12471|>\n\nIt looks like your message got garbled", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand.", "<|vq_lbr", "<", "<|", "\n\n```\n\nIt", "<|vq_lbr_audio_124437|", "<|vq", "<|vq_lbr_image_12456|>\n\nIt looks like there was", "<|vq_lbr_audio_124877|>", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_124740|>", "jects<|vq_lbr_124740|>", "<|vq_lbr_audio_124740|\n\nIt looks like the text you provided is a mix", "<|vq_lbr_image_1245|>", "<|vq_lbr_audio_124740|>", "ula\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent sentence or paragraph. If you have a specific question or", "<|vq_lbr_audio_124437| \n```\n\n", "<|vq_lbr_image_1245|>", "<|vq_lbr_audio_124740|", "<|vq_lbr_124740|>", "<|vq_lbr_124740|>", "<|vq_lbr_userWhat is the best way to get a job?\n\nThe best way to get a job can vary depending on your industry, experience level, and personal circumstances, but here are some general steps that can help you increase your chances of finding a job:\n\n1. **Self-Assessment**: Identify your strengths, skills, interests, and values. This will help you target jobs that are a good fit for you.\n\n2. **Resume and Cover Letter**: Create a professional resume", "<", "<|vq_lbr_audio_124437| \n```", "<|vq_12471|>", "<|vq_12471|>\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel\n\nIt looks like your message got a bit", "<|", "\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel", "\n\nIt", "ble<|vq_lbr_audio_124437|>", "<|vq_lbr_audio_124215|>", "de\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please provide", "<|vq_12471|>\n\nIt looks like your message", "<|vq_lbr", "<|vq_lbr_image_12486|>", "\n\n```\n\nIt looks like the text you provided is a mix of random characters and symbols, possibly due to", "<|vq_lbr_audio_124437|>", "<|vq_lbr_audio_124437|>", "<|vq_lbr_user\n\nIt looks like you're trying to create a new user in a PostgreSQL database using a Python script. However,", "<", "<|vq_lbr\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel\n\nIt looks", "<|vq_", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! If you have a", "<", "<|vq_12471|>\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel", "<|vq_lbr_image_12486|>", "ang<|vq_lbr_image_12486|>```\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or", "<|vq_lbr_image_12471|>", "\n\nIt looks", "Service", "<|vq_lbr_audio_124437|>", "\"]}\n\nIt looks like the text you provided is a", "<|vq_lbr_image_12486|", "<", "\n\n```\n\nIt looks like the text you posted is a garbled mix of multiple languages and characters, possibly due to a formatting error or a corrupted file. If", "<|vq_12471|>\n\nIt looks like your message got garbled or mixed up", "<|vq_lbr_124740|>", "<|vq_lbr_image_", "UPATION<|vq_lbr_124740|>", "\n\nIt looks like the text you provided is a", "<|vq_lbr_userWhat is the best way to get a job?\n\nThe best way to get a job can vary depending on your industry, location, and personal circumstances. However, here are some general steps that can increase your chances of finding a job:\n\n1. Identify your career goals: Determine what type of", "<|vq_12471|", "<|vq_lbr_image_1240|>", "<|vq_lbr_audio_124437|}\n\nIt looks", "<|vq_lbr_user", "<|vq_lbr\n\nIt looks", "<|vq_lbr_audio", "<|vq_lbr_audio_124437|>", "<|vq_lbr_audio_124877|>", "\n\n", "ablenew<|vq_lbr\n\nIt looks like your message got garbled or mixed up with a lot", "\ufffd<|vq_lbr_image_1245", "<|vq_lbr_", "<|vq_lbr_audio_", "<|", "<|vq_lbr", "<|vq", "<|vq_lbr_audio_124740", "<|vq_lbr_audio_124740|>", "", "ger\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand", "OfRangeException<|vq_12471|>\n\n", "<|vq_lbr_124", "l\n\n", "up<|vq_lbr_audio", "<|vq_lbr_124740|>", "<|vq", "<|vq_lbr_image_12486|>", " \ufffd\ufffd\ufffd\n\ufffd \ufffd\ufffd\ufffd\n\ufffd \ufffd\ufffd\ufffd\n\ufffd \ufffd\ufffd\ufffd\n", "\n\n[\n\nIt looks like the text", "<|vq_lbr_124740|>", "<|", "<|vq_lbr\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something,", "\n\n", "<|vq_lbr_audio_124", "<|vq_lbr_124740|>", "<|", "", "<|vq_lbr_image_12471|>", "<", "<", "<|vq_12471|>\n\nIt looks like your message got a bit garbled", "<|vq_lbr_userWhat is the best way to get a 2D array in python?\n\nThe best way", "<|vq_lbr_124740", "<|vq_lbr_image", "<|vq_lbr_audio", "<|vq_lbr_audio_124740|>", "<", "<|vq_lbr_audio_124740|>", "<|", "\u0acb<|vq_lbr_audio\n\nIt seems like the text you provided is a mix of different languages and characters, making it difficult", "<|vq_lbr_image_12486|>", "\n\n```\n\nIt looks like the text you provided is a mix of random characters, symbols, and words from various languages. It doesn't form", "<|", "<|", "<|vq", "<|vq_lbr_image_12486|>", "<|vq_lbr_image_12486", "<|vq_l", "ere\n\n```\n\nIt", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and", "\n\n", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific", "<|vq_lbr_124044", "<|vq_lbr_image_12471|>\n\nIt looks like the text you provided is a", "<|", "<|vq_lbr_audio_124740|>", "", "<", "<|vq_lbr_audio_124740|>", "<|vq_lbr_124740|><\n\n```\n\nIt", "<|vq_lbr_124740|>", "isk\n\n```\n\nIt looks like the text you provided is a mix", "\ufffd<|vq", "<|vq_lbr_audio", "<", "<|vq_lbr_image_12486|>", "", "<|", "<", "", "\u0cc6<|vq_lbr", "<|vq_lbr", "<|vq_lbr_image_1245|>", "<|vq_lbr_image_12486|", "\u03ae\u03c3\n\nIt looks like the text you provided is a mix of different", "<", "<|vq_lbr_124", "<|vq_lbr_audio_124215|>", "<|vq", "\n\nIt looks like your message", "<", "<|vq_lbr_124740|><\n\n", "<|vq_lbr_audio_124", "\n\n```\n\nIt looks like the text", "<|vq_lbr_image_124", "<|vq_12471|>\n\nIt looks like the text you provided is a mix", "AGE<|vq_12471|>", "<|vq_l", "<|vq_12471|>\n\nIt", "<|vq_lbr_124740|><\n\nIt looks like the text you provided is a mix of random characters and phrases that don't form a coherent or understandable request. If you have a specific question or need assistance with a", "<|vq_lbr_124740|>", "<|", "<|vq_lbr_image_12486|>", "<|vq_lbr_userWhat is the best way to get a good grade in a class?\n\nGetting a good grade in a class typically involves a combination of effective study habits, active participation", "<|vq_lbr_image", "<", "i\n\nIt looks like your message contains a mix of text in multiple languages and possibly some code or data that got scrambled. If", "<|vq_lbr_", "<|vq_lbr_image_12471|>", "<|vq_lbr_124740|>", "", "<|vq_lbr", "<|vq_lbr_user\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you", "<|vq_lbr_124740|>", "<|vq_lbr_124044|>", "<", "s", "ie<|vq_lbr_audio_124215|>", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and", "", "\n\n```\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't form a coherent sentence or question. If you have a specific question or need", "<|vq_lbr_image_12486|>", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters,", "<|vq_12471|>\n\nIt looks like your message contains a", "<|vq_lbr_124", "lich", "<|vq_lbr_audio_124437|>", "<|vq_lbr", "<|vq", "\ufffd \ufffd\n\n```\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't form a coherent sentence or paragraph. If you have a specific question or if there's something specific you'd like assistance with,", "<|vq_lbr_image_12471|>", "<|vq_lbr\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent sentence or paragraph. If you have a specific question or", "<|vq_lbr_image_1245|>", "<|vq_lbr", "<|vq_12471|>\n\nIt looks like your message got garbled", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124", "<|vq_lbr_image_1245|>", "ama<|vq_lbr_audio_124740|>", "<", "<|vq", "<|vq_lbr_audio_124437|>", "ident", "<|vq_12471|>\n\nIt looks like your message contains a mix of text in multiple languages and possibly some code", "\n\nIt looks like your message contains", "<", "\ufffd \ufffd\ufffd\ufffd\n\nIt looks like the text you provided is a mix of random characters and symbols, and it doesn't form a coherent or understandable sentence", "<", "\n\nIt", "<|vq_lbr_userWhat is the best way to get a job?\n\nThe best way to get a", "<|vq_lbr_image_1245|>```\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or", "<", "\n\n", "<|vq_lbr_124740|>", "", "<|vq_lbr_audio_124215|>", "<|vq_lbr_124740|", "<|vq_lbr\n\nIt looks like your message got garbled or mixed up with a", "<|vq_12471", "<|vq", "<|vq_lbr_124740|>", "\u0acb<|vq_lbr_user|>", "<|vq_lbr_audio_124332|>", "\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have", "\n\nIt looks like the text", "<|vq_lbr_image_12486|", "<|vq_lbr_image_12486|>", "<", "<|vq_lbr_image_12471|>```\n\nIt looks like the", "<|vq_lbr_image_12486", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124437|", "<|vq_l", "<|vq_lbr_user\n\nIt looks like your message got a bit garbled", "\n\nIt looks like your message contains a mix of text in multiple", "\n\nIt looks like the text you provided is a mix of", "\n\n[\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent or meaningful sentence or paragraph. If you have", "<|vq_lbr_124", "<", "\u0bc1\n\nIt looks like your", "\n\n", "<|vq_lbr_image_12471|>", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! Could you clarify what you need help with?\n\nIt looks like your message got a bit garbled!\n\nIt looks like your message got a bit garbled!\n\nIt looks\n\nIt looks\n\nIt looks\n\nIt looks\n\nIt looks\n\nIt looks\n\n", "<|vq_lbr_audio_124437|>\n\nIt looks like the text you provided is a mix of different languages", "\u043d<|vq_lbr_audio_124437|>\n\nIt looks like the text you provided is a mix of", "<|vq_lbr_user|>\n\nIt looks like your message got a", "<|vq_lbr_user\n\nIt looks like you pasted a", ">\n\nIt looks like your message got a bit garbled!", "<|vq_lbr_124740", "<|vq", "<|vq_12471|>\n\nIt looks like the text you provided", "<", "<|vq_l", "", "<|vq_lbr_124740|>", "<|vq_lbr_image_", "<|vq_lbr_image_124", "<|vq_lbr_image_12471|>", "<", "<|vq_l", "<|vq_l", "", "<|vq_lbr_audio\n\nIt looks like the text you provided is a mix of multiple languages and", "i\n\nIt", "ot<|vq_lbr_124740|>", "<|vq_12471|>\n\nIt", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! If you have a specific question", "<|vq_lbr_image_12486|>", "<|vq_lbr\n\nIt", "\n\nIt looks like your message got garbled or mixed up with a", "\n\n```\n\nIt looks like the text you provided is a mix of", "", "<", "<|vq_lbr\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand or translate", "<|vq_lbr_audio\n\nIt", "<|", "<|vq_lbr", "0\n\nIt", "<", "<|vq_l", "<|vq_lbr_audio_124437", "<|vq_lbr_audio_124215|>", "<|vq_lbr_audio_124740|>", "<|vq", "", "<|vq_lbr_image_124", "<|vq_lbr_audio_124215|>", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! If you have a specific question or", "<|vq", "<|vq_lbr_audio", "<", "<|vq_lbr_audio_", "<|vq_lbr\n\n", "", "<|vq_lbr_userWhat is the best way to get a good grade in a class", "<|vq_12471|>\n\n", "\ufffd<", "<|vq_lbr_audio_124215|>", "<|vq", "<|vq_12471|>\n\nIt looks like the text you provided", "<|vq_lbr\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel\n\nSure! Here\u2019s", "\u0438\u0439\u0441\u043a\u0438\u0439<|vq_lbr_audio", "<", "<|vq_lbr_image_12471|>", "<|vq_lbr", "Pane\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a", "<|vq_lbr_image", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you provided is a mix of different languages and characters,", "Key<|vq_lbr_image_12486|>", "<|vq_lbr", "<|", "<|", "<|vq_lbr_user=\n\nIt looks like your message got a bit garbled! If you have a specific", "\n\n", "<|", "\n\n[\n\nIt looks like the text you provided is a mix of", "<|", "<", "<|vq", "<|vq_lbr", "\n\nIt looks like the text you provided", "<|vq_lbr_audio_124877|><\n\nIt looks like the text you", "<|vq_12473|>\n\nIt looks like your message got garbled or mixed up with a", "<|vq_lbr_image_1240|>", "<|vq_lbr_image_12486|>", "<", "<|vq_lbr_audio_124740", "ages", "\n\n```\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't form a coherent sentence or question", "<|vq_lbr", "<|vq_lbr_user\n\nIt", "", "<|vq_lbr_audio_124", "<|vq_lbr_audio_124437| \n```\n\nIt looks like", "\n\n```\n\nIt looks like the text you provided", "<|vq_lbr_image_12486|>", "<|vq_lbr_audio_124", "<|vq_lbr_124740|>", "<|vq_lbr_image_12486|>", "\n\nIt looks like your message contains a mix of different languages and possibly some random text. If you have a specific question", "<|", "ac\n\nIt looks", "<|vq_lbr_image", "<|vq", "/", "<", "<|vq_lbr_user|>", "<", "igh\n\nIt", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124215|>", "ime", "<|vq_lbr_image_12471|>\n\nIt looks like the text you provided is a mix of different languages and possibly some random characters. It seems", "<|vq", "<|vq_lbr\n\nIt looks like the", "<|vq_lbr_124740|><\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a", "Builder<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and symbols, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please provide a clear and concise request, and I'll do my best to help you.\n\nIt looks like the text you", "\n\nIt", "\n\n```\n\nIt looks like the text you provided is a mix of different languages and characters,", "<", "<|vq_lbr_124740|>", "<|vq_lbr_124740|>", "\n\nIt looks like the text", "<|vq_lbr\n\nIt looks like the text you provided is", "```\n\nIt looks like the", "<|vq_lbr", "<|vq_12471", "ium<|vq_12471|>\n\nIt looks like the text you", "<|vq_lbr_audio_124437|>", "<|vq_lbr\n\nThe problem is to compute the number of ways to partition a set of N elements into K non-empty subsets (i.e., the Stirling numbers of the second kind", "<|vq_lbr_124740|>", "ic<|vq_lbr_audio_124437| \n```", "<|vq_12471|>\n\nIt looks like your message contains", "<|vq_lbr_audio_124437| \n```", "<|vq_lbr_image_12486|>\n\nIt looks like the text", "<|vq_lbr\n\nIt looks", "<|vq_lbr_image_12486|>", "<", "<|", "<|vq", "```\n\n", "<|vq_lbr_124740|>", "<", "\n\n", "<|", "<|vq_lbr_image_12473|>", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you provided is a mix of different languages and characters,", "\n\nIt looks like your message contains a mix of text in multiple languages and possibly some", "\n\n```\n\nIt looks like the", "<|vq_lbr_audio_124215|>", "<|vq_lbr_audio_124437|>", "<|vq_lbr_user|", "<|vq_lbr_image_12486|>", "<|vq_lbr_audio_124437|>", "<|vq_12471|", "\n\n", "<|vq_lbr_image_1245|", "Ptr<|vq_lbr_audio", "<|vq_lbr_audio_124437|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have", "<", "\n\nIt looks like your message contains a mix of text in multiple languages and possibly some code or data that might be corrupted or incorrectly formatted. If you have a specific question or need help with a particular topic, could you please clarify or provide more details? This will help me give you a more accurate and helpful response.\n\nIt looks", "<|vq_lbr_124740|><\n\nIt looks like the text you provided", "<|vq_lbr\n\nIt looks like the text you provided is a mix of random characters and phrases in multiple languages, which doesn't form a coherent or understandable request. If you have a specific", "<|vq", "\n\n```\n\nIt looks like the text you provided is a mix of different languages and", "<|vq", "<|vq_lbr_124740|>", "<", "<|vq_lbr\n\nIt looks", "\n\nIt looks like the", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! If you have", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't seem to form a coherent sentence or", "<", "<|vq_lbr_audio_124740|>", "<|", "\n\nIt looks like the text you provided is a mix of multiple languages and appears to", "<|vq_lbr_audio_124877|>", "<|vq_12471|>\n\nIt looks like the text you provided is", "<|vq_lbr_audio_124740|>", "To\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please provide", "<|vq_lbr", "<|vq_12471|>\n\n", "<|vq_12471|>\n\nIt looks like the text you", "<|vq_lbr_audio_124437|>", "its<|vq_lbr_image_124", "<|vq_lbr\n\nIt looks like the text you provided is a mix of random characters and phrases in multiple languages, which doesn't form a coherent or understandable request. If", "<|vq_lbr_audio_124215|>", "<|vq_lbr_audio_124437| \n", "<|vq_lbr_image", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you provided is", "<|vq_12471|>\n\nIt seems like the text you provided is a mix of different languages and characters, making it difficult to understand", "\n\nIt looks like the", "", "<|vq_lbr_audio_124", "as\n\n```\n\nIt looks", "<|vq_lbr_user\n\nIt looks like you're trying to create a", "<|", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or", "<|vq_lbr_image_1245|>", "<|", "<|vq_lbr_image_12486|>", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel", "<|vq_lbr_audio_124437|>\n\nIt looks", "\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you provided is a mix", "<|vq_lbr_124740|>", "<|vq_lbr_image_12486|>", "<|vq_lbr", "<|vq_lbr", "<", "<|vq_lbr_124740|>", "Y<|vq_lbr_image_12457|>", "\n\n```\n\nIt looks like the text you provided is a mix of different languages and characters", "```\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to", "\n\n```\n\nIt looks like the text you provided is a mix of multiple languages and possibly some corrupted or nonsensical data. It appears to be a gar", "matisme<|vq_lbr_audio", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of", "<|vq_lbr_124", "<|vq_lbr", "\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please provide a clear and concise request, and I'll do my best to help", "", "<|vq_lbr_user\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you", "of\n\nIt looks like your message contains a mix of text in multiple", "\n\nIt looks like your message", "<|vq_lbr_audio_", "<|vq_12471|>\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you", "<|vq", "<|vq_lbr_image_1245", "<", "<|vq_l", "<|", "<|vq_lbr_", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of", "<|vq_lbr_audio_", "", "<|vq_lbr_audio_124740|", "<|vq_lbr_audio_124215|>\n\nIt", "<|", "<", "<|vq_lbr_124740|>", "<|vq_lbr", "<|vq_lbr_124740|>", "\n\n```\n\nIt looks like the text you posted is a", "<|vq_lbr_audio_124437|>", "<", "<|vq_lbr_124740|>", "\n\n```\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't seem to form a coherent sentence or", "<|vq_lbr_image_1245|>\n\nIt looks like the text you provided is a mix", "<|vq_lbr_image_12486|>", "<", "<|vq_lbr_audio_124740|", "<|vq_lbr", "<|vq_lbr_image_1245|>\n\n", "<|vq_lbr_image_12457|>", "ff<|vq_lbr_image_", "<|vq_lbr_audio_124437|}\n\nIt looks like the text you provided is a mix", "<|vq_lbr_image", "<|vq_l", "<|vq_lbr_image_12486|>\n\nIt looks", "\n\n", "<|vq_lbr", "\n\nIt looks like your message contains a", "\n\n", "<", "<|vq_lbr_124740|>", "<|vq_lbr_image_11504|>", "<|vq_lbr\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form", "<|vq_lbr_image_12486|>", "<|vq_lbr_audio_", "ik<|vq_lbr_audio\n\nIt looks like the text you provided", "n", "able", "<|vq_l", "<|vq_lbr_image_12471|>", "<|", "<|vq_lbr_image", "<|vq_lbr_audio_124740|\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand or translate. If you have a specific question or need assistance with a particular part of the text, please let me\n\nIt looks like the text you provided is a mix\n\nIt appears that the text you provided is a mix of different languages and characters, making it difficult to understand", "\n\n```\n\nIt", "<|vq_lbr_audio_124437|}\n\nIt looks like the text you provided is a mix", "<", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you", "<|vq_lbr_124740", "\n\nIt looks like the text you provided is a mix of different languages and characters,", "<", "<|vq_lbr_124740|>", "<|", "<|vq_l", "<|vq_12471|>\n\nIt looks like your message contains a mix of text in", "\n\nIt looks like the text you provided is a mix of random characters", "\n\nIt looks like", "<|vq_12471|>\n\nIt looks like your message got a bit garbled! If you have a specific question or need help", "<", "<|vq", ")\n\nIt", "and", "<|vq_lbr_124740|>", "<|vq_lbr_image_12486|>", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_124740|>", "", "<|vq_lbr_audio_124740|>", "\ufffd<|vq_lbr_image_12486|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific", "<|vq_lbr_image_1245|>", "\n\n```\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't", "<|vq_lbr_audio_124437|>", "", "\n\nIt looks like the text you provided is a", "<|vq_lbr_124740|><\n\n", "<|vq_lbr_image_124215|>\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't seem to form a coherent or understandable sentence. If", "\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\nIt looks like the text you provided is a random collection of characters and symbols that doesn't form a coherent sentence or paragraph. If you have a specific question or need assistance with something, feel\n\nIt looks like the text you provided is a random collection of characters and symbols that doesn't form a coherent\n\nIt", "<|vq_lbr_image_1245|>\n\nIt looks like the text you provided is a mix of multiple languages and appears to", "<|vq_lbr_user\n\n", "<|vq_lbr_124740|>", "<", "<|vq_l", "<|vq_lbr_124740|>", "<", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_124215|>", "<", "<|", "<|vq_lbr_image_1245|>\n\nIt", "<|vq_lbr_image_12486|>", "<", "<|vq_lbr_image_12473|>", "<", "<|vq_124", "<|vq_", "<", "<|vq_lbr_124740|>", "<|vq_lbr_image_124", "<|vq_l", "<|vq_lbr", "<|vq_lbr_audio_124740|>", "<|vq_12471|>\n\nIt looks like", "<|vq_l", "<|vq_lbr_audio_124877|>", "\n\n```\n\nIt looks like the", "\n\nIt looks like the text you provided is a mix of different languages and symbols, and it doesn't form a coherent sentence or request. If you have a specific question or need assistance", "<|vq_", "<|", "\n\n```\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel\n\nIt looks like your message got a bit", "<|vq", "<", "<|vq_12471|>\n\nIt looks", "end<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words", "<|vq", "\n\nIt looks like the text you posted is a garbled mix of code snippets, comments, and possibly some unrelated text. It appears to", "", "<|vq_lbr_audio_124437|>", "ing<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you posted is a mix", "<|vq_lbr", "<|vq_lbr_image", "<|", "\u0440\u0430<|vq_lbr_audio_124215|", "<|vq_lbr_audio_124215|>", "<|vq_lbr_image_12486|", "<|vq_lbr_124740|>", "<|vq_lbr_user|>\n\nIt", "<|vq_lbr_user", "<|", "<", "<|vq_lbr_user", "<|vq_lbr_image_1243|>", "<|vq_lbr\n\n", "<|vq_lbr_audio_124740|>", "<|vq_lbr_image_12473|>", "<|vq_lbr_audio_124437", "<", "<|vq_lbr_124740|>", "page<|vq_lbr_124740|>", "<|vq_lbr_audio_124740|", "<|vq_lbr_audio_124437|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please let me know, and I'll do my best", "<|vq_12471|>\n\nIt looks like your message got a bit garbled! If you", "<|vq_lbr_", "<|vq_12471", "\n\nIt looks like your message got garbled or mixed up with a lot", "<|", "<|vq_lbr\n\nIt looks like your message got", "<|vq_lbr_user\n\n```\n\nIt looks like your", "", "", "", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem", "<", "<|vq_lbr_userWhat is the best way to get a", "", "", "", "", "", "\u0a41<|vq_lbr_image_1245|>\n\nIt looks", "<|vq_lbr_audio_124740|>", "<", "<|vq_lbr_image_1240|>", "<|vq_lbr_image_12457|>", "<|vq_lbr_audio_124877", "<|vq_lbr_audio_124877|>", "", "", "", "<|vq_lbr_124740|>", "", "", "<|vq_lbr", "<|vq_lbr", "<|vq_lbr_image_1245|>", "<|vq_lbr_user|>\n\nIt looks like", "<", "", "", "<", "<|vq_lbr_audio_124437|>\n\n", "", "", "", "<|vq_lbr_124740|>", "", "", "<|vq_lbr", "<|vq_lbr_audio_124437|}\n\nIt looks like the text you provided is a mix", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_124740|>", "<|vq_lbr_image_1245|>", "<|vq", "", "", "", "", "<|vq_lbr_image", "<|vq_lbr_audio_124740|>", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of", "", "<|vq_lbr_image_12486|>", "", "", "<", "ij<|vq_12471|>\n\nIt looks like the", "<|vq_lbr_image_1245|>", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of", "", "", "<|vq_lbr_124740|>", "<|vq_lbr_user\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something,", "\u0c3f<|vq_lbr_audio_124215|", "<|vq_lbr_image_1245|>\n\nIt looks", "<|vq_lbr", "", "", "", "", "", "<|vq_lbr_image_12471|>\n\nIt looks like your message got garbled or mixed up with a lot of", "", "", "", "", "", "ic<|vq_12471|>\n\nIt looks", "<|vq", "", "<|vq_lbr_image_12457|>", "", "", "", "", "", "", "", "", "", "<|vq_lbr_124740|><\n\nIt", "<|vq_lbr_image", "", "<|vq_lbr_124", "", "", "", "\n\n```\n\nIt looks like the text you posted is a garbled", "", "", "", "", "<|vq_lbr_audio_124740|>", "<|vq_lbr_image_1245|>", "", "ively<|vq_lbr_audio_124740|>", "<", "", "\n\nIt looks like your message contains a mix of text in multiple languages and possibly some code or data", "", "", "", "", "", "", "", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't form a coherent sentence or request. If you have a specific question or need assistance with something, please provide a clear and concise request, and I'll do my best to help you.\n\nIt looks like the text you provided is a mix of different", "<|vq_lbr_audio_124215|>", "<|vq_lbr_124740|>", "<|vq_lbr_userWhat is the best way to get a job?\n\nThe best way to get a job can vary depending on your industry, location, and personal circumstances. However, here are some general steps that can increase your chances of finding a job:\n\n1. Update your resume and cover letter: Tailor your resume and cover letter to highlight relevant skills and experiences for each job you apply to.\n\n2. Network:", "<|vq_lbr_124044|>", "<|vq_lbr_audio_124877|>", "ysics<|vq_lbr_image_12486|>", "<|vq_lbr_image", "<|vq_lbr_audio", "", "", "<|vq_lbr_image_12486|", "", "", "", "", "", "", "", ">", "<|vq_lbr_audio_124215", "", "", "", "", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent sentence or", "<|vq_lbr_audio_124437|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please provide a clear and concise request, and", "", "", "<|vq_lbr_124740|>", "\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel\n\n", "<|vq_lbr_image_124", "<", "", "<|vq_lbr_image_12486|>", "", "<|", "<", "", "", "", "", "<|vq_lbr_audio_124215|>", "<|vq", "<|vq_lbr_image_1245|>\n\nIt looks like the text you provided is a mix of different languages and possibly some random characters. If", "<|vq_12471|>\n\nIt looks", "<", "\n\n```\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a garbled or corrupted output. It doesn't seem to be a", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124437|>", "<", "<|vq_lbr_audio", "", "", "", "", "", "", "<|vq_12471", "<", "<|vq_lbr_124740|>", "", "<|vq_lbr_124740|>", "S<|vq", "<|vq_l", "", "", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random", "", "", "obally<|vq_lbr_124740|>", "\n\n```\n\nIt looks like the text you posted is a garbled mix of multiple", "", "", "\n\n```\n\nIt looks like the text you provided is a mix", "<|vq_lbr_124740|>", "", "", "", "", "", "<", "ed<|vq_lbr_124740|>", "<|vq_l", "", "<", "<|vq_lbr_image_", "<|vq_12471|>", "<|vq_lbr_image_12471|>```\n\nIt looks like the text you provided is a mix of different languages and symbols, and it doesn't form a coherent sentence or paragraph. If you have a specific question or if there's something specific you'd like assistance with, please let me know, and I'll do my best to help!\n\nIt looks", "or<|vq_lbr_image_", "```\n\nIt looks like the text you provided is a mix of multiple languages and appears to", "<", "\n\n```\n\nIt looks like the text you provided is a", "\n\nIt looks like your message got gar", "", "", "", "", "", "<|vq_lbr_image", "", "", "", "", "<|vq_lbr", "<|vq_lbr_image_12486|>", "<|vq_lbr\n\nIt looks like your message got gar", "", "", "<|vq_lbr_image_1240|>", "\n\nIt looks like the text you provided is a mix of different languages and possibly some code or technical terms. It", "<|vq_l\n\nIt looks like the", "", "", "", "", "ING<|vq_lbr_audio_124215|>\n\nIt looks like the text you posted is a mix of different languages and symbols,", "", "", "<|vq_lbr\n\nIt looks like your message got a", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you posted is a", "", "", "<|vq_lbr_user=\n\nIt looks like your message got a bit garbled! If you have a specific", "", "<|vq_lbr_124", "", "<|vq", "<|vq_lbr_image_1245|>", "", "", "", "", "", "", "\u0ac0<|vq_lbr_image_12471|>\n\nIt looks like the text", "<|vq_lbr", "<|vq_lbr_audio_124740|>\n\nIt looks like the text you provided is a mix of", "", "", "", "", "", "", "", "<|vq", "", "<", "<|vq_l", "<|vq", ")\ufffd<|vq_lbr_124740|>", "<|vq_lbr_image_12457|>", "<|vq_lbr_image_12486|>", "<|vq_l", "", "", "", "", "", "", "", "", "", "able<|vq_lbr", "leasepool<|vq_12471|>\n\nIt looks", "<|vq_lbr_image_1245|", "<|", "\n\n```\n\n", "<|vq_lbr_audio_124740|>", "<|vq", "<|vq_lbr_124740|>", "ple<|vq_lbr_audio_124437|>\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent or meaningful sentence or paragraph. If you have", "<|vq_lbr_124740|>", "", "", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel", "<|vq_lbr_124740|>", "", "", "", "", "", "<|vq_lbr_audio_124215|>", "<|vq_lbr", "<", "<|vq_lbr_audio_124740|>", "", "", "", "<|vq_l", "<", "<|vq_lbr_user\n\nIt looks like the text you provided is a mix", "<|vq_lbr\n\nIt looks like you're trying to create a comprehensive and detailed description for", "<|vq", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and", "", "<|vq_lbr_124740|>", "", "", "", "", "", "<|vq_lbr_image_12486|>", "<|vq_lbr", "<|vq_lbr_image_12486|>", "<|", "<|vq_lbr_audio_124437|}\n\nIt looks like the text you provided is a mix of different languages and characters", "\n\nIt looks like your message contains a mix of text in multiple languages and possibly some code or data that got scrambled. If", "<|vq_lbr_audio_124877|>", "<|", "<|vq_lbr_124740|>", "w\n\nIt looks like your message", "", "<|vq_lbr_image_124", "", "", "<|", "<|vq_lbr_image_12486", "\u0ba9\u0bcd\u0bbe\u0bcd<|vq_lbr_userWhat is the best", "<", "```\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have", "", "", "", "", "", "", "<|vq_lbr\n\nIt looks like the text you provided", "<|vq_12471|>\n\nIt looks", "", "", "", "<|vq_lbr\n\nIt looks", "<|vq_lbr_image_124", "<|vq_lbr_124740|", "<|vq_lbr_image_12486|>", "\ud55c<|vq_lbr\n\nThe text you provided appears to be a random collection of words and phrases in multiple languages", "<|vq_lbr\n\nIt looks like the text you provided is a mix of multiple languages and appears to", "<|vq_l", "\n\n", "", "zare<|vq_lbr_audio_124437|\n\nIt looks like you're", "", "\n\n```\n\nIt looks like the text you provided is a mix of different languages and characters, and it", "<|vq_lbr_audio", "", "\n\nIt looks like the text you provided is a", "<|vq_lbr_124740|>", "", "", "", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases.", "", "", "", "", "", "", "", "", "", "\u0d3f<|vq_lbr_image", "\n\n", "", "<|vq_lbr_audio_124740|>", "", "", "", "", "", "<|vq_12471|>\n\nIt looks like", "\n\n```\n\nIt looks like the text", "", "", "", "", "<|vq_l", "<|vq_lbr_image", "", "", "<", "\n\n", "<|vq_lbr_userWhat is the best way to get", "<|vq_lbr_124740|>", "", "<|vq_lbr_audio_124437|>", "<|vq", "", "", "", "\n\n```\n\nIt looks like the text you posted is a mix", "", "", "<|vq_lbr_", "\u0642<|", "", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! If you have a specific question or", "\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't form a coherent sentence or paragraph. If you", "", "", "", "<|vq_l", "Member<|vq", "", "", "", "", "", "<|vq_lbr_audio_124740|>", "\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to", "<|vq_12471|>\n\nIt looks like your message", "", "", "", "", "", "", "", "", "", "<|vq_l\n\nIt looks like the text you provided is a mix of random characters and phrases in multiple languages, which doesn't form a coherent or understandable request. If you have a specific question or need assistance with a particular topic", "<|vq_lbr_audio_124740", "<|vq_lbr_image", "rrr\n\nIt looks like the", "Event\n\nIt looks like the text you provided is a mix of different languages and symbols, making it difficult to understand. If you have a specific question or need assistance with a particular topic", "", "", "", "<|vq_12471|>\n\nIt looks like your message", "\n\n```\n\nIt looks like the", "<|vq_lbr_audio_124437|>", "<|vq_lbr_124761|", "", "```\n\nIt looks like the text you provided is", "<", "", "", "", "", "", "", "", "\n\n```\n\nIt looks like the text you provided", "\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form", "", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_124740|>", "<|vq_lbr_124740|>", "ktiv<", "<|vq_lbr_image_12473|>", "", "", "g<|vq_lbr_124740|>", "<|vq_lbr_124740|>", "", "", "", "<|vq_lbr_image_12486|>", "```\n\nIt looks like the", "\n\nIt looks like the text you provided", "", "", "", "<", "<|vq_lbr_124740|>", "\n\n[Assistant]\n\nIt looks like the", "<|vq_lbr_userWhat is the best way to get a", "", "<|vq_12471|>\n\nIt", "ik<|vq_lbr_user\n\nIt looks like the text you provided", "\ufffd \ufffd\ufffd\ufffd\r\n\ufffd\r\n\ufffd\r\n\ufffd\r\n\ufffd\r\n\ufffd\r\n\ufffd\r\n\ufffd\r\n\ufffd\r\n\ufffd\r\n\ufffd\r\n\ufffd\r\n", "\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't form a coherent sentence or phrase. If you have a specific question or if there's something specific you'd like assistance with, please", "", "", "<|vq_lbr_image", "<|vq_l", "", "", "<", "<|", "", "", "", "", "", "<|vq_124", "<|vq_lbr_audio_124877|>", "<|vq", "\n\nIt looks like your message contains a", "<|vq_lbr_image_1245|>\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent or meaningful sentence or paragraph. If you have a specific question or need assistance with a particular topic, feel\n\nIt looks like the text you provided is a mix", "", "", "", "", "", "", "<|vq_l\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand or translate. If you have a specific question or need assistance with a", "<|vq_lbr_image_", "", "", "", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't form a coherent sentence or question. If you have a specific question or need assistance with something, please provide", "<|vq_12471", "", "", "", "<|vq_12471|>\n\nIt looks", "", "", "<|vq_l", "<|vq_lbr_124740|>", "", "", "", "", "<|vq_lbr_image_12486|>", "", "", "", "", "", "", "<|vq_lbr_image_124740|><", "", "", "", "<|vq_lbr", "<|vq_lbr", "<|vq_lbr_userWhat is the best way to get a job?\n\nThe best", "<|vq", "<|", "", "", "", "", "", "", "<|vq_lbr", "<|", "", "", "ictions<|vq_lbr_user|>\n\nIt looks like your message got garbled or mixed up with a lot of", "<|vq_lbr_124", "", "", "", "", "", "\n\nIt looks", "UserId<|", "<|vq_lbr", "<|vq_lbr_image_1245", "", "<|vq", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "<|vq_lbr_audio_124877|>", "\n\n```\n\nIt looks like the text", "<|vq_lbr_image_12486|>```\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult", "\n\n```\n\nIt looks like the text you provided is a mix of different languages", "\n\nIt looks like the text you provided is a mix of", "<|vq_12471|>\n\nIt looks like the text", "<|vq_lbr\n\nIt looks like your message", "<|vq_lbr_audio_124437| \n```\n\nIt looks like", "<|vq_12471|>\n\n", "<|vq_lbr_image_12486", "<|vq_l", "", "", "", "", "<|vq_lbr_image_12486|>", "", "", "", "", "", "\n\n```\n\nIt looks like the text you provided is a mix of random characters and symbols, which doesn't form a coherent or understandable message. If you have", "\n\n```\n\nIt looks", "<|", "<|vq_lbr_image_12486|>", "", "", "", "", "", "", "<|vq_lbr_124740|>", "<|vq_lbr_124740", "", "", "", "", "", "", "", "\n\nIt looks like the text you provided is a mix of different languages", "", "", "", "<|vq_lbr_124", "<|vq_lbr_image_124", "\n\n```\n\nIt looks like the text you provided is a mix of random characters, symbols, and fragments of text in multiple languages. It doesn't form a coherent or understandable message. If you have", "", "", "\u00a0\u00a0<|vq_lbr_124740|>", "", "", "", "", "", "", "", "", "<", "<|vq_lbr_audio_124437|>", " \t<|vq_12471|>\n\n", "urerected<|vq", "<|vq_lbr_image_12486|>", "<|vq_lbr_124740|>", "", "<|vq_lbr_image_12486|>", "", "", "", "", "", "", "<|vq", "<|vq_lbr", "", "", "<|vq_lbr_", "<|vq_lbr_124740|>", "", "", "", "\n\nIt looks like the text you provided is a mix", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please", "", "<|vq_lbr\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel", "<|vq_lbr_audio", "", "", "", "", "", "", "", "", "", "", "", "userWhat is the answer", "<|vq_lbr\n\nIt looks like the text you provided is a mix of different languages and characters, making it", "<|vq_lbr_audio_124437|}\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with", "<|vq_lbr_audio_124437|>\n\nIt looks", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem", "<|vq_lbr_audio_124437|>", "\n\nIt", "<|vq_lbr_124740|>", "\n\nIt looks like your message contains a mix of different languages and possibly some random text. If you have a specific question or need assistance with something, please let me know, and I'll do my best to help!\n\nIt looks", "<|vq_l", "", "<|vq_lbr_audio_124437|>", "<|vq_lbr", "", "", "", "<", "<", "", "", "", "", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please", "<|vq_12471|>\n\nIt looks like the text you provided is a", "<|vq_lbr_image_124", "<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_124437|}\n\nIt looks like the text you provided is a mix of different languages and symbols, making it difficult to understand. If you have", "<|vq", "", "", "", "", "", "\n\n```", "<|vq_lbr_audio_124740|>", "<|vq_lbr\n\nIt looks like the text", "<|vq_lbr_124740|>", "ire<|vq_12471|>\n\nIt", "i\n\n```\n\n", "\u03bc<|vq_lbr_image_124", "<|vq", "", "", "", "", "<", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please provide a clear", "<|", "<|vq_lbr_image_12486|>\n\nIt looks like the text you provided is a mix of different languages and possibly some code or technical terms.", "\n\nIt looks like the text you provided is a mix of different", "", "\n\n```\n\nIt looks like the text you provided is a mix of different languages and characters", "<|vq_lbr_audio_124", "", "<", "<|vq_12471|>\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel", "", "", "", "", "", "", "", "", "", "<|vq_lbr_audio_124437|>", "<|vq_lbr_audio_124740|>", "", "<|vq_lbr_image_", "", "", "", "", "", "<|vq_lbr_image_1245", "", "", "<|vq_lbr_audio_124437| \n```", "\n\nIt looks like the text you provided", "", "", "", "", "", "<|vq_l", "", "", "<", "<|", "\n\nIt looks like the text you provided is a", "<|vq_lbr", "<|vq_lbr_image_12471|>", "", "", "", "", "", "", "", "<|vq_lbr_audio_124437|>", "\n\nIt looks like your message", "\n\n```\n\nIt", "<|vq_12471|>\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a", "<|vq_lbr\n\nIt looks like your message got a", "<|vq_124", "", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and characters, making it difficult to understand or provide", "<|vq_12471|>", "<|vq_lbr\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel", "<|vq_lbr_image_12471|>", "<|vq_lbr_image_1245|>", "", "", "<|", "<|vq_lbr_124", "", "", "", "<|vq_lbr_image_12486|>", "at\n\nIt looks like the text you provided is a mix of code snippets, comments, and possibly some corrupted or gar", "", "", "", "<|vq_lbr_image_1240|>", "", "", "", "", "", "<", "aus", "<|vq_lbr_audio_", "<", "<|vq_lbr_audio_124215|>", "", "", "<|vq_lbr_audio", "<|vq_lbr_image_", "\n\nIt looks like your message contains a mix", "<|vq_12471|>\n\nIt looks like you've pasted a large amount of text that appears to be a mix of different languages and possibly some code or data. If you have a specific question or need help with a particular part of this text,", "<|vq_l", "\n\n```", "", "", "\u0cbe<|vq_lbr_image_1245|>\n\nIt looks like the text you posted is a mix of different languages and possibly", "", "", "", "", "", "", "", "", "", "", "<|vq_l", "", "", "", "", "", "<", "ObjectContext<|vq_", "", "", "", "<|vq_lbr_124740|>", "<", "", "\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic", "<|vq_lbr_image", "<|vq_l", "<", "", "<|vq_lbr_audio_124740|>", "<", "", "", "", "", "<|vq_lbr_audio_124", "<|vq_lbr_image_12486|", "", "", "", "", "", "", "", "<|vq_lbr", "", "<|vq_lbr_audio_124877|>\n\nIt looks like the text you provided", "<", "", "", "<|", "ic<|vq_12471|", "", "", "", "", "<|vq_lbr_audio_124437|}\n\nIt looks like the text you provided is a mix of different languages", "\n\n", "", "\u093e<|vq", "\n\n```\n\nIt looks like the text you", "", "", "", "", "", "", "<|vq_lbr_audio_", "<|vq_lbr_124740|>", "", "", "<|vq_lbr_image_12457|>", "<|vq_lbr_image_1245|>", "<|vq_lbr_audio_124740|>", "", "", "", "<|vq_lbr_audio_124437| \n```", "\u00e4<|vq", "vency<|vq_lbr_audio_124215|>", "<", "", "", "<|vq_lbr_124740|>", "", "<", "\u001a\u001b\u001c\u001d\u001e\u001f !\"#$%&'()*+,-./012", "<", "<|", "", "", "", "", "", "", "", "", "", "", "<|vq_lbr_124740|>", "<|vq_12471|>\n\nIt looks like the text you provided is a mix", "", "", "<|vq_lbr_image_12473|>", "", "", "", "", "<|vq_12471", "", "", "", "", "", "<|vq_lbr_audio_124877|>", "<|vq", "<|", "<|vq_lbr\n\nIt looks like your message", "", "", "<", "<|vq_l", "<|vq_lbr_image", "", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of", "\n\nIt", "```\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent sentence or", "<|", "<|vq_lbr_image_12486|>", "<|vq_lbr_audio_124437|}\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please provide a clear and concise question in English, and I'll do my best to", "<|vq_lbr_audio_124740|>", "", "", "<|vq_12471|>\n\nIt looks like your message", "", "", "", "", "", "<|vq_lbr_audio_124740|", "<|vq_lbr_audio_124332|", "", "", "", "", "", "", "", "", "", "", "<|vq_l", "", "", "", "", "<|", "", "", "", "", "<|vq_lbr_userWhat is the best way to get a good grade", "", "<|vq_lbr_audio_124437", "<|vq_lbr_", "", "", "", "her<|vq_l", "<|vq_lbr_audio_124437|>", "\n\n```\n\nIt looks like the text you provided is a mix of random characters and words in multiple languages, making it difficult to understand or provide a", "<", "<|vq_lbr_124740|>", "<|vq_l", "<|vq_lbr_audio_124917|", "<", "", "://\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a", "<|vq_lbr_image_12486|>", "", "<|vq_lbr_image_1240|>", "", "", "", "", "", "<|vq_lbr\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with", "<|vq_lbr_audio_124437|}\n\nIt looks like", "", "<|vq_12471|>\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel", "\n\n", "", "<|vq_l", "", "<", "\n\nIt", "<|vq_lbr", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "\n\n```\n\nIt", "<|", "", "<|vq", "<|vq_lbr_124740|", "", "", "<", "<|vq_lbr_audio_124740|>", "", "", "<|vq_lbr_audio_124215|>", "<|vq_lbr\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand or translate accurately. If you have a specific", "", "\ufffd<|vq_lbr_audio_124740|>", "", "", "", "", "\n\n", "", "", "<|vq_lbr_image_12484|>", "", "", "<|vq_lbr_audio_124437|>", "CHOR<|vq_lbr_audio_124740|>", "<|vq_lbr_image_", "", "", "<|vq_lbr\n\n", "", "<", "", "\n\nIt looks like the text you provided is a mix of code snippets, comments, and possibly some unrelated text. It seems to be a combination of different programming languages and possibly some random text", "<", "<|vq_lbr\n\nIt looks like the text", "<|vq", "", "<|vq_12471|>\n\nIt looks", "", "", "", "", "an", "```\n\nIt looks like the text you provided is", "", "", "", "", "", "", "", "", "", "", "", "<|vq_lbr_124044|>", "<", "\n\nIt looks like the text you provided is a mix of different languages and characters, and it seems to be garbled or corrupted. If you have a specific question or need assistance with a particular topic, please provide a clear and concise request, and I'll do my best to help you.\n\nIt", "", "", "", "", "<", "", "", "<|vq_lbr_audio_124437|>", "", "", "", "", "", "os\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a", "<|vq_lbr", "\n\n```\n\nIt looks like the text you posted is a mix of random characters and phrases in multiple languages, which", "<", "<|vq_lbr_image_12486|>", "", "", "", "", "", "", "<|vq_lbr_image_1245|>", "", "", "", "", "", "<", "<", "<|vq", "<|vq_lbr_124740|>", "<|vq", "<", "<|vq_lbr_audio_124215|>", "", "", "", "", "", "", "", "", "", "<|vq_lbr_image_12486|>", "", "", "", "<|vq_lbr_image_12486|>", "<|vq_lbr", "", "", "", "", "", "", "<|vq_l", "", "", "", "", "<|", "<|vq_lbr_image_1245|", "", "", "", "", "", "", "<|vq", "", "", "", "", "", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel free to let me know what you're", "<|vq_lbr_", "", "", "", "", "<|vq_lbr_image", "<|vq_lbr_image_1245|", "", "", "<|vq_12471", "", "", "", "", "", "", "", "", "", "", "", "", "<|vq_lbr_audio_124740|>", "\n\nIt looks like the text you provided is a mix", "ed", "<|vq_lbr_audio_124215|>```\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you", "<|vq_lbr_image_12486|", "ill<|vq_lbr_124740|>", "", "", "", "", "", "", "", "<|vq_lbr_audio_", "<|vq_lbr_audio_124740|>", "<|vq_lbr_image", "", "", "<|vq_lbr_user\n\nThe text you provided appears to be a random collection of words and phrases in multiple languages, possibly generated by a text generator or a random text", "", "", "", "<|vq_lbr_image_12486|>", "<|vq_lbr_image_12486|>\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words", "<", "", "", "<|vq", "<|vq_lbr_", "<|vq_", "", "", "", "", "", "", "", "", "<|vq_12471|>\n\nIt looks like the text you provided is a mix", "<|", "", "<|vq_12471|>\n\nIt looks like you've pasted a large amount", "<|vq_12471|>\n\nIt looks like the text you provided", "<|vq_lbr_audio_124740|>", "<|", "<", "<|vq_lbr_user", "<|vq_12471|>", "", "", "", "caten", "", "", "", "", "", "", "", "Column<|vq_lbr_user|>\n\n", "<|vq_lbr", "<|vq_lbr_124740|>", "aller<|vq_lbr_124740|", "", "", "", "", "<|vq_lbr_image_12471|>", "\t<|vq", "", "<|vq_lbr_image_1245|>", "", "", "<|vq_12471|>\n\nIt looks like", "", "", "", "", "", "", "<|vq_lbr_124740|>", "<", "<|vq_lbr_audio_124740|>", "<", "", "<|vq_lbr_image_1245|>", "", "", "", "", "", "", "", "", "", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic", "", "", "", "", "", "", "", "<|vq_lbr_124740|>", "<|vq_lbr_image_12486|>", "<|vq_l", "<", "\u0bc8", "\u0c35", "<|vq_lbr", "\n\n```\n\nIt looks like the", "<|vq_lbr_124740|>", "<|vq_12471|>\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel free to", "<|", "<|vq_lbr_124740|>", "<|vq_lbr_124740|><\n\nIt looks", "<|vq_lbr_124740|>", "<|vq_lbr_image_12486|>", "<", "<|", "", "", "", "<", "<", "<", "S<|vq_lbr_124740|>", "<|vq", "", "", "", "", "", "<|vq_lbr_audio_124437|>", "<|vq_lbr_image_12486|>", "<|", "", "", "<|vq_lbr_124740|>", "<|vq_lbr_124740|>", "", "", "<|vq_124", "", "", "ip<|vq_lbr_image_12486|>```\n\n", "<", "<|vq_l", "<|vq_1245|>\n\n", "", "", "<|vq_lbr_audio_124740|>", "\n\n[\n\nIt looks like the text", "", "", "\n\nIt looks like the text you provided", "", "<|vq_lbr_image_12457|>", "", "", "\n\n```\n\nIt looks like the text you provided", "<|vq_lbr_image_1245|>", "", "<|vq_124", "<|vq_lbr_image", "", "", "", "", "", "", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or", "", "<|vq_lbr_image_", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "ed<|vq_124", "<|vq_lbr_audio_124740|\n\nIt looks like the text you provided is a", "", "<|vq_lbr_124740|>", "", "", "", "", "", ".com/\n\nIt looks", "<|vq_lbr_audio_124740|>", "<|vq_lbr_124740|>", "<", "\n\n```\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't", "<|vq_lbr_124740|", "<|vq_lbr_audio", "", "", "", "", "", "<", "<|vq_lbr", "", "", "", "", "", "<|vq_lbr_124", "<|vq_lbr_audio_124215|>", "", "", "", "", "<|vq", "\n\nIt looks like your message contains a mix of text in multiple languages and possibly some code or data that might be corrupted or", "<|vq_12471|>\n\n", "", "<|vq_l", "<|vq_12471|>\n\nIt looks like the text you provided", "", "", "", "<|vq_lbr_image_12457", "", "", "", "", "", "", "", "", "<|", "", "", "<|vq_lbr_audio", "", "", "nia", "", "", "", "", "", "", "<|vq_lbr_image_12473|>", "", "```\n\nIt looks like the text you posted is a mix of random characters, symbols, and fragments from different languages and contexts. It doesn't", "Box<|vq_12471", "Token<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and appears", "", "", "", "<|vq_lbr_image_12471|>\n\nIt looks like the text you provided", "", "<|", "", "", "\n\nIt looks like the text you provided is", "<|vq_lbr_124740|>", "", "", "<", "", "", "", "<|vq_lbr_audio_", "", "", "<", "", "", "", "", "", "", "", "", "", "", "", "", "<|vq_lbr_image_12486|>", "<|vq_lbr_124740|>\n\nIt looks like your message got a bit garbled! If you have", "", "<|vq", "<", "<|vq_12471|>", "", "", "", "", "<|vq_lbr_image_124", "", "", "<|vq_l", "<|vq_lbr", "<|vq_lbr_124740|>", "<|vq_lbr_audio", "", "", "", "", "", "", "", "", "", "", "", "", "", "<|vq_lbr_user|>\n\nIt looks like your message got a bit gar", "<|", "<|vq_l", "m<", "<|vq_lbr_image_12486|>", "", "", "<|vq_lbr_124740", "<|vq", "<|vq", "", "", "<|vq_lbr_124740|>", "", "", "", "", "", "", "", "", "", "", "", "", "", "<", "", "", "<|vq_lbr_image_1245|>", "<|vq_lbr_audio_124437|>\n\nIt looks like the", "", "", "<", "", "<|vq_lbr_audio", "", "<", "", "", "", "", "<|vq_lbr_image_12486|>\n\nIt looks like the text", "", "", "", "<|vq_lbr_image_12486|>", "", "", "", "\n\n```\n\nIt looks like the", "", "", "", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of random characters and symbols, possibly from a corrupted or incorrectly formatted file. If you", "", "", "", "", "", "", "", "", "", "<|vq_lbr_user|>\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. Could you clarify what you need help with", "\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text", "\n\n", "<", "<|vq", "<|vq_lbr_124740|>", "<|vq_lbr_user|>\n\nIt", "<|vq_lbr_image_12457|>", "ur<|vq_l", "<", "en\u00ed<|vq_lbr_audio", "<|vq_l", "<|vq_lbr_image", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't form a coherent sentence or request. If you have a specific", "<|vq_lbr", "<|vq_lbr", "<|vq", "<|vq_lbr_124740|>", "\ufffd<|vq", "\n\n```\n\nIt looks like the text", "", "<|vq_lbr_image_12457|>", "<|vq_lbr_user\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent or meaningful sentence or paragraph. If you have a specific question or need assistance with a particular topic, feel\n\nIt looks like the text you provided is a mix of multiple languages and appears to be", "<|", "<|vq_lbr_image_124", "", "", "", "", "", "", "<|", "<|", "<|vq_lbr_", "<|vq_lbr_124740", "<|vq_lbr_user\n\n[User]\n\n\n\n[Assistant]\n\n\n\n[User]\n\n\n\n[Assistant]\n\n\n\n[User]\n\n\n\n[Assistant]\n\n\n\n[User]\n\n\n\n[Assistant]\n\n\n\n[User]\n\n\n\n[Assistant]\n\n\n\n[User]\n\n\n\n[Assistant]\n\n\n\n[User]\n\n\n\n[Assistant]\n\n\n\n[User]\n\n\n\n[Assistant]\n\n\n\n[User]\n\n\n\n[Assistant]\n\n\n\n[User]\n\n\n\n[Assistant]\n\n\n\n[User]\n\n\n\n[Assistant]\n\n\n\n[", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! If you have", "\n\n```\n\nIt looks like the text you provided is a mix of multiple languages", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of", "<|vq_12471", "\u0cc1<|vq_lbr_audio_124215|>", "<", "", "", "", "", "", "<|vq_lbr_124740|>", "\t<|vq_12471|>\n\n", "<|vq_lbr_audio_124740|>", "\u0cc1\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent or meaningful sentence. If you have", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text you provided is a mix of multiple languages and appears to be", "<", "<", "", "", "", "", "", "", "", "", "<|vq_lbr\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent or meaningful sentence or paragraph. If you have a specific question or need assistance with a particular topic, feel\n\nIt looks like the text you provided is a mix of multiple languages and appears to", "", "", "", "", "", "<", "<|vq_lbr_user\n\nIt looks like you're trying to create a new user in a PostgreSQL database using a", "<|vq_l", "<|vq_124", "<|", "<|vq_lbr\n\nIt looks like your", "<|vq_lbr_audio_124437", "<|vq_lbr", "\u0e49<|vq_lbr_audio_124740|>", "<|vq_lbr_audio_124740|>", "<", "<|vq_lbr_audio_124437|>", "\n\nIt looks like the text", "<|vq_lbr_image_1245|>", "<|vq_lbr_image_1245|>\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't seem", "", "", "", "", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124740|>", "<|vq_lbr_124740|>", "<|vq_lbr_userWhat is the best way", "<|", "", "", "<|vq_lbr_124740|>", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic", "<", "<|vq_lbr_124740|>", "<|vq_lbr_124740|>", "<|vq_lbr_image_12473|>", "<|vq_l", "ri\n\nIt looks like", "<|vq_lbr_audio_124437| \n```\n\nIt", "<|vq_lbr_image_12486|>", "<|vq_lbr_124740|>", "<|vq_lbr_image_12486|>", "", "", "", "<", "", "", "<|vq_lbr_image_12486|>\n\nIt looks like your message got a", "", "", "", "", "", "", "<|vq_lbr_image_1245|>", "", "", "<|vq_lbr_image_12471|>", "", "", "", "", "<|vq_lbr\n\nIt looks like the text you provided is a mix of random characters and phrases that don't form a coherent or understandable message. If you have a specific question or need help with a particular topic, feel\n\nIt looks like the text you provided is a mix of random characters and phrases that don't form a coherent or understandable\n\nIt looks like the", "", "", "", "", "", "", "", "", "", "<|vq", "", "", "", "", "", "<|vq_lbr_audio_124215|>", "<|vq_lbr_audio_124437|>", "<|vq_lbr_image_1245|>", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the text", "<|vq_lbr_124740|>", "", "<|vq_lbr_124740|>", "ify<|vq_12471|>\n\nIt", "<|vq_12471|>\n\nIt looks like the text you provided is", "and\n\n```\n\nIt looks like the", "", "", "", "", "", "", "", "", "", "", "", "", "<|vq_lbr_image_12486|", "\n\n", "<", "<|vq_lbr_audio_124740|>", "<|vq_lbr\n\nIt looks like the text you provided is a mix of", "Case<|vq_lbr_124740|>", "<", "\n\nIt looks like the", "<|vq_lbr_audio_124437| \n```\n\nIt looks like the", "", "<|vq_lbr_audio_124437|", "_", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "<|vq_lbr_image_1245|>\n\nIt looks like the text", "<|vq_lbr_124740", "", "", "", "<", "<", "", "", "", "<|", "<|vq_lbr_image_1245|>", "<|vq_lbr_image", "", "", "", "", "\n\n```\n\nIt", "", "", "", "\n\n```\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't seem to form a coherent or understandable sentence. If you have a specific question or need", "", "", "<|vq_lbr_124740|", "", "", "", "", "<|vq_lbr_124740|>", "<|vq_lbr_124740|>", "", "<|vq_lbr_image_12486|>\n\n", "", "", "<", "<|vq_lbr_124740|>", "<", "", "", "", "<|vq_lbr_audio_124437", "<|vq_lbr_124740|>", "", "<|vq_lbr_124044|>", "", "", "<|vq_lbr\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel\n\nSure! If you're looking for a way to create a new user in a PostgreSQL database using a Python script, here's a simple example using the `psycopg2` library.", "<|vq_12471|>\n\nIt looks like your message contains a mix of text in multiple languages and possibly some code or data that might have been garbled or incorrectly formatted. If you have a", "", "", "", "<|vq_lbr_audio_124740|>", "<|vq", "\n\n", "<|vq_lbr_audio_124740", "", "", "<", "", "", "", "<|vq_lbr_user", "<|vq_lbr\n\nIt looks like the text you provided is a mix of random", "", "", "", "", "", "", "", "<|vq_lbr_124740|>", "<|vq_l", "", "", "\n\n```\n\nIt looks like the text you provided is a mix", "<|vq_lbr\n\nIt looks like you're trying to create a complex and detailed prompt for a text-to-image AI model, specifically for generating an", "<|vq_lbr_userWhat is", "", "", "", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! Could you try sending it again?", "", "", "", "<|", "", "", "", "", "", ">\n\nIt looks like", "", "", "\u09bf<|vq_l", "", "", "", "<|vq", "<|vq_lbr_image_12486|>", "<|vq_lbr_image_1245|>", "", "", "", "", "", "", "", "", "", "<|vq_lbr_image_124", "", "", "<|vq_lbr_audio_124437|}", "<", "<|vq", "<|vq_lbr_audio_", "\n\nIt looks like the text you provided is a mix of multiple", "\n\n```\n\nIt looks like the text you provided is", "<|vq_lbr_audio_124215", "", "", "", "<|vq_lbr_124740|>", "ution<|vq_lbr_image_12486|", "\n\n```\n\nIt looks like the text you provided", "<|vq_lbr_124740|>", "\n\n```\n\nIt looks like the text you provided is a mix of different languages", "", "", "<|vq_lbr_audio_124740|>", "\n\nIt looks like your message contains a mix of different languages and possibly", "<", "<|vq", "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@", "", "<", "<|vq_12471|>", "<|vq_lbr_user", "<|vq_lbr_124044|>", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124740|>", "<|vq_lbr_124740|>", "<|vq_lbr_image_1245", "<|vq_lbr_124819|><|vq_l", "<|vq_lbr_audio_124740|>", "<", "\n\nIt", "<|vq_lbr_audio_124740|>", "<", "<|vq_lbr_image_12486|>\n\nIt looks like the text you provided is a", "<", "<|vq_lbr_124740|>", "ed<", "<|vq_lbr_audio_124740|>", "pace<|vq_lbr_audio_124740|>", "<|vq_12471|>\n\nIt looks like your message", "<|vq_12471|>\n\nIt looks like your message got garbled or mixed up with a lot of unrelated", "ia<|vq", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! If you have a specific question", "\t<", "<|vq_lbr_image_1243|>", "\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't seem to form a coherent sentence or phrase", "<|vq", "\u0cc1<|vq_lbr_image_1245|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please provide a clear and concise request", "```\n\n", "", "", "", "<|", "<|vq_lbr_user|>\n\nIt looks like your message got garbled", "<|vq_12471", "\n\nIt looks like", "", "", "", "<|vq_lbr_image", "", "", "", "", "", "", "", "", "", "", "", "", "", "<|vq_12471|>\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something", "\n\n", "<|vq_12471|>\n\nIt looks like the text", "", "", "mer<|", "", "", "", "", "", "", "", "<|vq_lbr", "<|vq_lbr", "<", "<|vq_lbr", "id<|vq_lbr_audio_124215|>", "<|vq_lbr\n\nIt looks like you're trying to create a script that involves a complex set of operations, possibly related", "", "", "", "<|vq_lbr_image_12486|>\n\nIt seems like the text you provided is a mix of different languages and characters, making it difficult", "<|vq_12471|", "<|vq_lbr_image_12457|>", "\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent or", "", "", "", "", "", "<|vq_lbr_image_1245", "", "", "", "", "", "<|", "", "", "", "", "", "", "", "", "<|vq_l", "", "", "", "", "", "", "", "<|vq_lbr_audio", "<|vq_lbr", "<|vq_lbr_audio_124215|", "\n\nIt", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of", "\n\nIt looks like your message contains a mix of text", "", "<|vq_12471|>\n\nIt looks like the text you", "\n\nIt looks like your message contains a", "<|vq_lbr_image", "<|vq_lbr_audio_124437|>\n\nIt looks like the text you posted is a mix of different languages and possibly some random or corrupted", "<|vq_lbr_124740|>", "<|vq_", "", "<|vq_12471|>\n\n", "<|vq_lbr_audio_124215|>", "", "", "<|vq_lbr_audio_124437", "", "", "<|vq_lbr_image_12486|>", "", "", "", "", "", "", "", "", "<|vq_lbr_image_12471|>", "<|vq_lbr_user|", "<|vq_12471|", "<|vq_lbr_image_1245|>", "\u09be<|vq_lbr_124740|>", "", "<|vq_lbr\n\nIt looks like your message got a bit garbled! If you have", "ence", "<|vq_lbr_image_1245|>", "<|vq_lbr\n\nIt looks like your message got a bit garbled!", "\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a specific", "", "", "", "<", "<|vq_lbr_image_12471", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel", "\n\nIt looks like the", "<|vq_l", "ave<", "", "", "<|vq_lbr_124740|", "parison<|vq", "", "", "<|vq_lbr", "", "", "", "<|", "", "<|vq_lbr_image_12473|>", "", "", "<|vq_lbr_124215|>", "<", "", "", "", "", "<|vq_lbr_user|", "", "", "", "", "\n\nIt looks like the text you provided", "", "<", "", "", "", "\t\t<|vq_12471|>\n\nIt looks like the text you provided is a mix of code snippets, comments, and", "<", "<|vq_lbr\n\nIt looks like the text you provided is a mix of multiple languages and appears", "<|vq_lbr", "", "", "", "", "", "", "", "", "", "", "<|vq_lbr", "", "", "", "", "", "<|vq_l", "<|vq_lbr_audio_124740|>", "", "", "", "<|vq_lbr_124740|>", "", "", "<|vq_lbr_audio_124", "\n\n```\n\nIt looks like the text you provided is a mix", "\n\n```\n\nIt looks like the", "<|vq_lbr", "Writer<|vq_lbr_124740|>", "<|vq", "\n\n", "<|vq_lbr_audio_124215|>", "", "", "", "", "", "", "", "<|vq_lbr_userWhat is the", "", "", "\n\nIt looks like the text you provided is a mix of different languages and symbols, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please provide a clear and concise request, and I'll do my", "<|vq", "<|vq_lbr_audio_124215|>", "<|vq_lbr_image_12486|>", "<|vq_lbr_image_1240|>", "<|vq_lbr_audio_124437|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult", "<|vq_lbr_image_124", "<|vq_lbr_image_12486|>\n\nIt looks like the text you provided is a mix of different languages and symbols, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please provide a clear and concise request,", "", "<|vq", "<|vq_lbr_124819|>", "<|vq_lbr_audio", "", "", "", "<|", "", "", "", "", "", "<|vq_lbr_userWhat is the best way to get a good night's sleep?\n\nGetting a good night's sleep is essential for overall health and well-being. Here are some tips", "", "", "", "", "", "", "<|vq_lbr_audio_124437| \n```\n\nIt", "/\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. Could you please clarify or resend your question? I'm here to help!\n\nIt looks like your message got garbled\n\nIt seems there might have been a mix-up in the text. Could you please resend your question or clarify what you need help with? I'm here to assist!\n\nIt looks\n\nIt looks like there might have been a", "<|vq_lbr_image_", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of", "<", "<|vq_lbr_audio_124740|>", "<|vq_lbr_124740|", "<|vq_lbr_124740|>", "<|vq_lbr_image_12486", "", "", "", "", "\n\n", "", "", "", "", "<|", "\ufffd  \ufffd\n\ufffd  \ufffd\n\ufffd  \ufffd\n\ufffd  \ufffd\n\ufffd  \ufffd\n", "", "", "", "", "", "<|vq_lbr_124740|><\n\nIt looks like the text you provided is a mix of different", "<", "able<", "<|vq_lbr_image_1245|>\n\nIt looks", "<|vq_lbr", "<|vq_lbr", "<|vq_lbr_audio_", "<|vq_lbr_audio", "/\n\nIt looks like", "<|vq_lbr_image_124", "", "", "", "", "", "<|vq_lbr_image_12486|>", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "<|vq_lbr_userWhat is the best way to get a good grade in a", "<|vq_lbr", "<", "<|vq_lbr_audio_", "", "", "", "", "", "", "", "<|vq_lbr_audio_124437|", "<", "<", "<|vq_lbr_audio_124215|>", "<|vq_lbr", "<|vq_lbr_audio_124437| \n```", "<|vq_12471|>\n\nIt", "", "", "", "", "", "", "", "", "", "ly<|", "<|vq_lbr_image_12486|>", "", "", "", "", "", "<|vq_lbr_audio_124740|\n\nIt looks", "", "", "", "", "<|vq", "", "", "", "", "<|", "<", "\u09be<|vq_lbr_image_12486|>\n\nIt looks like the text you provided", "", "<|vq_lbr_image_", "", "", "<|vq_lbr_image_12486|>\n\nIt looks like the text you provided", "<|vq_lbr_124740|>", "<", "<", "", "", "<|vq", "", "", "", "", "", "", "<|vq_lbr", "", "", "", "<|vq_12471|>", "<|", "", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124740|>", "\n\n```\n\nIt looks like the text you provided is a mix of different languages and characters, and", "<|vq_lbr_audio_124877|>", "<|vq_lbr_124740|", "<|vq_lbr_image_12486|>", "<", "<|vq_lbr_audio_124437|>", "<|vq_l", "```\n\nIt looks like the text you provided is a mix of different languages and characters,", "<|vq_124", "<|vq_lbr_image_12471|>", "<|vq_lbr_124740|>", "<|vq_l", "<|vq_12471|>\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel", "<|vq_l", "ong", "", "", "<|", "", "", "", "", "", "el", "<|vq_lbr_audio_124437", "<|vq_lbr_image_1245|>", "<|vq_lbr_audio_124740|>", "<|vq_lbr_user|>\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with", "<|vq_lbr_audio_", "", "<|vq_lbr_image_12486|>", "s<|vq", "<|vq", "<", "<|vq_lbr_user|>\n\nIt looks", "", "", "", "", "<|", "", "", "", "", "", "", "\n\n```\n\nIt looks like the text you provided is a mix", "<|vq_lbr_audio", "<", "", "<|vq", "<|vq_124", "<|vq_12471|>\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel", "<|vq_l", "RO<|vq_lbr\n\nIt", "", "\n\n", "<|vq", "<|vq_lbr_124740|>", "Column", "", "<|vq_lbr\n\nIt looks", "", "", "", "", "", "", "<|vq_lbr_image_12457|>", "", "", "", "", "", "<|vq_lbr_userWhat is the best way to get a job?\n\nThe best way to get a job can vary depending on your industry, experience level, and personal circumstances.", "", "", "", "", "", "<", "<|vq_lbr_image_12486|>", "\n\nIt looks like your", "\n\n```\n\nIt", "<|vq_lbr_image", "<|vq_lbr_124", "", "<|vq_lbr_audio_124437|>\n\nIt looks like the text you provided is a mix of multiple languages and possibly", "\n\nIt looks", "<|vq", "", "", "```\n\nIt looks like the text you provided", "<|vq_lbr\n\nIt looks like the text you provided is a mix of random characters", "", "", "", "<|vq_12471|>\n\nIt", "<|vq_lbr_image_", "<|vq_lbr_image_124", "<|vq_lbr_124740|>", "<|vq_lbr", "<|", "<", "", "ger<|vq_12471|>\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with", "<|vq_lbr_image_12486|>", "<|vq", "<|vq_lbr\n\nIt looks like your message got a bit garbled! If", "\n\n[", "<|vq_lbr_", "<|vq_12471|>\n\nIt looks like the text you provided is", "\n\nIt looks like your message got", "<|vq_lbr\n\nIt looks like your message got garbled or mixed", "<|vq_l", "\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with", "", "<|vq_lbr_124740|", "<|vq_lbr_124740|><\n\nIt looks like the text you provided is a mix of different languages and symbols, making it difficult to understand or translate accurately. If you have a specific part of the text that you", "<|vq_lbr_image", "", "<", "<|vq_lbr_image_12486|>", "\n\n```\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't seem to form a coherent sentence or phrase. If you have", "\u044b\u0439<|vq_12471|>\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel", "<|vq_lbr_124740|>", "Box<", "<|vq_lbr_audio_124437|>", "<|vq_lbr\n\nIt", "<|vq_l", "", "\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of", "<|vq_lbr_124740|>", "", "lect<|vq_12471|>\n\nIt", "icletype\n\nIt looks like the text you provided is a mix of different languages and", "", "\ufffd \ufffd\ufffd\ufffd\r\n\ufffd\r\n\ufffd\r\n\ufffd\r\n\ufffd\r\n\ufffd\r\n", "<", "<|vq", "<|vq_lbr_image_12486|>\n\nIt looks like the text you provided is a mix of different languages and possibly some random characters. It doesn't seem to", "<", "<|vq_lbr_image_1245|>```\n\nIt looks like the text you provided is a mix of different", "<|vq_lbr_audio", "", "", "<|vq_lbr_audio_124877|>", "<|vq_lbr_image_124", "<|vq_lbr_image_1240|>", "", "", "<|vq_lbr_124740|>", "<|vq_lbr_user|>", "\n\nIt looks like the text you provided is a mix of different languages and characters, making it", "", "", "", "", "<|vq_lbr_image_12486", "", "", "<|vq_lbr\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand or translate. If you have a specific question or need assistance with a particular part of the text, please let me\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand or translate. If you have a specific\n\nIt looks like the text you provided is a mix of", "-<|vq_lbr_124740|><\n\nIt looks like your message got a bit garbled! If you have a specific question or", "<|vq", "<|vq_lbr_image_", "", "", "", "<|vq_lbr_audio_124437|}\n\nIt looks like the text you provided is a mix of different languages and characters, and", "", "", "", "", "<", "<|vq_lbr_image_12486|", "<|vq_lbr_audio_124740|>", "", "", "", "", "", "<", "<|vq", "\n\nIt", "<|vq_lbr_image_1245", "", "<", "", "", "", "<|vq_lbr_124740|>", "<|vq_lbr_image_12486|>", "\n\n[\n\nIt looks like the text you provided is a mix of random characters and", "", "", "", "<|vq_lbr_audio_124437|}", "<|vq_lbr_image_12457|>", "<|vq_lbr_audio_124437|}\n\nIt looks like the text you provided is a mix of different languages and characters,", "\n\nIt looks like the text you posted", "<|vq_lbr_124740|>", "", "<|vq_lbr_audio", "<|vq_lbr_image_1245|>", "<|vq_lbr_124819|><\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand or translate accurately. If you have a specific portion or a particular language you'd like to focus", "\u00fc<|vq_lbr_userWhat is the best way to get a job?\n\nThe best way to get", "", "<|vq_lbr_124740", "<|vq_lbr_image_12471|>\n\nIt looks like the text you provided is", "<|vq_lbr", "<|", "", "<|vq", "<|vq_lbr", "<|vq_lbr_user|>\n\nIt looks", "<|vq_lbr_audio_124215|>\n\nIt looks like the text you provided is a mix of", "<|vq_124", "\ufffd \ufffd\n\n```\n\nIt", "<|vq_lbr_image_12471|>", "<|vq_lbr_124740|>", "", "", "", "", "", "", "<|vq_12471|>\n\nIt looks like your message got garbled or mixed up with a lot", "al<|vq_lbr_124740|>", "\n\nIt looks like the text", "<|vq_lbr_image", "<|vq", "\n\n```\n\n", "", "", "<|vq_l", "", "\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases. It doesn't seem to form a coherent sentence or paragraph. If", "<|vq_lbr", "", "", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it", "<", "<|vq_l", "<|vq_lbr_image_1245|>", "ances<", "\n\nIt looks like the text you provided is a mix of random characters, symbols, and fragments of sentences in multiple languages. It doesn't form a coherent or understandable passage. If you have a specific", "<|vq_lbr_audio_124437|>", "\u00f6der\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with", "<|vq", "<|vq_lbr_image_1245|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If", "<", "<", "\n\nIt looks like the text you provided is a mix of code snippets, comments, and possibly some corrupted", "<|vq_lbr_124740|>", "<|vq", "<|vq_lbr_audio_124877|>\n\nIt looks like the text you provided is a", "", "", "", "<|vq_lbr_user\n\nIt looks like you're trying to create a function that calculates the sum of a list of numbers. However, the code snippet you provided", "\n\nIt looks like your message got garbled and contains a mix of unrelated text and code snippets. If you have a", "", "<", "", "<|vq_lbr_audio_124740|>", "itional<|vq_lbr\n\n", "", "<|", "<|vq_12471|>\n\nIt looks", "<|vq_lbr_audio", "<|vq_12471|>\n\nIt looks like the text you provided is", "<|vq_lbr_", "<", "<|vq_lbr", "<", "<|vq_lbr_audio_124437|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please provide a clear and concise request, and I'll do", "\n\nIt looks like the text you provided is a mix of multiple languages and appears to be a random collection of words and phrases", "<|vq_12471|>\n\nIt looks like the text you provided is a mix of different languages and characters, making it difficult to understand. If you have a specific question or need assistance with a particular topic, please provide a clear and", "\u09be<|vq_lbr_audio_124437", "<|vq_lbr_audio_124877|", "<|vq_l", "<|vq", "<|vq", "<|vq_lbr_124740", "<|vq_lbr\n\nIt looks like the text you provided is a mix of random characters and", "<|vq_lbr_124740|>", "<|vq_lbr_audio_124437|>\n\nIt looks like the text you provided is a mix of different languages and characters", "<|vq_lbr_image_12471|>", "", "", "", "", "", "<|vq_lbr", "<", "", "<|vq_lbr_image_12486|>", "", "", "<|vq_lbr_image_1245|>\n\nIt looks like the text you provided is a mix of different languages and characters, and it doesn't seem to form a coherent sentence or phrase. If you have a specific question or if there's", "\ufffd 0.0.0.", "", "<|vq_lbr_image_12486|>", "\n\nIt", "aining<|vq_lbr_image_12457|>", "\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\nIt looks like your message got garbled or mixed up with a lot of unrelated text. If you have a specific question or need help with something, feel", "", "", "", "", "", "", "", "", "", "", "", "", "Class<|vq", "", "", "", "<|vq_lbr_124740|><\n\nIt looks like the text you", "", "<|vq_lbr_audio_124740", "<|vq_lbr_audio_124740|>", "<|vq_12471|>", "", "", "", "", "", "", "<|vq_lbr\n\nIt looks like the text you provided is a mix of random characters and phrases that don't form a coherent or understandable message.", "<|vq_lbr_user|>\n\nIt seems like your message got a bit garbled! If you have a specific question", "", "", "", "<", "<", "", "", "<|vq_lbr_124740|", "", "", "", "", "<|vq_lbr_audio_", "trib<|vq_", "", "", "<|vq_lbr_audio_", "", "", "", "<", "illate<|vq_lbr_124740|><\n\nIt looks", "<|vq_lbr_image_12486|>", "<|vq_lbr_124740|>", "", "<|vq_lbr_124740|>", "", "", "", "", "", "", "", ""], "errors": ["", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n", "Traceback (most recent call last):\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1115, in _wrap_create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 122, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 73, in start_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohappyeyeballs/impl.py\", line 183, in _connect_sock\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/socket.py\", line 233, in __init__\nOSError: [Errno 24] Too many open files\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 290, in async_request_openai_completions\n    async with session.post(\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 1425, in __aenter__\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/client.py\", line 703, in _request\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 548, in connect\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1056, in _create_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1406, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1375, in _create_direct_connection\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/connector.py\", line 1130, in _wrap_create_connection\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:8000 ssl:default [Too many open files]\n"], "request_timestamps": [1760037553.6715057, 1760037553.684717, 1760037553.7023335, 1760037553.9834156, 1760037554.022361, 1760037554.0224051, 1760037554.0395725, 1760037554.0493662, 1760037554.1326826, 1760037554.275636, 1760037554.275533, 1760037554.2755015, 1760037554.2756844, 1760037554.27567, 1760037554.275654, 1760037554.3439841, 1760037554.3543463, 1760037554.6112845, 1760037554.752452, 1760037554.8006806, 1760037554.8134086, 1760037554.951994, 1760037554.9944746, 1760037555.0477998, 1760037555.0518076, 1760037555.0728452, 1760037555.12257, 1760037555.1718009, 1760037555.1961417, 1760037555.2079582, 1760037555.2079973, 1760037555.2722068, 1760037555.4289792, 1760037555.4917674, 1760037555.5406027, 1760037555.5967665, 1760037555.6456838, 1760037555.6522956, 1760037555.6896164, 1760037555.888937, 1760037555.8946528, 1760037555.894638, 1760037555.932963, 1760037555.941089, 1760037555.986631, 1760037556.0659618, 1760037556.1057115, 1760037556.1634383, 1760037556.1974764, 1760037556.2550435, 1760037556.389638, 1760037556.5328407, 1760037556.6228116, 1760037556.6445696, 1760037556.6576362, 1760037556.6753464, 1760037556.731805, 1760037556.8484063, 1760037556.8666155, 1760037556.8666625, 1760037556.929995, 1760037556.9766545, 1760037557.0178123, 1760037557.038577, 1760037557.0478544, 1760037557.0910554, 1760037557.1005745, 1760037557.1267896, 1760037557.213517, 1760037557.3254457, 1760037557.3434968, 1760037557.427556, 1760037557.472291, 1760037557.6296644, 1760037557.750453, 1760037557.829478, 1760037557.8837512, 1760037557.9926884, 1760037558.066493, 1760037558.1247287, 1760037558.1435785, 1760037558.1669827, 1760037558.2659652, 1760037558.2951293, 1760037558.2950792, 1760037558.534164, 1760037558.5887182, 1760037558.7360144, 1760037558.8760877, 1760037558.8935652, 1760037559.0618882, 1760037559.0618484, 1760037559.0961745, 1760037559.0960963, 1760037559.1519463, 1760037559.163398, 1760037559.2481265, 1760037559.2528496, 1760037559.2678158, 1760037559.3508632, 1760037559.4624019, 1760037559.5234156, 1760037559.530495, 1760037559.5381029, 1760037559.652634, 1760037559.6751018, 1760037559.7463794, 1760037559.7628102, 1760037559.833383, 1760037559.8647773, 1760037559.8812444, 1760037559.8812745, 1760037559.9864786, 1760037560.006428, 1760037560.068408, 1760037560.1398902, 1760037560.139944, 1760037560.1784377, 1760037560.2569852, 1760037560.3451562, 1760037560.429219, 1760037560.4449682, 1760037560.4710636, 1760037560.5223513, 1760037560.596444, 1760037560.6754282, 1760037560.6803014, 1760037560.7691803, 1760037560.9295917, 1760037561.0690222, 1760037561.089113, 1760037561.239176, 1760037561.3808205, 1760037561.5855124, 1760037561.6419353, 1760037561.647943, 1760037561.663131, 1760037561.705105, 1760037561.7551265, 1760037561.8087075, 1760037561.8086576, 1760037561.826849, 1760037561.826809, 1760037561.86183, 1760037561.8669555, 1760037561.8780403, 1760037561.9661808, 1760037561.9933279, 1760037561.993299, 1760037562.0115912, 1760037562.0445192, 1760037562.1560292, 1760037562.1560075, 1760037562.170352, 1760037562.3739707, 1760037562.3965192, 1760037562.4806013, 1760037562.8937905, 1760037563.0962725, 1760037563.1484256, 1760037563.229511, 1760037563.4839647, 1760037563.677223, 1760037563.7246218, 1760037563.7552886, 1760037563.8140266, 1760037563.9513845, 1760037564.0828567, 1760037564.1562064, 1760037564.160626, 1760037564.1843266, 1760037564.205222, 1760037564.23199, 1760037564.260477, 1760037564.3718925, 1760037564.4229925, 1760037564.57016, 1760037564.5781126, 1760037564.7161086, 1760037564.7437057, 1760037564.891882, 1760037564.9248834, 1760037565.041521, 1760037565.074924, 1760037565.0875661, 1760037565.201064, 1760037565.275487, 1760037565.2961872, 1760037565.355333, 1760037565.3618808, 1760037565.4183686, 1760037565.5355847, 1760037565.550768, 1760037565.5787864, 1760037565.7007723, 1760037565.7007391, 1760037565.7353816, 1760037565.8140552, 1760037565.834494, 1760037565.8636792, 1760037565.9631279, 1760037565.977552, 1760037565.9849467, 1760037565.9911852, 1760037566.0173056, 1760037566.1328907, 1760037566.147688, 1760037566.156783, 1760037566.1923957, 1760037566.2032998, 1760037566.242497, 1760037566.7574277, 1760037566.8065574, 1760037566.8250997, 1760037567.0434928, 1760037567.0524173, 1760037567.0896125, 1760037567.1610265, 1760037567.2163935, 1760037567.2963986, 1760037567.296448, 1760037567.3407245, 1760037567.363349, 1760037567.3780544, 1760037567.3846905, 1760037567.4001584, 1760037567.422411, 1760037567.4375196, 1760037567.4977114, 1760037567.5093172, 1760037567.553802, 1760037567.6055586, 1760037567.6822586, 1760037567.6852682, 1760037567.7969646, 1760037567.811594, 1760037567.9490926, 1760037568.0899904, 1760037568.124724, 1760037568.1611023, 1760037568.175917, 1760037568.2473173, 1760037568.3824754, 1760037568.4000008, 1760037568.6023011, 1760037568.602352, 1760037568.633498, 1760037568.8904264, 1760037568.912308, 1760037569.0806887, 1760037569.1983922, 1760037569.3440485, 1760037569.3577218, 1760037569.4451182, 1760037569.4596782, 1760037569.4863665, 1760037569.5447123, 1760037569.5500698, 1760037569.7313712, 1760037569.7314038, 1760037569.7407062, 1760037569.7511268, 1760037569.8344696, 1760037569.8643186, 1760037569.918685, 1760037569.9778674, 1760037570.0845296, 1760037570.1840236, 1760037570.1957726, 1760037570.228547, 1760037570.2719672, 1760037570.2988243, 1760037570.3581057, 1760037570.3956666, 1760037570.4881022, 1760037570.497777, 1760037570.5520918, 1760037570.5796087, 1760037570.688465, 1760037570.6957061, 1760037570.7352765, 1760037570.7615457, 1760037570.791026, 1760037570.8226852, 1760037570.8620965, 1760037570.9028885, 1760037570.920981, 1760037571.035234, 1760037571.1129444, 1760037571.2235603, 1760037571.325817, 1760037571.3652194, 1760037571.365268, 1760037571.414439, 1760037571.6886945, 1760037571.7079668, 1760037572.0838208, 1760037572.0916321, 1760037572.091681, 1760037572.1050706, 1760037572.1259763, 1760037572.1593854, 1760037572.2066765, 1760037572.2464366, 1760037572.352049, 1760037572.3711638, 1760037572.4405055, 1760037572.4940267, 1760037572.5234988, 1760037572.5405765, 1760037572.6428802, 1760037572.670229, 1760037572.689571, 1760037572.779118, 1760037572.816149, 1760037572.9059978, 1760037573.0507033, 1760037573.079635, 1760037573.111267, 1760037573.1575093, 1760037573.1833994, 1760037573.2712283, 1760037573.2800012, 1760037573.4066854, 1760037573.4410906, 1760037573.4411426, 1760037573.5261734, 1760037573.5756705, 1760037573.6960332, 1760037573.7105193, 1760037573.821994, 1760037574.0474226, 1760037574.0545743, 1760037574.2517624, 1760037574.2835002, 1760037574.364086, 1760037574.364039, 1760037574.4518015, 1760037574.47583, 1760037574.555928, 1760037574.565587, 1760037574.6707654, 1760037574.688848, 1760037574.7295089, 1760037574.7349198, 1760037574.7983212, 1760037574.8259966, 1760037574.8834245, 1760037574.9187286, 1760037574.9584374, 1760037574.9700224, 1760037575.0437686, 1760037575.0492072, 1760037575.2536983, 1760037575.3087397, 1760037575.3163874, 1760037575.3854604, 1760037575.4388497, 1760037575.5076473, 1760037575.5680265, 1760037575.57575, 1760037575.7050734, 1760037575.9122565, 1760037575.9928863, 1760037575.992838, 1760037576.1046288, 1760037576.2722344, 1760037576.3495486, 1760037576.3779926, 1760037576.4117522, 1760037576.4117048, 1760037576.4655948, 1760037576.5023518, 1760037576.558498, 1760037576.7563791, 1760037576.7758615, 1760037576.8048692, 1760037576.817568, 1760037576.8212156, 1760037576.8453145, 1760037576.964003, 1760037577.1446285, 1760037577.157459, 1760037577.2654116, 1760037577.5033355, 1760037577.609854, 1760037577.882903, 1760037577.8895175, 1760037577.8944535, 1760037577.9912238, 1760037578.0779953, 1760037578.0988731, 1760037578.3585436, 1760037578.3999739, 1760037578.6027102, 1760037578.6113276, 1760037578.7318013, 1760037578.7675784, 1760037578.8691244, 1760037578.8850987, 1760037578.9433837, 1760037578.94855, 1760037578.9529207, 1760037578.9720578, 1760037579.0357115, 1760037579.096972, 1760037579.1324992, 1760037579.1681757, 1760037579.1960168, 1760037579.3580213, 1760037579.4771016, 1760037579.4903302, 1760037579.5205553, 1760037579.5456822, 1760037579.8242354, 1760037579.8759847, 1760037579.884267, 1760037579.9840755, 1760037580.0437264, 1760037580.0651898, 1760037580.1768427, 1760037580.3199813, 1760037580.4012067, 1760037580.4966633, 1760037580.5640917, 1760037580.7493014, 1760037580.7677686, 1760037580.7795453, 1760037580.8019962, 1760037581.0808148, 1760037581.2151937, 1760037581.2971005, 1760037581.335343, 1760037581.3572192, 1760037581.4298663, 1760037581.6316798, 1760037581.7295914, 1760037581.753338, 1760037581.8141692, 1760037581.8196437, 1760037581.9086432, 1760037581.9281328, 1760037581.9464793, 1760037582.0141618, 1760037582.041588, 1760037582.146785, 1760037582.1524239, 1760037582.1524622, 1760037582.182849, 1760037582.2389903, 1760037582.245805, 1760037582.3544552, 1760037582.4202425, 1760037582.5191593, 1760037582.7414434, 1760037582.7414942, 1760037582.7463415, 1760037582.8761218, 1760037582.906789, 1760037583.0904193, 1760037583.1573184, 1760037583.2305524, 1760037583.2608194, 1760037583.2954981, 1760037583.4020107, 1760037583.4720702, 1760037583.4982145, 1760037583.6036735, 1760037583.6938176, 1760037583.8170843, 1760037583.8881276, 1760037583.9046438, 1760037583.9045954, 1760037583.9112332, 1760037583.9471788, 1760037583.950769, 1760037584.054232, 1760037584.0678535, 1760037584.0822144, 1760037584.1689813, 1760037584.1690156, 1760037584.2010903, 1760037584.2344875, 1760037584.2705798, 1760037584.3146658, 1760037584.492814, 1760037584.5440557, 1760037584.5993361, 1760037584.6207457, 1760037584.7439857, 1760037585.0152802, 1760037585.115469, 1760037585.1895845, 1760037585.4457157, 1760037585.5820873, 1760037585.6896386, 1760037585.8526194, 1760037585.941346, 1760037585.9679863, 1760037586.1138313, 1760037586.161707, 1760037586.4157197, 1760037586.422011, 1760037586.5278275, 1760037586.558539, 1760037586.7631388, 1760037586.7631743, 1760037586.7965138, 1760037586.7964826, 1760037586.8431928, 1760037586.8733747, 1760037586.8807118, 1760037586.9244251, 1760037586.9765542, 1760037587.1165774, 1760037587.1402738, 1760037587.2148514, 1760037587.326901, 1760037587.4409492, 1760037587.5142708, 1760037587.5496054, 1760037587.7938232, 1760037587.9760928, 1760037587.9829483, 1760037588.0391476, 1760037588.04488, 1760037588.1134405, 1760037588.2193294, 1760037588.219379, 1760037588.2981374, 1760037588.3141131, 1760037588.3394651, 1760037588.366841, 1760037588.447593, 1760037588.4837291, 1760037588.6200771, 1760037588.6625423, 1760037588.708611, 1760037588.7956817, 1760037589.0184238, 1760037589.1374402, 1760037589.2436473, 1760037589.25677, 1760037589.2768896, 1760037589.2942784, 1760037589.345108, 1760037589.3638747, 1760037589.4157124, 1760037589.5096328, 1760037589.5177948, 1760037589.565164, 1760037589.5900705, 1760037589.6137922, 1760037589.6388144, 1760037589.6571634, 1760037589.6668904, 1760037589.674879, 1760037589.7572641, 1760037590.002433, 1760037590.113816, 1760037590.143705, 1760037590.3879397, 1760037590.4165907, 1760037590.4446335, 1760037590.4490278, 1760037590.5522068, 1760037590.7500618, 1760037590.785443, 1760037590.8950343, 1760037590.8980324, 1760037590.908092, 1760037590.9405057, 1760037590.9518316, 1760037591.0400515, 1760037591.1790266, 1760037591.2206068, 1760037591.342918, 1760037591.414755, 1760037591.4507933, 1760037591.4958415, 1760037591.5712993, 1760037591.57945, 1760037591.6066408, 1760037591.748615, 1760037591.760252, 1760037591.7771792, 1760037591.8852193, 1760037591.951915, 1760037592.0169668, 1760037592.0716915, 1760037592.1122587, 1760037592.2516015, 1760037592.265189, 1760037592.2752142, 1760037592.278725, 1760037592.3862689, 1760037592.4153967, 1760037592.4999099, 1760037592.534079, 1760037592.6262283, 1760037592.704742, 1760037592.729019, 1760037592.7290397, 1760037592.7475626, 1760037592.8214645, 1760037592.8283663, 1760037592.8490603, 1760037593.0198457, 1760037593.3259757, 1760037593.3732207, 1760037593.4249926, 1760037593.4453702, 1760037593.4909108, 1760037593.5257275, 1760037593.607784, 1760037593.6905715, 1760037593.7018776, 1760037593.7090375, 1760037593.7575705, 1760037593.8228097, 1760037593.8561804, 1760037593.9999816, 1760037594.021729, 1760037594.0692325, 1760037594.0969806, 1760037594.2027824, 1760037594.2388463, 1760037594.2847981, 1760037594.3472059, 1760037594.4377434, 1760037594.6177666, 1760037594.7030172, 1760037594.745764, 1760037594.7682855, 1760037594.7898183, 1760037594.860182, 1760037594.8958666, 1760037594.8959155, 1760037595.0579314, 1760037595.0873036, 1760037595.2640715, 1760037595.3469498, 1760037595.5039065, 1760037595.6121495, 1760037595.6779501, 1760037595.6890306, 1760037595.8009117, 1760037595.872409, 1760037596.0715053, 1760037596.0829775, 1760037596.1010473, 1760037596.1385098, 1760037596.3653886, 1760037596.4593267, 1760037596.4776661, 1760037596.4931505, 1760037596.5350673, 1760037596.5752537, 1760037596.5752935, 1760037596.604327, 1760037596.6634855, 1760037596.6760652, 1760037596.7112665, 1760037596.7288775, 1760037596.7289195, 1760037596.7898238, 1760037596.9829917, 1760037597.0533974, 1760037597.0912337, 1760037597.0912025, 1760037597.0912476, 1760037597.101195, 1760037597.1435945, 1760037597.165879, 1760037597.1838396, 1760037597.241593, 1760037597.4026675, 1760037597.4026139, 1760037597.4460144, 1760037597.520247, 1760037597.5636816, 1760037597.7101648, 1760037597.7239969, 1760037597.7240322, 1760037597.853776, 1760037597.8759766, 1760037598.0215654, 1760037598.3325415, 1760037598.3587244, 1760037598.4575212, 1760037598.5353231, 1760037598.627859, 1760037598.6706667, 1760037598.723086, 1760037598.743017, 1760037598.764757, 1760037598.8289862, 1760037598.8365278, 1760037598.8596957, 1760037598.8727076, 1760037598.918251, 1760037599.0429282, 1760037599.0484142, 1760037599.100486, 1760037599.19112, 1760037599.2813125, 1760037599.2988815, 1760037599.3168843, 1760037599.402096, 1760037599.4144266, 1760037599.4348094, 1760037599.5217648, 1760037599.5830078, 1760037599.590563, 1760037599.6203806, 1760037599.6771808, 1760037599.8782167, 1760037599.9173074, 1760037600.0337298, 1760037600.1018312, 1760037600.1434553, 1760037600.2986467, 1760037600.5563035, 1760037600.7131011, 1760037600.8419487, 1760037600.936643, 1760037601.0886524, 1760037601.1074986, 1760037601.2262533, 1760037601.2794156, 1760037601.2945416, 1760037601.346205, 1760037601.3783436, 1760037601.5063, 1760037601.5159993, 1760037601.5321429, 1760037601.5629768, 1760037601.5679662, 1760037601.7347345, 1760037601.8347764, 1760037601.8799813, 1760037602.0370054, 1760037602.053224, 1760037602.0657465, 1760037602.1396222, 1760037602.2044618, 1760037602.3207695, 1760037602.401033, 1760037602.43855, 1760037602.4666805, 1760037602.565574, 1760037602.693331, 1760037602.8194232, 1760037602.8378825, 1760037602.8542416, 1760037602.909236, 1760037602.9539568, 1760037602.9821937, 1760037603.2172313, 1760037603.2254677, 1760037603.3457143, 1760037603.3938427, 1760037603.4667928, 1760037603.5549402, 1760037603.6021857, 1760037603.8285015, 1760037603.8743467, 1760037603.8933692, 1760037604.0351312, 1760037604.0828564, 1760037604.2460136, 1760037604.29574, 1760037604.3101776, 1760037604.3560216, 1760037604.6192698, 1760037604.6254673, 1760037604.6378987, 1760037604.6558192, 1760037604.7387092, 1760037604.75344, 1760037604.8863397, 1760037605.0744202, 1760037605.1010246, 1760037605.143915, 1760037605.2630205, 1760037605.2817786, 1760037605.2912812, 1760037605.3354623, 1760037605.3857584, 1760037605.5167956, 1760037605.5337338, 1760037605.5337868, 1760037605.5661342, 1760037605.5997257, 1760037605.6046855, 1760037605.7147758, 1760037605.7253745, 1760037605.8789344, 1760037605.8890123, 1760037606.0416355, 1760037606.0521085, 1760037606.0699198, 1760037606.086402, 1760037606.1867578, 1760037606.2194672, 1760037606.3743181, 1760037606.4235795, 1760037606.4338555, 1760037606.4338174, 1760037606.493258, 1760037606.6152747, 1760037606.648424, 1760037606.6694613, 1760037606.6803477, 1760037606.7102618, 1760037606.8123243, 1760037606.8588543, 1760037606.8931868, 1760037606.910256, 1760037606.9566433, 1760037607.083488, 1760037607.1597865, 1760037607.1697834, 1760037607.2423222, 1760037607.259782, 1760037607.2597601, 1760037607.2659082, 1760037607.317737, 1760037607.3353667, 1760037607.4107668, 1760037607.5281026, 1760037607.5500476, 1760037607.638008, 1760037607.6573772, 1760037607.763238, 1760037607.928455, 1760037607.960616, 1760037607.9674673, 1760037608.0122864, 1760037608.0318425, 1760037608.0771022, 1760037608.1214314, 1760037608.251761, 1760037608.3099048, 1760037608.3157375, 1760037608.3870177, 1760037608.4791486, 1760037608.5067766, 1760037608.524722, 1760037608.6590595, 1760037608.8541536, 1760037608.8588986, 1760037609.0311875, 1760037609.4837599, 1760037609.5254617, 1760037609.6376421, 1760037609.6543543, 1760037609.6912441, 1760037609.7698662, 1760037609.7757473, 1760037609.9121614, 1760037609.9122293, 1760037609.9121785, 1760037609.9122417, 1760037609.9918785, 1760037610.0342958, 1760037610.1001618, 1760037610.295498, 1760037610.4007235, 1760037610.4166603, 1760037610.4166164, 1760037610.5028174, 1760037610.5625787, 1760037610.5873053, 1760037610.7449903, 1760037610.8302784, 1760037610.8396442, 1760037610.8673959, 1760037610.9120479, 1760037610.988315, 1760037611.0516572, 1760037611.1973927, 1760037611.4960663, 1760037611.5023372, 1760037611.7396996, 1760037611.8160894, 1760037611.9152877, 1760037611.9252932, 1760037612.0042825, 1760037612.124459, 1760037612.1737165, 1760037612.182244, 1760037612.2508566, 1760037612.2583258, 1760037612.291035, 1760037612.3318968, 1760037612.4071152, 1760037612.438827, 1760037612.509845, 1760037612.5372748, 1760037612.570687, 1760037612.579424, 1760037612.6209557, 1760037612.6645877, 1760037612.6923535, 1760037612.692393, 1760037612.7466903, 1760037612.8142307, 1760037612.9136686, 1760037613.071, 1760037613.0753944, 1760037613.260613, 1760037613.2894678, 1760037613.2933347, 1760037613.3591037, 1760037613.365517, 1760037613.3709598, 1760037613.4063363, 1760037613.4766088, 1760037613.4841547, 1760037613.5337806, 1760037613.5673842, 1760037613.6136498, 1760037613.6683748, 1760037613.8401554, 1760037613.9023023, 1760037613.9376318, 1760037613.9617097, 1760037613.9709888, 1760037614.0101202, 1760037614.166792, 1760037614.2458034, 1760037614.541919, 1760037614.5837483, 1760037614.620929, 1760037614.869419, 1760037614.9380114, 1760037614.9454393, 1760037615.0256853, 1760037615.080391, 1760037615.3010232, 1760037615.4936752, 1760037615.5931756, 1760037615.6107173, 1760037615.6949275, 1760037615.8545258, 1760037615.854557, 1760037615.8602607, 1760037615.899917, 1760037615.96249, 1760037615.9837284, 1760037616.0309386, 1760037616.0309079, 1760037616.0829477, 1760037616.0963402, 1760037616.2130892, 1760037616.2648468, 1760037616.3345716, 1760037616.3774176, 1760037616.3969269, 1760037616.3968878, 1760037616.5486963, 1760037616.6333537, 1760037616.633398, 1760037616.7210588, 1760037616.7279809, 1760037617.000167, 1760037617.0429127, 1760037617.1876485, 1760037617.221615, 1760037617.3480973, 1760037617.5910892, 1760037617.6188061, 1760037617.7671797, 1760037617.821795, 1760037617.8536139, 1760037618.112264, 1760037618.2464085, 1760037618.2759273, 1760037618.4437704, 1760037618.5253222, 1760037618.5812395, 1760037618.5967321, 1760037618.6225321, 1760037618.6500707, 1760037618.8060884, 1760037618.8901484, 1760037618.9781117, 1760037619.0114572, 1760037619.1059728, 1760037619.1059496, 1760037619.1526484, 1760037619.3007338, 1760037619.3972967, 1760037619.4587183, 1760037619.4929383, 1760037619.4929817, 1760037619.5195582, 1760037619.591192, 1760037619.6724472, 1760037619.7257519, 1760037619.7298548, 1760037620.0174434, 1760037620.0174658, 1760037620.0453296, 1760037620.0889473, 1760037620.2088351, 1760037620.2896311, 1760037620.3068223, 1760037620.3521585, 1760037620.3784695, 1760037620.5527534, 1760037620.5894482, 1760037620.6380851, 1760037620.6800897, 1760037620.6880927, 1760037620.7303357, 1760037620.835619, 1760037620.9056506, 1760037620.9159744, 1760037620.9715042, 1760037621.0539403, 1760037621.2468212, 1760037621.4430754, 1760037621.5207613, 1760037621.6400595, 1760037621.6748407, 1760037621.796196, 1760037621.8951564, 1760037621.9805405, 1760037622.0077336, 1760037622.1053214, 1760037622.2015305, 1760037622.3235307, 1760037622.3644574, 1760037622.3914187, 1760037622.5483077, 1760037622.6016293, 1760037622.625884, 1760037622.8273964, 1760037622.8370771, 1760037623.000279, 1760037623.0277092, 1760037623.087121, 1760037623.1409657, 1760037623.1782033, 1760037623.1881828, 1760037623.2338865, 1760037623.2532196, 1760037623.6433342, 1760037623.7521164, 1760037623.8052497, 1760037623.8883948, 1760037624.0255065, 1760037624.0315454, 1760037624.1193938, 1760037624.1238163, 1760037624.1554308, 1760037624.2098355, 1760037624.2281954, 1760037624.2420278, 1760037624.2444632, 1760037624.2497106, 1760037624.256978, 1760037624.2826662, 1760037624.3195367, 1760037624.3462718, 1760037624.3462207, 1760037624.3922668, 1760037624.4025452, 1760037624.4650471, 1760037624.4820046, 1760037624.5405304, 1760037624.5405922, 1760037624.6811717, 1760037624.772498, 1760037624.779036, 1760037624.8872502, 1760037624.929139, 1760037624.9614007, 1760037624.9985669, 1760037625.2077339, 1760037625.257548, 1760037625.2710917, 1760037625.3152406, 1760037625.365373, 1760037625.4007616, 1760037625.4070215, 1760037625.4377544, 1760037625.5323954, 1760037625.5381756, 1760037625.5818505, 1760037625.6011674, 1760037625.616064, 1760037625.666841, 1760037625.7308838, 1760037625.7658947, 1760037625.9337466, 1760037625.9406004, 1760037625.9468784, 1760037626.033466, 1760037626.05172, 1760037626.1254745, 1760037626.236112, 1760037626.2443058, 1760037626.4128137, 1760037626.5314434, 1760037626.552767, 1760037626.671506, 1760037626.679194, 1760037626.7898383, 1760037626.8564663, 1760037626.9883611, 1760037627.0065691, 1760037627.1254, 1760037627.1648374, 1760037627.2589648, 1760037627.2589202, 1760037627.285336, 1760037627.3266332, 1760037627.3927124, 1760037627.4241002, 1760037627.4340687, 1760037627.5022476, 1760037627.5241756, 1760037627.611789, 1760037627.64071, 1760037627.7616172, 1760037627.8372922, 1760037627.8680308, 1760037627.8924587, 1760037627.9177475, 1760037627.9323401, 1760037628.0370524, 1760037628.052442, 1760037628.0840604, 1760037628.2821567, 1760037628.3103154, 1760037628.33231, 1760037628.3642335, 1760037628.364278, 1760037628.4321547, 1760037628.4447882, 1760037628.5076776, 1760037628.5795999, 1760037628.610359, 1760037628.7461007, 1760037628.7817676, 1760037628.9241345, 1760037629.0868514, 1760037629.1462557, 1760037629.3579874, 1760037629.429051, 1760037629.5228279, 1760037629.547042, 1760037629.5530806, 1760037629.6068518, 1760037629.606801, 1760037629.6846507, 1760037629.7172341, 1760037629.7589765, 1760037629.7655802, 1760037629.952019, 1760037630.0241303, 1760037630.0679152, 1760037630.214143, 1760037630.3324485, 1760037630.3631117, 1760037630.419148, 1760037630.4247575, 1760037630.6222417, 1760037630.8091373, 1760037630.8450732, 1760037630.8580825, 1760037631.005924, 1760037631.0321627, 1760037631.0321977, 1760037631.0831988, 1760037631.1786494, 1760037631.1785986, 1760037631.249496, 1760037631.3034565, 1760037631.319224, 1760037631.3286443, 1760037631.4459407, 1760037631.522101, 1760037631.5439684, 1760037631.5500686, 1760037631.5978177, 1760037631.6693125, 1760037631.674103, 1760037631.711554, 1760037631.716404, 1760037631.7555082, 1760037631.9206865, 1760037631.9896665, 1760037631.989714, 1760037632.0776343, 1760037632.0876465, 1760037632.303048, 1760037632.3858955, 1760037632.4671385, 1760037632.4715884, 1760037632.5296597, 1760037632.5511847, 1760037632.5511544, 1760037632.5573237, 1760037632.6735766, 1760037632.7568896, 1760037632.827556, 1760037632.850099, 1760037632.9248016, 1760037632.9357212, 1760037633.1129382, 1760037633.226459, 1760037633.2599342, 1760037633.2681115, 1760037633.2681482, 1760037633.4989748, 1760037633.6338954, 1760037633.6606183, 1760037633.7152665, 1760037633.9277065, 1760037633.9430242, 1760037634.004895, 1760037634.0518572, 1760037634.0642254, 1760037634.0741744, 1760037634.0811052, 1760037634.503167, 1760037634.6202729, 1760037634.6749957, 1760037634.6847284, 1760037634.684767, 1760037634.7718549, 1760037634.7718003, 1760037634.9245517, 1760037634.9324908, 1760037634.9541001, 1760037634.9829283, 1760037634.98832, 1760037635.052907, 1760037635.1284342, 1760037635.1728637, 1760037635.2362037, 1760037635.283985, 1760037635.2944202, 1760037635.377456, 1760037635.3924415, 1760037635.6037886, 1760037635.6154022, 1760037635.6224864, 1760037635.6498353, 1760037635.6602952, 1760037635.6653957, 1760037635.8686283, 1760037636.1348317, 1760037636.387513, 1760037636.401956, 1760037636.4208238, 1760037636.4573133, 1760037636.5620723, 1760037636.5684123, 1760037636.6948907, 1760037636.728085, 1760037636.8151305, 1760037636.8392339, 1760037637.0256188, 1760037637.0783455, 1760037637.2083192, 1760037637.2715518, 1760037637.4060006, 1760037637.4984093, 1760037637.5439975, 1760037637.5804026, 1760037637.6089563, 1760037637.7023642, 1760037637.7216542, 1760037637.8937597, 1760037638.098812, 1760037638.3140764, 1760037638.3294024, 1760037638.3293524, 1760037638.3344567, 1760037638.4003696, 1760037638.4270117, 1760037638.426966, 1760037638.4437454, 1760037638.574787, 1760037638.616574, 1760037638.625511, 1760037638.6985433, 1760037638.8310676, 1760037638.9970398, 1760037639.004415, 1760037639.0444164, 1760037639.0913763, 1760037639.1320481, 1760037639.1320806, 1760037639.1424117, 1760037639.2382069, 1760037639.250186, 1760037639.2501523, 1760037639.2534702, 1760037639.2813022, 1760037639.2862854, 1760037639.3267493, 1760037639.5112631, 1760037639.5629985, 1760037639.6279562, 1760037639.7164962, 1760037639.7536576, 1760037639.7983825, 1760037639.8395722, 1760037639.9441087, 1760037640.0502958, 1760037640.0545812, 1760037640.0953767, 1760037640.1311321, 1760037640.2004464, 1760037640.2312214, 1760037640.2388546, 1760037640.2695363, 1760037640.3453658, 1760037640.4315107, 1760037640.4402697, 1760037640.464485, 1760037640.498121, 1760037640.508711, 1760037640.6176615, 1760037640.6275318, 1760037640.632482, 1760037640.6711738, 1760037640.7977266, 1760037640.808217, 1760037640.8664362, 1760037640.8887215, 1760037640.940208, 1760037641.0159855, 1760037641.070656, 1760037641.1379807, 1760037641.1551461, 1760037641.1577206, 1760037641.1731043, 1760037641.1779842, 1760037641.364451, 1760037641.4510515, 1760037641.4774597, 1760037641.512431, 1760037641.5709586, 1760037641.6326976, 1760037641.6327453, 1760037641.7754145, 1760037641.8275626, 1760037641.8621004, 1760037641.9571474, 1760037642.0682907, 1760037642.1065035, 1760037642.389345, 1760037642.4240618, 1760037642.4496162, 1760037642.7149737, 1760037642.7149284, 1760037642.778165, 1760037642.879392, 1760037642.9217875, 1760037642.9877381, 1760037643.0614908, 1760037643.3747566, 1760037643.543664, 1760037643.6154776, 1760037643.623425, 1760037643.6318514, 1760037643.634433, 1760037643.7284439, 1760037643.7736742, 1760037643.7967668, 1760037643.8018801, 1760037643.8443425, 1760037643.8638077, 1760037643.967594, 1760037644.0146577, 1760037644.1099203, 1760037644.3442726, 1760037644.3744516, 1760037644.380507, 1760037644.4844522, 1760037644.7875688, 1760037644.851913, 1760037645.11201, 1760037645.195377, 1760037645.260817, 1760037645.2641826, 1760037645.2774456, 1760037645.3503754, 1760037645.4285216, 1760037645.4492233, 1760037645.4491718, 1760037645.534716, 1760037645.6336792, 1760037645.7014613, 1760037645.7439227, 1760037645.7498114, 1760037645.8446894, 1760037645.9040067, 1760037645.9215968, 1760037645.9216645, 1760037645.9216511, 1760037646.222174, 1760037646.3616028, 1760037646.606641, 1760037646.649167, 1760037646.7527468, 1760037646.7862701, 1760037646.8068311, 1760037646.8400953, 1760037646.8628755, 1760037646.9214275, 1760037646.9278526, 1760037646.9489076, 1760037647.0130212, 1760037647.0994732, 1760037647.1143744, 1760037647.1143308, 1760037647.325251, 1760037647.5216537, 1760037647.533262, 1760037647.6012099, 1760037647.6523535, 1760037647.820528, 1760037647.9385917, 1760037648.0626912, 1760037648.2860699, 1760037648.2860377, 1760037648.3139803, 1760037648.3139327, 1760037648.3383172, 1760037648.4204118, 1760037648.4354749, 1760037648.4355319, 1760037648.4355452, 1760037648.851878, 1760037648.9293458, 1760037649.0386596, 1760037649.199053, 1760037649.2500293, 1760037649.4420104, 1760037649.5278695, 1760037649.6304786, 1760037649.7593086, 1760037649.767329, 1760037649.8610988, 1760037649.9756463, 1760037649.9956937, 1760037650.1171112, 1760037650.1500065, 1760037650.381307, 1760037650.425705, 1760037650.434651, 1760037650.434722, 1760037650.4347062, 1760037650.4731386, 1760037650.6533036, 1760037650.6699402, 1760037650.7970335, 1760037650.8131075, 1760037651.0130396, 1760037651.0243504, 1760037651.0243146, 1760037651.1020324, 1760037651.1457987, 1760037651.1753922, 1760037651.29645, 1760037651.3654568, 1760037651.4361646, 1760037651.4608443, 1760037651.4707534, 1760037651.64389, 1760037651.7150471, 1760037651.8043563, 1760037651.9521098, 1760037651.9865804, 1760037652.0652108, 1760037652.0713427, 1760037652.2134783, 1760037652.2779133, 1760037652.4956112, 1760037652.5389621, 1760037652.5389776, 1760037652.5389333, 1760037652.72674, 1760037652.7308128, 1760037652.7939289, 1760037652.8227687, 1760037652.8794978, 1760037652.87945, 1760037652.8851762, 1760037652.8852193, 1760037652.9498024, 1760037653.0774553, 1760037653.1460423, 1760037653.1603193, 1760037653.1915374, 1760037653.2744145, 1760037653.4207432, 1760037653.4416773, 1760037653.5253484, 1760037653.7835197, 1760037653.8451436, 1760037653.9114296, 1760037653.9450202, 1760037653.9925952, 1760037654.0008843, 1760037654.09022, 1760037654.13537, 1760037654.1806083, 1760037654.3262553, 1760037654.4079516, 1760037654.4177108, 1760037654.4451902, 1760037654.4973097, 1760037654.5886428, 1760037654.5941417, 1760037654.6448364, 1760037654.6957085, 1760037654.770616, 1760037654.9660444, 1760037654.976026, 1760037654.9887543, 1760037655.0195093, 1760037655.1737628, 1760037655.2632945, 1760037655.2669172, 1760037655.3884168, 1760037655.4346745, 1760037655.5012822, 1760037655.6289449, 1760037655.6887627, 1760037655.69749, 1760037655.6975355, 1760037655.936037, 1760037656.055209, 1760037656.5019095, 1760037656.5080097, 1760037656.6684642, 1760037656.7040048, 1760037656.746603, 1760037656.7932644, 1760037656.793295, 1760037656.7933097, 1760037656.8998725, 1760037657.0522685, 1760037657.1853807, 1760037657.1983879, 1760037657.321321, 1760037657.321287, 1760037657.3213356, 1760037657.406821, 1760037657.579567, 1760037657.6118846, 1760037657.6364908, 1760037657.7339807, 1760037657.7759438, 1760037657.9070332, 1760037657.9511514, 1760037658.2000387, 1760037658.2344077, 1760037658.3109477, 1760037658.339082, 1760037658.4060483, 1760037658.605569, 1760037658.8215902, 1760037658.8711457, 1760037659.0262847, 1760037659.0485373, 1760037659.1205196, 1760037659.2630346, 1760037659.2882805, 1760037659.3421915, 1760037659.445322, 1760037659.633519, 1760037659.633494, 1760037659.7135339, 1760037659.7274632, 1760037659.7538614, 1760037659.875406, 1760037659.9566016, 1760037660.0074253, 1760037660.0174382, 1760037660.0518277, 1760037660.1020613, 1760037660.1460824, 1760037660.290679, 1760037660.414645, 1760037660.419806, 1760037660.6693776, 1760037660.7040858, 1760037660.8615282, 1760037660.8704858, 1760037660.8918965, 1760037660.9738522, 1760037661.0423088, 1760037661.086425, 1760037661.1052377, 1760037661.177272, 1760037661.30099, 1760037661.3199673, 1760037661.4340599, 1760037661.5210779, 1760037661.5979102, 1760037661.6033318, 1760037661.8752563, 1760037662.0787365, 1760037662.2661424, 1760037662.2757645, 1760037662.4023411, 1760037662.4338808, 1760037662.4884715, 1760037662.4946105, 1760037662.5165322, 1760037662.6682806, 1760037662.7808504, 1760037662.966734, 1760037663.0211847, 1760037663.1312933, 1760037663.2321293, 1760037663.2877445, 1760037663.3076386, 1760037663.3757107, 1760037663.3935745, 1760037663.442639, 1760037663.482313, 1760037663.4822803, 1760037663.5295873, 1760037663.540344, 1760037663.5560632, 1760037663.575721, 1760037663.7234921, 1760037663.86914, 1760037663.8758695, 1760037663.8989875, 1760037663.9260495, 1760037664.1026697, 1760037664.1587522, 1760037664.1637568, 1760037664.3932428, 1760037664.4544866, 1760037664.4659452, 1760037664.6946292, 1760037664.7331607, 1760037664.7971113, 1760037664.8857203, 1760037665.0173025, 1760037665.059853, 1760037665.1263053, 1760037665.1528492, 1760037665.2284107, 1760037665.2977297, 1760037665.3875535, 1760037665.3957517, 1760037665.4052086, 1760037665.4998388, 1760037665.5693974, 1760037665.624033, 1760037665.6734354, 1760037665.7584844, 1760037665.95222, 1760037665.9705083, 1760037666.224943, 1760037666.2627313, 1760037666.542674, 1760037666.5575578, 1760037666.695707, 1760037666.71354, 1760037666.790887, 1760037666.932463, 1760037666.939754, 1760037666.9397163, 1760037666.95007, 1760037667.0278552, 1760037667.2617536, 1760037667.2981591, 1760037667.3027453, 1760037667.3434148, 1760037667.373044, 1760037667.4071317, 1760037667.4372013, 1760037667.446248, 1760037667.5667098, 1760037667.6810572, 1760037667.810754, 1760037667.9776912, 1760037668.0411186, 1760037668.0896056, 1760037668.1180477, 1760037668.1280107, 1760037668.155487, 1760037668.209098, 1760037668.248597, 1760037668.5050023, 1760037668.5049534, 1760037668.5149825, 1760037668.603174, 1760037668.6214309, 1760037668.6556523, 1760037668.8817906, 1760037668.8969114, 1760037668.9796987, 1760037669.1122572, 1760037669.213005, 1760037669.3200588, 1760037669.3263686, 1760037669.3263283, 1760037669.371756, 1760037669.4571786, 1760037669.4865413, 1760037669.6894956, 1760037669.7754533, 1760037669.812378, 1760037669.8508599, 1760037669.9654775, 1760037669.9737873, 1760037670.0030968, 1760037670.058913, 1760037670.3750834, 1760037670.4004314, 1760037670.4744492, 1760037670.530984, 1760037670.990315, 1760037671.1425045, 1760037671.148131, 1760037671.169457, 1760037671.1917536, 1760037671.387791, 1760037671.424656, 1760037671.4825413, 1760037671.493717, 1760037671.5328164, 1760037671.6192708, 1760037671.8871377, 1760037672.0529282, 1760037672.1324818, 1760037672.1376352, 1760037672.16943, 1760037672.309967, 1760037672.3460536, 1760037672.4232306, 1760037672.529712, 1760037672.6617498, 1760037672.7279017, 1760037672.7603054, 1760037672.8431842, 1760037672.8505983, 1760037672.903814, 1760037672.9497638, 1760037673.0722756, 1760037673.1531909, 1760037673.3465424, 1760037673.4988816, 1760037673.7364633, 1760037673.7364202, 1760037673.77315, 1760037673.779233, 1760037673.7791877, 1760037674.1406133, 1760037674.3382735, 1760037674.3809705, 1760037674.4036002, 1760037674.6182222, 1760037674.6533744, 1760037674.6586552, 1760037674.6796877, 1760037674.7404656, 1760037674.7897062, 1760037674.8405979, 1760037674.8660812, 1760037674.9246554, 1760037674.9477959, 1760037674.9944117, 1760037675.0626729, 1760037675.18665, 1760037675.202518, 1760037675.2419212, 1760037675.3169045, 1760037675.3727384, 1760037675.481986, 1760037675.5009727, 1760037675.5106487, 1760037675.555456, 1760037675.6886175, 1760037675.7470796, 1760037675.751527, 1760037675.9206774, 1760037675.9207234, 1760037675.949798, 1760037675.982517, 1760037676.1251667, 1760037676.1344056, 1760037676.18017, 1760037676.2479522, 1760037676.2571633, 1760037676.5725288, 1760037676.6040668, 1760037676.6512904, 1760037676.6985404, 1760037676.7190714, 1760037676.7663214, 1760037676.8041282, 1760037676.8781307, 1760037676.916455, 1760037676.9340231, 1760037677.1032493, 1760037677.1137738, 1760037677.203259, 1760037677.2077217, 1760037677.2468088, 1760037677.298601, 1760037677.3481305, 1760037677.4625728, 1760037677.539853, 1760037677.6675997, 1760037677.7706563, 1760037677.7753446, 1760037677.8891897, 1760037677.9190626, 1760037677.9350796, 1760037677.948752, 1760037678.327828, 1760037678.3340974, 1760037678.3809428, 1760037678.407222, 1760037678.4389908, 1760037678.46172, 1760037678.4749298, 1760037678.7435613, 1760037678.7961144, 1760037678.8897495, 1760037679.081382, 1760037679.0814166, 1760037679.1981604, 1760037679.2683117, 1760037679.276101, 1760037679.3593833, 1760037679.4094784, 1760037679.4094474, 1760037679.4833646, 1760037679.550495, 1760037679.5595345, 1760037679.5595715, 1760037679.6173403, 1760037679.6586843, 1760037679.7111712, 1760037679.894801, 1760037680.1308496, 1760037680.340062, 1760037680.3592482, 1760037680.3743548, 1760037680.395843, 1760037680.4907477, 1760037680.5007212, 1760037680.5280006, 1760037680.613298, 1760037680.6512105, 1760037680.6511793, 1760037680.7171702, 1760037680.8310006, 1760037680.8689432, 1760037680.9677224, 1760037680.9942706, 1760037681.0034146, 1760037681.0732582, 1760037681.2134533, 1760037681.2526376, 1760037681.2526062, 1760037681.7742376, 1760037681.7870367, 1760037681.8003073, 1760037681.8003514, 1760037681.8080332, 1760037681.839554, 1760037681.9767954, 1760037682.0224304, 1760037682.0293114, 1760037682.029272, 1760037682.1050696, 1760037682.1554775, 1760037682.248038, 1760037682.4708936, 1760037682.5530486, 1760037682.5779216, 1760037682.7314484, 1760037682.7404792, 1760037682.9015944, 1760037682.9015636, 1760037682.912507, 1760037683.098179, 1760037683.1611176, 1760037683.2219517, 1760037683.2423859, 1760037683.2680466, 1760037683.5210092, 1760037683.5884137, 1760037683.6733687, 1760037683.7201536, 1760037683.867692, 1760037683.9705396, 1760037684.0371494, 1760037684.1494381, 1760037684.172512, 1760037684.3672645, 1760037684.5378988, 1760037684.6816545, 1760037684.7299778, 1760037684.7383573, 1760037684.764354, 1760037684.7691135, 1760037684.9542615, 1760037685.0095494, 1760037685.1144116, 1760037685.203528, 1760037685.3802478, 1760037685.4063613, 1760037685.5277855, 1760037685.5896251, 1760037685.594782, 1760037685.6304314, 1760037685.7722464, 1760037685.8050935, 1760037685.994743, 1760037686.067774, 1760037686.1144602, 1760037686.1220837, 1760037686.1972346, 1760037686.2202504, 1760037686.2419357, 1760037686.7038467, 1760037686.7730713, 1760037686.8087308, 1760037686.8605561, 1760037686.9613473, 1760037687.2049847, 1760037687.272966, 1760037687.3128452, 1760037687.3632133, 1760037687.3714013, 1760037687.533477, 1760037687.654496, 1760037687.6958096, 1760037687.703571, 1760037687.8984945, 1760037688.0358686, 1760037688.1876392, 1760037688.3200247, 1760037688.4979217, 1760037688.512773, 1760037688.5302804, 1760037688.5458376, 1760037688.5701907, 1760037688.651489, 1760037688.7619605, 1760037688.794808, 1760037688.8471124, 1760037688.9637797, 1760037689.1313884, 1760037689.163503, 1760037689.1897273, 1760037689.4183345, 1760037689.5777965, 1760037689.607225, 1760037689.7689848, 1760037689.7689495, 1760037689.795782, 1760037689.7958262, 1760037689.84589, 1760037689.8565507, 1760037689.986009, 1760037690.017948, 1760037690.1295288, 1760037690.2102442, 1760037690.2323895, 1760037690.2474627, 1760037690.3684707, 1760037690.4813583, 1760037690.5911927, 1760037690.6377413, 1760037690.6446052, 1760037690.833546, 1760037690.8656452, 1760037690.8724213, 1760037691.042655, 1760037691.2231731, 1760037691.2772307, 1760037691.325968, 1760037691.3365495, 1760037691.3936784, 1760037691.5276303, 1760037691.5749698, 1760037691.5995598, 1760037691.7112916, 1760037691.8277342, 1760037691.8422515, 1760037691.8616416, 1760037691.937139, 1760037691.9497745, 1760037691.9689984, 1760037691.9727097, 1760037691.993737, 1760037692.0975683, 1760037692.1480289, 1760037692.1998696, 1760037692.2065501, 1760037692.3580582, 1760037692.4216862, 1760037692.5082965, 1760037692.51632, 1760037692.6876166, 1760037692.8468215, 1760037692.9292872, 1760037692.9477499, 1760037693.0128832, 1760037693.028258, 1760037693.0408533, 1760037693.055849, 1760037693.2457533, 1760037693.3723838, 1760037693.3887863, 1760037693.4534726, 1760037693.498603, 1760037693.6135414, 1760037693.6878133, 1760037693.7328005, 1760037693.789917, 1760037693.8667436, 1760037694.0958915, 1760037694.1503713, 1760037694.184643, 1760037694.2488081, 1760037694.2784884, 1760037694.4250042, 1760037694.4368849, 1760037694.4711952, 1760037694.4830127, 1760037694.5017889, 1760037694.5345728, 1760037694.585893, 1760037694.615496, 1760037694.691585, 1760037694.7658184, 1760037694.8115282, 1760037694.8421955, 1760037694.979711, 1760037694.987241, 1760037695.020856, 1760037695.1303396, 1760037695.1770146, 1760037695.1890042, 1760037695.2432935, 1760037695.414216, 1760037695.6645486, 1760037695.8295515, 1760037695.878242, 1760037695.8840523, 1760037695.9418366, 1760037696.1216342, 1760037696.1287668, 1760037696.3461154, 1760037696.5186923, 1760037696.5360203, 1760037696.5529292, 1760037696.5643249, 1760037696.784186, 1760037696.8435454, 1760037697.3319678, 1760037697.4016056, 1760037697.4198308, 1760037697.5672715, 1760037697.7603638, 1760037697.8053951, 1760037697.8317304, 1760037697.971629, 1760037698.3578196, 1760037698.5621967, 1760037698.6004214, 1760037698.6619663, 1760037698.6729608, 1760037699.0311532, 1760037699.3523664, 1760037699.4185596, 1760037699.4985204, 1760037700.0927873, 1760037700.0980308, 1760037700.274975, 1760037700.4524024, 1760037700.6980038, 1760037700.7214808, 1760037700.9110973, 1760037701.0894527, 1760037701.131045, 1760037701.7077491, 1760037701.8074923, 1760037701.9681473, 1760037701.992971, 1760037702.0129704, 1760037702.034302, 1760037702.2474706, 1760037702.3270335, 1760037702.3499184, 1760037702.5742693, 1760037703.0988352, 1760037703.1156263, 1760037703.1956306, 1760037703.2493782, 1760037703.5817692, 1760037703.7824433, 1760037703.8766801, 1760037703.91197, 1760037704.1432133, 1760037704.2508786, 1760037704.2761917, 1760037704.4522529, 1760037704.558683, 1760037704.9223483, 1760037704.9933808, 1760037704.9999874, 1760037705.019004, 1760037705.1113992, 1760037705.1915238, 1760037705.2473974, 1760037705.3504772, 1760037705.8542955, 1760037705.9804144, 1760037705.998861, 1760037706.1512423, 1760037706.2095912, 1760037706.239442, 1760037706.371592, 1760037706.610703, 1760037706.7000968, 1760037706.7634356, 1760037706.7670856, 1760037707.0077586, 1760037707.0077112, 1760037707.1451192, 1760037707.2714636, 1760037707.2804232, 1760037707.3887787, 1760037707.4163723, 1760037707.501423, 1760037707.61744, 1760037707.7001648, 1760037707.775103, 1760037707.783145, 1760037708.0781343, 1760037708.2871149, 1760037708.3594408, 1760037708.370385, 1760037708.6359816, 1760037708.6910772, 1760037708.776205, 1760037708.963405, 1760037709.211289, 1760037709.2433548, 1760037709.2987366, 1760037709.4571846, 1760037709.6707463, 1760037709.893011, 1760037709.9487257, 1760037710.218972, 1760037710.2482243, 1760037710.266081, 1760037710.7908704, 1760037711.1080408, 1760037711.112148, 1760037711.250405, 1760037711.2606468, 1760037711.423928, 1760037711.4663322, 1760037711.5408986, 1760037711.8727362, 1760037712.0227168, 1760037712.0394173, 1760037712.0837634, 1760037712.108598, 1760037712.1621914, 1760037712.223093, 1760037712.3470325, 1760037712.5741043, 1760037712.5740554, 1760037712.713226, 1760037712.7716413, 1760037712.8672214, 1760037712.8822591, 1760037713.0015285, 1760037713.0931668, 1760037713.3566208, 1760037713.414566, 1760037713.532407, 1760037713.5719733, 1760037713.626882, 1760037713.648624, 1760037713.7270691, 1760037713.9676464, 1760037713.9928353, 1760037714.1010604, 1760037714.3309066, 1760037714.347181, 1760037714.395439, 1760037714.4292955, 1760037714.5536451, 1760037714.5535989, 1760037714.5839243, 1760037714.802022, 1760037715.032157, 1760037715.0403829, 1760037715.1097715, 1760037715.168822, 1760037715.2332945, 1760037715.47148, 1760037715.5283163, 1760037715.7246082, 1760037715.7754726, 1760037715.8153446, 1760037715.8704052, 1760037715.8750937, 1760037715.8962774, 1760037715.9339478, 1760037716.051269, 1760037716.4158478, 1760037716.5154042, 1760037716.5415509, 1760037716.6800902, 1760037716.7498207, 1760037716.9070373, 1760037717.3746526, 1760037717.473526, 1760037717.6101282, 1760037717.7679186, 1760037717.8232522, 1760037718.015344, 1760037718.0831072, 1760037718.2482717, 1760037718.267857, 1760037718.2679172, 1760037718.2679317, 1760037718.422803, 1760037718.4491982, 1760037718.7491364, 1760037718.8705323, 1760037718.9416327, 1760037719.112194, 1760037719.137556, 1760037719.532644, 1760037719.545907, 1760037719.860425, 1760037719.8652515, 1760037719.8730173, 1760037720.579828, 1760037720.8572164, 1760037721.028231, 1760037721.0416768, 1760037721.106879, 1760037721.4147522, 1760037721.8181124, 1760037721.8345044, 1760037721.8345485, 1760037721.9876094, 1760037722.0242255, 1760037722.4574275, 1760037722.5061684, 1760037722.5624945, 1760037722.687905, 1760037722.7427363, 1760037722.7860763, 1760037722.858314, 1760037722.980216, 1760037723.0288012, 1760037723.1951475, 1760037723.2334619, 1760037723.2929914, 1760037723.5383031, 1760037723.567675, 1760037723.6072457, 1760037723.6232085, 1760037723.7541332, 1760037723.8364856, 1760037723.9453785, 1760037724.0110574, 1760037724.219336, 1760037724.3553011, 1760037724.573719, 1760037724.5772839, 1760037724.8360934, 1760037725.0637038, 1760037725.095718, 1760037725.1409159, 1760037725.2584171, 1760037725.6429813, 1760037725.723417, 1760037725.8725214, 1760037725.9109519, 1760037726.1597366, 1760037726.350578, 1760037726.3599699, 1760037726.605308, 1760037727.169277, 1760037727.35844, 1760037727.369821, 1760037727.4431458, 1760037727.6823404, 1760037727.702201, 1760037728.0435863, 1760037728.085538, 1760037728.3218157, 1760037728.5235372, 1760037728.8266232, 1760037728.9749403, 1760037729.0384202, 1760037729.1026573, 1760037729.1889012, 1760037730.0612082, 1760037730.07865, 1760037730.1216273, 1760037730.1515524, 1760037730.1896448, 1760037730.2464306, 1760037730.2877798, 1760037730.3093224, 1760037730.4802394, 1760037730.6619623, 1760037730.6643636, 1760037730.8520417, 1760037731.136687, 1760037731.16398, 1760037731.4096696, 1760037731.4251704, 1760037731.7347584, 1760037731.7642903, 1760037732.2543333, 1760037732.6477797, 1760037732.6549885, 1760037732.6810238, 1760037732.8044097, 1760037733.2575188, 1760037733.4374363, 1760037733.4497135, 1760037733.4765272, 1760037733.5260444, 1760037733.5905428, 1760037733.653831, 1760037734.166785, 1760037734.1881444, 1760037734.3807662, 1760037734.4118164, 1760037734.5904157, 1760037734.6394186, 1760037734.8000824, 1760037734.8200488, 1760037735.3888583, 1760037735.3969262, 1760037735.432376, 1760037735.5732238, 1760037735.6472456, 1760037735.7483842, 1760037735.8107057, 1760037735.832959, 1760037736.0316591, 1760037736.0692158, 1760037736.1752806, 1760037736.2188284, 1760037736.2927687, 1760037736.6554232, 1760037736.7161214, 1760037736.9549766, 1760037737.0651684, 1760037737.068584, 1760037737.1908803, 1760037737.22261, 1760037737.2898142, 1760037737.674434, 1760037737.834261, 1760037737.9893286, 1760037738.0538242, 1760037738.1205976, 1760037738.2457385, 1760037738.3364146, 1760037738.3546352, 1760037738.7310717, 1760037738.8946517, 1760037738.9005408, 1760037738.9177725, 1760037738.9239347, 1760037739.2181923, 1760037739.4289286, 1760037739.5290222, 1760037739.7989876, 1760037740.0736146, 1760037740.1072133, 1760037740.4733214, 1760037740.7694204, 1760037740.934552, 1760037740.9784472, 1760037741.2087848, 1760037741.384769, 1760037741.5403616, 1760037741.622393, 1760037741.6331234, 1760037741.6386936, 1760037742.0057304, 1760037742.0497859, 1760037742.133736, 1760037742.174475, 1760037742.2838783, 1760037742.3842149, 1760037742.4823472, 1760037742.4823127, 1760037742.5126812, 1760037742.521072, 1760037742.5514464, 1760037742.6978624, 1760037742.8939595, 1760037743.3343804, 1760037743.4253583, 1760037743.5657287, 1760037743.839082, 1760037743.9050756, 1760037743.955391, 1760037744.045122, 1760037744.0592933, 1760037744.3622506, 1760037744.3851938, 1760037744.393934, 1760037744.419024, 1760037744.4754853, 1760037744.6121678, 1760037745.001184, 1760037745.5855904, 1760037746.01391, 1760037746.0511198, 1760037746.1831825, 1760037746.2477267, 1760037746.5584853, 1760037746.699973, 1760037746.722689, 1760037746.7589064, 1760037746.8524916, 1760037746.8704255, 1760037747.094081, 1760037747.1133633, 1760037747.7701168, 1760037747.9402804, 1760037747.9402337, 1760037748.1594915, 1760037748.3165, 1760037748.3999462, 1760037748.4111357, 1760037748.5831306, 1760037748.6223695, 1760037748.8617027, 1760037748.8963258, 1760037749.0953162, 1760037749.196985, 1760037749.2257216, 1760037749.2806668, 1760037749.3683395, 1760037749.385511, 1760037749.420145, 1760037749.5031326, 1760037749.8895912, 1760037749.9596326, 1760037750.0304315, 1760037750.0435174, 1760037750.6640825, 1760037750.6999075, 1760037750.8358436, 1760037750.913398, 1760037751.2657444, 1760037751.685838, 1760037751.7111363, 1760037751.7426763, 1760037751.7645178, 1760037752.123133, 1760037752.1289015, 1760037752.3889933, 1760037752.7094464, 1760037752.7367885, 1760037752.7957618, 1760037752.8500483, 1760037752.9082386, 1760037752.9122133, 1760037753.031348, 1760037753.234999, 1760037753.4480891, 1760037753.4586651, 1760037754.2111216, 1760037754.5710917, 1760037755.1029952, 1760037755.2021666, 1760037755.202119, 1760037755.6338851, 1760037755.6446106, 1760037755.7447884, 1760037755.7529273, 1760037755.8255649, 1760037755.9384174, 1760037756.0449245, 1760037756.0541086, 1760037756.4267244, 1760037756.555013, 1760037756.7497342, 1760037757.0184994, 1760037757.1034176, 1760037757.192407, 1760037757.2809615, 1760037757.3448782, 1760037757.4936814, 1760037757.625229, 1760037757.6855004, 1760037758.6847737, 1760037758.767906, 1760037759.0346935, 1760037759.0720537, 1760037759.439937, 1760037759.4528818, 1760037759.6351006, 1760037759.7357483, 1760037759.8456721, 1760037760.076792, 1760037760.3943336, 1760037760.5035112, 1760037760.5381546, 1760037760.6083028, 1760037760.8954213, 1760037760.9979897, 1760037761.2224874, 1760037761.3702366, 1760037761.4255514, 1760037761.4289408, 1760037761.5830991, 1760037761.8427925, 1760037761.8925734, 1760037762.4646797, 1760037762.4708784, 1760037762.5200784, 1760037762.7816863, 1760037762.833511, 1760037763.0679643, 1760037763.102062, 1760037763.1137953, 1760037763.2399125, 1760037763.2629406, 1760037763.5524845, 1760037763.817576, 1760037763.9236937, 1760037764.203941, 1760037764.231951, 1760037764.356585, 1760037764.408074, 1760037764.454897, 1760037764.6721606, 1760037764.9670668, 1760037765.0643075, 1760037765.1584337, 1760037765.3363378, 1760037765.4988697, 1760037765.7841337, 1760037766.080655, 1760037766.0875213, 1760037766.3072538, 1760037766.3510547, 1760037766.7433462, 1760037767.3639293, 1760037767.5830026, 1760037767.6721528, 1760037767.7434955, 1760037767.800325, 1760037767.9538484, 1760037768.4607065, 1760037768.5091205, 1760037768.6872225, 1760037768.9458687, 1760037769.043711, 1760037769.1608582, 1760037769.182894, 1760037769.3060026, 1760037769.3359134, 1760037769.3860037, 1760037769.7401793, 1760037769.7607641, 1760037769.890747, 1760037769.923924, 1760037769.995614, 1760037770.1135755, 1760037770.16575, 1760037770.3985162, 1760037770.4670382, 1760037770.579489, 1760037770.8201766, 1760037771.0419636, 1760037771.15229, 1760037771.2326088, 1760037771.7101789, 1760037771.7226346, 1760037772.1087048, 1760037772.3035326, 1760037772.5406477, 1760037772.5944622, 1760037772.599458, 1760037772.6560152, 1760037772.7840326, 1760037773.1637263, 1760037773.5979946, 1760037773.6182218, 1760037773.705, 1760037773.9752626, 1760037774.2507784, 1760037774.3491983, 1760037774.375673, 1760037774.4883175, 1760037774.4974372, 1760037774.809629, 1760037774.8170223, 1760037774.8734, 1760037774.890717, 1760037774.8984616, 1760037774.9059331, 1760037774.9678552, 1760037774.9750395, 1760037775.196344, 1760037775.196311, 1760037775.3509495, 1760037775.3773394, 1760037775.425778, 1760037775.6640382, 1760037775.718661, 1760037776.0097046, 1760037776.1025052, 1760037776.1024601, 1760037776.3779685, 1760037776.7344816, 1760037776.835326, 1760037776.8398619, 1760037777.019844, 1760037777.19797, 1760037777.2471738, 1760037777.2912, 1760037777.5229511, 1760037777.7724752, 1760037777.9089618, 1760037778.0419729, 1760037778.0470083, 1760037778.3067653, 1760037778.4453833, 1760037779.3951714, 1760037779.437879, 1760037779.5771568, 1760037779.9996586, 1760037780.0127795, 1760037780.0993178, 1760037780.3446379, 1760037780.5779006, 1760037780.6699364, 1760037780.8326917, 1760037781.05189, 1760037781.0998826, 1760037781.519489, 1760037781.5320997, 1760037781.7924016, 1760037781.7965767, 1760037781.8888032, 1760037782.02343, 1760037782.131393, 1760037782.4300396, 1760037782.832376, 1760037783.1495624, 1760037783.3276188, 1760037783.396391, 1760037783.52276, 1760037783.8331413, 1760037783.962129, 1760037784.0919425, 1760037784.2725124, 1760037784.5926483, 1760037784.8952258, 1760037785.0012472, 1760037785.611493, 1760037785.7526128, 1760037786.0042818, 1760037786.612686, 1760037786.6413171, 1760037786.8413715, 1760037786.8679295, 1760037786.8994431, 1760037787.0337653, 1760037787.3567212, 1760037787.3679824, 1760037787.4017408, 1760037787.520834, 1760037788.1421726, 1760037788.1972198, 1760037788.3276453, 1760037788.3797834, 1760037788.3888018, 1760037788.696022, 1760037788.7876427, 1760037788.8307228, 1760037789.00006, 1760037789.4222822, 1760037789.6535025, 1760037789.6653445, 1760037790.300601, 1760037790.3758562, 1760037790.5803854, 1760037790.8564293, 1760037791.1465669, 1760037791.43021, 1760037791.6429129, 1760037792.1424973, 1760037792.183522, 1760037792.5148935, 1760037792.6214077, 1760037792.621428, 1760037792.625962, 1760037792.6259382, 1760037792.7839847, 1760037792.823729, 1760037792.9930372, 1760037793.0537534, 1760037793.1135, 1760037793.1214209, 1760037793.1588683, 1760037793.2889783, 1760037793.354361, 1760037793.3996696, 1760037793.4450235, 1760037793.44507, 1760037793.5597663, 1760037793.631026, 1760037794.0614152, 1760037794.1542277, 1760037794.163844, 1760037794.2725415, 1760037794.5633583, 1760037794.5633113, 1760037794.869141, 1760037794.8818214, 1760037795.0111916, 1760037795.0592322, 1760037795.11547, 1760037795.1925118, 1760037795.235249, 1760037795.2481015, 1760037795.2676282, 1760037795.4759014, 1760037795.5239818, 1760037795.588331, 1760037795.6105635, 1760037795.7081602, 1760037795.7369394, 1760037795.7566442, 1760037796.030215, 1760037796.373431, 1760037796.681205, 1760037796.9421935, 1760037797.097062, 1760037797.1519425, 1760037797.1670713, 1760037797.1758637, 1760037797.4267476, 1760037797.4481227, 1760037797.4809768, 1760037797.5292208, 1760037797.5292506, 1760037797.5705028, 1760037797.586708, 1760037797.658432, 1760037797.7835054, 1760037797.9959397, 1760037797.9991412, 1760037798.0360813, 1760037798.0360322, 1760037798.2094493, 1760037798.32003, 1760037798.574083, 1760037798.740721, 1760037798.8414729, 1760037798.841529, 1760037798.864404, 1760037799.119437, 1760037799.1503425, 1760037799.2494075, 1760037799.3019907, 1760037799.4704025, 1760037799.6974268, 1760037799.9086897, 1760037800.425408, 1760037800.544892, 1760037800.7897472, 1760037801.198125, 1760037801.4282005, 1760037801.5343962, 1760037801.636578, 1760037801.7518487, 1760037801.774646, 1760037801.9587786, 1760037801.9773335, 1760037802.103889, 1760037802.179191, 1760037802.646808, 1760037802.7629094, 1760037802.9000711, 1760037802.9760363, 1760037803.1110466, 1760037803.3385046, 1760037803.3535576, 1760037803.367608, 1760037803.391287, 1760037803.6308951, 1760037803.6546128, 1760037804.813458, 1760037804.8553967, 1760037804.9898355, 1760037805.122358, 1760037805.248873, 1760037805.3921633, 1760037805.4709208, 1760037805.731456, 1760037805.8824415, 1760037806.1718585, 1760037806.4780219, 1760037806.6135862, 1760037806.6624618, 1760037806.8754354, 1760037806.8791661, 1760037806.91622, 1760037807.1474164, 1760037807.215049, 1760037807.3270662, 1760037807.5943103, 1760037807.60137, 1760037807.85939, 1760037807.9564025, 1760037807.9757698, 1760037808.0152485, 1760037808.191307, 1760037808.4386775, 1760037808.454019, 1760037808.69637, 1760037808.7442522, 1760037808.9107647, 1760037808.922216, 1760037809.0041995, 1760037809.2341864, 1760037809.3591433, 1760037809.63907, 1760037809.7985816, 1760037810.1354537, 1760037810.144863, 1760037810.196591, 1760037810.6357338, 1760037811.198557, 1760037811.3049586, 1760037811.3523011, 1760037811.405356, 1760037811.4216056, 1760037811.5128088, 1760037811.544631, 1760037811.6886942, 1760037811.7205439, 1760037811.838121, 1760037811.9355812, 1760037812.073233, 1760037812.14722, 1760037812.241377, 1760037812.333515, 1760037812.3957229, 1760037812.4218876, 1760037812.8916352, 1760037813.1774018, 1760037813.2206407, 1760037813.2709181, 1760037813.3179061, 1760037813.328346, 1760037813.3944151, 1760037813.4569283, 1760037813.4738722, 1760037813.4738333, 1760037813.6263125, 1760037813.6760843, 1760037813.8123507, 1760037813.9724414, 1760037813.9806807, 1760037814.0194805, 1760037814.1012566, 1760037814.1328406, 1760037814.1593373, 1760037814.2044072, 1760037814.3635159, 1760037814.389358, 1760037814.480402, 1760037814.514656, 1760037814.5515528, 1760037814.554589, 1760037814.5814712, 1760037814.6885903, 1760037814.7232914, 1760037814.7478118, 1760037814.9486358, 1760037815.0091915, 1760037815.139117, 1760037815.2102668, 1760037815.2992253, 1760037815.861753, 1760037815.915558, 1760037816.228189, 1760037816.308875, 1760037816.4171312, 1760037817.0880446, 1760037817.1732628, 1760037817.308766, 1760037817.315919, 1760037817.3652823, 1760037817.4022958, 1760037817.4823914, 1760037817.633786, 1760037817.6367517, 1760037817.687657, 1760037818.1824746, 1760037818.3513794, 1760037818.7836313, 1760037819.5692468, 1760037819.7166536, 1760037819.7987337, 1760037819.8200214, 1760037819.8554113, 1760037819.8624642, 1760037820.0714912, 1760037820.113835, 1760037820.2512407, 1760037820.3480895, 1760037820.3991015, 1760037820.4618742, 1760037820.5613956, 1760037820.5667117, 1760037820.745664, 1760037820.9636264, 1760037821.496196, 1760037821.5064187, 1760037821.5961065, 1760037821.6409762, 1760037821.7432265, 1760037821.8802462, 1760037821.963649, 1760037821.9740686, 1760037822.0695968, 1760037822.119308, 1760037822.349587, 1760037822.3909085, 1760037822.4416015, 1760037822.455602, 1760037822.6051338, 1760037822.6620846, 1760037822.8838031, 1760037823.0301104, 1760037823.1144311, 1760037823.4301343, 1760037823.633214, 1760037823.8570943, 1760037823.8663363, 1760037824.4989667, 1760037824.7967286, 1760037824.9317896, 1760037825.2880454, 1760037825.4448633, 1760037825.4808302, 1760037825.4988296, 1760037826.0528283, 1760037826.2243023, 1760037826.3007596, 1760037826.4481263, 1760037826.633835, 1760037826.7100878, 1760037826.7202263, 1760037826.8287115, 1760037826.930344, 1760037827.001959, 1760037827.036348, 1760037827.0545444, 1760037827.6889093, 1760037827.9738235, 1760037828.0006118, 1760037828.0937915, 1760037828.1840873, 1760037828.3541763, 1760037828.4415812, 1760037828.4916184, 1760037828.491565, 1760037828.5540628, 1760037828.564921, 1760037828.6143768, 1760037828.8110836, 1760037829.1745687, 1760037829.6156523, 1760037829.6370707, 1760037829.6633663, 1760037829.9065104, 1760037829.9537714, 1760037830.0082142, 1760037830.0344186, 1760037830.1036026, 1760037830.1418717, 1760037830.4725766, 1760037830.7496789, 1760037830.7594478, 1760037831.0412002, 1760037831.0511398, 1760037831.1182551, 1760037831.1799183, 1760037831.1851585, 1760037831.216467, 1760037831.2342806, 1760037831.2504435, 1760037831.280525, 1760037831.2851026, 1760037831.416281, 1760037831.8935263, 1760037831.912774, 1760037831.9128044, 1760037832.0660408, 1760037832.4378061, 1760037832.4722316, 1760037832.5097163, 1760037832.5096676, 1760037832.5176384, 1760037832.5176039, 1760037832.5921624, 1760037832.9227657, 1760037832.9420006, 1760037833.3563623, 1760037833.6426408, 1760037833.7523587, 1760037833.7700624, 1760037833.781821, 1760037834.021676, 1760037834.2698777, 1760037834.3865802, 1760037834.4018288, 1760037834.4369245, 1760037834.6407905, 1760037834.8391385, 1760037835.075333, 1760037835.1774604, 1760037835.3550086, 1760037835.6532497, 1760037835.8182673, 1760037835.9664655, 1760037836.1893582, 1760037836.28452, 1760037836.3129468, 1760037836.3599174, 1760037836.359884, 1760037836.3599355, 1760037836.3599498, 1760037836.3648074, 1760037836.3920362, 1760037836.5355937, 1760037836.5831466, 1760037836.5949407, 1760037836.6021223, 1760037836.7521658, 1760037837.2499967, 1760037837.3338146, 1760037837.3433836, 1760037837.582409, 1760037837.7604353, 1760037837.773529, 1760037837.999433, 1760037838.1073475, 1760037838.178862, 1760037838.2590723, 1760037838.2697241, 1760037838.6400228, 1760037838.8648562, 1760037838.8936784, 1760037838.899685, 1760037839.2649908, 1760037839.2721941, 1760037839.2796361, 1760037839.3561351, 1760037839.3895228, 1760037839.4770985, 1760037839.628802, 1760037839.6927948, 1760037839.7362797, 1760037839.9313116, 1760037840.2523894, 1760037840.618148, 1760037840.8981721, 1760037841.1185062, 1760037841.178896, 1760037841.186455, 1760037841.3688245, 1760037841.3688557, 1760037841.4543562, 1760037841.4543116, 1760037841.4786599, 1760037841.8115604, 1760037841.8651266, 1760037842.1791854, 1760037842.2006783, 1760037842.7178228, 1760037842.738746, 1760037842.8227515, 1760037842.8914437, 1760037842.9416177, 1760037843.0120895, 1760037843.0414815, 1760037843.229391, 1760037843.3678625, 1760037843.4086974, 1760037843.6254535, 1760037843.6387348, 1760037843.6924477, 1760037843.7318063, 1760037843.765373, 1760037843.7784042, 1760037843.9737258, 1760037844.0726705, 1760037844.0776525, 1760037844.151531, 1760037844.1854377, 1760037844.3104968, 1760037844.3324273, 1760037844.458219, 1760037844.5325124, 1760037844.582874, 1760037844.6280756, 1760037844.7182717, 1760037844.8746784, 1760037844.9687886, 1760037845.0932474, 1760037845.0932941, 1760037845.3220272, 1760037845.3307858, 1760037845.330826, 1760037845.3986895, 1760037845.4742892, 1760037845.7301173, 1760037845.74554, 1760037845.9138682, 1760037845.9609866, 1760037846.0018048, 1760037846.3456044, 1760037846.356092, 1760037846.427996, 1760037846.8005207, 1760037846.9488616, 1760037846.9990902, 1760037847.0043194, 1760037847.020861, 1760037847.1915638, 1760037847.3693793, 1760037847.3740814, 1760037847.391751, 1760037847.6936269, 1760037847.7024655, 1760037847.7135994, 1760037847.7192922, 1760037847.7943676, 1760037848.2562313, 1760037848.2759705, 1760037848.389441, 1760037848.481257, 1760037848.4900298, 1760037848.4992845, 1760037848.523792, 1760037848.5466754, 1760037848.7530997, 1760037848.791122, 1760037848.8670883, 1760037848.932163, 1760037849.3414001, 1760037849.355033, 1760037849.4795935, 1760037849.48674, 1760037849.587214, 1760037849.7686687, 1760037849.8886526, 1760037849.8954709, 1760037850.1000636, 1760037850.1720176, 1760037850.2292879, 1760037850.2744522, 1760037850.4045045, 1760037850.4704983, 1760037850.6496155, 1760037850.717433, 1760037850.7298944, 1760037850.752075, 1760037850.8641274, 1760037851.0920804, 1760037851.1599975, 1760037851.6071248, 1760037851.7646563, 1760037851.8207111, 1760037851.8508258, 1760037851.850794, 1760037852.1259212, 1760037852.1473255, 1760037852.1674547, 1760037852.219548, 1760037852.2694862, 1760037852.3508687, 1760037852.361831, 1760037852.5035574, 1760037852.5996375, 1760037852.690964, 1760037852.8476024, 1760037852.989344, 1760037853.0365238, 1760037853.2966495, 1760037853.403708, 1760037853.4402313, 1760037853.6374438, 1760037853.7888937, 1760037854.1632478, 1760037854.209432, 1760037854.2094026, 1760037854.2417438, 1760037854.260924, 1760037854.3631268, 1760037854.3768406, 1760037854.3768263, 1760037854.3767717, 1760037854.3967264, 1760037854.525262, 1760037854.8327007, 1760037854.91567, 1760037854.9200487, 1760037855.2314942, 1760037855.2590883, 1760037855.2710872, 1760037855.3461065, 1760037855.359232, 1760037855.5943847, 1760037855.7126818, 1760037855.8768492, 1760037856.0673995, 1760037856.2305872, 1760037856.3305807, 1760037856.414837, 1760037856.4637842, 1760037856.5143504, 1760037857.1062663, 1760037857.3886466, 1760037857.5691564, 1760037857.5938342, 1760037857.6184485, 1760037857.7954469, 1760037857.860616, 1760037857.9752836, 1760037858.117839, 1760037858.24656, 1760037858.4777982, 1760037858.4945328, 1760037858.6378722, 1760037858.883779, 1760037858.9635663, 1760037859.0270326, 1760037859.0726147, 1760037859.2838178], "mean_ttft_ms": 86297.66292666667, "median_ttft_ms": 104168.63031200046, "std_ttft_ms": 41466.541347542516, "p99_ttft_ms": 133008.5385398796, "mean_tpot_ms": 215.9249037311584, "median_tpot_ms": 215.77037737483806, "std_tpot_ms": 14.44657766957169, "p99_tpot_ms": 238.74100072036862, "mean_itl_ms": 215.9809267035574, "median_itl_ms": 213.75175299908733, "std_itl_ms": 28.40260760463295, "p99_itl_ms": 282.723939349944}