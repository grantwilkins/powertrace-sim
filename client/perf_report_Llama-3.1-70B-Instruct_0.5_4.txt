Performance Report for meta-llama/Llama-3.1-70B-Instruct
================================

Test Parameters:
- Poisson arrival rate: 0.5
- Tensor parallel size: 4
- Time window: 600.0s

Test Summary:
- Total requests: 268
- Total input tokens: 36925
- Total output tokens: 94527
- Avg tokens per request: 490.49

Latency Metrics:
- Average E2E latency: 12.02s
- P50 latency: 7.06s
- P90 latency: 24.20s
- P99 latency: 66.73s

Throughput Metrics:
- Average prefill throughput: 3689.71 tokens/s
- Average decode throughput: 60.93 tokens/s
- Max prefill throughput: 24637.32 tokens/s
- Max decode throughput: 362.23 tokens/s
- Aggregate prefill throughput: 3689.71 tokens/s
- Aggregate decode throughput: 60.93 tokens/s

Batch Metrics:
- Average batch size: 7.00
- Max batch size: 19.0
- Batch size P50: 7.00
- Batch size P90: 10.30

Throughput Analysis by Batch Size:
- Batch size (0.0, 1.0]: Prefill=1978.04 tokens/s, Decode=28.55 tokens/s, Requests=4
- Batch size (1.0, 2.0]: Prefill=2597.92 tokens/s, Decode=45.12 tokens/s, Requests=11
- Batch size (2.0, 4.0]: Prefill=3334.49 tokens/s, Decode=47.58 tokens/s, Requests=52
- Batch size (4.0, 8.0]: Prefill=3292.71 tokens/s, Decode=60.19 tokens/s, Requests=118
- Batch size (8.0, 16.0]: Prefill=4666.12 tokens/s, Decode=73.66 tokens/s, Requests=77
- Batch size (16.0, 32.0]: Prefill=5797.89 tokens/s, Decode=88.61 tokens/s, Requests=5

Token Distribution:
- Average input tokens: 137.78
- Average output tokens: 352.71
- Max input tokens: 1336
- Max output tokens: 4857
