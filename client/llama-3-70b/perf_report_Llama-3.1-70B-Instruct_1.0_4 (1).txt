Performance Report for meta-llama/Llama-3.1-70B-Instruct
================================

Test Parameters:
- Poisson arrival rate: 1.0
- Tensor parallel size: 8
- Time window: 600.0s

Test Summary:
- Total requests: 567
- Total input tokens: 74722
- Total output tokens: 191800
- Avg tokens per request: 470.06

Latency Metrics:
- Average E2E latency: 13.76s
- P50 latency: 9.31s
- P90 latency: 29.10s
- P99 latency: 57.00s

Throughput Metrics:
- Average prefill throughput: 2601.62 tokens/s
- Average decode throughput: 47.53 tokens/s
- Max prefill throughput: 15172.40 tokens/s
- Max decode throughput: 662.65 tokens/s
- Aggregate prefill throughput: 2601.62 tokens/s
- Aggregate decode throughput: 47.53 tokens/s

Batch Metrics:
- Average batch size: 16.72
- Max batch size: 31.0
- Batch size P50: 16.00
- Batch size P90: 23.00

Throughput Analysis by Batch Size:
- Batch size (2.0, 4.0]: Prefill=5723.24 tokens/s, Decode=114.03 tokens/s, Requests=1
- Batch size (4.0, 8.0]: Prefill=3939.20 tokens/s, Decode=55.91 tokens/s, Requests=13
- Batch size (8.0, 16.0]: Prefill=2625.24 tokens/s, Decode=47.89 tokens/s, Requests=272
- Batch size (16.0, 32.0]: Prefill=2505.77 tokens/s, Decode=46.55 tokens/s, Requests=281

Token Distribution:
- Average input tokens: 131.78
- Average output tokens: 338.27
- Max input tokens: 1293
- Max output tokens: 5780
