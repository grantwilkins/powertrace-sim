Performance Report for meta-llama/Llama-3.1-70B-Instruct
================================

Test Parameters:
- Poisson arrival rate: 2.0
- Tensor parallel size: 8
- Time window: 600.0s

Test Summary:
- Total requests: 1069
- Total input tokens: 148273
- Total output tokens: 366818
- Avg tokens per request: 481.84

Latency Metrics:
- Average E2E latency: 16.71s
- P50 latency: 11.99s
- P90 latency: 39.94s
- P99 latency: 60.15s

Throughput Metrics:
- Average prefill throughput: 3197.02 tokens/s
- Average decode throughput: 56.85 tokens/s
- Max prefill throughput: 23272.47 tokens/s
- Max decode throughput: 1321.72 tokens/s
- Aggregate prefill throughput: 3197.02 tokens/s
- Aggregate decode throughput: 56.85 tokens/s

Batch Metrics:
- Average batch size: 26.88
- Max batch size: 31.0
- Batch size P50: 30.00
- Batch size P90: 31.00

Throughput Analysis by Batch Size:
- Batch size (2.0, 4.0]: Prefill=9822.95 tokens/s, Decode=126.30 tokens/s, Requests=3
- Batch size (4.0, 8.0]: Prefill=6482.06 tokens/s, Decode=117.85 tokens/s, Requests=9
- Batch size (8.0, 16.0]: Prefill=4825.52 tokens/s, Decode=90.21 tokens/s, Requests=49
- Batch size (16.0, 32.0]: Prefill=3068.80 tokens/s, Decode=54.48 tokens/s, Requests=1008

Token Distribution:
- Average input tokens: 138.70
- Average output tokens: 343.14
- Max input tokens: 1278
- Max output tokens: 9981
