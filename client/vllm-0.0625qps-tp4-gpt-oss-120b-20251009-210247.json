{"date": "20251009-210247", "backend": "vllm", "model_id": "openai/gpt-oss-120b", "tokenizer_id": "openai/gpt-oss-120b", "num_prompts": 19, "tensor_parallel_size": 4, "request_rate": 0.0625, "burstiness": 1.0, "max_concurrency": null, "duration": 345.30099872400024, "completed": 18, "total_input_tokens": 116308, "total_output_tokens": 173, "request_throughput": 0.052128433067138144, "request_goodput:": null, "output_throughput": 0.5010121622563832, "total_token_throughput": 337.33177844962876, "input_lens": [13911, 3103, 5864, 16384, 15588, 681, 5682, 1691, 22106, 3138, 2341, 9894, 4615, 2284, 3255, 2884, 10337, 11837, 2819], "output_lens": [2, 6, 7, 13, 9, 71, 1, 3, 0, 16, 4, 10, 4, 2, 1, 12, 2, 3, 7], "ttfts": [0.05207218500072486, 0.04704118400331936, 0.08346995600004448, 0.21251472699805163, 0.19998937800119165, 0.02759878100187052, 0.07937567699991632, 0.033953059999475954, 0.0, 0.05851239899857319, 0.04086119199928362, 0.10949731300206622, 0.06349504399986472, 0.038440997999714455, 0.048078299001645064, 0.045159067998611135, 0.1084839799987094, 0.15823665000061737, 0.04443169599835528], "itls": [[0.0018095439991157036], [0.0020625429970095865, 0.00341693000154919, 0.0034786389987857547, 0.003563506001228234, 0.004080020000401419], [0.001578839001012966, 0.003301275999547215, 0.0038151440021465532, 0.004079438000189839, 0.004092094997758977, 0.0046143799991114065], [0.0003067069992539473, 0.0033670360026007984, 0.0036651049995271023, 0.0036015820005559362, 0.003632831998402253, 0.003842606998659903, 0.003991160003351979, 0.004106301999854622, 0.0037763299988000654, 0.004237073000695091, 0.004174309000518406, 0.004608477000147104], [0.0002146500009985175, 0.003259158998844214, 0.0036796300009882543, 0.0037079220019222703, 0.0036739119968842715, 0.003856137002003379, 0.004237516001012409, 0.004237122997437837], [0.0022620129966526292, 0.0035498340002959594, 0.003504202999465633, 0.0035969490018032957, 0.003617425998527324, 0.003648642003099667, 0.004156747996603372, 0.004042839002067922, 0.0038720379998267163, 0.004225387001497438, 0.003831780999462353, 0.003825941999821225, 0.0041592609995859675, 0.0037201070008450188, 0.003915162000339478, 0.0040881139975681435, 0.0036045750021003187, 0.004022715998871718, 0.004220729999360628, 0.003839020999294007, 0.0037833099995623343, 0.0038946640015637968, 0.004036932001326932, 0.004134358998271637, 0.004169038998952601, 0.0038107649997982662, 0.0037693330014008097, 0.0036751920015376527, 0.00395652999941376, 0.0035557310002332088, 0.004079301997990115, 0.0040098270001180936, 0.00408788400090998, 0.004307593000703491, 0.003912088999641128, 0.0038962010003160685, 0.0037445339985424653, 0.003943367002648301, 0.004320963998907246, 0.0037169200004427694, 0.004194322998955613, 0.0038021479995222762, 0.0037835200018889736, 0.003858131996821612, 0.004018422001536237, 0.004205249999358784, 0.003691077999974368, 0.004054196000652155, 0.0042418529992573895, 0.003912918000423815, 0.004045648998726392, 0.003973632003180683, 0.003870794997055782, 0.0040793710031721275, 0.004252731996530201, 0.003953006002120674, 0.003668090997962281, 0.004165740003372775, 0.004087489000085043, 0.004004052996606333, 0.0038847480027470738, 0.0042937830003211275, 0.004228288999001961, 0.004305544000089867, 0.004113512000913033, 0.00401009199777036, 0.00412450799922226, 0.003926746001525316, 0.004098130000784295, 0.004058241000166163], [], [0.0020867800012638327, 0.003629200997238513], [], [0.0019331019975652453, 0.003229137000744231, 0.003755909001483815, 0.0034480180001992267, 0.0037115009981789626, 0.0037721709995821584, 0.004186148002190748, 0.004020689997560112, 0.0040491720028512646, 0.004042287997435778, 0.00420489500174881, 0.003982769998401636, 0.003780122999160085, 0.004086136003024876, 0.00433958400026313], [0.0020100340007047635, 0.00327859100070782, 0.0037949289981042966], [0.0013493309998011682, 0.0032478050015924964, 0.00358912099909503, 0.0036921789978805464, 0.003706375002366258, 0.003879288000462111, 0.00413750499865273, 0.004299603999243118, 0.004505009001150029], [0.0019569289979699533, 0.0032210310018854216, 0.0038077839999459684], [0.002208060999691952], [], [0.0019086869979219045, 0.003349208000145154, 0.0036005750007461756, 0.003578299998480361, 0.0037214470030448865, 0.003942831997846952, 0.004006235001725145, 0.004059300998051185, 0.003973172999394592, 0.0041689400022733025, 0.004674412997701438], [0.0016071490026661195], [0.0006627410002693068, 0.0037484960012079682], [0.002189711001847172, 0.0031277399975806475, 0.0037306480007828213, 0.0036308880007709377, 0.0035292020002088975, 0.004499753998970846]], "generated_texts": ["<|", "<|vq_lbr_", "\n\n```\n\nIt looks like the", "<|vq_12471|>\n\nIt looks like you've", "<|vq_lbr\n\nIt looks like", "<|vq_lbr_image_12457|>\n\nIt looks like the text you posted is a mix of different languages and possibly some random characters or symbols. It seems to be a garbled or corrupted text that doesn't form a coherent message or request. If you have a specific question or need assistance with something, please provide a clear and concise", "<", "<|vq", "", "\ufffd\n\nIt seems like the text you provided is a mix of different languages and characters", "<|vq_l", "<|vq_lbr\n\nIt looks like the", "<|vq_l", "<|", "<", "<|vq_lbr_image_12457|>", "<|", "<|vq", "<|vq_lbr_124"], "errors": ["", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", ""], "request_timestamps": [1760043422.5082712, 1760043441.1759326, 1760043475.2061446, 1760043515.3151526, 1760043519.239222, 1760043532.5341501, 1760043564.6100938, 1760043575.990546, 1760043656.4893367, 1760043657.8694654, 1760043663.097739, 1760043663.233323, 1760043692.8137453, 1760043709.4970794, 1760043738.9649968, 1760043743.90921, 1760043752.0331223, 1760043764.8996823], "mean_ttft_ms": 80.62286594455752, "median_ttft_ms": 55.292291999649024, "std_ttft_ms": 54.7666894352341, "p99_ttft_ms": 210.3854176685854, "mean_tpot_ms": 3.0661325152551884, "median_tpot_ms": 3.3392300873401837, "std_tpot_ms": 0.7100346543774261, "p99_tpot_ms": 3.9097232035887184, "mean_itl_ms": 3.665371477414268, "median_itl_ms": 3.858131996821612, "std_itl_ms": 0.7740687262124947, "p99_itl_ms": 4.611192379670683}