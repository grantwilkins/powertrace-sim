{
  "date": "20251008-050007",
  "backend": "vllm",
  "model_id": "openai/gpt-oss-20b",
  "tokenizer_id": "openai/gpt-oss-20b",
  "num_prompts": 9,
  "tensor_parallel_size": 1,
  "request_rate": 0.015625,
  "burstiness": 1.0,
  "max_concurrency": null,
  "duration": 743.3153933959998,
  "completed": 8,
  "total_input_tokens": 41852,
  "total_output_tokens": 1497,
  "request_throughput": 0.010762591587738068,
  "request_goodput:": null,
  "output_throughput": 2.013949950855486,
  "total_token_throughput": 58.31844784210719,
  "input_lens": [
    8192,
    2303,
    4302,
    8192,
    21473,
    520,
    15737,
    1269,
    1337
  ],
  "output_lens": [
    3,
    909,
    75,
    10,
    0,
    219,
    10,
    127,
    144
  ],
  "ttfts": [
    0.030440189999808354,
    0.024350007000066398,
    0.030315404999782913,
    0.03977837100001125,
    0.0,
    0.022023436999916157,
    0.0651734379998743,
    0.02078455400032908,
    0.021889289999762696
  ],
  "itls": [
    0.0028375020001476514,
    0.0033861961552865538,
    0.003415865797300334,
    0.0033339994444456047,
    0.0033339994444456047,
    0.003400237596328842,
    0.0033247056666772957,
    0.003390922095236636,
    0.003389943986015048
  ],
  "generated_texts": [
    " ",
    "<|vq_clip_12273|>this image displays a list of items in a table format. the first item is a \"c\" and the second item is a \"c\" with a \"c\" and \"c\" in the third column. the third item is a \"c\" with a \"c\" and \"c\" in the fourth column. the fourth item is a \"c\" with a \"c\" and \"c\" in the fifth column. the fifth item is a \"c\" with a \"c\" and \"c\" in the sixth column. the sixth item is a \"c\" with a \"c\" and \"c\" in the seventh column. the seventh item is a \"c\" with a \"c\" and \"c\" in the eighth column. the ninth item is a \"c\" with a \"c\" and \"c\" in the ninth column. the tenth item is a \"c\" with a \"c\" and \"c\" in the eleventh column. the twelfth item is a \"c\" with a \"c\" and \"c\" in the thirteenth column. the thirteenth item is a \"c\" with a \"c\" and \"c\" in the fourteenth column. the fifteenth item\n\nIt seems like your message got a bit garbled. If you have a specific question or need help with something, feel free to let me know!\n\nIt looks like your message got a bit garbled. If you have a specific question or need help with something, feel free to let me know!\n\nIt seems like your message got a bit garbled. If you have a specific question or need help with something, feel free to let me know!\n\nIt looks like your message got a bit garbled. If you have a specific question or need help with something, feel free to let me know!\n\nIt seems like your message got a bit garbled. If you have a specific question or need help with something, feel free to let me know!\n\nIt looks like your message got a bit garbled. If you have a specific question or need help with something, feel free to let me know!\n\nIt seems like your message got a bit garbled. If you have a specific question or need help with something, feel free to let me know!\n\nIt looks like your message got a bit garbled. If you have a specific question or need help with something, feel free to let me know!\n\nIt seems like your message got a bit garbled. If you have a specific question or need help with something, feel free to let me know!\n\nIt looks like your message got a bit garbled. If you have a specific question or need help with something, feel free to let me know!\n\nIt seems like your message got a bit garbled. If you have a specific question or need help with something, feel free to let me know!\n\nIt looks like your message got a bit garbled. If you have a specific question or need help with something, feel free to let me know!\n\nIt seems like your message got a bit garbled. If you have a specific question or need help with something, feel free to let me know!\n\nIt looks like your message got a bit garbled. If you have a specific question or need help with something, feel free to let me know!\n\nIt seems like your message got a bit garbled. If you have a specific question or need help with something, feel free to let me know!\n\nIt looks like your message got a bit garbled. If you have a specific question or need help with something, feel free to let me know!\n\nIt seems like your message got a bit garbled. If you have a specific question or need help with something, feel free to let me know!\n\nIt looks like your message got a bit garbled. If you have a specific question or need help with something, feel free to let me know!\n\nIt seems like your message got a bit garbled. If you have a specific question or need help with something, feel free to let me know!\n\nIt looks like your message got a bit garbled. If you have a specific question or need help with something, feel free to let me know!\n\nIt seems like your message got a bit garbled. If you have a specific question or need help with something, feel free to",
    "\u00e9ration<|vq_clip_12273|>this is a screenshot of a website that displays a list of products. the page is divided into two sections, one for the product and the other for the product's details. the product section shows a list of products with their respective prices and descriptions. the product details section shows a list of products with their respective prices and",
    "<|vq_clip_12273|>",
    "",
    "<|vq_clip_12273|>this image displays a list of 10 items, each with a different color and shape. the items are arranged in a grid, with each item having a different color and shape. the first item is a blue square with a white circle in the center, the second item is a green square with a white circle in the center, and the third item is a yellow square with a white circle in the center. the fourth item is a red square with a white circle in the center, and the fifth item is a purple square with a white circle in the center. the sixth item is a blue square with a white circle in the center, the seventh item is a green square with a white circle in the center, and the eighth item is a yellow square with a white circle in the center. the ninth item is a red square with a white circle in the center, and the tenth item is a purple square with a white circle in the center. the image is a screenshot of a website that displays a list of items in a grid.",
    "<|vq_clip_12273|>",
    "<|vq_clip_12273|>this is a screenshot of a code editor with a python script. the script is written in a dark theme and has a line of code that says \"print('hello world')\". the code editor is open to a file named \"main.py\" and the user is working on a project. the code editor has a dark background and the text is displayed in a light blue color. the user is working on a project that involves writing a python script to print a message. the code editor is open to a file named \"main.py\" and the user is working on a project.",
    "<|vq_clip_12273|>this is a screenshot of a conversation between two users on a messaging app. the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a person named \"sara\". the conversation is in a casual tone and the user is asking for a photo of a person named \"sara\" and the other user is responding with a photo of a person named \"sara\". the conversation is in a casual tone and the user is asking for a photo of a person named \"sara\". the conversation is in a casual tone and the user is asking for a photo of a person named \"sara\"."
  ],
  "errors": [
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "",
    "",
    ""
  ],
  "request_timestamps": [
    1759898864.0202172,
    1759898880.1233933,
    1759898911.4249222,
    1759899060.583953,
    1759899159.6918123,
    1759899308.7171366,
    1759899315.3787644,
    1759899539.4929452
  ],
  "mean_ttft_ms": 31.844336499943893,
  "median_ttft_ms": 27.332705999924656,
  "std_ttft_ms": 13.928944461843136,
  "p99_ttft_ms": 63.39578330988388,
  "mean_tpot_ms": 3.309864828053768,
  "median_tpot_ms": 3.388069041211472,
  "std_tpot_ms": 0.18114148407379108,
  "p99_tpot_ms": 3.414769102937528,
  "mean_itl_ms": 3.3890621208868184,
  "median_itl_ms": 3.392005000023346,
  "std_itl_ms": 0.12491655393101617,
  "p99_itl_ms": 3.612421520192583
}