Performance Report for meta-llama/Llama-3.1-8B-Instruct
================================

Test Parameters:
- Poisson arrival rate: 0.125
- Tensor parallel size: 2
- Time window: 600.0s

Test Summary:
- Total requests: 70
- Total input tokens: 9561
- Total output tokens: 29752
- Avg tokens per request: 561.61

Latency Metrics:
- Average E2E latency: 4.70s
- P50 latency: 2.27s
- P90 latency: 6.31s
- P99 latency: 49.98s

Throughput Metrics:
- Average prefill throughput: 7297.44 tokens/s
- Average decode throughput: 214.11 tokens/s
- Max prefill throughput: 41104.26 tokens/s
- Max decode throughput: 468.67 tokens/s
- Aggregate prefill throughput: 7297.44 tokens/s
- Aggregate decode throughput: 214.11 tokens/s

Batch Metrics:
- Average batch size: 1.93
- Max batch size: 6.0
- Batch size P50: 1.00
- Batch size P90: 5.00

Throughput Analysis by Batch Size:
- Batch size (0.0, 1.0]: Prefill=7250.90 tokens/s, Decode=189.89 tokens/s, Requests=26
- Batch size (1.0, 2.0]: Prefill=14082.82 tokens/s, Decode=261.80 tokens/s, Requests=9
- Batch size (2.0, 4.0]: Prefill=2794.81 tokens/s, Decode=248.34 tokens/s, Requests=15
- Batch size (4.0, 8.0]: Prefill=4005.09 tokens/s, Decode=319.54 tokens/s, Requests=8

Token Distribution:
- Average input tokens: 136.59
- Average output tokens: 425.03
- Max input tokens: 620
- Max output tokens: 5528
