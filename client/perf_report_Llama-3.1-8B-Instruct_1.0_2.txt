Performance Report for meta-llama/Llama-3.1-8B-Instruct
================================

Test Parameters:
- Poisson arrival rate: 1.0
- Tensor parallel size: 2
- Time window: 600.0s

Test Summary:
- Total requests: 557
- Total input tokens: 78739
- Total output tokens: 225554
- Avg tokens per request: 546.31

Latency Metrics:
- Average E2E latency: 8.10s
- P50 latency: 5.08s
- P90 latency: 16.43s
- P99 latency: 44.01s

Throughput Metrics:
- Average prefill throughput: 6291.97 tokens/s
- Average decode throughput: 216.31 tokens/s
- Max prefill throughput: 93203.05 tokens/s
- Max decode throughput: 1732.25 tokens/s
- Aggregate prefill throughput: 6291.97 tokens/s
- Aggregate decode throughput: 216.31 tokens/s

Batch Metrics:
- Average batch size: 19.84
- Max batch size: 31.0
- Batch size P50: 20.00
- Batch size P90: 31.00

Throughput Analysis by Batch Size:
- Batch size (1.0, 2.0]: Prefill=13835.47 tokens/s, Decode=248.07 tokens/s, Requests=3
- Batch size (2.0, 4.0]: Prefill=10095.32 tokens/s, Decode=163.57 tokens/s, Requests=24
- Batch size (4.0, 8.0]: Prefill=13729.77 tokens/s, Decode=245.03 tokens/s, Requests=51
- Batch size (8.0, 16.0]: Prefill=7508.92 tokens/s, Decode=279.94 tokens/s, Requests=109
- Batch size (16.0, 32.0]: Prefill=4600.38 tokens/s, Decode=196.77 tokens/s, Requests=370

Token Distribution:
- Average input tokens: 141.36
- Average output tokens: 404.94
- Max input tokens: 1519
- Max output tokens: 5742
