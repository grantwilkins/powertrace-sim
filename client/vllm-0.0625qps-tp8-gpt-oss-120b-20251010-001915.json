{"date": "20251010-001915", "backend": "vllm", "model_id": "openai/gpt-oss-120b", "tokenizer_id": "openai/gpt-oss-120b", "num_prompts": 19, "tensor_parallel_size": 8, "request_rate": 0.0625, "burstiness": 1.0, "max_concurrency": null, "duration": 345.29025291200014, "completed": 18, "total_input_tokens": 116308, "total_output_tokens": 140, "request_throughput": 0.052130055361242524, "request_goodput:": null, "output_throughput": 0.4054559861429974, "total_token_throughput": 337.2467048169983, "input_lens": [13911, 3103, 5864, 16384, 15588, 681, 5682, 1691, 22106, 3138, 2341, 9894, 4615, 2284, 3255, 2884, 10337, 11837, 2819], "output_lens": [2, 6, 7, 13, 9, 38, 1, 3, 0, 16, 4, 10, 4, 2, 1, 12, 2, 3, 7], "ttfts": [0.05022160899898154, 0.04058909100058372, 0.0813572330007446, 0.1659973349997017, 0.16018499699930544, 0.02246499999819207, 0.07644020099905902, 0.031090854998183204, 0.0, 0.047648530002334155, 0.03504048499962664, 0.09398583000074723, 0.059801706000143895, 0.032396839997090865, 0.042749583000841085, 0.03976856699955533, 0.09059649600021658, 0.1284791590005625, 0.03877661799924681], "itls": [[0.001800527999876067], [0.0018444980014464818, 0.002890899999329122, 0.0031519000003754627, 0.0033469890004198533, 0.003530665999278426], [0.0025889719981933013, 0.0033226170016860124, 0.0031429789996764157, 0.003273713999078609, 0.003317517002869863, 0.0036229239995009266], [0.0012071600031049456, 0.0030046159990888555, 0.0033860699986689724, 0.0032616780008538626, 0.0034201109992864076, 0.0035998880011902656, 0.003991591998783406, 0.0040868460018828046, 0.0038836599997011945, 0.0038469339997391216, 0.0034632479982974473, 0.004583878002449637], [0.0008248609992733691, 0.0029010780017415527, 0.003381083999556722, 0.0032675689981260803, 0.003417763000470586, 0.0033202810009242967, 0.004017426999780582, 0.004066276000230573], [0.002168517003156012, 0.0031594590000167955, 0.0033974599973589648, 0.004156533999776002, 0.0037817400007043034, 0.003738201001397101, 0.003822031998424791, 0.0037774930024170317, 0.0033546079976076726, 0.0039433339989045635, 0.003403628001251491, 0.0036594119992514607, 0.0036801860005652998, 0.0038205210003070533, 0.0036539210013870616, 0.00357609499769751, 0.003501619001326617, 0.003512138999212766, 0.003641660001449054, 0.003386807999049779, 0.003573789999791188, 0.003757272999791894, 0.0037673219994758256, 0.0035192510003980715, 0.0037495239994314034, 0.0033847380000224803, 0.0037503610001294874, 0.0033353120015817694, 0.0037736970007244963, 0.0033133899996755645, 0.003638919999502832, 0.003721854998730123, 0.003445831000135513, 0.003727488001459278, 0.004222380001010606, 0.004138573000091128, 0.004265207997377729], [], [0.001916863999213092, 0.003347925998241408], [], [0.0016626129981887061, 0.002890234001824865, 0.003163287998177111, 0.0033600520000618417, 0.0034710569998424035, 0.0037764770022477023, 0.0038636489989585243, 0.0038058069985709153, 0.0036159400005999487, 0.003755026002181694, 0.0036782850002055056, 0.003637897996668471, 0.0037572110013570637, 0.003807149001659127, 0.004080041999259265], [0.0019280990018160082, 0.0030044630002521444, 0.0033888449979713187], [0.0007026780003798194, 0.0031004289994598366, 0.003173475997755304, 0.003337199002999114, 0.0032740489987190813, 0.003847220999887213, 0.003795947999606142, 0.003995877999841468, 0.004467671999009326], [0.002477340000041295, 0.0028776839972124435, 0.003423225000005914], [0.0023883159992692526], [], [0.0014197559976310004, 0.0031167850029305555, 0.0031888979974610265, 0.0031604180003341753, 0.0033333700012008194, 0.0036459129987633787, 0.003843710001092404, 0.003970931000367273, 0.0037201070008450188, 0.003618941998865921, 0.0040534100007789675], [0.0012986789988644887], [0.000440897998487344, 0.0032919889999902807], [0.0019177630019839853, 0.0027917689985770267, 0.003154066998831695, 0.0032239659994957037, 0.0033545620026416145, 0.004048782997415401]], "generated_texts": ["<|", "<|vq_lbr_audio", "\n\n```\n\nIt looks like the", "<|vq_12471|>\n\nIt looks like you've", "<|vq_lbr\n\nIt looks like", "<|vq_lbr_image_12457|>\n\nIt looks like your message got a bit garbled! If you have a specific question or need help with something, feel", "<", "<|vq", "", "\ufffd\n\nIt seems like the text you provided is a mix of different languages and characters", "<|vq_l", "<|vq_lbr\n\nIt looks like the", "<|vq_l", "<|", "<", "<|vq_lbr_image_12486|>", "<|", "<|vq", "<|vq_lbr_124"], "errors": ["", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", ""], "request_timestamps": [1760055210.2206292, 1760055228.8896546, 1760055262.9008033, 1760055303.0235684, 1760055306.9498825, 1760055320.2352931, 1760055352.3192377, 1760055363.698751, 1760055444.1889606, 1760055445.5726511, 1760055450.79783, 1760055450.9330544, 1760055480.513968, 1760055497.2065303, 1760055526.674465, 1760055531.6168911, 1760055539.7461717, 1760055552.6033874], "mean_ttft_ms": 68.75500749972868, "median_ttft_ms": 48.935069500657846, "std_ttft_ms": 42.695042488691634, "p99_ttft_ms": 165.00923753963434, "mean_tpot_ms": 2.8339472094461358, "median_tpot_ms": 3.017358633284554, "std_tpot_ms": 0.6572083238407086, "p99_tpot_ms": 3.6066767013265206, "mean_itl_ms": 3.3143709835533883, "median_itl_ms": 3.4345280000707135, "std_itl_ms": 0.7549311060652745, "p99_itl_ms": 4.425154558666689}