Performance Report for meta-llama/Llama-3.1-8B-Instruct
================================

Test Parameters:
- Poisson arrival rate: 2.0
- Tensor parallel size: 1
- Time window: 600.0s

Test Summary:
- Total requests: 501
- Total input tokens: 67000
- Total output tokens: 194383
- Avg tokens per request: 521.72

Latency Metrics:
- Average E2E latency: 54.50s
- P50 latency: 20.69s
- P90 latency: 153.69s
- P99 latency: 292.08s

Throughput Metrics:
- Average prefill throughput: 5100.71 tokens/s
- Average decode throughput: 108.28 tokens/s
- Max prefill throughput: 36027.45 tokens/s
- Max decode throughput: 1140.17 tokens/s
- Aggregate prefill throughput: 5100.71 tokens/s
- Aggregate decode throughput: 108.28 tokens/s

Batch Metrics:
- Average batch size: 26.42
- Max batch size: 31.0
- Batch size P50: 31.00
- Batch size P90: 31.00

Throughput Analysis by Batch Size:
- Batch size (2.0, 4.0]: Prefill=20443.46 tokens/s, Decode=169.29 tokens/s, Requests=3
- Batch size (4.0, 8.0]: Prefill=6201.00 tokens/s, Decode=94.12 tokens/s, Requests=12
- Batch size (8.0, 16.0]: Prefill=8421.31 tokens/s, Decode=131.73 tokens/s, Requests=63
- Batch size (16.0, 32.0]: Prefill=4466.13 tokens/s, Decode=104.75 tokens/s, Requests=423

Token Distribution:
- Average input tokens: 133.73
- Average output tokens: 387.99
- Max input tokens: 1169
- Max output tokens: 6415
