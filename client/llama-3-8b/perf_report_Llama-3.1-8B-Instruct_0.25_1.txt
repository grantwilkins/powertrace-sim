Performance Report for meta-llama/Llama-3.1-8B-Instruct
================================

Test Parameters:
- Poisson arrival rate: 0.25
- Tensor parallel size: 1
- Time window: 600.0s

Test Summary:
- Total requests: 153
- Total input tokens: 22752
- Total output tokens: 52475
- Avg tokens per request: 491.68

Latency Metrics:
- Average E2E latency: 6.15s
- P50 latency: 4.45s
- P90 latency: 13.84s
- P99 latency: 28.06s

Throughput Metrics:
- Average prefill throughput: 6265.92 tokens/s
- Average decode throughput: 197.82 tokens/s
- Max prefill throughput: 88106.42 tokens/s
- Max decode throughput: 549.00 tokens/s
- Aggregate prefill throughput: 6265.92 tokens/s
- Aggregate decode throughput: 197.82 tokens/s

Batch Metrics:
- Average batch size: 5.14
- Max batch size: 9.0
- Batch size P50: 6.00
- Batch size P90: 8.00

Throughput Analysis by Batch Size:
- Batch size (0.0, 1.0]: Prefill=6571.66 tokens/s, Decode=127.61 tokens/s, Requests=11
- Batch size (1.0, 2.0]: Prefill=9883.69 tokens/s, Decode=192.10 tokens/s, Requests=12
- Batch size (2.0, 4.0]: Prefill=7816.89 tokens/s, Decode=176.63 tokens/s, Requests=14
- Batch size (4.0, 8.0]: Prefill=5141.73 tokens/s, Decode=210.22 tokens/s, Requests=103
- Batch size (8.0, 16.0]: Prefill=14825.52 tokens/s, Decode=358.07 tokens/s, Requests=5

Token Distribution:
- Average input tokens: 148.71
- Average output tokens: 342.97
- Max input tokens: 1036
- Max output tokens: 2388
