Performance Report for meta-llama/Llama-3.1-8B-Instruct
================================

Test Parameters:
- Poisson arrival rate: 4.0
- Tensor parallel size: 1
- Time window: 600.0s

Test Summary:
- Total requests: 458
- Total input tokens: 63089
- Total output tokens: 173172
- Avg tokens per request: 515.85

Latency Metrics:
- Average E2E latency: 57.38s
- P50 latency: 29.75s
- P90 latency: 173.06s
- P99 latency: 230.84s

Throughput Metrics:
- Average prefill throughput: 5657.46 tokens/s
- Average decode throughput: 102.37 tokens/s
- Max prefill throughput: 55515.00 tokens/s
- Max decode throughput: 1263.39 tokens/s
- Aggregate prefill throughput: 5657.46 tokens/s
- Aggregate decode throughput: 102.37 tokens/s

Batch Metrics:
- Average batch size: 29.15
- Max batch size: 31.0
- Batch size P50: 31.00
- Batch size P90: 31.00

Throughput Analysis by Batch Size:
- Batch size (4.0, 8.0]: Prefill=12673.31 tokens/s, Decode=196.17 tokens/s, Requests=5
- Batch size (8.0, 16.0]: Prefill=9473.57 tokens/s, Decode=137.60 tokens/s, Requests=24
- Batch size (16.0, 32.0]: Prefill=5362.21 tokens/s, Decode=99.30 tokens/s, Requests=429

Token Distribution:
- Average input tokens: 137.75
- Average output tokens: 378.10
- Max input tokens: 1555
- Max output tokens: 9474
