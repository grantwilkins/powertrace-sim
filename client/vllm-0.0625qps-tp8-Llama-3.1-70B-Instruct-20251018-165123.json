{"date": "20251018-165123", "backend": "vllm", "model_id": "meta-llama/Llama-3.1-70B-Instruct", "tokenizer_id": "meta-llama/Llama-3.1-70B-Instruct", "num_prompts": 19, "tensor_parallel_size": 8, "request_rate": 0.0625, "burstiness": 1.0, "max_concurrency": null, "duration": 405.7364533740001, "completed": 18, "total_input_tokens": 116308, "total_output_tokens": 154, "request_throughput": 0.04436377320873346, "request_goodput:": null, "output_throughput": 0.37955672634138626, "total_token_throughput": 287.0385419686398, "input_lens": [13911, 3103, 5864, 16384, 15588, 681, 5682, 1691, 22106, 3138, 2341, 9894, 4615, 2284, 3255, 2884, 10337, 11837, 2819], "output_lens": [2, 6, 7, 13, 2, 71, 1, 1, 0, 1, 4, 10, 4, 2, 1, 17, 2, 3, 7], "ttfts": [0.06456470900002387, 0.16692280799998116, 0.29229448699970817, 0.8389217020003343, 0.7699493069999335, 0.06778003900035401, 0.2687850930001332, 0.10737626300033298, 0.0, 0.16908152399992105, 0.13110515300013503, 0.5014897559999554, 0.23515528999996604, 0.1308278540000174, 0.17591655700016418, 0.15480829300031473, 0.5315047779999986, 0.573191468999994, 0.15840307700000267], "itls": [[0.009806331000163482], [0.008908075999897846, 0.010808325000198238, 0.010284250000040629, 0.010638143000051059, 0.010680676999982097], [0.0091814960001102, 0.010754847999578487, 0.010904086000209645, 0.009858979000000545, 0.011028135999822553, 0.010914488000253186], [0.009301376000166783, 0.010631218000071385, 0.010710279999784689, 0.011006573000031494, 0.010914855999999418, 0.010999451000316185, 0.01153049499998815, 0.010559769999872515, 0.010893220000070869, 0.010799146999943332, 0.011597203999826888, 0.011354855000263342], [0.009131177999734064], [0.0093275710000853, 0.010594494000088162, 0.009665372999734245, 0.010793790000207082, 0.010244832999887876, 0.009835963000114134, 0.010533406999911676, 0.01055115700000897, 0.009752218999892648, 0.01066932599997017, 0.010310210000170628, 0.010109258999818849, 0.01070282099999531, 0.01012521500024377, 0.009920480999880965, 0.010668945999896096, 0.010481711000011273, 0.010335416000089026, 0.009756485999787401, 0.010643028000231425, 0.010274719999870285, 0.010276616000282957, 0.009653780999997252, 0.010644019999745069, 0.010602704000120866, 0.009531192999929772, 0.010715357000208314, 0.010376567999628605, 0.010326435000024503, 0.009632986000269739, 0.010675591000108398, 0.00958475199968234, 0.010862773000098969, 0.009703419999823382, 0.010623918000419508, 0.01054072399983852, 0.009798231999866402, 0.01047967200020139, 0.010583831000076316, 0.010113687999819376, 0.009656263000124454, 0.010875442999804363, 0.010437627000101202, 0.010346692999974039, 0.009585587999936251, 0.010507098999823938, 0.010499451000214322, 0.01037277700015693, 0.009873111999695539, 0.01053253300005963, 0.010337069999877713, 0.01056274000029589, 0.009575987000062014, 0.010392358999979479, 0.010692785999708576, 0.010279060000357276, 0.00995507199968415, 0.010588105000351788, 0.009719528999994509, 0.010760118999769475, 0.010388083000179904, 0.010242420999929891, 0.010422328999993624, 0.009648490000017773, 0.010678138000002946, 0.010450170999774855, 0.010326329000236, 0.010276044999955047, 0.01029079099998853, 0.010483126000053744], [], [], [], [], [0.009296728999743209, 0.010062761999961367, 0.010658959000011237], [0.008693694000157848, 0.010812756999712292, 0.010533151000345242, 0.010660060999725829, 0.010951551000289328, 0.01053106499966816, 0.010782973999994283, 0.010634350000145787, 0.01101478100008535], [0.009406937999756337, 0.010743634999926144, 0.010960317000353825], [0.00894806799988146], [], [0.009324653000021499, 0.010504474000299524, 0.010579386999779672, 0.011422192000281939, 0.010133499999938067, 0.3399825169999531, 0.13603243499983364, 0.009967393999886554, 0.009855928999968455, 0.010517534000427986, 0.010384974999851693, 0.010705844999847614, 0.010466357000041171, 0.010516514999835636, 0.010365895000177261, 0.010770862999834208], [0.009840015999998286], [0.008908435999728681, 0.010973243000080402], [0.009106720000090718, 0.011088375999861455, 0.010548713999924075, 0.010624645999996574, 0.010425195000152598, 0.011009092000222154]], "generated_texts": ["\ufffd.", "\ufffd_HOMESCREEN", "\ufffd_LIST\ufffd_LIST", "ventually\t\t\ufffd_HPPROPERTY\ufffd_HPP", "", "\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_", "\t", "", "", "", "\u0435\u0440\u0435\u043c\u0435\u043d", "stry\ufffd_id\ufffd_id\ufffd_id", "witcher\ufffd_", "<|", "", "es\t\t<|reserved_special_token_96|>I apologize, but it", "\ufffd_", "ality\ufffd.", "\ufffd_\ufffd_\ufffd_"], "errors": ["", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", ""], "request_timestamps": [1760805877.3094006, 1760805886.620045, 1760805948.9196582, 1760805956.077982, 1760805966.5794241, 1760805985.2301629, 1760806019.2539415, 1760806059.347588, 1760806076.605985, 1760806108.666446, 1760806120.0705562, 1760806159.8648336, 1760806200.5345407, 1760806201.9273808, 1760806207.1369753, 1760806207.3096051, 1760806236.898588, 1760806253.5522847], "mean_ttft_ms": 296.5598977222928, "median_ttft_ms": 172.4990405000426, "std_ttft_ms": 233.34778069500774, "p99_ttft_ms": 827.1963948502661, "mean_tpot_ms": 12.121150518089166, "median_tpot_ms": 10.266048928581638, "std_tpot_ms": 7.429194477474807, "p99_tpot_ms": 35.20727014102408, "mean_itl_ms": 13.681780705884622, "median_itl_ms": 10.491288500134033, "std_itl_ms": 30.07181244146515, "p99_itl_ms": 92.48010414983199}