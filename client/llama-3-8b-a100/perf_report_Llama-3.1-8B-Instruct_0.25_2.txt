Performance Report for meta-llama/Llama-3.1-8B-Instruct
================================

Test Parameters:
- Poisson arrival rate: 0.25
- Tensor parallel size: 2
- Time window: 600.0s

Test Summary:
- Total requests: 143
- Total input tokens: 18680
- Total output tokens: 48073
- Avg tokens per request: 466.80

Latency Metrics:
- Average E2E latency: 4.44s
- P50 latency: 3.24s
- P90 latency: 8.90s
- P99 latency: 18.19s

Throughput Metrics:
- Average prefill throughput: 6319.67 tokens/s
- Average decode throughput: 293.57 tokens/s
- Max prefill throughput: 64351.20 tokens/s
- Max decode throughput: 710.14 tokens/s
- Aggregate prefill throughput: 6319.67 tokens/s
- Aggregate decode throughput: 293.57 tokens/s

Batch Metrics:
- Average batch size: 5.36
- Max batch size: 12.0
- Batch size P50: 6.00
- Batch size P90: 8.80

Throughput Analysis by Batch Size:
- Batch size (0.0, 1.0]: Prefill=13428.54 tokens/s, Decode=166.15 tokens/s, Requests=6
- Batch size (1.0, 2.0]: Prefill=9561.30 tokens/s, Decode=185.39 tokens/s, Requests=18
- Batch size (2.0, 4.0]: Prefill=7708.19 tokens/s, Decode=278.41 tokens/s, Requests=34
- Batch size (4.0, 8.0]: Prefill=4385.02 tokens/s, Decode=323.41 tokens/s, Requests=68
- Batch size (8.0, 16.0]: Prefill=5972.70 tokens/s, Decode=399.51 tokens/s, Requests=15

Token Distribution:
- Average input tokens: 130.63
- Average output tokens: 336.17
- Max input tokens: 863
- Max output tokens: 1612
