Performance Report for meta-llama/Llama-3.1-8B-Instruct
================================

Test Parameters:
- Poisson arrival rate: 2.0
- Tensor parallel size: 2
- Time window: 600.0s

Test Summary:
- Total requests: 604
- Total input tokens: 86213
- Total output tokens: 229073
- Avg tokens per request: 522.00

Latency Metrics:
- Average E2E latency: 24.95s
- P50 latency: 5.88s
- P90 latency: 82.62s
- P99 latency: 199.28s

Throughput Metrics:
- Average prefill throughput: 7870.85 tokens/s
- Average decode throughput: 196.53 tokens/s
- Max prefill throughput: 117525.11 tokens/s
- Max decode throughput: 1357.17 tokens/s
- Aggregate prefill throughput: 7870.85 tokens/s
- Aggregate decode throughput: 196.53 tokens/s

Batch Metrics:
- Average batch size: 21.62
- Max batch size: 31.0
- Batch size P50: 24.00
- Batch size P90: 31.00

Throughput Analysis by Batch Size:
- Batch size (1.0, 2.0]: Prefill=15837.83 tokens/s, Decode=220.36 tokens/s, Requests=2
- Batch size (2.0, 4.0]: Prefill=8876.92 tokens/s, Decode=110.94 tokens/s, Requests=8
- Batch size (4.0, 8.0]: Prefill=12183.96 tokens/s, Decode=167.85 tokens/s, Requests=60
- Batch size (8.0, 16.0]: Prefill=11797.56 tokens/s, Decode=233.28 tokens/s, Requests=128
- Batch size (16.0, 32.0]: Prefill=5936.40 tokens/s, Decode=190.75 tokens/s, Requests=406

Token Distribution:
- Average input tokens: 142.74
- Average output tokens: 379.26
- Max input tokens: 1409
- Max output tokens: 3241
