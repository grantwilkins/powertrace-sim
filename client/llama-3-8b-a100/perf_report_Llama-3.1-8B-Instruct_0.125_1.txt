Performance Report for meta-llama/Llama-3.1-8B-Instruct
================================

Test Parameters:
- Poisson arrival rate: 0.125
- Tensor parallel size: 1
- Time window: 600.0s

Test Summary:
- Total requests: 79
- Total input tokens: 12432
- Total output tokens: 28864
- Avg tokens per request: 522.73

Latency Metrics:
- Average E2E latency: 5.68s
- P50 latency: 4.31s
- P90 latency: 10.56s
- P99 latency: 26.32s

Throughput Metrics:
- Average prefill throughput: 6330.92 tokens/s
- Average decode throughput: 205.23 tokens/s
- Max prefill throughput: 30803.62 tokens/s
- Max decode throughput: 394.63 tokens/s
- Aggregate prefill throughput: 6330.92 tokens/s
- Aggregate decode throughput: 205.23 tokens/s

Batch Metrics:
- Average batch size: 3.10
- Max batch size: 9.0
- Batch size P50: 3.00
- Batch size P90: 6.20

Throughput Analysis by Batch Size:
- Batch size (0.0, 1.0]: Prefill=4498.26 tokens/s, Decode=120.95 tokens/s, Requests=6
- Batch size (1.0, 2.0]: Prefill=7120.98 tokens/s, Decode=182.13 tokens/s, Requests=13
- Batch size (2.0, 4.0]: Prefill=6994.44 tokens/s, Decode=258.17 tokens/s, Requests=32
- Batch size (4.0, 8.0]: Prefill=4767.87 tokens/s, Decode=246.35 tokens/s, Requests=15
- Batch size (8.0, 16.0]: Prefill=5785.35 tokens/s, Decode=188.12 tokens/s, Requests=1

Token Distribution:
- Average input tokens: 157.37
- Average output tokens: 365.37
- Max input tokens: 869
- Max output tokens: 1411
