{
  "date": "20251007-170319",
  "backend": "vllm",
  "model_id": "meta-llama/Llama-3.1-8B-Instruct",
  "tokenizer_id": "meta-llama/Llama-3.1-8B-Instruct",
  "num_prompts": 9,
  "tensor_parallel_size": 4,
  "request_rate": 0.015625,
  "burstiness": 1.0,
  "max_concurrency": null,
  "duration": 685.612053864,
  "completed": 7,
  "total_input_tokens": 43417,
  "total_output_tokens": 109,
  "request_throughput": 0.010209855501444466,
  "request_goodput:": null,
  "output_throughput": 0.15898203566534955,
  "total_token_throughput": 63.48488150798169,
  "input_lens": [
    13911,
    3103,
    5864,
    16384,
    42946,
    681,
    31474,
    1691,
    1783
  ],
  "output_lens": [
    9,
    24,
    2,
    16,
    0,
    46,
    0,
    8,
    4
  ],
  "ttfts": [
    0.04198974999997063,
    0.05911202799995863,
    0.08905961100003879,
    0.23464073600007396,
    0.0,
    0.04144107100000838,
    0.0,
    0.04633015300009902,
    0.047657784000193715
  ],
  "itls": [
    0.0029727653749915817,
    0.0028896001739143608,
    0.0011844829999745343,
    0.0031019936666704475,
    0.0031019936666704475,
    0.002931417133332717,
    0.002931417133332717,
    0.0027431625714403446,
    0.0025708229999281684
  ],
  "generated_texts": [
    "\ufffd_\ufffd_\ufffd_\ufffd_",
    "\r\n\u00ad_\u00ad_\u00ad_\u00ad_\u00ad_\u00ad_\u00ad_\u00ad_\u00ad_\u00ad_\u00ad_\u00ad",
    "\ufffd.",
    "\ufffd.\ufffd.\ufffd.\ufffd\ufffd.\ufffd\ufffd.\ufffd\ufffd.\ufffd\ufffd.\ufffd\ufffd.",
    "",
    "\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0\ufffd\u00a0",
    "",
    "\ufffd_\ufffd_\ufffd_\ufffd_",
    "\ufffd_\ufffd_"
  ],
  "errors": [
    "",
    "",
    "",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 352, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 380, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n",
    "",
    ""
  ],
  "request_timestamps": [
    1759855914.0782769,
    1759855924.4520302,
    1759855940.5643744,
    1759855971.8899639,
    1759856159.2305505,
    1759856368.9122746,
    1759856375.6096125
  ],
  "mean_ttft_ms": 80.03301900004901,
  "median_ttft_ms": 47.657784000193715,
  "std_ttft_ms": 64.96524473909827,
  "p99_ttft_ms": 225.90586850007176,
  "mean_tpot_ms": 2.505262036955567,
  "median_tpot_ms": 2.889594086957953,
  "std_tpot_ms": 0.6898968274013088,
  "p99_tpot_ms": 3.0942171224995527,
  "mean_itl_ms": 2.9130185148505467,
  "median_itl_ms": 2.970856000047206,
  "std_itl_ms": 0.4098162823924255,
  "p99_itl_ms": 3.4146530000498387
}