{"date": "20251016-090401", "backend": "vllm", "model_id": "meta-llama/Llama-3.1-8B-Instruct", "tokenizer_id": "meta-llama/Llama-3.1-8B-Instruct", "num_prompts": 19, "tensor_parallel_size": 4, "request_rate": 0.0625, "burstiness": 1.0, "max_concurrency": null, "duration": 405.60913672300376, "completed": 18, "total_input_tokens": 116308, "total_output_tokens": 178, "request_throughput": 0.044377698553404274, "request_goodput:": null, "output_throughput": 0.43884613013922, "total_token_throughput": 287.18781076065835, "input_lens": [13911, 3103, 5864, 16384, 15588, 681, 5682, 1691, 22106, 3138, 2341, 9894, 4615, 2284, 3255, 2884, 10337, 11837, 2819], "output_lens": [2, 6, 7, 13, 9, 71, 1, 3, 0, 16, 4, 10, 4, 2, 1, 17, 2, 3, 7], "ttfts": [0.06720076000055997, 0.027307092997943982, 0.04118528499384411, 0.07865541800128995, 0.07934787400154164, 0.018459322993294336, 0.03809212300257059, 0.022677629996906035, 0.0, 0.02653708100115182, 0.02530123600445222, 0.05429646999982651, 0.03575912600354059, 0.024893109999538865, 0.023091907001798972, 0.0215892820051522, 0.05320431899599498, 0.06131967200053623, 0.02493792000313988], "itls": [[0.0044740209996234626], [0.005029692001699004, 0.00564886999927694, 0.005758204002631828, 0.005651795996527653, 0.005771507996541914], [0.004557830005069263, 0.00565037799970014, 0.005720396999095101, 0.005727089999709278, 0.005724055001337547, 0.006139074997918215], [0.003995983999629971, 0.0058214200034854, 0.005973942999844439, 0.006157805000839289, 0.005730951997975353, 0.0059177290022489615, 0.006075751996831968, 0.006030459000612609, 0.0059543370007304475, 0.005913731001783162, 0.00594219499907922, 0.006373675001668744], [0.004134953000175301, 0.005762874003266916, 0.006030480995832477, 0.006147257001430262, 0.005801937004434876, 0.00596195300022373, 0.006030149997968692, 0.006230462000530679], [0.005286829997203313, 0.005472415003168862, 0.005595572998572607, 0.005493142998602707, 0.005672334998962469, 0.00549167999997735, 0.0055989200045587495, 0.005506516994500998, 0.00569432700285688, 0.005416820997197647, 0.005659482005285099, 0.0055422739969799295, 0.005577108000579756, 0.00555934599833563, 0.005557962998864241, 0.005569746004766785, 0.005517386998690199, 0.0056231350026791915, 0.005480158994032536, 0.005733087004045956, 0.00551517400162993, 0.005412513994087931, 0.005570546003582422, 0.008459067001240328, 0.002617537000332959, 0.005593648995272815, 0.005533538002055138, 0.005545309999433812, 0.005628042999887839, 0.005444984002679121, 0.005443260000902228, 0.005570255998463836, 0.005625990001135506, 0.005533026000193786, 0.005571749999944586, 0.005547382999793626, 0.005537835997529328, 0.005580595003266353, 0.005450713993923273, 0.005495047000295017, 0.005538076002267189, 0.005588038999121636, 0.005483395005285274, 0.0055875779944472015, 0.005561530000704806, 0.005605500999081414, 0.005433502999949269, 0.005628222999803256, 0.0054063620045781136, 0.005560808996960986, 0.0055312129989033565, 0.005483596003614366, 0.0055109749955590814, 0.005496921003214084, 0.005441455999971367, 0.005575896997470409, 0.004845591000048444, 0.004947300003550481, 0.004816146996745374, 0.0050070409997715615, 0.004845652001677081, 0.005001028999686241, 0.004794877997483127, 0.004802611001650803, 0.005025436003052164, 0.004780950999702327, 0.0048509810003452, 0.005043047996878158, 0.004813441999431234, 0.0051011360046686605], [], [0.005005067003367003, 0.005864191996806767], [], [0.005153202000656165, 0.005546360996959265, 0.00582046100316802, 0.005459289001009893, 0.005672346000210382, 0.005777329999546055, 0.005621189993689768, 0.0056840270044631325, 0.005584562000876758, 0.005807386995002162, 0.005621219999738969, 0.005672085004334804, 0.005704914998204913, 0.005519452002772596, 0.006072397998650558], [0.00506615199992666, 0.0056243170038214885, 0.005822644998261239], [0.004692167000030167, 0.005542013997910544, 0.005707470001652837, 0.005742053996073082, 0.005769715004134923, 0.005787579000752885, 0.005706817995815072, 0.005905858000915032, 0.005867526997462846], [0.004881389002548531, 0.005514691998541821, 0.006061566004063934], [0.004983104001439642], [], [0.005379973001254257, 0.005537826000363566, 0.0057077509991358966, 0.005592227003944572, 0.0056112410020432435, 0.005797287994937506, 0.005503781998413615, 0.005769846000475809, 0.0057230390011682175, 0.005564256003708579, 0.005696889995306265, 0.00569825300044613, 0.005637419999402482, 0.005663790005201008, 0.0057762680007726885, 0.005712128993764054], [0.004914030003419612], [0.004381393999210559, 0.006076647994632367], [0.005152284000359941, 0.006022827998094726, 0.005133106998982839, 0.005661007002345286, 0.005672468003467657, 0.005920547999267001]], "generated_texts": ["\ufffd.", "\ufffd_\ufffd_\ufffd_", "", "\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_", "", "\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_", "\t", "\ufffd_", "", "\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_", "", "\ufffd_\ufffd_\ufffd_\ufffd_\ufffd_", "\r\n<|reserved", "<|", "\r\n", "\r\n\t\t\ufffd<|reserved_special_token_104|>I apologize, but", "\ufffd_", "\ufffd.", "\r\n\t\ufffd_\ufffd_"], "errors": ["", "", "", "", "", "", "", "", "Traceback (most recent call last):\n  File \"/home/azureuser/powertrace-sim/client/backend_request_func.py\", line 296, in async_request_openai_completions\n    async for chunk_bytes in response.content:\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 52, in __anext__\n    rv = await self.read_func()\n         ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 360, in readline\n    return await self.readuntil()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/azureuser/miniconda3/envs/inference/lib/python3.12/site-packages/aiohttp/streams.py\", line 388, in readuntil\n    raise ValueError(\"Chunk too big\")\nValueError: Chunk too big\n", "", "", "", "", "", "", "", "", "", ""], "request_timestamps": [1760605036.1078613, 1760605045.412933, 1760605107.692172, 1760605114.852088, 1760605125.3558226, 1760605143.99069, 1760605177.9980571, 1760605218.0534282, 1760605235.3076324, 1760605267.3661096, 1760605278.77847, 1760605318.5745258, 1760605359.2273674, 1760605360.6183598, 1760605365.829051, 1760605366.001666, 1760605395.5654833, 1760605412.2202199], "mean_ttft_ms": 40.214201611282384, "median_ttft_ms": 31.533109500742285, "std_ttft_ms": 19.776887381459684, "p99_ttft_ms": 79.23015648149885, "mean_tpot_ms": 5.419130584113596, "median_tpot_ms": 5.538146499505577, "std_tpot_ms": 0.3448880676021373, "p99_tpot_ms": 5.814756397997674, "mean_itl_ms": 5.526503706323638, "median_itl_ms": 5.58606999766198, "std_itl_ms": 0.5086108835863472, "p99_itl_ms": 6.2891793309972845}